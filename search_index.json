[["index.html", "金融時系列解析 1 はじめに 1.1 時系列モデリング 1.2 金融時系列データの特徴 1.3 シミュレーションによるサンプルパス生成 1.4 Rにおける時系列オブジェクト・クラスおよび関数の例 1.5 時系列データの分解", " 金融時系列解析 林 高樹 2025-02-02 (内容は随時更新します) 1 はじめに 1.1 時系列モデリング ターゲットの時系列データの特徴を表現できるような確率・統計モデルの構築 金融証券市場で観察される”stylized facts”等の中から, 重要な特徴にフォーカスする 実際の時系列データと構築モデルの持つ特徴が類似するように 時系列プロット, 散布図, ヒストグラム, 要約統計量等に関して 理論計算やシミュレーション(パスの生成) 金融時系列データに現れる特徴は, データ期間 (例, コロナ禍以前・以後) の他, データの観測頻度 (例, 月次, 週次, 日次, 5分次) にも依存 時系列データにおいて, 時間を通じて安定的に観察される”規則性”や構造 (“時系列構造”) をモデルによって表現する. その規則性が将来予測の源泉となる 規則性には, トレンドや周期性などの時系列データから目視できる特徴の他, “定常性”と呼ばれる時系列データの背後にある確率過程モデルの従う確率分布やモーメントに関する特徴などがある 構築される時系列モデルに望まれる性質 (要件) 記述性 (ターゲットの時系列データとの特徴の類似性の表現) 解析容易性, 解釈可能性 操作性・取扱容易性 推定容易性, 計算効率性 モデル安定性・頑強性 予測精度の高さなど 候補となるモデルは無数 汎用的で, 良い性質を持つモデルクラスに関する研究 時系列解析分野で中核を成すクラス → 線形+定常時系列過程 モデル選択・推定, モデルの利用 ターゲット時系列の特徴を踏まえ. 適切なモデルクラスを選択する データに対してモデルを適合し, パラメータを推定する 推定モデルの妥当性をチェック (モデル診断) 予測や制御等に利用 本授業で扱う対象・アプローチ 目的変数 (観測変数) 自体が時系列構造を持ち, 時系列モデルで記述されるケースに主要な関心 出発点(基本的設定): 1変量の線形・定常時系列過程 → 金融時系列データは, 線形・定常時系列過程から乖離する特徴も有する → 非線形 and/or 非定常な時系列過程へ 観測変数が多次元で時系列構造を持つケース (多変量時系列) 観測変数に影響を与える外部変数 (“共変量”) のあるケース 金融時系列解析におけるチャレンジ 時系列データは, 確率過程の観点からは, 一本の”サンプルパス”の実現と見なせる マクロ・ミクロの状態が 時間と共に変化する金融・経済時系列データは, 再現性の乏しいデータであると考えられる さらに, 金融市場は過去に実現したデータに基づいて市場参加者が行動を変化させる ある種の規則性・ 法則性を過去のデータから見出し, それをモデルにより表現することで, 将来を予測し, 金融市場において”最適な”行動を取りたい 1.2 金融時系列データの特徴 金融時系列データの特徴: みずほ (8411) 株価データの例 quantmod()による株価データの取得 library(&#39;quantmod&#39;) YJ8411.T &lt;- getSymbols(&#39;8411.T&#39;,from = &#39;2020-09-01&#39;, to = &#39;2024-08-30&#39;, src = &quot;yahoo&quot;, auto.assign = FALSE) # 日次株価の時系列プロット chartSeries(YJ8411.T) Figure 1.1: … # 日次4本値 chartSeries(OHLC(YJ8411.T)) Figure 1.2: … 日次収益率の時系列プロット # 日次収益率の時系列プロット ret_YJ8411 &lt;- ClCl(YJ8411.T) chartSeries(ret_YJ8411) 日次収益率のヒストグラム # 日次収益率のヒストグラム hist(ret_YJ8411) 日次収益率の要約統計量 library(psych) describe(ret_YJ8411) #&gt; vars n mean sd median trimmed mad min max range skew kurtosis se #&gt; X1 1 979 0 0.02 0 0 0.01 -0.2 0.09 0.28 -1.87 22.68 0 # 要約統計量を計算 # デフォルト出力 # mean # standard deviation # trimmed mean (with trim defaulting to .1) # median (standard or interpolated # mad: median absolute deviation (from the median). # minimum # maximum # skew # kurtosis # standard error # 注) kurtosisは-3した値 日次収益率の自己相関 # 日次収益率の自己相関 acf(ret_YJ8411, na.action = na.pass) 日次収益率絶対値の自己相関 # 日次収益率絶対値の自己相関 acf(abs(ret_YJ8411), na.action = na.pass) 1.3 シミュレーションによるサンプルパス生成 時系列モデリングでは, 観測時系列データの特徴と比較し, 適切なモデルを見い出すため, シミュレーションを積極的に利用する 正規AR(1)モデルの例: \\(X(t)=\\phi X(t-1) + W(t)\\), \\(W(t) \\sim_{i,i.d.} N(0,\\sigma^2)\\) x_ts &lt;- NULL; tlen &lt;- 50 phi &lt;- -0.8; s &lt;- 2 for (seed_tmp in 1:5){ set.seed(seed_tmp) x &lt;- w &lt;- rnorm(tlen) * s for (t in 2:tlen) x[t] &lt;- phi * x[t - 1] + w[t] # x_ts &lt;- ts.intersect(x_ts, ts(cumsum(x))) } ts.plot(x_ts, type = &quot;l&quot;, col = 1:5, lty = 1:5, ylab = &quot;&quot;, main = &quot;Simulated sample paths&quot;) 1.4 Rにおける時系列オブジェクト・クラスおよび関数の例 1.4.1 日付・時間データに対するクラス 1.4.1.1 Dateクラス 日付を表現する R内部的には, “Date”というclass属性を持つdouble型の値を持つ # as.Date(): 日付を表す文字列をDate型に変更する tomorrow &lt;- as.Date(&quot;2023-10-04&quot;) tomorrow #&gt; [1] &quot;2023-10-04&quot; attributes(tomorrow) # 出力オブジェクトの属性(attribute) #&gt; $class #&gt; [1] &quot;Date&quot; # typeof(tomorrow) # 出力オブジェクトの型(type) # typeof(&quot;2023-10-23&quot;) # 入力オブジェクトの型(type) today &lt;- Sys.Date() today #&gt; [1] &quot;2025-02-02&quot; 1.4.1.2 POSIXctクラス 日時 (日-時間) を表現する Rの内部的には, “POSIXct”というclass属性を持つdouble型の値を持つ POSIX = Portable Operating System Interfaceの略 POSIXct, POSXltの2種類: ct = calender time, lt = local time now_ct &lt;- as.POSIXct(&quot;2023-10-05 19:00&quot;, tz = &quot;UTC&quot;) now_ct #&gt; [1] &quot;2023-10-05 19:00:00 UTC&quot; attributes(now_ct) #&gt; $class #&gt; [1] &quot;POSIXct&quot; &quot;POSIXt&quot; #&gt; #&gt; $tzone #&gt; [1] &quot;UTC&quot; tomorrow_ct &lt;- as.POSIXct(&quot;2023-10-06 20:00&quot;, tz = &quot;UTC&quot;) tomorrow_ct - now_ct # 時間差(1日当たり) #&gt; Time difference of 1.041667 days attributes(tomorrow_ct - now_ct) #&gt; $class #&gt; [1] &quot;difftime&quot; #&gt; #&gt; $units #&gt; [1] &quot;days&quot; 1.4.1.3 difftimeクラス 時間差を表現する Rの内部的には, “POSIXct”というclass属性を持つdouble型の値を持つ onewk_1 &lt;- as.difftime(1, units = &quot;weeks&quot;) onewk_1 #&gt; Time difference of 1 weeks typeof(onewk_1) #&gt; [1] &quot;double&quot; attributes(onewk_1) #&gt; $class #&gt; [1] &quot;difftime&quot; #&gt; #&gt; $units #&gt; [1] &quot;weeks&quot; onewk_2 &lt;- as.difftime(7, units = &quot;days&quot;) onewk_2 #&gt; Time difference of 7 days 1.4.1.4 よりモダンかつ柔軟な日付や時間の操作 lubridateパッケージ hmsパッケージ (日内時間の操作・蓄積に特化) 1.4.2 時系列データに対するクラス(1): tsクラス tsクラス: Rの時系列オブジェクトの基本クラス # AirPassengers, # Pan Am, # international passenger bokking (in 1000s) per month # 1949--1960 (Brown, 1963) data(AirPassengers) ap &lt;- AirPassengers ap #&gt; Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #&gt; 1949 112 118 132 129 121 135 148 148 136 119 104 118 #&gt; 1950 115 126 141 135 125 149 170 170 158 133 114 140 #&gt; 1951 145 150 178 163 172 178 199 199 184 162 146 166 #&gt; 1952 171 180 193 181 183 218 230 242 209 191 172 194 #&gt; 1953 196 196 236 235 229 243 264 272 237 211 180 201 #&gt; 1954 204 188 235 227 234 264 302 293 259 229 203 229 #&gt; 1955 242 233 267 269 270 315 364 347 312 274 237 278 #&gt; 1956 284 277 317 313 318 374 413 405 355 306 271 306 #&gt; 1957 315 301 356 348 355 422 465 467 404 347 305 336 #&gt; 1958 340 318 362 348 363 435 491 505 404 359 310 337 #&gt; 1959 360 342 406 396 420 472 548 559 463 407 362 405 #&gt; 1960 417 391 419 461 472 535 622 606 508 461 390 432 #is.ts(ap); is.vector(ap) #attributes(ap) class(ap) # tsクラス #&gt; [1] &quot;ts&quot; start(ap); end(ap); frequency(ap) #&gt; [1] 1949 1 #&gt; [1] 1960 12 #&gt; [1] 12 plot(ap, ylab = &quot;Passengers (1000&#39;s)&quot;) layout(1:2) plot(aggregate(ap)) # annual levelに累計, seasonal effectsの除去、trend cycle(ap) # データ内各アイテムのシーズン抽出 #&gt; Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #&gt; 1949 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1950 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1951 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1952 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1953 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1954 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1955 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1956 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1957 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1958 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1959 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1960 1 2 3 4 5 6 7 8 9 10 11 12 boxplot(ap ~ cycle(ap)) # seasonal effects 1.4.3 時系列データに対するクラス(2): zooクラスとxtsクラス 有用な時系列オブジェクトのクラス: zoo, xts zoo, xts共に, 多変量時系列を扱うことも可能 xtsは, zooに類似. かつ, 高速なため, 大規模DATAの処理に適している zooやxtsのメリット. 有用な関数が多数用意されている: differencing, merging, periodic sampling, applying rolling functions xtsパッケージは, zooパッケージが出来ること全てできる - zooクラス・オブジェクトの生成 - ts &lt;- zoo(x, dt) - 時間(index)は, Dateオブジェクト, POSIXctオブジェクト, 整数, 浮動小数点でも, 順序付き数値なら何でもOK - xtsクラス・オブジェクトの生成 - ts &lt;- xts(x, dt) - 時間(index)は, Dateオブジェクト, POSIXctオブジェクト等、日付や時間のクラスのみに対応 # R マニュアル vignette(&quot;zoo&quot;) vignette(&quot;xts&quot;) zooクラス library(zoo) # 日経平均先物(ラージ), 2018年2月5日, 1日内約定データ prices &lt;- c(22790, 22800, 22790, 22790, 22790) seconds &lt;- c(32400.014, 32400.020, 32400.035, 32400.036) # タイムスタンプ (秒) nkft_sec &lt;- zoo(prices, seconds) print(nkft_sec) #&gt; 32400.014 32400.02 32400.035 32400.036 #&gt; 22790 22800 22790 22790 # 同, 2023年9月25日〜9月29日(5営業日) prices &lt;- c(32480, 32080, 32150, 31850, 32020) dates &lt;- as.Date(c(&quot;2023-09-25&quot;, &quot;2023-09-26&quot;, &quot;2023-09-27&quot;, &quot;2023-09-28&quot;, &quot;2023-09-29&quot;)) # 日付 nkft_daily &lt;- zoo(prices, dates) print(nkft_daily) #&gt; 2023-09-25 2023-09-26 2023-09-27 2023-09-28 2023-09-29 #&gt; 32480 32080 32150 31850 32020 coredata(nkft_daily) # 株価の取り出し #&gt; [1] 32480 32080 32150 31850 32020 index(nkft_daily) # 時間の取り出し #&gt; [1] &quot;2023-09-25&quot; &quot;2023-09-26&quot; &quot;2023-09-27&quot; &quot;2023-09-28&quot; &quot;2023-09-29&quot; coredata(nkft_sec) #&gt; [1] 22790 22800 22790 22790 index(nkft_sec) #&gt; [1] 32400.01 32400.02 32400.03 32400.04 nkft_daily[2:4] #&gt; 2023-09-26 2023-09-27 2023-09-28 #&gt; 32080 32150 31850 nkft_daily[as.Date(&quot;2023-09-26&quot;)] #&gt; 2023-09-26 #&gt; 32080 nkft_daily[&quot;2023-09-26&quot;] # &lt;-- NO #&gt; 2023-09-26 #&gt; 32080 window(nkft_daily, start = as.Date(&#39;2023-09-26&#39;), end = as.Date(&#39;2023-09-28&#39;)) #&gt; 2023-09-26 2023-09-27 2023-09-28 #&gt; 32080 32150 31850 library(xts) first(nkft_sec) # 最初のデータ #&gt; 32400.014 #&gt; 22790 last(nkft_sec) # 最後のデータ #&gt; 32400.036 #&gt; 22790 1.4.3.1 quantmodパッケージの利用による株価取得 &amp; チャート作成 library(&#39;quantmod&#39;) yj8411 &lt;- getSymbols(&#39;8411.T&#39;,from = &#39;2020-10-01&#39;, to = &#39;2023-09-29&#39;, src = &quot;yahoo&quot;, auto.assign = FALSE) # 注) R/RStudioや, guantmodのバージョンによっては, 動かないことがある # 注) 画面に&quot;Error in new.session() : Could not establish session after 5 attempts.&quot;が表示され, # 株価を取得できない場合には, quantmodのバージョンを最新のものにすること. chartSeries(ClCl(yj8411)) chartSeries(yj8411) chartSeries(OHLC(yj8411)) Mizuho_ret &lt;- diff(log(Ad(yj8411))) # Adjusted price plot(Mizuho_ret) chartSeries(Mizuho_ret) class(Mizuho_ret) #&gt; [1] &quot;xts&quot; &quot;zoo&quot; # 便利な関数の例 Mizuho_m &lt;- apply.monthly(Mizuho_ret, mean, na.rm = T) # xts Mizuho_w &lt;- apply.weekly(Mizuho_ret, mean, na.rm = T) # xts # zooオブジェクトの場合, 一旦xtsに変換して適用 # apply.monthly(as.xts(ts), df) Mizuho_ma5 &lt;- rollapply(Mizuho_ret, width = 5, mean, align = &quot;right&quot;) # zooパッケージ内 head(Mizuho_ma5) #&gt; 8411.T.Adjusted #&gt; 2020-10-02 NA #&gt; 2020-10-05 NA #&gt; 2020-10-06 NA #&gt; 2020-10-07 NA #&gt; 2020-10-08 NA #&gt; 2020-10-09 0.002418754 #Mizuho_ma21 &lt;- rollapply(Mizuho_ret, width = 21, mean, align = &quot;right&quot;) # zooパッケージ内 # timestamp is taken from the rightmost value chartSeries(Mizuho_ma5) #chartSeries(Mizuho_ma21) 1.5 時系列データの分解 - データセット: AirPassengers - Pan Am, # international passenger bokking (in 1000s) per month - 1949--1960 (Brown, 1963) data(AirPassengers) ap &lt;- AirPassengers ap #&gt; Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #&gt; 1949 112 118 132 129 121 135 148 148 136 119 104 118 #&gt; 1950 115 126 141 135 125 149 170 170 158 133 114 140 #&gt; 1951 145 150 178 163 172 178 199 199 184 162 146 166 #&gt; 1952 171 180 193 181 183 218 230 242 209 191 172 194 #&gt; 1953 196 196 236 235 229 243 264 272 237 211 180 201 #&gt; 1954 204 188 235 227 234 264 302 293 259 229 203 229 #&gt; 1955 242 233 267 269 270 315 364 347 312 274 237 278 #&gt; 1956 284 277 317 313 318 374 413 405 355 306 271 306 #&gt; 1957 315 301 356 348 355 422 465 467 404 347 305 336 #&gt; 1958 340 318 362 348 363 435 491 505 404 359 310 337 #&gt; 1959 360 342 406 396 420 472 548 559 463 407 362 405 #&gt; 1960 417 391 419 461 472 535 622 606 508 461 390 432 # is.ts(ap); is.vector(ap) # attributes(ap) class(ap) # tsクラス #&gt; [1] &quot;ts&quot; start(ap); end(ap); frequency(ap) #&gt; [1] 1949 1 #&gt; [1] 1960 12 #&gt; [1] 12 plot(ap, ylab = &quot;Passengers (1000&#39;s)&quot;) layout(1:2) plot(aggregate(ap)) # annual levelに累計, seasonal effectsの除去、trend cycle(ap) # データ内各アイテムのシーズン抽出 #&gt; Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #&gt; 1949 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1950 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1951 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1952 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1953 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1954 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1955 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1956 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1957 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1958 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1959 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1960 1 2 3 4 5 6 7 8 9 10 11 12 boxplot(ap ~ cycle(ap)) # seasonal effects 1.5.1 トレンド抽出, 平滑化 (smoothing) 対称移動平均 (centered moving average) # filter()関数の使用 f12 &lt;- c(1 / 24, rep(1 / 12, 11), 1 / 24) f12 #&gt; [1] 0.04166667 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 #&gt; [7] 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 #&gt; [13] 0.04166667 ap_m &lt;- stats::filter(as.vector(ap), f12, sides = 2) # vectorとして入力 --&gt; 年情報が欠落 plot(cbind(as.vector(ap), ap_m)) # --&gt; 年情報が欠落 # ap_m2 &lt;- filter(ap, f12, sides = 2) # tsとして入力 # plot(cbind(ap, ap_m2)) # または ap_m &lt;- ts(ap_m, start = c(1949, 1), frequency = 12) # &lt;-- 年情報を戻す # plot(cbind(ap, ap_m)) # grid() # lines(1:length(ap_m), ap_m, col=&quot;blue&quot;) # トレンド除去済データ ap_s &lt;- ap - ap_m # 上のts()を使った式によるap_mの生成が必要 plot(ap_s) 1.5.2 分解モデル 時系列データ (確率過程のサンプルパス) を時系列プロットすることで, トレンドや周期性などの明確な規則性・パターンを観察できることがある. 原系列をこのような特徴を持つ成分に分解することで, 現象に対する解釈や理解を得たり, さらには, 成分ごとに 予測することで, 全体としてより精度の高い 原系列の予測を行える可能性がある. “古典的”方法 - decompose, &quot;古典的&quot;分解モデル (Rのデフォルト) - The function first determines the trend component using a moving average (if filter is NULL, a symmetric window with equal weights is used), and removes it from the time series. Then, the seasonal figure is computed by averaging, for each time unit, over all periods. The seasonal figure is then centered. Finally, the error component is determined by removing trend and seasonal figure (recycled as needed) from the original time series. 加法モデル (デフォルト) decompose(ap) #&gt; $x #&gt; Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #&gt; 1949 112 118 132 129 121 135 148 148 136 119 104 118 #&gt; 1950 115 126 141 135 125 149 170 170 158 133 114 140 #&gt; 1951 145 150 178 163 172 178 199 199 184 162 146 166 #&gt; 1952 171 180 193 181 183 218 230 242 209 191 172 194 #&gt; 1953 196 196 236 235 229 243 264 272 237 211 180 201 #&gt; 1954 204 188 235 227 234 264 302 293 259 229 203 229 #&gt; 1955 242 233 267 269 270 315 364 347 312 274 237 278 #&gt; 1956 284 277 317 313 318 374 413 405 355 306 271 306 #&gt; 1957 315 301 356 348 355 422 465 467 404 347 305 336 #&gt; 1958 340 318 362 348 363 435 491 505 404 359 310 337 #&gt; 1959 360 342 406 396 420 472 548 559 463 407 362 405 #&gt; 1960 417 391 419 461 472 535 622 606 508 461 390 432 #&gt; #&gt; $seasonal #&gt; Jan Feb Mar Apr May Jun #&gt; 1949 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1950 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1951 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1952 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1953 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1954 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1955 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1956 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1957 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1958 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1959 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1960 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; Jul Aug Sep Oct Nov Dec #&gt; 1949 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1950 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1951 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1952 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1953 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1954 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1955 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1956 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1957 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1958 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1959 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1960 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; #&gt; $trend #&gt; Jan Feb Mar Apr May Jun Jul Aug #&gt; 1949 NA NA NA NA NA NA 126.7917 127.2500 #&gt; 1950 131.2500 133.0833 134.9167 136.4167 137.4167 138.7500 140.9167 143.1667 #&gt; 1951 157.1250 159.5417 161.8333 164.1250 166.6667 169.0833 171.2500 173.5833 #&gt; 1952 183.1250 186.2083 189.0417 191.2917 193.5833 195.8333 198.0417 199.7500 #&gt; 1953 215.8333 218.5000 220.9167 222.9167 224.0833 224.7083 225.3333 225.3333 #&gt; 1954 228.0000 230.4583 232.2500 233.9167 235.6250 237.7500 240.5000 243.9583 #&gt; 1955 261.8333 266.6667 271.1250 275.2083 278.5000 281.9583 285.7500 289.3333 #&gt; 1956 309.9583 314.4167 318.6250 321.7500 324.5000 327.0833 329.5417 331.8333 #&gt; 1957 348.2500 353.0000 357.6250 361.3750 364.5000 367.1667 369.4583 371.2083 #&gt; 1958 375.2500 377.9167 379.5000 380.0000 380.7083 380.9583 381.8333 383.6667 #&gt; 1959 402.5417 407.1667 411.8750 416.3333 420.5000 425.5000 430.7083 435.1250 #&gt; 1960 456.3333 461.3750 465.2083 469.3333 472.7500 475.0417 NA NA #&gt; Sep Oct Nov Dec #&gt; 1949 127.9583 128.5833 129.0000 129.7500 #&gt; 1950 145.7083 148.4167 151.5417 154.7083 #&gt; 1951 175.4583 176.8333 178.0417 180.1667 #&gt; 1952 202.2083 206.2500 210.4167 213.3750 #&gt; 1953 224.9583 224.5833 224.4583 225.5417 #&gt; 1954 247.1667 250.2500 253.5000 257.1250 #&gt; 1955 293.2500 297.1667 301.0000 305.4583 #&gt; 1956 334.4583 337.5417 340.5417 344.0833 #&gt; 1957 372.1667 372.4167 372.7500 373.6250 #&gt; 1958 386.5000 390.3333 394.7083 398.6250 #&gt; 1959 437.7083 440.9583 445.8333 450.6250 #&gt; 1960 NA NA NA NA #&gt; #&gt; $random #&gt; Jan Feb Mar Apr May Jun #&gt; 1949 NA NA NA NA NA NA #&gt; 1950 8.4987374 29.1047980 8.3244949 6.6199495 -7.9103535 -25.1527778 #&gt; 1951 12.6237374 26.6464646 18.4078283 6.9116162 9.8396465 -26.4861111 #&gt; 1952 12.6237374 29.9797980 6.1994949 -2.2550505 -6.0770202 -13.2361111 #&gt; 1953 4.9154040 13.6881313 17.3244949 20.1199495 9.4229798 -17.1111111 #&gt; 1954 0.7487374 -6.2702020 4.9911616 1.1199495 2.8813131 -9.1527778 #&gt; 1955 4.9154040 2.5214646 -1.8838384 1.8282828 -3.9936869 -2.3611111 #&gt; 1956 -1.2095960 -1.2285354 0.6161616 -0.7133838 -1.9936869 11.5138889 #&gt; 1957 -8.5012626 -15.8118687 0.6161616 -5.3383838 -4.9936869 19.4305556 #&gt; 1958 -10.5012626 -23.7285354 -15.2588384 -23.9633838 -13.2020202 18.6388889 #&gt; 1959 -17.7929293 -28.9785354 -3.6338384 -12.2967172 4.0063131 11.0972222 #&gt; 1960 -14.5845960 -34.1868687 -43.9671717 -0.2967172 3.7563131 24.5555556 #&gt; Jul Aug Sep Oct Nov Dec #&gt; 1949 -42.6224747 -42.0732323 -8.4785354 11.0593434 28.5934343 16.8699495 #&gt; 1950 -34.7474747 -35.9898990 -4.2285354 5.2260101 16.0517677 13.9116162 #&gt; 1951 -36.0808081 -37.4065657 -7.9785354 5.8093434 21.5517677 14.4532828 #&gt; 1952 -31.8724747 -20.5732323 -9.7285354 5.3926768 15.1767677 9.2449495 #&gt; 1953 -25.1641414 -16.1565657 -4.4785354 7.0593434 9.1351010 4.0782828 #&gt; 1954 -2.3308081 -13.7815657 -4.6868687 -0.6073232 3.0934343 0.4949495 #&gt; 1955 14.4191919 -5.1565657 2.2297980 -2.5239899 -10.4065657 1.1616162 #&gt; 1956 19.6275253 10.3434343 4.0214646 -10.8989899 -15.9482323 -9.4633838 #&gt; 1957 31.7108586 32.9684343 15.3131313 -4.7739899 -14.1565657 -9.0050505 #&gt; 1958 45.3358586 58.5101010 0.9797980 -10.6906566 -31.1148990 -33.0050505 #&gt; 1959 53.4608586 61.0517677 8.7714646 -13.3156566 -30.2398990 -17.0050505 #&gt; 1960 NA NA NA NA NA NA #&gt; #&gt; $figure #&gt; [1] -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; [7] 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; #&gt; $type #&gt; [1] &quot;additive&quot; #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;decomposed.ts&quot; ap_decom &lt;- decompose(ap) # additive (デフォルト) plot(ap_decom) 原系列が正のトレンドを持ち, 水準が時間と共に切り上がるにつれて分散も増大. → 積分解がベター 乗法モデル オプション type = “multiplicative” (or “mult”) を指定 ap_decom_m &lt;- decompose(ap, type = &quot;mult&quot;) plot(ap_decom_m) trend &lt;- ap_decom_m$trend seasonal &lt;- ap_decom_m$seasonal ts.plot(cbind(trend, trend * seasonal), lty = 1:2) # トレンド成分 vs トレンド×季節性成分 または, 時系列を対数変換 lnap &lt;- log(ap) lnap_decom &lt;- decompose(lnap) plot(lnap_decom) trend &lt;- lnap_decom$trend seasonal &lt;- lnap_decom$seasonal ts.plot(cbind(trend, trend + seasonal), lty = 1:2) → 残差項の分散は, 加法モデルと比べて時間的に安定 参考文献: CM (2009), Ch.1 (自主課題) decompose()と同じように3成分に分解する自作関数を作成せよ 1.5.2.1 代替的方法 観察された1本の時系列データ\\({Y_t}\\)を, \\[ Y_t = m_t + s_t + \\epsilon_t \\] のように, トレンド\\(m_t\\), 季節性\\(s_t\\), 誤差項\\(\\epsilon_t\\) に分解する方法は無数に存在する. ここでは, R関数として利用可能なものを幾つか紹介する. - stl(), Seasonal Decomposition of Time Series by Loess - loess(locally weighted regression)によるsmoothingを行い, 3成分に分解 # plot(stl(ap, s.window = 13)) # plot(stl(ap, s.window = 5)) plot(stl(ap, s.window = &quot;per&quot;)) - timsac: 統数研開発パッケージ - H.Akaike, T.Ozaki, M.Ishiguro, Y.Ogata, G.Kitagawa, Y-H.Tamura, E.Arahata, K.Katsura and Y.Tamura (1984) Computer Science Monographs, Timsac-84 Part 1. The Institute of Statistical Mathematics. library(timsac) # decomp() # Decompose a nonstationary time series into several possible components by square-root filter. # トレンド成分、AR成分、季節変動成分、曜日効果、白色雑音 # データセット: Blsallfood data(Blsallfood) # アメリカの食品産業に従事する労働者の人数を毎月調べた時系列 (合衆国 Bureau of Labor Statistics (BLS) 公表) # z &lt;- decomp(Blsallfood, trade = TRUE, year = 1973) # year: the first year of the data z &lt;- decomp(Blsallfood, year = 1973) z$aic; z$lkhd #&gt; [1] 1505.477 #&gt; [1] -743.7385 z$sigma2; z$tau1; z$tau2; z$tau3 #&gt; [1] 209.0874 #&gt; [1] 0.0004305741 #&gt; [1] 1.0001 #&gt; NULL z &lt;- decomp(Blsallfood, trade = TRUE, year = 1973) # decomp(as.vector(ap), year = 1949) # OK? z &lt;- decomp(ap, year = 1949) - baysea() - Decompose a nonstationary time series into several possible components z &lt;- baysea(ap, forecast = 12) 代替的方法: Prophet パッケージprophet内, 関数prophet() https://facebook.github.io/prophet/docs/quick_start.html#r-api https://cran.r-project.org/web/packages/prophet/prophet.pdf “非線形のトレンドに年次・週次・日次の季節性, さらに 休日効果を加えた加法モデルに基づいて時系列データを予測する手続を実装. 強い季節性があり, 数シーズンの過去データを持つ時系列データに対して良く機能. 欠損値やトレンドのシフトに対して頑強. 通常, 外れ値をうまく処理.” prophet()の主な引数 - growth: &quot;linear&quot;(デフォルト), &quot;logisitc&quot;, &quot;flat&quot; - changepoints (変化点): 日付ベクトルをユーザー指定 or 潜在的な変化点の自動選択(デフォルト) - n.changepoints (変化点の数): 25 (デフォルト) - yearly.seasonality (年次季節性への適合): &quot;auto&quot;(デフォルト), T, F, 生成するFourier項の数 - weekly.seasonality (週次季節性への適合): 同上 - daily.seasonality (週次季節性への適合): 同上 - holidays (休日の指定): なし(デフォルト - seasonality.mode (季節性の入り方): &quot;additive&quot;(加法的)(デフォルト), &quot;multiplictive&quot;(乗法的) # install.packages(&quot;prophet&quot;) library(prophet) library(zoo) # index, yearmon # 以下, 生データのまま使用 (対数変換せず) # 年月の取り出し tt &lt;- as.Date(yearmon(index(ap))) prophetモデルの適合 # prophetモデルの生成 ap_df &lt;- data.frame(ds = tt, y = ap) ap_ppht &lt;- prophet(ap_df) # 予測年月の生成 dates_ft &lt;- make_future_dataframe(ap_ppht, periods = 12, freq = &quot;month&quot;) tail(dates_ft) #&gt; ds #&gt; 151 1961-07-01 #&gt; 152 1961-08-01 #&gt; 153 1961-09-01 #&gt; 154 1961-10-01 #&gt; 155 1961-11-01 #&gt; 156 1961-12-01 適合モデルによる予測 # 予測値の生成 ap_forecast &lt;- predict(ap_ppht, dates_ft) tail(ap_forecast[c(&#39;ds&#39;, &#39;yhat&#39;, &#39;yhat_lower&#39;, &#39;yhat_upper&#39;)]) #&gt; ds yhat yhat_lower yhat_upper #&gt; 151 1961-07-01 576.3980 548.7551 603.1591 #&gt; 152 1961-08-01 576.8090 546.9246 604.4478 #&gt; 153 1961-09-01 528.3037 499.2396 556.2268 #&gt; 154 1961-10-01 493.0463 464.0012 522.4671 #&gt; 155 1961-11-01 459.2066 431.0374 487.5216 #&gt; 156 1961-12-01 488.5528 460.4595 518.0849 str(ap_forecast) #&gt; &#39;data.frame&#39;: 156 obs. of 16 variables: #&gt; $ ds : POSIXct, format: &quot;1949-01-01&quot; &quot;1949-02-01&quot; ... #&gt; $ trend : num 106 108 110 113 115 ... #&gt; $ additive_terms : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ additive_terms_lower : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ additive_terms_upper : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ yearly : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ yearly_lower : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ yearly_upper : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ multiplicative_terms : num 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ multiplicative_terms_lower: num 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ multiplicative_terms_upper: num 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ yhat_lower : num 58 50 80.9 78.5 84.2 ... #&gt; $ yhat_upper : num 114 110 138 138 139 ... #&gt; $ trend_lower : num 106 108 110 113 115 ... #&gt; $ trend_upper : num 106 108 110 113 115 ... #&gt; $ yhat : num 84.3 77.7 109.9 107.4 110.9 ... plot(ap_ppht, ap_forecast) # prophetによる予測の各成分のプロット prophet_plot_components(ap_ppht, ap_forecast) 1.5.2.2 代替的方法: Holt-Winters法 原系列が, level (講義資料では”水準”), trend (“傾き”), seasonality (“季節性”) の成分 (のいずれか) で構成されているとみなし, 各構成成分に指数平滑化法を適用して予測値を計算し, それらを積み上げて原系列の予測値を算出するアプローチ. 時系列の分解は手段であり, 原系列の将来予測の方に興味. 関数HoltWinters() 与えられた時系列に対してHolt-Wintersフィルタリングを実行 未知パラメータは平方予測誤差で決定 標準ライブラリstatsに含まれる Usage: HoltWinters(x, alpha = NULL, beta = NULL, gamma = NULL, seasonal = c(&quot;additive&quot;, &quot;multiplicative&quot;), start.periods = 2, l.start = NULL, b.start = NULL, s.start = NULL, optim.start = c(alpha = 0.3, beta = 0.1, gamma = 0.1), optim.control = list()) Holt-Wintersフィルタリングの実行 (季節性に関する乗法バージョン) ap_hw &lt;- HoltWinters(ap, seasonal = &quot;mult&quot;) # 原系列 (観測値) vs (各成分を合計した) フィルタ値 plot(ap_hw) 各成分 (状態変数) の推定値 a: level (水準), b: trend (傾き), s1–sp: seasonality (季節性) ap_hw$coef #&gt; a b s1 s2 s3 s4 #&gt; 469.3232206 3.0215391 0.9464611 0.8829239 0.9717369 1.0304825 #&gt; s5 s6 s7 s8 s9 s10 #&gt; 1.0476884 1.1805272 1.3590778 1.3331706 1.1083381 0.9868813 #&gt; s11 s12 #&gt; 0.8361333 0.9209877 平滑化パラメータの各推定値 (デフォルト: 1期先予測の平方誤差を最小化) 1に近い → 適応性が高い・直近の情報にウェイト 0に近い → 持続性が高い・過去の情報にもウェイト (より滑らかなパス) ap_hw$alpha; ap_hw$beta; ap_hw$gamma #&gt; alpha #&gt; 0.2755925 #&gt; beta #&gt; 0.03269295 #&gt; gamma #&gt; 0.8707292 # ap_hw$seasonal → 季節性成分 (\\(\\hat{\\gamma}=0.87\\)) は適応性が高く, 傾き成分 (\\(\\hat{\\beta}=0.03\\)) は持続性が高い 予測誤差 (1期先予測に対する) # 誤差平方和 ap_hw$SSE #&gt; [1] 16570.78 # RMSE sqrt(ap_hw$SSE / length(ap)) #&gt; [1] 10.72729 # 原系列の標準偏差 sd(ap) #&gt; [1] 119.9663 成分ごとの各時点\\(t\\)におけるフィルタ値と残差 # 成分ごとの各時点tにおけるフィルタ値 (filtered series) plot(ap_hw$fitted) # 残差 residuals(ap_hw) #&gt; Jan Feb Mar Apr May #&gt; 1950 3.918191291 3.668547859 3.560987430 2.676619655 1.520319537 #&gt; 1951 10.169631710 0.294856559 11.459174000 1.250271622 22.242492007 #&gt; 1952 0.639058465 2.561809528 -13.247937478 -4.960743337 -1.798362274 #&gt; 1953 -2.309951793 -10.984490575 11.807034404 20.934576164 6.324760310 #&gt; 1954 -7.884606924 -25.278507451 -6.844292266 -4.126648634 11.152422735 #&gt; 1955 9.492307599 6.844512503 -17.984109810 -2.954044415 -4.414349879 #&gt; 1956 2.366074092 7.032754109 -3.174999872 -8.276899149 -4.045741326 #&gt; 1957 -0.103179026 -3.405357956 6.941798182 -1.292551022 -0.073176743 #&gt; 1958 -12.616294292 -16.810889595 -24.941371144 -24.190854481 -9.090123850 #&gt; 1959 9.356931169 7.005413487 15.314121160 9.501136587 12.869260335 #&gt; 1960 3.083235437 -1.451160572 -41.170501367 25.578209728 6.904887268 #&gt; Jun Jul Aug Sep Oct #&gt; 1950 1.332711685 7.556756288 4.470410387 4.112287706 -3.318641449 #&gt; 1951 -7.647723596 -7.262153619 -4.180886326 -2.419252204 3.852200863 #&gt; 1952 22.315604495 2.501602281 12.995228211 -6.630984243 4.713402630 #&gt; 1953 -13.737994926 -4.358000825 -3.595138563 -3.950054519 -5.418708751 #&gt; 1954 19.596410444 31.074569878 4.536718996 5.674435479 0.542766289 #&gt; 1955 13.889124087 26.518519783 11.014466838 14.163333928 6.699554535 #&gt; 1956 6.048821526 -4.203225397 10.393752287 2.693344663 -2.449808881 #&gt; 1957 7.639077734 2.908853356 18.020294032 6.364989620 1.549021882 #&gt; 1958 -0.498537076 12.581616475 28.702263571 -13.219138602 4.563093559 #&gt; 1959 -19.604975309 4.219977680 9.064706000 13.361230112 7.086972733 #&gt; 1960 0.647289130 5.264644362 -21.551048083 -2.133147349 14.837197056 #&gt; Nov Dec #&gt; 1950 -5.090610790 6.011280050 #&gt; 1951 7.631271802 -3.141340932 #&gt; 1952 5.962357239 1.157482330 #&gt; 1953 -11.302349202 -11.165209087 #&gt; 1954 4.233276856 2.674631856 #&gt; 1955 0.007456865 11.099310837 #&gt; 1956 4.303662198 -3.394161373 #&gt; 1957 0.756961385 -9.615242815 #&gt; 1958 -1.876474530 -8.975126182 #&gt; 1959 13.602784883 18.347906089 #&gt; 1960 -5.452817647 -2.572462781 先述の諸手法との比較のため, 原系列を”トレンド”と季節性, “ノイズ”に分解 (水準と傾き → “トレンド”に統合) ap_hw_decomp &lt;- ts.union(y = ap_hw$x, trend = ap_hw$fitted[, &quot;level&quot;] + ap_hw$fitted[, &quot;trend&quot;], season = ap_hw$fitted[, &quot;season&quot;], resid. = residuals(ap_hw)) plot(ap_hw_decomp, main = &quot;Holt-Winters&quot;) 外挿予測 (3年先まで) # 予測 ap_hw_pred &lt;- predict(ap_hw, n.ahead = 3*12) ts.plot(ap, ap_hw_pred, lty = 1:2) Non-Seasonal Holt-Wintersの実行例 データセット: uspop - 米国の国勢調査人口 (百万人), 1790--1970年 x &lt;- uspop + rnorm(uspop, sd = 5) m &lt;- HoltWinters(x, gamma = FALSE) plot(m) "],["定常性と自己相関関数.html", "2 定常性と自己相関関数 2.1 確率過程の2次特性: 平均関数と自己共分散関数 2.2 定常性 (stationarity) 2.3 標本平均と標本自己共分散関数 2.4 R操作: 標本ACF 2.5 母ACF vs 標本ACF", " 2 定常性と自己相関関数 2.1 確率過程の2次特性: 平均関数と自己共分散関数 \\(E[X_t]&lt;\\infty\\)である確率過程 \\(\\{X_t,t=0,\\pm1,\\pm2,\\ldots\\}\\) に対して以下の二つの関数を定義することができる. 平均関数 (mean function): \\[ \\mu_X(t) = E[X_t] \\qquad (\\#eq:mean.func)\\] 自己共分散関数 (autocovariance function): \\[ \\gamma_X(t,s) = Cov[X_t,X_s] = E[(X_t - \\mu_X(t))(X_s - \\mu_X(s))] \\] さらに, 自己相関関数 (autocorrelation function) も定義できる: \\[ \\rho_X(t,s) = \\frac{\\gamma_X(t,s)}{\\sqrt{\\gamma_X(t,t)}\\sqrt{\\gamma_X(s,s)}} \\] 時系列解析では, 主にこれら1次, 2次モーメントに依存する時系列的性質に注意を向ける. 2.2 定常性 (stationarity) 確率過程に関する規則性の概念の一つ 大雑把に言えば, \\(\\{X_t,t=0,\\pm1,\\pm2,\\ldots\\}\\) とそれが時間的に任意の整数\\(h\\)だけシフトした \\(\\{X_{t+h},t=0,\\pm1,\\pm2,\\ldots\\}\\) とが統計的に類似の性質を持つこと 理論面ばかりでなく, 時系列データの解析の実践面においても想定されることの多い重要な性質 大きく, 強定常性 (strict stationarity), 弱定常性 (weak stationarity)の2種類 2.2.1 強定常性 確率過程 \\(\\{X_t,t=0,\\pm1,\\pm2,\\ldots\\}\\) が強定常であるとは (定義): 任意の長さ\\(k=1,2,\\ldots\\), 任意の時点組合せ\\(t_1,t_2,\\ldots,t_k\\), 任意のラグ\\(h=0,\\pm1,\\pm2,\\ldots\\)に対して, 二つの確率変数ベクトル \\((X_{t_1},X_{t_2},\\ldots,X_{t_k})\\) と \\((X_{t_1+h},X_{t_2+h},\\ldots,X_{t_k+h})\\) が, 同じ確率分布を持つ. すなわち, 強定常であれば, \\(X_t\\)は同一分布を持つ. また, iid確率過程は, 強定常である. 2.2.2 弱定常性 確率過程 \\(\\{X_t,t=0,\\pm1,\\pm2,\\ldots\\}\\) が弱定常であるとは (定義): \\(\\mu_X(t)\\)が時間\\(t\\)に独立である: \\(\\mu_X(t) =\\mu_X(0) =: \\mu\\) \\(\\gamma_X(t+h,t)\\)が, 各\\(h\\)に対して時間\\(t\\)に独立である: : \\(\\gamma_X(t+h,t) = \\gamma_X(h,0) =: \\gamma_X(h)\\) さらに, 自己相関関数: \\[ \\rho_X(h) = \\frac{\\gamma_X(h)}{\\gamma_X(0)}\\] 習慣により, 時系列解析では単に“定常”と言えば弱定常を指す. 2.2.3 ホワイトノイズ 最も単純な定常過程にホワイトノイズ (白色ノイズ) がある. ホワイトノイズは, 時系列解析で使われる各種モデルの構築に中心的役割を果たす. ホワイトノイズ (“弱ホワイトノイズ”): 平均が一定(通常, ゼロ), 分散が有限で一定, 自己相関がゼロの確率過程 表記: \\(\\{X_t\\} \\sim WN(0,\\sigma^2)\\) 数式表現: \\(E[X_t]=0\\), \\(E[X_t^2]=\\sigma^2 &lt; \\infty \\quad (\\forall t)\\) \\[ E[X_t X_s] = \\begin{cases} \\sigma^2 &amp; (t = s)\\\\ 0 &amp; (t \\ne s) \\end{cases} \\quad (\\forall t,s) \\] IIDノイズ 有限分散を持つiid確率過程 (通常, 平均ゼロ) 独立性 → 無相関性により, ホワイトノイズと同じ形の自己共分散関数を持つ 表記: \\(\\{X_t\\} \\sim IID(0,\\sigma^2)\\) “強ホワイトノイズ”と呼ばれることもある 2.3 標本平均と標本自己共分散関数 観測された時系列データ\\(x_1,x_2,\\ldots,x_n\\)に対して 標本平均: \\[ \\bar{x} = \\frac{1}{n} \\sum_{t=1}^n x_t \\qquad (\\#eq:smean)\\] 確率過程 \\(\\{X_t,t=0,\\pm1,\\pm2,\\ldots\\}\\) の実現値を時間軸方向に平均した値 標本自己共分散関数: \\[ \\hat{\\gamma}(h) = \\frac{1}{n} \\sum_{i=1}^{n-|h|} (x_{t+|h|}-\\bar{x})(x_{t}-\\bar{x}),\\quad|h|&lt;n \\] 標本自己相関関数: \\[ \\hat{\\rho}(h) = \\frac{\\hat{\\gamma}(h)}{\\hat{\\gamma}(0)}, \\quad |h|&lt;n \\] 定常性の仮定が成立していなとくとも, 任意の時系列データに対して, (時間軸に沿って) 標本平均関数および標本自己共分散関数・標本自己相関関数を計算することができる. 標本自己共分散関数・標本自己相関関数の形状は, トレンドや周期性の存在を示す手掛かりとなる. 2.3.1 アンサンブル平均 vs 標本平均 平均関数の定義式における期待値 (式@ref(eq:mean.func)) は, 時点\\(t\\)において, 確率変数 \\(X_t\\) の全ての実現可能な値に対して平均を計算したもの (“アンサンブル平均”) である. 一方, 標本平均 (式(??)) は, 時系列データ (確率過程の実現値) を時間軸方向に平均した値 (時系列平均) である. よって, アンサンブル平均と時系列平均は, 概念的には別物である. データの背後にある確率過程\\(\\{X_t\\}\\)が定常であれば, 平均関数は定数値 \\(\\mu\\) を取るので, 標本平均を用いて推定する意味が出てくる. 標本平均 \\(\\bar{x}\\) の計算において, 十分に長いデータ期間を取る (標本サイズ \\(n \\rightarrow \\infty\\) ) ことで, \\(\\bar{x}\\) が真の値 \\(\\mu\\)に次第に近付いていく確率過程の性質を, (平均)エルゴード性 (ergodicity in (the) mean) と呼ぶ. 定常な確率過程を前提とした時系列解析は, 通常は, エルゴード性を有するモデルを前提に行われる. 2.4 R操作: 標本ACF 関数acf()を使うことで, 与えられた時系列データの標本自己相関関数 (標本ACF) を 計算し, コレログラムを作図することができる. 参考文献: CM, Ch.2 &amp; 4, Tsay, Ch.2 2.4.1 白色ノイズ 正規乱数を使って生成 → 正規白色ノイズ (Gaussian white noise)と呼ばれる. # 乱数のシード設定 set.seed(1) w &lt;- rnorm(100) # 時系列プロット plot(w, type = &quot;l&quot;) # ヒストグラム z &lt;- seq(-3, 3, length = 1000) hist(rnorm(100), prob = T, xlim = c(-3, 3)); points(z, dnorm(z), type = &quot;l&quot;) # 自己相関関数(ACF) acf(w) # 2乗系列のACF acf(w ^ 2) # 絶対値系列のACF acf(abs(w)) 2.4.2 ランダムウォーク 正規乱数を使って生成 → 正規ランダムウォーク (Gaussian random walk)と呼ばれる. x &lt;- cumsum(w) # 時系列プロット plot(x, type = &quot;l&quot;) # ACF acf(x) # 2乗系列のACF acf(x ^ 2) # 絶対値系列のACF acf(abs(x)) 2.4.3 非定常成分を含む時系列 2.4.3.1 AirPassengersデータ (出所: CM, Ch.2) 1章でも登場したAirPassengersデータを利用して, ACFを作成する. 特に, 同データに見られる非定常性成分であるトレンドや季節性がACFの形状にどのように影響するかを確認する. data(AirPassengers) ap &lt;- AirPassengers acf(ap) ACFはゆっくり減衰しつつ, 横軸が1.0 (月次データのラグ=12に対応) で, 山が作られることが観察される. 2.4.3.2 時系列の分解 関数decompose()を利用して積分解する. - トレンド成分 # 乗法モデルを仮定 ap_decom &lt;- decompose(ap, &quot;multiplicative&quot;) # トレンド成分 plot(ts(ap_decom$trend[7:138])) acf(ts(ap_decom$trend[7:138])) 正の (直線的な) トレンド → ACFの減衰が遅いことが確認される. 季節性成分 # 季節性成分 plot(ts(ap_decom$seasonal[7:138])) acf(ts(ap_decom$seasonal[7:138])) 1年周期 → 6ヶ月に負の最小値, 12ヶ月に正の最大値が確認される. ランダムノイズ成分 # ランダムノイズ成分 plot(ts(ap_decom$random[7:138])) acf(ts(ap_decom$random[7:138])) 周期性が未だ残っているが, 自己相関はかなり除去されたことが確認される. #library(zoo) # na.trim()使用 #acf(ap_decom$random, na.action = na.trim) # ← NA除去 # 標準偏差 sd(ap[7:138]) # sd of the original series #&gt; [1] 109.4187 sd(ap[7:138] - ap_decom$trend[7:138]) # after substracting the trend estimate #&gt; [1] 41.11491 sd(ap_decom$random[7:138]) # the error component #&gt; [1] 0.0333884 # → std dev gets smaller #または #library(zoo) #ap_d_zoo = zoo(ap_decom$random) 関数stl()の利用 # stl(): Seasonal Decomposition of Time Series by Loess ap_stl&lt;- stl(ap, &quot;period&quot;) # トレンド成分 plot(ap_stl$time.series[, &quot;trend&quot;]) # 季節性成分 plot(ap_stl$time.series[, &quot;seasonal&quot;]) # ランダムノイズ成分 plot(ap_stl$time.series[, &quot;remainder&quot;]) acf(ap_stl$time.series[, &quot;remainder&quot;]) 2.4.3.3 階差 (differencing) 次に, 時系列データに対して, 階差 (差分) 操作を行うことによりACFの形状がどう変化するかを観察する. 上の観察から, 原系列を一旦対数変換してから 階差を取る. # ap &lt;- AirPassengers # is.ts(ap); is.vector(ts) # ACF # acf(ap) # 対数値の階差系列のACF plot(diff(log(ap), lag = 1)) # 前月との階差 acf(diff(log(ap), lag = 1)) ラグ1の階差を取ることにより, トレンドは消えたが, 横軸1.0 (ラグ12ヶ月に対応) にピークがあり, この階差系列には1年の周期性が残っていることが分かる. plot(diff(log(ap), lag = 12)) # 1年前との階差 acf(diff(log(ap), lag = 12)) 一方, ラグ12の階差を取ると, 1年の周期性は概ね消えるが, 自己相関の減衰が遅く, トレンドが残った系列 であることが分かる. かばん検定 ラグ12の階差を取った系列に対して, Box-Pierce検定, Ljung-Box検定 を実行してみる. # かばん検定 (portmanteau test) Box.test(diff(log(ap), lag = 12)) # Box-Pierce検定 (デフォルト) #&gt; #&gt; Box-Pierce test #&gt; #&gt; data: diff(log(ap), lag = 12) #&gt; X-squared = 67.234, df = 1, p-value = 2.22e-16 Box.test(diff(log(ap), lag = 12), type = &quot;Ljung&quot;) # Ljung-Box検定 #&gt; #&gt; Box-Ljung test #&gt; #&gt; data: diff(log(ap), lag = 12) #&gt; X-squared = 68.774, df = 1, p-value &lt; 2.2e-16 2.4.3.4 株価データの例 (出所: Tsay, Ch.2) 教科書のIBM月次株価データを利用して ACFを計算する. ifl &lt;- file.path(idir, &quot;m-ibmsp-2611.txt&quot;) da &lt;- read.table(&quot;m-ibmsp-2611.txt&quot;, header = T) #da &lt;- read.table(&quot;m-ibmsp6709.txt&quot;, header = T) head(da) #&gt; data ibm sp #&gt; 1 19260130 -0.010381 0.022472 #&gt; 2 19260227 -0.024476 -0.043956 #&gt; 3 19260331 -0.115591 -0.059113 #&gt; 4 19260430 0.089783 0.022688 #&gt; 5 19260528 0.036932 0.007679 #&gt; 6 19260630 0.068493 0.043184 ibm &lt;- da$ibm sp5 &lt;- da$sp plot(sp5, ibm) plot(ibm, type = &quot;l&quot;) plot(cumsum(log(ibm + 1)), type = &quot;l&quot;) # 原系列に対する自己相関性の検証 acf(ibm) acf(ibm)$acf #&gt; , , 1 #&gt; #&gt; [,1] #&gt; [1,] 1.000000000 #&gt; [2,] 0.037561974 #&gt; [3,] -0.008664145 #&gt; [4,] -0.016156989 #&gt; [5,] -0.030554233 #&gt; [6,] 0.015370816 #&gt; [7,] -0.041809301 #&gt; [8,] 0.003236462 #&gt; [9,] 0.063082544 #&gt; [10,] 0.048232274 #&gt; [11,] 0.037150816 #&gt; [12,] 0.011816712 #&gt; [13,] 0.010848647 #&gt; [14,] -0.067274698 #&gt; [15,] -0.011545286 #&gt; [16,] -0.038790792 #&gt; [17,] 0.031043139 #&gt; [18,] 0.029670820 #&gt; [19,] 0.065795548 #&gt; [20,] 0.019771486 #&gt; [21,] -0.013009184 #&gt; [22,] -0.012984508 #&gt; [23,] 0.002353094 #&gt; [24,] -0.072724702 #&gt; [25,] 0.053508492 #&gt; [26,] -0.010189813 #&gt; [27,] 0.036015597 #&gt; [28,] 0.019976030 #&gt; [29,] 0.032989584 #&gt; [30,] 0.004650878 #&gt; [31,] -0.016390330 Box.test(ibm, lag = 30) # Box-Pierce (デフォルト) #&gt; #&gt; Box-Pierce test #&gt; #&gt; data: ibm #&gt; X-squared = 38.094, df = 30, p-value = 0.1473 Box.test(ibm, lag = 30, type = &#39;Ljung&#39;) # Ljung-Box #&gt; #&gt; Box-Ljung test #&gt; #&gt; data: ibm #&gt; X-squared = 38.75, df = 30, p-value = 0.1314 #lnibm &lt;- log(ibm + 1) # Transfer to log returns #Box.test(lnibm, lag = 30, type = &#39;Ljung&#39;) # 絶対値系列, 2乗系列に対する自己相関性の検証 acf(abs(ibm)) acf(ibm ^ 2) Box.test(abs(ibm), lag = 30, type = &#39;Ljung&#39;) # Ljung-Box #&gt; #&gt; Box-Ljung test #&gt; #&gt; data: abs(ibm) #&gt; X-squared = 256.75, df = 30, p-value &lt; 2.2e-16 Box.test(ibm^2, lag = 30, type = &#39;Ljung&#39;) # Ljung-Box #&gt; #&gt; Box-Ljung test #&gt; #&gt; data: ibm^2 #&gt; X-squared = 189.3, df = 30, p-value &lt; 2.2e-16 2.4.4 線形・定常時系列モデル 2.4.4.1 MA(1)・AR(1)モデル 2.4.4.1.1 シミュレーションによるパス生成 AR(1)モデル #par(mfrow = c(3,1)) tlen = 100 set.seed(1) phi &lt;- - 0.8 x &lt;- w &lt;- rnorm(100) for (t in 2:100) x[t] = phi * x[t-1] + w[t] plot(x, type = &quot;l&quot;) # 時系列プロット acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) MA(1)モデル theta &lt;- - 0.8 for (t in 2:100) x[t] &lt;- w[t] + theta * w[t-1] plot(x, type = &quot;l&quot;) # 時系列プロット acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 2.4.4.2 ARMA(1,1)モデル ARMA(1,1)モデル phi &lt;- 0.5; theta &lt;- 0.5 set.seed(1) x &lt;- arima.sim(n = tlen, model = list(order = c(1,0,1), ar = phi, ma = theta)) plot(x, type = &quot;l&quot;) # 時系列プロット acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 2.5 母ACF vs 標本ACF AR(2)モデルを例に, ACFの理論値 (母自己相関関数) とシミュレーションで生成した パスから計算される標本値 (標本自己相関関数) の形状を比較する. AR(2) モデルのシミュレーション 4つのパラメータセットに対して, 各400個の正規乱数を 使って, AR(2)モデルのサンプルパスを1本ずつ生成する. 次に, 各パスに対して関数acf()を適用し, コレログラムを2枚作図する. 左図が標本ACF (自己相関), 右図が標本PACF (偏自己相関) である. 本節では, 左図に注目する. sim_AR2 &lt;- function(phi_par, n_sim = 100, seed = 1, ...){ set.seed(seed) # par(mfrow = c(3, 1)) x &lt;- w &lt;- rnorm(n_sim) for (t in 3:n_sim) {x[t] &lt;- phi_par[1] * x[t-1] + phi_par[2] * x[t-2] + w[t]} par(mfrow = c(1, 1)) plot(x, type = &quot;l&quot;, ...) par(mfrow = c(1, 2)) acf(x, lag.max = 20); pacf(x, lag.max = 20) par(mfrow = c(1,1)) } # Tsay, p_57, Fig 2_9のパラメータ例 phi_par1 &lt;- c(1.2, -0.35) # (phi1, phi2) phi_par2 &lt;- c(0.6, -0.4) # (phi1, phi2) phi_par3 &lt;- c(0.2, 0.35) # (phi1, phi2) phi_par4 &lt;- c(-0.2, 0.35) # (phi1, phi2) nsize &lt;- 400 seed_tmp &lt;- 100 sim_AR2(phi_par1, n_sim = nsize, seed = seed_tmp, main = &quot;(1)&quot;) sim_AR2(phi_par2, n_sim = nsize, seed = seed_tmp, main = &quot;(2)&quot;) sim_AR2(phi_par3, n_sim = nsize, seed = seed_tmp, main = &quot;(3)&quot;) sim_AR2(phi_par4, n_sim = nsize, seed = seed_tmp, main = &quot;(4)&quot;) AR(2)のACF理論値の計算およびプロット AR(2)の特性方程式の解 sol_AR2eqn &lt;- function(phi_par){ D &lt;- phi_par[1]^2 + 4 * phi_par[2] if (D&gt;= 0){ z1 &lt;- (phi_par[1] + sqrt(D)) / (-2 * phi_par[2]) z2 &lt;- (phi_par[1] - sqrt(D)) / (-2 * phi_par[2]) } else{ z1 &lt;- complex(re = phi_par[1] / (-2 * phi_par[2]), im = sqrt(-D)/(-2 * phi_par[2])) z2 &lt;- complex(re = phi_par[1] / (-2 * phi_par[2]), im = -sqrt(-D)/(-2 * phi_par[2])) } return(c(z1,z2)) } sol_AR2eqn(phi_par1) ## [1] 2.000000 1.428571 sol_AR2eqn(phi_par2) ## [1] 0.75+1.391941i 0.75-1.391941i sol_AR2eqn(phi_par3) ## [1] -2.000000 1.428571 sol_AR2eqn(phi_par4) ## [1] -1.428571 2.000000 AR(2)のACF理論値: rhoに関する差分方程式(漸化式)より計算 plot_ACF_AR2 &lt;- function(phi_par, hlen = 20){ rho_0 &lt;- 1 rho_1 &lt;- phi_par[1]/(1-phi_par[2]) ACF_h &lt;- c(rho_0, rho_1) for (h in 1:hlen){ rho_2 = phi_par[1]*rho_1 + phi_par[2]*rho_0 ACF_h = c(ACF_h, rho_2) rho_0 = rho_1; rho_1 = rho_2 } barplot(ACF_h, main=phi_par) } 代替的アプローチ: 特性方程式の解を使って導出 plot_ACF_AR2_2 &lt;- function(phi_par, hlen = 20){ zvec &lt;- sol_AR2eqn(phi_par) # 特性方程式の解 rho_0 &lt;- 1 rho_1 &lt;- phi_par[1]/(1-phi_par[2]) # c1, c2に関する連立方程式 cvec &lt;- solve(matrix(c(1, 1 , 1 / zvec[1], 1 / zvec[2]), 2, byrow = T), c(rho_0, rho_1) ) hvec &lt;- 0:hlen if (! is_complex(zvec)){ # 実根の場合 if (zvec[1] != zvec[2]) ACF_h &lt;- cvec[1] * zvec[1] ^ (-hvec) + cvec[2] * zvec[2] ^ (-hvec) else ACF_h &lt;- zvec[1]^(-hvec) * (cvec[1] + cvec[2] * hvec) # 重根 } else{ # 複素共役 (complex conjugates) の場合 z_mod &lt;- Mod(zvec[1]) th &lt;- Arg(zvec[1]) ACF_h &lt;- z_mod ^ (-hvec) * cos(hvec * th) } barplot(ACF_h, main = phi_par) } plot_ACF_AR2(phi_par1) plot_ACF_AR2(phi_par2) plot_ACF_AR2(phi_par3) plot_ACF_AR2(phi_par4) 先に生成した理論ACFと, それぞれの形状が類似していることが 確認される. "],["armapqモデル.html", "3 ARMA\\((p,q)\\)モデル 3.1 ARMA\\((p,q)\\)モデルとは 3.2 ARMA\\((p,q)\\)モデルによる予測 3.3 ARMA\\((p,q)\\)モデルの推定 3.4 ARMA\\((p,q)\\)モデルの同定 (次数の特定) 3.5 R操作 3.6 データ分析例 (Tsay, Ch2より)", " 3 ARMA\\((p,q)\\)モデル 時系列解析の体系において中核をなす, 最も基本的な 特性をもつ線形・定常確率過程, その 線形・定常確率過程の中で, 実用上最も良く用いられる 時系列モデルのクラスにARMA\\((p,q)\\)モデルがある. ARMA\\((p,q)\\)モデルは, 有限個のパラメータで定常時系列の 動的構造を表現するパラメトリックなクラスである. AR\\((p)\\)項にMA\\((q)\\)項を加えることで, 比較的少数のパラメータを使って, 複雑な定常時系列の挙動, すなわち, 自己相関の構造を (近似的に) 表現することができる. 3.1 ARMA\\((p,q)\\)モデルとは 定常, かつ 次の差分方程式を満たす\\({X_t}\\): \\[ X_t - \\phi_1 X_{t-1} - \\cdots - \\phi_p X_{t-p}= Z_t + \\theta_1 X_{t-1} + \\cdots + \\theta_q Z_{t-q} \\tag{1}\\] コンパクトな代替表現: \\[ \\phi(B)X_t = \\theta(B) Z_t \\tag{2}\\] Backward shift operator \\(B\\) AR多項式 \\(\\phi(z)=1 - \\phi_1 z - \\cdots - \\phi_p z^p\\) MA多項式 \\(\\theta(z)=1 + \\theta_1 z + \\cdots + \\theta_q z^q\\) 因果性と反転可能性 差分方程式の解\\({X_t}\\) 形式的に解くと, \\[ X_t = \\frac{\\theta(B)}{\\phi(B)} Z_t \\tag{3}\\] 解が存在 (定常, 因果的) するための条件? 定常性: \\(\\phi(z) \\ne 0,\\ \\forall |z|=1\\) 因果性: \\(\\phi(z) \\ne 0,\\ \\forall |z|\\le 1\\) +反転可能性: \\(\\theta(z) \\ne 0,\\ \\forall |z|\\le 1\\) ※ \\(\\phi(z)=0, \\theta(z)=0\\)は共通根を持たない (識別可能性) ※ 因果性は実用上不可欠: \\(X_t = \\sum_{i=0}^{\\infty}\\psi_i Z_{t-i}\\) (with \\(\\sum_{i=0}^{\\infty}|\\psi_i|&lt;\\infty\\)) (MA\\((\\infty)\\)表現) ※ 反転可能性は推定のために付加する条件: \\(Z_t = \\sum_{i=0}^{\\infty}\\pi_i X_{t-i}\\) (with \\(\\sum_{i=0}^{\\infty}|\\pi_i|&lt;\\infty\\)) (AR\\((\\infty)\\)表現) ARMA\\((p,q)\\)モデルの意義 なぜ必要か? AR(p)過程 実際の時系列データの記述 → 大きな\\(p\\)が必要となる可能性 MA\\((q)\\)過程. 反転可能な場合, AR\\((\\infty)\\)表現が可能 \\[ Z_t = X_t + \\sum_{i=1}^{\\infty}\\pi_i X_{t-i} \\] ∴ AR\\((p)\\)過程にMA\\((q)\\)項を付与することで, 少ないパラメータで, 現象を表現できることが期待される 3.2 ARMA\\((p,q)\\)モデルによる予測 過去データ\\(X_t,X_{t-1},\\cdots,X_1\\)に基づき, \\(h\\)期先の値\\(X_{t+h}\\)を予測したい モデルを推定 → 推定モデルを使って予測 どのように予測するか? 定常過程の予測 (当然, ARMA\\((p,q)\\)過程を含む) 線形予測 (Best Linear Prediction) 線形回帰問題を解く(正規方程式の解) AR\\((p)\\)モデル → \\(\\phi\\)係数をそのまま予測に使用 一般的解法 (MA\\((q)\\), ARMA\\((p,q)\\)モデル等にも適用): アルゴリズムによる予測(Duribin-Levinsonアルゴリズム, Innovationアルゴリズム) 3.3 ARMA\\((p,q)\\)モデルの推定 モデルをどのように推定するか? 次数\\(p,q\\)の同定(identification) (モデル選択) モデルパラメータ\\(\\phi\\) , \\(\\theta\\)の推定 予備的な推定 (→ 最尤法の初期値に利用可能) AR\\((p)\\)モデルのみ: Yule-Walker法, Burg法 MA\\((q)\\), ARMA\\((p,q)\\)モデル: Innovationアルゴリズム, Hannan-Rissanenアルゴリズム等 最尤法 標準的には, \\(Z_t\\)が正規ホワイトノイズ (IID + 正規分布) → \\(X_t\\)は, Gaussian過程 \\(Z_t\\)が非正規のIIDノイズの場合でも, 大標本ならば使用OK モデル診断 適合モデルから得られた残差系列がホワイトノイズか? 時系列プロット, 標本ACFプロット 自己相関の検定, かばん検定 正規性検定 (qqプロット, Jarque-Bera検定など) 参考文献: Brockwell and Davis, Introduction to Time Series and Forecasting. 3.4 ARMA\\((p,q)\\)モデルの同定 (次数の特定) 標本自己相関(ACF), 標本偏自己相関(PACF)の使用 定常過程は, ACVF/ACFによって特徴付けられる →時系列データから標本SACFをプロット AR\\((p)\\) → PACFが\\((p+1)\\)次以降のラグが値\\(0\\) MA\\((q)\\) → ACFが\\((q+1)\\)次以降のラグが値\\(0\\) ARMA\\((p,q)\\) →Extended ACF(EACF)の表内で, “○”(値が有意でない)の領域中で最も左上の要素の位置(行\\(p\\),列\\(q\\))を見つける AIC, BICなどのモデル選択基準の使用 モデル推定と同時に行う モデル選択基準 = - 2・対数尤度 + 罰則項(パラメータ数の増加関数) 3.5 R操作 ARMA\\((p,q)\\)モデルの同定 (ACF/PACF/EACFの利用) AR(3)モデル #par(mfrow = c(3,1)) Tlen = 100 phi=c(0.5,-0.8, 0.5); theta = NULL set.seed(10) x = arima.sim(n = Tlen, model = list(order = c(3,0,0), ar = phi, ma = theta)) #plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) MA(2)モデル phi = NULL; theta=c(0.3,0.4) set.seed(10) x = arima.sim(n = Tlen, model = list(order = c(0,0,2), ar = phi, ma = theta)) #plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) par(mfrow = c(1, 1)) ARMA(2,1)モデル phi = c(0.3,-0.8); theta = 0.9 set.seed(10) x = arima.sim(n = Tlen, model = list(order = c(2,0,1), ar = phi, ma = theta)) #plot(x, type=&quot;l&quot;) # 時系列プロット par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) par(mfrow = c(1, 1)) require(TSA) ## Loading required package: TSA ## ## Attaching package: &#39;TSA&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## acf, arima ## The following object is masked from &#39;package:utils&#39;: ## ## tar m1 = eacf(x, 6, 8) # Simplified table ## AR/MA ## 0 1 2 3 4 5 6 7 8 ## 0 x x x x x o x o o ## 1 x x x x x x x o o ## 2 x o o o o o o o o ## 3 x o o o o o o o o ## 4 x x x o o o o o o ## 5 x o x o o o o o o ## 6 x o o o o o o o o print(m1$eacf, digits = 2) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## [1,] 0.30 -0.613 -0.41 0.304 0.3518 -0.131 -0.269 0.048 0.197 ## [2,] 0.34 -0.767 -0.43 0.462 0.3388 -0.214 -0.250 0.088 0.182 ## [3,] 0.50 -0.021 -0.13 -0.135 -0.0102 0.053 0.033 -0.095 -0.205 ## [4,] 0.51 -0.097 -0.11 -0.140 -0.0241 0.116 0.031 -0.062 -0.183 ## [5,] 0.26 -0.364 0.40 -0.137 -0.0169 -0.032 0.012 -0.078 -0.104 ## [6,] 0.47 -0.028 0.23 -0.162 0.0055 -0.045 0.055 -0.055 -0.114 ## [7,] 0.49 0.052 0.17 -0.067 -0.1727 -0.019 0.038 -0.070 -0.059 → EACFは\\((p,q)=(2,1)\\)を示唆. ARMA\\((p,q)\\)モデルの推定・診断 仮に\\((p,q)=(2,2)\\)を選んだとすると, (x.fit = arima(x,order = c(2,0,2))) # ARMA(2,2)モデルの推定(制約なし) ## ## Call: ## arima(x = x, order = c(2, 0, 2)) ## ## Coefficients: ## ar1 ar2 ma1 ma2 intercept ## 0.3556 -0.7777 0.8059 -0.0712 -0.0247 ## s.e. 0.0887 0.0687 0.1279 0.1353 0.1187 ## ## sigma^2 estimated as 0.9372: log likelihood = -140.93, aic = 291.87 # --&gt; 有意でない係数=0を指定 (x.fit2 = arima(x,order = c(2,0,2), fixed = c(NA,NA,NA,0,NA))) # 制約付き推定 ## ## Call: ## arima(x = x, order = c(2, 0, 2), fixed = c(NA, NA, NA, 0, NA)) ## ## Coefficients: ## ar1 ar2 ma1 ma2 intercept ## 0.3270 -0.7772 0.8604 0 -0.0260 ## s.e. 0.0706 0.0691 0.0802 0 0.1249 ## ## sigma^2 estimated as 0.9407: log likelihood = -141.07, aic = 290.15 tsdiag(x.fit2, gof = 20) # モデル診断 Box.test(x.fit2$residuals, lag = 20, type = &#39;Ljung&#39;) # Ljung-Box検定 ## ## Box-Ljung test ## ## data: x.fit2$residuals ## X-squared = 13.785, df = 20, p-value = 0.8412 パッケージ{forecast}の利用 モデルの自動選択・推定 require(forecast) ## Loading required package: forecast ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo ## Registered S3 methods overwritten by &#39;forecast&#39;: ## method from ## fitted.Arima TSA ## plot.Arima TSA (x.fit3 = auto.arima(x)) # AIC/AICc(デフォルト)/BICによりモデルを自動選択&amp;推定 ## Series: x ## ARIMA(2,0,1) with zero mean ## ## Coefficients: ## ar1 ar2 ma1 ## 0.3273 -0.7773 0.8606 ## s.e. 0.0706 0.0691 0.0801 ## ## sigma^2 = 0.9702: log likelihood = -141.1 ## AIC=290.19 AICc=290.61 BIC=300.61 推定モデルを使った予測 (x.pred = forecast(x.fit3, h=20)) ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 101 4.8076600 3.5453579 6.0699620 2.8771355 6.7381844 ## 102 3.2942800 1.3342557 5.2543043 0.2966815 6.2918785 ## 103 -2.6587345 -4.6791846 -0.6382845 -5.7487463 0.4312772 ## 104 -3.4306758 -5.8473695 -1.0139821 -7.1266899 0.2653382 ## 105 0.9437980 -1.4734713 3.3610674 -2.7530964 4.6406925 ## 106 2.9754436 0.3543532 5.5965340 -1.0331682 6.9840554 ## 107 0.2401888 -2.4072595 2.8876371 -3.8087340 4.2891116 ## 108 -2.2341203 -4.9639829 0.4957423 -6.4090848 1.9408442 ## 109 -0.9178543 -3.6944931 1.8587845 -5.1643569 3.3286483 ## 110 1.4361307 -1.3626481 4.2349096 -2.8442321 5.7164936 ## 111 1.1834256 -1.6613440 4.0281953 -3.1672741 5.5341253 ## 112 -0.7289626 -3.5757196 2.1177945 -5.0827018 3.6247766 ## 113 -1.1584110 -4.0375796 1.7207575 -5.5617193 3.2448973 ## 114 0.1874876 -2.6922716 3.0672467 -4.2167240 4.5916991 ## 115 0.9617589 -1.9352597 3.8587775 -3.4688487 5.3923665 ## 116 0.1690270 -2.7318039 3.0698578 -4.2674110 4.6054649 ## 117 -0.6922301 -3.5997273 2.2152671 -5.1388633 3.7544032 ## 118 -0.3579265 -3.2709875 2.5551344 -4.8130688 4.0972157 ## 119 0.4209117 -2.4936672 3.3354906 -4.0365521 4.8783755 ## 120 0.4159582 -2.5036126 3.3355289 -4.0491400 4.8810563 plot(x.pred) # 3.6 データ分析例 (Tsay, Ch2より) 出所: Tsay, Ch.2 (一部改変) 標本ACF pp.46–47 Example 2.1 ifl &lt;- file.path(dir_introTS, &quot;m-dec12910.txt&quot;) da = read.table(ifl, header=T) #da = read.table(&quot;m-dec12910.txt&quot;, header = T) head(da) ## date dec1 dec2 dec9 dec10 ## 1 19670131 0.068568 0.080373 0.180843 0.211806 ## 2 19670228 0.008735 0.011044 0.048767 0.064911 ## 3 19670331 0.039698 0.035364 0.067494 0.068904 ## 4 19670428 0.044030 0.037541 0.040785 0.044602 ## 5 19670531 -0.050631 -0.036233 -0.002191 0.000295 ## 6 19670630 0.014998 0.018870 0.102075 0.118678 d10 = da$dec10 # select the Decile 10 returns dec10 = ts(d10, frequency = 12, start = c(1967, 1)) par(mfcol = c(2, 1)) plot(dec10, xlab = &#39;year&#39;, ylab = &#39;returns&#39;) # matplot(da[, -1], type = &quot;l&quot;) title(main = &#39;(a): Simple returns&#39;) acf(d10, lag = 24) # command to obtain sample ACF of the data # RK: 有意性確認 f1 = acf(d10, lag = 24) f1$acf ## , , 1 ## ## [,1] ## [1,] 1.000000000 ## [2,] 0.227386585 ## [3,] -0.019026447 ## [4,] -0.021258247 ## [5,] 0.011011345 ## [6,] 0.002676057 ## [7,] -0.027654887 ## [8,] -0.016910608 ## [9,] -0.049183690 ## [10,] -0.039617756 ## [11,] 0.013265549 ## [12,] 0.061013220 ## [13,] 0.130411045 ## [14,] -0.036881195 ## [15,] -0.082462743 ## [16,] -0.020950139 ## [17,] 0.016726386 ## [18,] -0.013961209 ## [19,] -0.059422809 ## [20,] -0.082246074 ## [21,] -0.063641596 ## [22,] -0.039858376 ## [23,] 0.017770989 ## [24,] -0.015413528 ## [25,] 0.052212082 # (tt = f1$acf[13] * sqrt(516)) # nrow(da) = 516 (tt = f1$acf[13] * sqrt(length(d10))) # 絶対値の大きいh = 13でのt値 ## [1] 2.962369 Ljung-Box Q statistics P.48, Example 2.2 ifl &lt;- file.path(dir_introTS, &quot;m-ibmsp6709.txt&quot;) da = read.table(ifl, header=T) #da = read.table(&quot;m-ibmsp6709.txt&quot;, header = T) ibm = da$ibm lnibm = log(ibm + 1) # Transfer to log returns Box.test(ibm, lag = 12, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: ibm ## X-squared = 7.5666, df = 12, p-value = 0.818 Box.test(lnibm, lag = 12, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: lnibm ## X-squared = 7.4042, df = 12, p-value = 0.8298 AR, MA, ARMA (2.4–2.6) p.58, Example 2.3 GNP, 1947.Q1–2010.Q1 par(mfrow = c(1, 1)) ifl &lt;- file.path(dir_introTS, &quot;q-gnp4710.txt&quot;) da = read.table(ifl, header=T) #da = read.table(&quot;q-gnp4710.txt&quot;, header = T) head(da); tail(da); nrow(da) ## Year Mon Dat VALUE ## 1 1947 1 1 238.1 ## 2 1947 4 1 241.5 ## 3 1947 7 1 245.6 ## 4 1947 10 1 255.6 ## 5 1948 1 1 261.7 ## 6 1948 4 1 268.7 ## Year Mon Dat VALUE ## 248 2008 10 1 14317.2 ## 249 2009 1 1 14172.2 ## 250 2009 4 1 14164.2 ## 251 2009 7 1 14281.9 ## 252 2009 10 1 14442.8 ## 253 2010 1 1 14637.6 ## [1] 253 G = da$VALUE plot(G, type = &quot;l&quot;) LG = log(G) gnp = diff(LG) dim(da) ## [1] 253 4 #tdx = c(1:253) / 4 + 1947 # create the time index tdx = c(1:length(G)) / 4 + 1947 # 1947スタート, 四半期データ par(mfcol = c(2, 1)) plot(tdx, G, xlab = &#39;year&#39;, ylab = &#39;GNP&#39;, type = &#39;l&#39;) #plot(tdx[2:253], gnp, type = &#39;l&#39;, xlab = &#39;year&#39;, ylab = &#39;growth&#39;) plot(tdx[-1], gnp, type = &#39;l&#39;, xlab = &#39;year&#39;, ylab = &#39;growth&#39;) # par(mfrow = c(1, 2)) acf(gnp, lag = 12) pacf(gnp, lag = 12) # compute PACF par(mfrow = c(1, 1)) arima(): 一変量arimaモデルの適合 (次数order, 分析者が指定) (m1 = arima(gnp, order = c(3, 0, 0))) # ARIMA(3, 0, 0) = AR(3) ## ## Call: ## arima(x = gnp, order = c(3, 0, 0)) ## ## Coefficients: ## ar1 ar2 ar3 intercept ## 0.4386 0.2063 -0.1559 0.0163 ## s.e. 0.0620 0.0666 0.0626 0.0012 ## ## sigma^2 estimated as 9.549e-05: log likelihood = 808.56, aic = -1607.12 tsdiag(m1, gof = 12) # model checking discussed later p1 = c(1, -m1$coef[1:3]) # set-up the polynomial (AR係数) (r1 = polyroot(p1)) # solve the polynomial equation (AR特性方程式の解) ## [1] 1.616116+8.642123e-01i -1.909216+3.670031e-17i 1.616116-8.642123e-01i Mod(r1) # compute absolute value ## [1] 1.832674 1.909216 1.832674 (k = 2 * pi / acos(1.616116 / 1.832674)) # compute length of the period ## [1] 12.79523 # &lt;-- (ACF)周期の計算, p.56内, k = の式 (参考) zooクラスにして実行した場合 library(zoo) ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric G.zoo = zoo(G, tdx) plot(G.zoo) m1.zoo = arima(diff(log(G.zoo)), order = c(3, 0, 0)) tsdiag(m1.zoo, gof = 12) # gnp.zoo = zoo(gnp, tdx[-1]) gnp.zoo = diff(log(G.zoo)) # zoo クラス plot(gnp.zoo) # Q statistic: based on lag autocorrelation coefficients Box.test(m1.zoo$residuals, lag = 1, type = &quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: m1.zoo$residuals ## X-squared = 0.0071647, df = 1, p-value = 0.9325 Box.test(m1.zoo$residuals, lag = 5, type = &quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: m1.zoo$residuals ## X-squared = 6.1525, df = 5, p-value = 0.2917 Box.test(m1.zoo$residuals, lag = 12, type = &quot;Ljung-Box&quot;) # → p = 0.05271 ## ## Box-Ljung test ## ## data: m1.zoo$residuals ## X-squared = 20.844, df = 12, p-value = 0.05271 p.63 mm1 = ar(gnp, method = &#39;mle&#39;) # yule-walker(デフォルト), burg, ols, yw # aic = T (デフォルト) --&gt; 次数選択実行 mm1$order # Find the identified order ## [1] 9 names(mm1) ## [1] &quot;order&quot; &quot;ar&quot; &quot;var.pred&quot; &quot;x.mean&quot; &quot;aic&quot; ## [6] &quot;n.used&quot; &quot;n.obs&quot; &quot;order.max&quot; &quot;partialacf&quot; &quot;resid&quot; ## [11] &quot;method&quot; &quot;series&quot; &quot;frequency&quot; &quot;call&quot; &quot;asy.var.coef&quot; print(mm1$aic, digits = 3) ## 0 1 2 3 4 5 6 7 8 9 10 ## 77.767 11.915 8.792 4.669 6.265 5.950 5.101 4.596 6.541 0.000 0.509 ## 11 12 ## 2.504 2.057 aic = mm1$aic # For plotting below. length(aic) ## [1] 13 plot(c(0:12), aic, type = &#39;h&#39;, xlab = &#39;order&#39;, ylab = &#39;aic&#39;) lines(0:12, aic, lty = 2) # RK: In ar.yw the variance matrix of the innovations is computed from the fitted coefficients and the autocovariance of x. (参考) zooクラス利用の場合 aic.zoo = zoo(aic, order.by = c(0:12)) plot(aic.zoo) table 2.1 (p.61)の例, Value-weighted Index # AR係数は小さいが有意. 定数項の有意性⇒期待値非ゼロ? #vw = read.table(&#39;m-ibm3dx.txt&#39;, header = T)[, 3] ifl &lt;- file.path(dir_introTS, &#39;m-ibm3dx2608.txt&#39;) vw = read.table(ifl, header=T)[, 3] ar(vw, method = &quot;mle&quot;) # demean = T ## ## Call: ## ar(x = vw, method = &quot;mle&quot;) ## ## Coefficients: ## 1 2 3 4 5 6 7 8 ## 0.1167 -0.0112 -0.1126 0.0217 0.0735 -0.0452 0.0254 0.0462 ## 9 ## 0.0660 ## ## Order selected 9 sigma^2 estimated as 0.002831 #ar(vw) # average annual simple gross returnの計算 (t1 = prod(vw + 1)) ## [1] 1592.953 # t1^(12 / 996)-1 # 年平均成長率 t1^(12 / length(vw))-1 # 年平均成長率 ## [1] 0.09290084 #tmp &lt;- ar(vw, method = &quot;mle&quot;) # tmp$ar / sqrt(diag(tmp$asy)) (m3 = arima(vw, order = c(3, 0, 0))) # include.mean = T (デフォルト) ## ## Call: ## arima(x = vw, order = c(3, 0, 0)) ## ## Coefficients: ## ar1 ar2 ar3 intercept ## 0.1158 -0.0187 -0.1042 0.0089 ## s.e. 0.0315 0.0317 0.0317 0.0017 ## ## sigma^2 estimated as 0.002875: log likelihood = 1500.86, aic = -2991.73 # --&gt; phi2有意でない (1-.1158 + .0187 + .1042)*mean(vw) # Compute the intercept phi(0). ## [1] 0.008967611 # m3$coef sqrt(m3$sigma2) # Compute standard error of residuals ## [1] 0.0536189 Box.test(m3$residuals, lag = 12, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: m3$residuals ## X-squared = 16.352, df = 12, p-value = 0.1756 # --&gt; X-squared = 16.352 (pv = 1-pchisq(16.35, 9)) # Compute p value using 12 degrees of freedom ## [1] 0.05992276 # ← カイ2乗分布の自由度12-3 = 9(AR多項式の次数p = 3) (m3 = arima(vw, order = c(3, 0, 0), fixed = c(NA, 0, NA, NA))) ## Warning in arima(vw, order = c(3, 0, 0), fixed = c(NA, 0, NA, NA)): some AR ## parameters were fixed: setting transform.pars = FALSE ## ## Call: ## arima(x = vw, order = c(3, 0, 0), fixed = c(NA, 0, NA, NA)) ## ## Coefficients: ## ar1 ar2 ar3 intercept ## 0.1136 0 -0.1063 0.0089 ## s.e. 0.0313 0 0.0315 0.0017 ## ## sigma^2 estimated as 0.002876: log likelihood = 1500.69, aic = -2993.38 # ← パラメータを推定する場合には&quot;NA&quot;指定: この例では, phi2 = 0 (1-.1136 + .1063)*.0089 # compute phi(0) ## [1] 0.00883503 sqrt(m3$sigma2) # compute residual standard error ## [1] 0.05362832 Box.test(m3$residuals, lag = 12, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: m3$residuals ## X-squared = 16.828, df = 12, p-value = 0.1562 (pv = 1-pchisq(16.83, 10)) ## [1] 0.07821131 # ← カイ2乗分布の自由度12-2 = 10(AR多項式の次数p = 2) p.77 ifl &lt;- file.path(dir_introTS, &#39;m-ibm3dx2608.txt&#39;) da = read.table(ifl, header=T) head(da) ## date ibmrtn vwrtn ewrtn sprtn ## 1 19260130 -0.010381 0.000724 0.023174 0.022472 ## 2 19260227 -0.024476 -0.033374 -0.053510 -0.043956 ## 3 19260331 -0.115591 -0.064341 -0.096824 -0.059113 ## 4 19260430 0.089783 0.038358 0.032946 0.022688 ## 5 19260528 0.036932 0.012172 0.001035 0.007679 ## 6 19260630 0.068493 0.056888 0.050487 0.043184 ew = da$ewrtn (m1 = arima(ew, order = c(0, 0, 9))) # unrestricted model ## ## Call: ## arima(x = ew, order = c(0, 0, 9)) ## ## Coefficients: ## ma1 ma2 ma3 ma4 ma5 ma6 ma7 ma8 ## 0.2144 0.0374 -0.1203 -0.0425 0.0232 -0.0302 0.0482 -0.0276 ## s.e. 0.0316 0.0321 0.0328 0.0336 0.0319 0.0318 0.0364 0.0354 ## ma9 intercept ## 0.1350 0.0122 ## s.e. 0.0323 0.0028 ## ## sigma^2 estimated as 0.005043: log likelihood = 1220.86, aic = -2419.72 # --&gt; 有意でない係数 = 0を指定 (m1 = arima(ew, order = c(0, 0, 9), fixed = c(NA, 0, NA, 0, 0, 0, 0, 0, NA, NA))) ## ## Call: ## arima(x = ew, order = c(0, 0, 9), fixed = c(NA, 0, NA, 0, 0, 0, 0, 0, NA, NA)) ## ## Coefficients: ## ma1 ma2 ma3 ma4 ma5 ma6 ma7 ma8 ma9 intercept ## 0.1909 0 -0.1199 0 0 0 0 0 0.1227 0.0122 ## s.e. 0.0293 0 0.0338 0 0 0 0 0 0.0312 0.0027 ## ## sigma^2 estimated as 0.005097: log likelihood = 1215.61, aic = -2421.22 sqrt(0.005097) ## [1] 0.07139328 Box.test(m1$residuals, lag = 12, type = &#39;Ljung&#39;) # model checking ## ## Box-Ljung test ## ## data: m1$residuals ## X-squared = 17.604, df = 12, p-value = 0.1283 (pv = 1-pchisq(17.6, 9)) # compute p-value after adjusting the d.f. ## [1] 0.04010828 # ← カイ2乗分布の自由度12-3 = 9(AR多項式の次数p = 3) # Out-of-sample prediction (m1 = arima(ew[1:986], order = c(0, 0, 9), fixed = c(NA, 0, NA, 0, 0, 0, 0, 0, NA, NA))) ## ## Call: ## arima(x = ew[1:986], order = c(0, 0, 9), fixed = c(NA, 0, NA, 0, 0, 0, 0, 0, ## NA, NA)) ## ## Coefficients: ## ma1 ma2 ma3 ma4 ma5 ma6 ma7 ma8 ma9 intercept ## 0.1844 0 -0.1206 0 0 0 0 0 0.1218 0.0128 ## s.e. 0.0295 0 0.0338 0 0 0 0 0 0.0312 0.0027 ## ## sigma^2 estimated as 0.005066: log likelihood = 1206.44, aic = -2402.88 predict(m1, 10) # prediction ## $pred ## Time Series: ## Start = 987 ## End = 996 ## Frequency = 1 ## [1] 0.004282626 0.013558874 0.015024191 0.014453445 0.012046343 0.001805558 ## [7] 0.012211538 0.005514814 0.008513456 0.012791824 ## ## $se ## Time Series: ## Start = 987 ## End = 996 ## Frequency = 1 ## [1] 0.07117456 0.07237493 0.07237493 0.07288176 0.07288176 0.07288176 ## [7] 0.07288176 0.07288176 0.07288176 0.07339566 EACF table ifl &lt;- file.path(dir_introTS, &#39;m-3m4608.txt&#39;) da = read.table(ifl, header=T) head(da) ## date rtn ## 1 19460228 -0.077922 ## 2 19460330 0.018592 ## 3 19460430 -0.100000 ## 4 19460531 0.209877 ## 5 19460628 0.005128 ## 6 19460731 0.076531 mmm = log(da$rtn + 1) library(TSA) # Load the package ## ## Attaching package: &#39;TSA&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## acf, arima ## The following object is masked from &#39;package:utils&#39;: ## ## tar m1 = eacf(mmm, 6, 12) # Simplified table ## AR/MA ## 0 1 2 3 4 5 6 7 8 9 10 11 12 ## 0 o o x o o x o o o x o x o ## 1 x o x o o x o o o o o x o ## 2 x x x o o x o o o o o o o ## 3 x x x o o o o o o o o o o ## 4 x o x o o o o o o o o o o ## 5 x x x o x o o o o o o o o ## 6 x x x x x o o o o o o o o print(m1$eacf, digits = 2) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## [1,] -0.056 -0.0380 -0.082 -0.0046 0.01774 0.0821 0.0080 0.0127 -0.03014 ## [2,] -0.474 0.0096 -0.074 -0.0209 0.00196 0.0772 -0.0288 0.0026 -0.00683 ## [3,] -0.383 -0.3476 -0.074 0.0160 -0.00553 0.0772 0.0269 0.0120 0.00045 ## [4,] -0.177 0.1381 0.384 -0.0224 0.00232 0.0419 -0.0232 0.0154 -0.00440 ## [5,] 0.421 0.0287 0.454 -0.0079 0.00071 0.0025 -0.0140 0.0305 0.01159 ## [6,] -0.114 0.2135 0.449 0.0096 0.20242 -0.0063 -0.0038 0.0403 -0.01294 ## [7,] -0.208 -0.2504 0.243 0.3111 0.16745 -0.0388 -0.0034 0.0429 -0.01009 ## [,10] [,11] [,12] [,13] ## [1,] -0.0778 0.0488 0.0909 -0.011 ## [2,] -0.0694 0.0372 0.0938 -0.024 ## [3,] -0.0268 0.0221 0.0428 0.042 ## [4,] -0.0254 0.0185 0.0100 0.043 ## [5,] 0.0042 0.0191 -0.0043 0.013 ## [6,] -0.0123 0.0315 0.0117 0.028 ## [7,] -0.0260 0.0078 0.0106 0.037 # --&gt; ARMA(0, 0)モデル "],["arimasarimaモデル.html", "4 ARIMA/SARIMAモデル 4.1 ARIMA\\((p,d,q)\\)モデルとは 4.2 SARIMA\\((p,d,q)\\times (P,D,Q)_s\\)モデル (周期\\(s\\))とは 4.3 SARIMAモデルのパス生成: パッケージsarimaの利用 4.4 SARIMAモデルの推定・診断 4.5 データ分析例 4.6 外生的トレンドがあるケース", " 4 ARIMA/SARIMAモデル 4.1 ARIMA\\((p,d,q)\\)モデルとは \\(Y_t:=(1-B)^d X_t\\)が, causal ARMA\\((p,q)\\)となる確率過程\\(X_t\\) (\\(d\\)は非負整数), すなわち, \\[ \\phi(B)Y_t = \\theta(B) Z_t \\tag{2}\\] Backward shift operator \\(B\\) AR多項式 \\(\\phi(z)=1 - \\phi_1 z - \\cdots - \\phi_p z^p\\) MA多項式 \\(\\theta(z)=1 + \\theta_1 z + \\cdots + \\theta_q z^q\\) 4.2 SARIMA\\((p,d,q)\\times (P,D,Q)_s\\)モデル (周期\\(s\\))とは \\(Y_t:=(1-B)^d (1-B^s)^D X_t\\)が, 以下で定義されるcausal ARMAとなる確率過程\\(X_t\\) (\\(d,D\\)は非負整数) \\[ \\phi(B)\\Phi(B^s) Y_t = \\theta(B) \\Theta(B^s) Z_t \\tag{2}\\] Backward shift operator \\(B\\) AR多項式 \\(\\phi(z)=1 - \\phi_1 z - \\cdots - \\phi_p z^p\\) MA多項式 \\(\\theta(z)=1 + \\theta_1 z + \\cdots + \\theta_q z^q\\) SAR多項式 \\(\\Phi(z)=1 - \\Phi_1 z - \\cdots - \\Phi_p z^P\\) SMA多項式 \\(\\Theta(z)=1 + \\Theta_1 z + \\cdots + \\Theta_q z^Q\\) 4.3 SARIMAモデルのパス生成: パッケージsarimaの利用 “SAR(1)”モデル (s=12) library(sarima) ## Loading required package: stats4 ## ## Attaching package: &#39;sarima&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## spectrum #par(mfrow = c(3,1)) seed_val &lt;- 10 tlen &lt;- 144 set.seed(seed_val) #x &lt;- sim_sarima(n = tlen, model = list(ar = c(rep(0,11), 0.8))) # 12 seasons x &lt;- sim_sarima(n = tlen, model = list(sar = 0.8, nseasons = 12, sigma2 = 1)) # 12 seasons ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) “SMA(1)”モデル set.seed(seed_val) #x &lt;- sim_sarima(n = tlen, model = list(ma = c(rep(0,11), 0.8))) # 12 seasons x &lt;- sim_sarima(n = tlen,model = list(sma = 0.8, nseasons = 12, sigma2 = 1)) # 12 seasons ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) I(1) モデル (“Random Walk”) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(iorder = 1, sigma2 = 1)) # (1-B)X_t = e_t (random walk) ts.plot(x, type=&quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((0,0,0) \\times (0,1,0)_{12}\\) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(siorder = 1,nseasons = 12, sigma2 = 1)) # (1-B)^{12} X_t = e_t ts.plot(x, type=&quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((0,1,0) \\times (0,1,0)_{12}\\) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(iorder = 1, siorder = 1, nseasons = 12, sigma2 = 1)) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((0,1,0) \\times (0,1,0)_{12}\\)に, 初期値xを指定したシミュレーション x &lt;- sim_sarima(n = tlen, model = list(iorder = 1, siorder = 1, nseasons = 12, sigma2 = 1), x = list(init=AirPassengers[1:13])) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((0,0,0) \\times (1,0,1)_{12}\\) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(sar = 0.4, sma = 0.5, iorder = 0, siorder = 0, nseasons = 12)) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((0,0,1) \\times (1,0,1)_{12}\\) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(ma = 0.7, sar = 0.4, sma = 0.5, iorder = 0, siorder = 0, nseasons = 12)) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((2,1,1) \\times (1,1,1)_{12}\\) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(ar = c(1.2, -0.8), ma = 0.4, sar = 0.3, sma = 0.7, iorder = 1, siorder = 1, nseasons = 12)) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) 4.4 SARIMAモデルの推定・診断 関数arima()は, SARIMAモデルの推定が可能 (一方, 関数arima.sim()はSARIMAモデルのパスを生成できない) 仮に\\((p,d,q)=(2,1,1), (P,D,Q)=(1,1,1), s=12\\)を正しく選んだとすると, (x.fit &lt;- arima(x, order = c(2,1,1), seasonal = list(order = c(1,1,1), period = 12))) ## ## Call: ## arima(x = x, order = c(2, 1, 1), seasonal = list(order = c(1, 1, 1), period = 12)) ## ## Coefficients: ## ar1 ar2 ma1 sar1 sma1 ## 1.2462 -0.8486 0.3504 0.2220 1.0000 ## s.e. 0.0589 0.0558 0.0842 0.0909 0.2598 ## ## sigma^2 estimated as 0.7217: log likelihood = -183.18, aic = 378.35 tsdiag(x.fit, gof = 20) # モデル診断 Box.test(x.fit$residuals,lag = 20,type = &#39;Ljung&#39;) # Ljung-Box検定 ## ## Box-Ljung test ## ## data: x.fit$residuals ## X-squared = 12.586, df = 20, p-value = 0.8944 ※ ARIMAモデル指定の場合には, 定数項パラメータは推定されない (include.meanオプションは無視される) パッケージforecastの利用 モデルの自動選択・推定 forecastの関数auto.arima()は, seasonalオプションによりSARIMAモデルを推定可能 (デフォルトは, seasonal = T) auto.arima() - 一変量時系列データに対してARIMA/SARIMAモデルを適合し, 情報量基準(AIC, AICc, BICの一つ)の下で最良のARIMAモデルを返す - 所与の次数の制約条件の下で, 全ての可能なモデルの中からサーチを実行 - パラメータのデフォルト値: - max.p = 5 # pの最大値 - max.q = 5 # qの最大値 - max.P = 2 # Pの最大値 - max.Q = 2 # Qの最大値 - max.order = 5 # p+q+P+Qの最大値 - max.d = 2 # dの最大値 - max.D = 1 # Dの最大値 require(forecast) ## Loading required package: forecast ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo (x.fit3 &lt;- auto.arima(x)) # AIC/AICc(デフォルト)/BICによりモデルを自動選択&amp;推定 ## Series: x ## ARIMA(4,1,1) with drift ## ## Coefficients: ## ar1 ar2 ar3 ar4 ma1 drift ## 2.2193 -2.3467 1.3199 -0.4084 -0.7300 -3.0955 ## s.e. 0.0898 0.1786 0.1721 0.0780 0.0598 0.4031 ## ## sigma^2 = 14.72: log likelihood = -393.94 ## AIC=801.88 AICc=802.71 BIC=822.62 → モデルは正しく推定はされてはいない. 定数項は大きな値 tsdiag(x.fit3, gof = 20) # モデル診断 Box.test(x.fit3$residuals, lag = 20, type = &#39;Ljung&#39;) # Ljung-Box検定 ## ## Box-Ljung test ## ## data: x.fit3$residuals ## X-squared = 145.11, df = 20, p-value &lt; 2.2e-16 → 季節性も残留 推定モデルを使った予測 x.pred &lt;- forecast(x.fit3, h = 20) plot(x.pred) # 4.5 データ分析例 データセット: bonds bonds {expsmooth} - 米国10年債利回り(年率) , 1994.1〜2004.5, 月次 - データ出所: Hyndman, R.J., Koehler, A.B., Ord, J.K., and Snyder, R.D., (2008). Forecasting with exponential smoothing: the state space approach, Springer. コード出所 (一部改変): # Hyndman and Khandakar (JSS, 2008) https://www.jstatsoft.org/article/view/v027i03 library(forecast) library(expsmooth) # required for the data 季節性成分なしARIMAモデルを適合 # Seasonal成分なし bnd_aafit &lt;- auto.arima(bonds, max.P = 0, max.Q = 0, D = 0, approximation = FALSE) bnd_aafit ## Series: bonds ## ARIMA(0,1,1) ## ## Coefficients: ## ma1 ## 0.322 ## s.e. 0.090 ## ## sigma^2 = 0.05675: log likelihood = 2.38 ## AIC=-0.77 AICc=-0.67 BIC=4.88 → AICc基準 (デフォルト設定) の下で, 次のARIMA\\((0,1,1)\\)モデルを最良モデルとして選択. \\[ X_t = Z_t + 0.322 Z_{t-1} \\] モデル残差のチェック tsdiag(bnd_aafit) 適合ARIMAモデルを使って予測 bnd_fcast &lt;- forecast(bnd_aafit) # 時系列プロット plot(bnd_fcast) 予測値 (点予測) は青線, および, 予測区間は青線を囲む色のついた領域 (デフォルトでは, 内側の濃い色の領域が信頼水準80%, 外側の薄い色が95%) で表示される. 予測の長さは, デフォルトでは, 周期があれば, その2倍, なければ (周期=1) 10 である. 適合結果および予測結果の要約 summary(bnd_fcast) ## ## Forecast method: ARIMA(0,1,1) ## ## Model Information: ## Series: bonds ## ARIMA(0,1,1) ## ## Coefficients: ## ma1 ## 0.322 ## s.e. 0.090 ## ## sigma^2 = 0.05675: log likelihood = 2.38 ## AIC=-0.77 AICc=-0.67 BIC=4.88 ## ## Error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set -0.006475772 0.2363103 0.1948763 -0.1916236 3.544951 0.2414321 ## ACF1 ## Training set -0.01876417 ## ## Forecasts: ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## Jun 2004 4.761471 4.456175 5.066767 4.294561 5.228381 ## Jul 2004 4.761471 4.255410 5.267532 3.987517 5.535425 ## Aug 2004 4.761471 4.114176 5.408766 3.771519 5.751423 ## Sep 2004 4.761471 3.998659 5.524283 3.594850 5.928092 ## Oct 2004 4.761471 3.898468 5.624474 3.441621 6.081321 ## Nov 2004 4.761471 3.808755 5.714187 3.304418 6.218524 ## Dec 2004 4.761471 3.726793 5.796149 3.179067 6.343875 ## Jan 2005 4.761471 3.650862 5.872080 3.062941 6.460001 ## Feb 2005 4.761471 3.579801 5.943141 2.954263 6.568679 ## Mar 2005 4.761471 3.512777 6.010165 2.851758 6.671184 ## Apr 2005 4.761471 3.449172 6.073770 2.754483 6.768459 ## May 2005 4.761471 3.388510 6.134432 2.661709 6.861233 ## Jun 2005 4.761471 3.330418 6.192524 2.572864 6.950078 ## Jul 2005 4.761471 3.274593 6.248349 2.487488 7.035454 ## Aug 2005 4.761471 3.220790 6.302152 2.405203 7.117739 ## Sep 2005 4.761471 3.168803 6.354139 2.325696 7.197246 ## Oct 2005 4.761471 3.118461 6.404481 2.248704 7.274238 ## Nov 2005 4.761471 3.069616 6.453326 2.174001 7.348941 ## Dec 2005 4.761471 3.022141 6.500801 2.101396 7.421546 ## Jan 2006 4.761471 2.975929 6.547013 2.030720 7.492222 ## Feb 2006 4.761471 2.930883 6.592059 1.961828 7.561114 ## Mar 2006 4.761471 2.886919 6.636023 1.894592 7.628350 ## Apr 2006 4.761471 2.843963 6.678979 1.828896 7.694046 ## May 2006 4.761471 2.801948 6.720994 1.764640 7.758302 データセット: AirPassengers # データセット: AirPassengers ap &lt;- AirPassengers (デフォルトの制約条件下) SARIMAモデルを選択・適合 ap_aafit &lt;- auto.arima(ap, approximation = FALSE) ap_aafit ## Series: ap ## ARIMA(2,1,1)(0,1,0)[12] ## ## Coefficients: ## ar1 ar2 ma1 ## 0.5960 0.2143 -0.9819 ## s.e. 0.0888 0.0880 0.0292 ## ## sigma^2 = 132.3: log likelihood = -504.92 ## AIC=1017.85 AICc=1018.17 BIC=1029.35 → AICc基準 (デフォルト設定) の下で, 次のARIMA\\((2,1,1)(0,1,0)_{12}\\) モデルを最良モデルとして選択. \\[ (1 - 0.5960 \\phi_1 - 0.2143 \\phi_2) (1 - B) (1 - B^{12}) X_t = Z_t - 0.9819 Z_{t-1} \\] モデル残差のチェック tsdiag(ap_aafit) 適合SARIMAモデルを使って予測 ap_fcast &lt;- forecast(ap_aafit) # 時系列プロット plot(ap_fcast) 24ヶ月先 (デフォルト設定により, 周期\\(s=12 \\times 2\\)倍) まで 予測を行っている. 先の米国債利回りデータと比べても, 予測区間が非常に狭い. 適合結果および予測結果の要約 summary(ap_fcast) ## ## Forecast method: ARIMA(2,1,1)(0,1,0)[12] ## ## Model Information: ## Series: ap ## ARIMA(2,1,1)(0,1,0)[12] ## ## Coefficients: ## ar1 ar2 ma1 ## 0.5960 0.2143 -0.9819 ## s.e. 0.0888 0.0880 0.0292 ## ## sigma^2 = 132.3: log likelihood = -504.92 ## AIC=1017.85 AICc=1018.17 BIC=1029.35 ## ## Error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 1.342306 10.84619 7.867539 0.4206996 2.800458 0.245628 ## ACF1 ## Training set -0.001248451 ## ## Forecasts: ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## Jan 1961 445.6349 430.8903 460.3794 423.0850 468.1847 ## Feb 1961 420.3950 403.0907 437.6993 393.9303 446.8596 ## Mar 1961 449.1983 429.7726 468.6240 419.4892 478.9074 ## Apr 1961 491.8399 471.0269 512.6529 460.0092 523.6706 ## May 1961 503.3944 481.5559 525.2330 469.9953 536.7936 ## Jun 1961 566.8624 544.2637 589.4611 532.3007 601.4242 ## Jul 1961 654.2601 631.0820 677.4383 618.8122 689.7081 ## Aug 1961 638.5974 614.9704 662.2245 602.4629 674.7319 ## Sep 1961 540.8837 516.9028 564.8646 504.2080 577.5593 ## Oct 1961 494.1266 469.8624 518.3908 457.0177 531.2355 ## Nov 1961 423.3327 398.8381 447.8272 385.8715 460.7939 ## Dec 1961 465.5075 440.8228 490.1922 427.7555 503.2595 ## Jan 1962 479.2908 448.9986 509.5830 432.9628 525.6187 ## Feb 1962 454.1768 421.7183 486.6352 404.5359 503.8177 ## Mar 1962 483.0869 448.7343 517.4395 430.5491 535.6247 ## Apr 1962 525.8192 490.1122 561.5262 471.2101 580.4283 ## May 1962 537.4506 500.6862 574.2150 481.2243 593.6769 ## Jun 1962 600.9838 563.3924 638.5753 543.4927 658.4750 ## Jul 1962 688.4369 650.1833 726.6905 629.9331 746.9408 ## Aug 1962 672.8212 634.0292 711.6133 613.4939 732.1485 ## Sep 1962 575.1474 535.9102 614.3845 515.1393 635.1555 ## Oct 1962 528.4241 488.8131 568.0350 467.8443 589.0038 ## Nov 1962 457.6589 417.7292 497.5885 396.5918 518.7259 ## Dec 1962 499.8581 459.6529 540.0633 438.3695 561.3466 4.6 外生的トレンドがあるケース 以下のような引数を使って, 外生的トレンドを指定できる: sim_sarima(): xinterceptオプション arima(), auto.arima(): xregオプション set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(sma = 0.4, ma = 0.4, sar = 0.8, ar = 0.5, nseasons = 12, sigma2 = 1), xintercept = (1:tlen) * 0.05) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) par(mfrow = c(1,1)) モデル次数, 線形トレンドを正しく指定した場合のarima()による適合 (x.fit &lt;- arima(x,order = c(1,0,1), seasonal = list(order = c(1,0,1), period = 12), xreg = 1:tlen)) ## ## Call: ## arima(x = x, order = c(1, 0, 1), seasonal = list(order = c(1, 0, 1), period = 12), ## xreg = 1:tlen) ## ## Coefficients: ## ar1 ma1 sar1 sma1 intercept 1:tlen ## 0.7606 0.1744 0.7531 0.6228 -5.2907 0.3521 ## s.e. 0.0656 0.1134 0.0576 0.0957 3.0592 0.0310 ## ## sigma^2 estimated as 0.9208: log likelihood = -211.59, aic = 437.19 tsdiag(x.fit, gof = 20) # モデル診断 Box.test(x.fit$residuals, lag = 20, type = &#39;Ljung&#39;) # Ljung-Box検定 ## ## Box-Ljung test ## ## data: x.fit$residuals ## X-squared = 11.261, df = 20, p-value = 0.9392 線形トレンドを正しく指定した場合のauto.arima()による適合 require(forecast) (x.fit3 &lt;- auto.arima(x, xreg = 1:tlen)) # AIC/AICc(デフォルト)/BICによりモデルを自動選択&amp;推定 ## Series: x ## Regression with ARIMA(1,0,0) errors ## ## Coefficients: ## ar1 intercept xreg ## 0.8291 -8.3410 0.3737 ## s.e. 0.0485 1.9888 0.0233 ## ## sigma^2 = 4.862: log likelihood = -317.26 ## AIC=642.53 AICc=642.81 BIC=654.41 "],["確率的トレンドと単位根検定.html", "5 確率的トレンドと単位根検定 5.1 確率的トレンド vs 確定的トレンド 5.2 単位根過程と見せかけの回帰 5.3 Augmented Dicky-Fuller (ADF) 検定 5.4 ADF検定以外の検定法", " 5 確率的トレンドと単位根検定 次のような定数項付きのランダムウォークを考える: \\[ X_t = \\beta + X_{t-1} +Z_t, \\quad \\{Z_t\\} \\sim WN(0,\\sigma^2). \\] いま, 定数項\\(\\beta \\ne 0\\)であれば, バイアス有りランダムウォークとも呼ばれる. 時点\\(t=0\\)において初期値\\(X_0=\\alpha\\)からスタートしたとすると, 再帰的代入によって, \\[ X_t = \\alpha + \\beta \\cdot t + \\eta_t \\] のように書ける. ただし, \\(\\eta_t = \\sum_{s=1}^{t} Z_s\\)と定義した (\\(\\sum_{s=1}^{0}=0\\)と表記). すなわち, 定数項\\(\\beta\\)は時点が1ステップ進むことに\\(X_t\\)の期待値が変化する量 (直線の傾き) を, 初期値\\(\\alpha\\)は\\(t=0\\)における\\(X_t\\)の期待値の値 (切片項) を表し, 全体として, \\(\\alpha + \\beta \\cdot t\\)は\\(X_t\\)の確定的な線形トレンドを構成している. 一方, 右辺第3項 \\(\\eta_t\\)は, (定数項なし, 初期値0スタートの) ランダムウォークであり, \\(I(1)\\), あるいは\\(ARIMA(0,1,0)\\)と表記される確定過程のクラスの代表例である. 第3項\\(\\eta_t\\)は, それ自体が確率的トレンドを形成する. 以上のように, 定数項付き (\\(\\beta \\ne 0\\)) のランダムウォークは, 線形トレンド部分と確率的トレンド部分を同時に持っている. 一方, 定数項なし (\\(\\beta = 0\\)) のランダムウォークは, 線形トレンド (傾き) を持たず確率的トレンドのみを持つが, 初期値(\\(X_0=\\alpha\\))の値だけ\\(y\\)軸方向にシフト (切片項) する. 次に, この定数項付きのランダムウォークを一般化して「確率的トレンド」モデルとして定義し, 一方, 第3項\\(\\eta_t\\)が (ランダムウォークせず) 確率的トレンドを持たないような「確定的トレンド」モデルとの比較を行う. 5.1 確率的トレンド vs 確定的トレンド -「確定的 (線形) トレンド (deterministic (linear) trend)」モデル \\[ X_{t}={\\color{olive}\\alpha}+\\beta\\cdot t+\\eta_{t}, \\quad \\{\\eta_{t}\\}\\sim\\mathrm{ARMA}(p,q) \\] -「確率的トレンド (stochastic trend)」モデル \\[ X_{t}={\\color{olive}\\alpha}+\\beta\\cdot t+\\eta_{t}, \\quad \\{\\eta_{t}\\}\\sim\\mathrm{ARIMA}(p,1,q) \\] より正確には, この「確率的トレンド」モデルは, 「確定的トレンド」を表す項\\(\\alpha+\\beta\\cdot t\\)と 文字通り「確率的トレンド」をもたらす項\\(\\eta_t\\)の 二つの成分が重なり合って生成されている. 例えば, \\(\\alpha=0,\\beta=0.05,\\phi(z)=1-\\phi_{1}z\\) において, 順に, \\(\\phi_{1}=1,0.98, 0.95\\)の場合について, 同一の乱数を用いて一本のサンプルパスを生成した場合を図示する. (テクニカルな注: 厳密には, いずれのケースも初期値\\(X_0=0\\)からシミュレーションをスタートしているため, 確定的トレンドの二つのケースは, 事象 \\(\\{X_0=0\\}\\)の条件の下での定常性を有する確率過程のサンプルパスである. 一方, 確率的トレンドのケースは初期値の設定有無によらず常に非定常である.) これらの「確定的な(線形トレンド)」モデルと「確率的トレンド」モデルは, モデルの形状は類似しているが, 時系列的な性質は大きく異なる. 特に, 確率的トレンドを持つ場合は, 時間と共に観測時系列の 分散は増大していく一方, それを持たない場合には, 時間を通じて 定常 (分散は一定) であるという違いがある. ある時系列データが, (より正確にはその背後にある確率過程が) 確率的トレンドを持つか否かを定量的に評価する方法が 単位根検定 (unit root test) である. 「確率的トレンド」モデルは, 確定的トレンド部分と確率的トレンド部分を同時に 持っていたが, 私達が手にする実際の時系列データが見かけ上トレンドを 持っている時, それを確定的トレンドの部分と 確率的トレンドの部分に仕分けするのは容易ではない. 単位根検定を実施する際に, 厄介なことに, 確定的線形トレンドを構成するパラメータ 切片項\\(\\alpha\\), 傾き\\(\\beta\\)の有無によって, 単位根検定を行う際の理論的な評価の計算方法が変わる ため, 検定結果がパラメータに関する仮定に依存する という課題が存在している. (正確には, 単位根帰無仮説の下で, 検定統計量が 従う漸近的な確率分布が異なることによって, それより計算される帰無仮説の棄却点が異なる) 例えば, より具体的には, 主要な単位根検定法であるADF検定 (その特別な場合のDF検定)においては, 確定的線形トレンドについて, トレンドが存在しない (\\(\\alpha=\\beta=0\\)), 定数項のみ存在する (\\(\\beta=0\\), \\(\\alpha\\)に制約なし), 定数項および傾きが存在する (\\(\\alpha,\\beta\\)に制約なし), の3ケースについて, 同一の検定統計量が異なる棄却域を持つため, 検定を実施するにあたり確定的トレンドがどのケースに 当てはまるのかを予め指定する必要がある. ところが, \\(\\alpha\\), \\(\\beta\\)が あるか否かは事前に分からない, あるいは, 上の例を見てもデータからは判断が難しいことも多い (グレイの点線がないものとしてプロットを目視してみよう). さらに, 単位根検定は十分な標本サイズの下で行うことが前提となっている. (正確には, 棄却点の評価を行うのに必要な帰無仮説の下での 検定統計量の従う確率分布は, 標本サイズを十分大きくとった場合, すなわち, 漸近分布として得られる) 実践において, ある時系列が単位根過程かどうか判断するには, 単位根検定を行うのと並行して, その時系列が それ自体に対して取引が行われているような 資産価格系列かどうか, すなわち, ランダムウォークするか (トレンドが予測できないような挙動を持つかどうか), あるいは, ある一定水準 (長期的な均衡値) の周りで 平均回帰的 (mean reversion) な性質を持つ系列かどうか など, 対象に関する前提知識や経験を活かすことが 重要である. 5.2 単位根過程と見せかけの回帰 5.2.1 単位根過程 ランダムウォークモデル (I(1))のパス生成 # require(sarima) Tlen &lt;- 100 Seedv &lt;- 1 # set.seed(Seedv) # x &lt;- sim_sarima(n = Tlen, model = list(iorder = 1, sigma2 = 1)) # (1-B)X_t = e_t (random walk) # y &lt;- sim_sarima(n = Tlen, model = list(iorder = 1, sigma2 = 1)) x &lt;- arima.sim(n = Tlen, list(order = c(0, 1, 0))) y &lt;- arima.sim(n = Tlen, list(order = c(0, 1, 0))) # # par(mfrow=c(1,2)) # acf(x) # 自己相関(ACF) # pacf(x) # 偏自己相関(PACF) # matplot(cbind(x, y), type = &quot;l&quot;) ts.plot(cbind(x, y), lty = 1:2) 5.2.2 見せかけの回帰 reslm &lt;- lm(y ~ x) summary(reslm) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.049 -2.862 1.383 3.172 5.519 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.42205 0.68668 0.615 0.54 ## x -0.51303 0.09909 -5.178 1.18e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.752 on 99 degrees of freedom ## Multiple R-squared: 0.2131, Adjusted R-squared: 0.2051 ## F-statistic: 26.81 on 1 and 99 DF, p-value: 1.182e-06 plot(x, y) plot(as.numeric(x), as.numeric(y)) abline(reslm) 5.2.3 見せかけの回帰の判定 library(lmtest) ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric dwtest(reslm) ## ## Durbin-Watson test ## ## data: reslm ## DW = 0.080227, p-value &lt; 2.2e-16 ## alternative hypothesis: true autocorrelation is greater than 0 Durbin-Watson検定 (簡便法) 回帰残差の系列相関の有無を検定 \\(DW \\approx 2(1-\\rho)\\) \\(0&lt;DW&lt;4\\). 無相関 \\(\\Leftrightarrow DW=2\\) 見せかけの回帰の場合. DWが小さい傾向 (正の系列相関) 代替法: Engle-Granger検定 「見せかけの回帰」への対処法については後日扱う. 5.2.4 Rで実行可能な主な単位根検定法 ADF検定: tseries内, adf.test(); fUnitRoots内, unitrootTest(), adfTest() Phillips-Perron(PP)検定: urca内, ur.pp(); tseries内, pp.test() PP検定は, 沖本, pp.118–120参照 KPSS検定: urca内, ur.kpss(); tseries内, kpss.test() KPSS検定は, 福地・伊藤, pp.139–140参照 その他の検定法: fUnitRoots内, urersTest() (Elliott-Rothenberg-Stock検定), urspTest() (Schmidt-Phillips検定), urzaTest() (Zivot-Andrews), 等 5.3 Augmented Dicky-Fuller (ADF) 検定 単位根検定としてもっとも良く用いられるのが Augmented Dicky-Fuller (ADF) 検定である. ADF検定は, 時系列\\(\\{X_t\\}\\)が, 確定的トレンド (線形トレンド) にAR(\\(p\\))に従う誤差を伴って観測されたと想定する: \\[ X_{t}=\\alpha+\\beta\\cdot t+\\eta_{t},\\quad\\eta_{t}=\\phi_{1}\\eta_{t-1}+\\cdots+\\phi_{p}\\eta_{t-p}+Z_{t}\\quad Z_{t}\\sim IID(0,\\sigma^{2})\\qquad(\\eta_{0}=0) \\] これを次式のように変形する: \\[ \\Delta X_{t}=a+bt+\\kappa X_{t-1}+\\sum_{j=1}^{p-1}\\delta_{j}\\Delta X_{t-j}+Z_{t} \\] 但し, \\(\\kappa=1-\\sum_{j=1}^{p}\\phi_{i}, \\,a=-\\kappa\\alpha+\\beta\\sum_{j=1}^{p}j\\phi_{i},\\, b=-\\kappa\\beta.\\) ADF検定は, この\\(\\{\\Delta X_t\\}\\)に対する回帰式の\\(X_{t-1}\\)の係数の大きさに基づいて単位根検定を行う. \\(H_{0}:\\kappa=0\\) (単位根あり) vs. \\(H_{1}:\\kappa&lt;0\\) (単位根なし) ADF (Augmented DF) 検定統計量 (の一つ). OLS推定量 \\(\\hat{\\kappa}\\) を用いて, \\[ ADF=\\frac{\\hat{\\kappa}}{s.e.(\\hat{\\kappa})} \\] ADF検定は, (その特別な場合であるDickey-Fuller検定と同様に) 確定的トレンドの有無により, 3つのモデル, 具体的には, (i) 定数項も1次トレンドも存在しない場合 (\\(a=0,b=0\\)), (ii) 定数項のみ存在する場合 (\\(b=0, a\\)制約なし), (iii) 定数項も1次トレンドも存在する場合 (\\(a,b\\) 制約なし) の3つのケースがあり, 各々のケースにより検定統計量が帰無仮説の下で従う (漸近的) 検定分布が異なるため, 検定結果が異なる可能性のあることに注意が必要である. この\\(\\{\\Delta X_t\\}\\)式におけるラグ次数 (\\(p-1\\)) の大きさは, 例えば, パッケージurcaの関数ur.df()を使えば自動選択することができる. ADF検定は, 標本サイズが十分大きいことを想定しているため, 小標本の時は結果の信頼性が保証されず注意が必要である. 以下では, Rを使って, ADF検定を幾つかのデータセットに対して実行する. パッケージfUnitRoots まず, ADF検定を行う二つのR関数unitrootTest(), adfTest()の実行例を示す. adfTest(): Banerjee&#39;s et al.(93)による検定統計量の計算 unitrootTest(): McKinnons(96) のアプローチによる検定統計量の計算 用法: adfTest(x, lags = 1, type = c(&quot;nc&quot;, &quot;c&quot;, &quot;ct&quot;), title = NULL, description = NULL) unitrootTest(x, lags = 1, type = c(&quot;nc&quot;, &quot;c&quot;, &quot;ct&quot;), title = NULL, description = NULL) 引数: - type: &quot;nc&quot;(定数項・時間トレンド項共なし), &quot;c&quot;(定数項のみ有), &quot;ct&quot;(定数項・時間トレンド項共有) - lags: 誤差項の持つ最大ラグ数 上記シミュレーションデータに対して, ADF検定を実行する. library(fUnitRoots) adfTest(x, type = &quot;nc&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: 0.282 ## P VALUE: ## 0.703 ## ## Description: ## Sun Feb 2 21:06:41 2025 by user: unitrootTest(x, type = &quot;nc&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## DF: 0.282 ## P VALUE: ## t: 0.7657 ## n: 0.7506 ## ## Description: ## Sun Feb 2 21:06:41 2025 by user: → 二つの関数の結果を比較せよ. adfTest(y, type = &quot;nc&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -0.7206 ## P VALUE: ## 0.3835 ## ## Description: ## Sun Feb 2 21:06:41 2025 by user: unitrootTest(y, type = &quot;nc&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## DF: -0.7206 ## P VALUE: ## t: 0.4021 ## n: 0.522 ## ## Description: ## Sun Feb 2 21:06:41 2025 by user: → いずれも, 帰無仮説 (\\(\\phi_1=1\\)) を棄却せず (単位根有り). adfTest(x, type = &quot;c&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -1.4551 ## P VALUE: ## 0.5166 ## ## Description: ## Sun Feb 2 21:06:41 2025 by user: # unitrootTest(x, type = &quot;c&quot;, lags = 1) adfTest(y, type = &quot;c&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -1.0635 ## P VALUE: ## 0.6617 ## ## Description: ## Sun Feb 2 21:06:41 2025 by user: # unitrootTest(y, type = &quot;c&quot;, lags = 1) adfTest(x, type = &quot;c&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -1.4551 ## P VALUE: ## 0.5166 ## ## Description: ## Sun Feb 2 21:06:41 2025 by user: # unitrootTest(x, type = &quot;ct&quot;, lags = 1) adfTest(y, type = &quot;c&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -1.0635 ## P VALUE: ## 0.6617 ## ## Description: ## Sun Feb 2 21:06:41 2025 by user: # unitrootTest(y, type = &quot;ct&quot;, lags = 1) パッケージtseries 次に, パッケージtseries内の関数adf.test()の実行例を示す. 用法: adf.test(x, alternative = c(&quot;stationary&quot;, &quot;explosive&quot;), k = trunc((length(x)-1)^(1/3))) 引数: - ラグ次数k: number of lags in the regression - デフォルト値: trunc((length(x)-1)^(1/3)): the suggested upper bound on the rate (to grow with the sample size for the general ARMA(p,q) setup) - 対立仮説alternative: &quot;stationary&quot;(デフォルト) or &quot;explosive&quot; 検定を行うデータセットは, パッケージquantmodにより取得する株価データ (みずほFG, 証券コード8411) である. - 注) R/RStudioやquantmodのバージョンが更新されていないと, 動かないことがある. library(&#39;quantmod&#39;) ## Loading required package: xts ## Loading required package: TTR ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo yj8411 &lt;- getSymbols(&#39;8411.T&#39;,from = &#39;2020-10-01&#39;, to = &#39;2024-10-31&#39;, src = &quot;yahoo&quot;, auto.assign = FALSE) p8411 &lt;- Ad(yj8411) # 調整後株価 # lnp8411 &lt;- log(Ad(yj8411)) # 対数株価 plot(p8411) par(mfrow = c(1,2)) acf(p8411) pacf(p8411) # acf(diff(p8411), na.action = na.omit) # pacf(diff(p8411),na.action = na.omit) 得られた日次株価データに対してADF検定を実行する. (帰無仮説\\(H_0\\): \\({X_t}\\)は単位根を持つ) # ADF検定 (Augmentd Dicky-Fuller test) # (H0: x has unit root) library(tseries) adf.test(p8411) adf.test(p8411, k = 1) # ← adfTest(p8411, type =&quot;ct&quot;, lags = 1)と同一の結果 adf.test(p8411, k = 1, alternative = &quot;explosive&quot;) # &lt;-- H0 と H1を入替 (→ 同一のDF値. 上行のp値 = 1-下行のp値) ## ## Augmented Dickey-Fuller Test ## ## data: p8411 ## Dickey-Fuller = -1.8837, Lag order = 9, p-value = 0.6275 ## alternative hypothesis: stationary ## ## ## Augmented Dickey-Fuller Test ## ## data: p8411 ## Dickey-Fuller = -2.7558, Lag order = 1, p-value = 0.2584 ## alternative hypothesis: stationary ## ## ## Augmented Dickey-Fuller Test ## ## data: p8411 ## Dickey-Fuller = -2.7558, Lag order = 1, p-value = 0.7416 ## alternative hypothesis: explosive パッケージurca 次に, パッケージurca内の関数ur.df()の実行例を示す. 用法: ur.df(y, type = c(&quot;none&quot;, &quot;drift&quot;, &quot;trend&quot;), lags = 1, selectlags = c(&quot;Fixed&quot;, &quot;AIC&quot;, &quot;BIC&quot;)) データセットは, パッケージexpsmoothに収納されているbondsを使用する. データセット: bonds {expsmooth} - 米国10年債利回り(年率) , 1994.1〜2004.5, 月次 - データ出所 (オリジナル): Hyndman, R.J., Koehler, A.B., Ord, J.K., and Snyder, R.D., (2008), Forecasting with exponential smoothing: the state space approach, Springer. # library(&quot;forecast&quot;) library(&quot;expsmooth&quot;) # required for the data ## Loading required package: forecast plot(bonds) par(mfrow = c(1,2)) acf(bonds) pacf(bonds) まず, ラグ次数 (引数lags) を1に固定した場合 (デフォルト) を実行する. トレンドの指定 (引数type) は, なし(“none”), 切片項のみ(“drift”), 切片項+傾き (“trend”) の3通りの結果を比較してみる. library(urca) ## ## Attaching package: &#39;urca&#39; ## The following objects are masked from &#39;package:fUnitRoots&#39;: ## ## punitroot, qunitroot, unitrootTable # ラグ次数固定 # selectlags = &quot;fixed&quot; (デフォルト) # lags = 1 (デフォルト) ur.df(bonds) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression none ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 - 1 + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.49498 -0.18042 -0.02486 0.18454 0.68176 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## z.lag.1 -0.002436 0.003747 -0.650 0.51690 ## z.diff.lag 0.265314 0.088063 3.013 0.00315 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2408 on 121 degrees of freedom ## Multiple R-squared: 0.07345, Adjusted R-squared: 0.05813 ## F-statistic: 4.796 on 2 and 121 DF, p-value: 0.0099 ## ## ## Value of test-statistic is: -0.65 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau1 -2.58 -1.95 -1.62 ur.df(bonds, type = &quot;drift&quot;) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression drift ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1 + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.50712 -0.18094 -0.04008 0.17625 0.61088 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.17260 0.11527 1.497 0.13692 ## z.lag.1 -0.03166 0.01987 -1.593 0.11371 ## z.diff.lag 0.28483 0.08858 3.216 0.00167 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2395 on 120 degrees of freedom ## Multiple R-squared: 0.08863, Adjusted R-squared: 0.07344 ## F-statistic: 5.835 on 2 and 120 DF, p-value: 0.003816 ## ## ## Value of test-statistic is: -1.5934 1.3345 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau2 -3.46 -2.88 -2.57 ## phi1 6.52 4.63 3.81 ur.df(bonds, type = &quot;trend&quot;) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression trend ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.56296 -0.15468 -0.01879 0.16003 0.60493 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.059755 0.289261 3.664 0.000373 *** ## z.lag.1 -0.143763 0.038789 -3.706 0.000321 *** ## tt -0.003952 0.001190 -3.320 0.001196 ** ## z.diff.lag 0.314505 0.085564 3.676 0.000357 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2301 on 119 degrees of freedom ## Multiple R-squared: 0.1659, Adjusted R-squared: 0.1449 ## F-statistic: 7.889 on 3 and 119 DF, p-value: 7.626e-05 ## ## ## Value of test-statistic is: -3.7062 4.6378 6.8862 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau3 -3.99 -3.43 -3.13 ## phi2 6.22 4.75 4.07 ## phi3 8.43 6.49 5.47 Rコーディング上のヒント: ur.df()は単体では検定結果を表示しないことから, ここでは, tidyverse流コーディングにより, パイプ演算子(%&gt;%)をsummary()と 組合せて, ur.df()の結果をsummary()に流し込んで, 一気に出力するようにした. 次に ラグ次数 (引数lags) を0に固定した場合 (DF検定に対応)を実行する. これはモデル式において, z.diff.lag項がないケースである. # ラグ次数固定 # lags = 0 (DF検定の場合) ← z.diff.lag項なし ur.df(bonds, lags = 0) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression none ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 - 1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.52732 -0.19639 -0.03244 0.21610 0.61778 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## z.lag.1 -0.002344 0.003852 -0.609 0.544 ## ## Residual standard error: 0.2486 on 123 degrees of freedom ## Multiple R-squared: 0.003001, Adjusted R-squared: -0.005104 ## F-statistic: 0.3703 on 1 and 123 DF, p-value: 0.544 ## ## ## Value of test-statistic is: -0.6085 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau1 -2.58 -1.95 -1.62 ur.df(bonds, type = &quot;drift&quot;, lags = 0) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression drift ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.53720 -0.19521 -0.04203 0.21914 0.56585 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.11873 0.11831 1.004 0.318 ## z.lag.1 -0.02246 0.02042 -1.100 0.273 ## ## Residual standard error: 0.2486 on 122 degrees of freedom ## Multiple R-squared: 0.009827, Adjusted R-squared: 0.001711 ## F-statistic: 1.211 on 1 and 122 DF, p-value: 0.2733 ## ## ## Value of test-statistic is: -1.1004 0.6887 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau2 -3.46 -2.88 -2.57 ## phi1 6.52 4.63 3.81 ur.df(bonds, type = &quot;trend&quot;, lags = 0) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression trend ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1 + tt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.58842 -0.17011 -0.01825 0.16278 0.51496 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.910594 0.288463 3.157 0.00201 ** ## z.lag.1 -0.122593 0.038880 -3.153 0.00204 ** ## tt -0.003553 0.001188 -2.991 0.00337 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2408 on 121 degrees of freedom ## Multiple R-squared: 0.07801, Adjusted R-squared: 0.06278 ## F-statistic: 5.119 on 2 and 121 DF, p-value: 0.007342 ## ## ## Value of test-statistic is: -3.1531 3.472 5.1193 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau3 -3.99 -3.43 -3.13 ## phi2 6.22 4.75 4.07 ## phi3 8.43 6.49 5.47 さらに, ラグ次数 (引数lags) を自動選択した場合を実行する. 引数selectlags=\"AIC\"に設定すればAIC基準で, selectlags=\"BIC\"とすればBIC基準で次数選択が行われる. デフォルトは, 上で示したように固定(selectlags=\"fixed\")である. # ラグ次数をAIC基準により自動選択 # selectlags = &quot;AIC&quot; # サーチするラグ次数の最大値lags=10 ur.df(bonds, selectlags = &quot;AIC&quot;, lags = 10) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression none ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 - 1 + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.46513 -0.13370 -0.02074 0.14663 0.60725 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## z.lag.1 -0.006504 0.003876 -1.678 0.0962 . ## z.diff.lag1 0.239620 0.093240 2.570 0.0115 * ## z.diff.lag2 -0.138994 0.098096 -1.417 0.1594 ## z.diff.lag3 0.135671 0.098201 1.382 0.1700 ## z.diff.lag4 0.003777 0.098249 0.038 0.9694 ## z.diff.lag5 -0.227444 0.095012 -2.394 0.0184 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2305 on 108 degrees of freedom ## Multiple R-squared: 0.1504, Adjusted R-squared: 0.1032 ## F-statistic: 3.185 on 6 and 108 DF, p-value: 0.006444 ## ## ## Value of test-statistic is: -1.6781 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau1 -2.58 -1.95 -1.62 出力結果によれば, 確定的トレンドなし(\\(a=0,b=0\\))のケースにおいては,1回差分\\(\\{\\Delta X_t\\}\\)に対する 上記ADF検定の回帰式における\\(\\{\\Delta X_t\\}\\)のラグ次数 (\\(p-1\\)) として, 5が, AIC基準の下で自動選択された. 二つのADF検定統計量tau2, phi1いずれも 有意でない (10%水準に達していない), すなわち, 単位根仮説は棄却されない. ur.df(bonds, type = &quot;drift&quot;, selectlags = &quot;AIC&quot;, lags = 10) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression drift ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1 + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.47654 -0.15143 -0.01987 0.14226 0.55707 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.23568 0.12153 1.939 0.05510 . ## z.lag.1 -0.04696 0.02121 -2.214 0.02894 * ## z.diff.lag1 0.24669 0.09214 2.677 0.00859 ** ## z.diff.lag2 -0.11712 0.09752 -1.201 0.23241 ## z.diff.lag3 0.15712 0.09760 1.610 0.11038 ## z.diff.lag4 0.02585 0.09768 0.265 0.79182 ## z.diff.lag5 -0.19839 0.09501 -2.088 0.03917 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2276 on 107 degrees of freedom ## Multiple R-squared: 0.1665, Adjusted R-squared: 0.1198 ## F-statistic: 3.563 on 6 and 107 DF, p-value: 0.002947 ## ## ## Value of test-statistic is: -2.2141 3.3245 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau2 -3.46 -2.88 -2.57 ## phi1 6.52 4.63 3.81 このケースでは, 切片項 (\\(a\\)) が回帰式に含まれており, 出力結果には”(Interecept)“として推定値や 標準誤差等が表示されている (ただし, \\(b=0\\)). ADF検定統計量tau1は 10%有意ではあるが, 5%有意ではない. すなわち, 有意水準を10%に設定した場合には, 単位根仮説は棄却される. ur.df(bonds, type = &quot;trend&quot;, selectlags = &quot;AIC&quot;, lags = 10) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression trend ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.52136 -0.16195 -0.03909 0.14174 0.61941 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.081602 0.323598 3.342 0.001142 ** ## z.lag.1 -0.154046 0.042816 -3.598 0.000486 *** ## tt -0.003555 0.001339 -2.655 0.009129 ** ## z.diff.lag1 0.300752 0.091537 3.286 0.001373 ** ## z.diff.lag2 -0.099373 0.095099 -1.045 0.298386 ## z.diff.lag3 0.244475 0.094637 2.583 0.011123 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2239 on 108 degrees of freedom ## Multiple R-squared: 0.1853, Adjusted R-squared: 0.1476 ## F-statistic: 4.914 on 5 and 108 DF, p-value: 0.0004322 ## ## ## Value of test-statistic is: -3.5979 5.095 7.0366 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau3 -3.99 -3.43 -3.13 ## phi2 6.22 4.75 4.07 ## phi3 8.43 6.49 5.47 線形トレンドあり (type = \"trend\") のケースは, それ以外の2ケースと異なり, tau3検定統計量では5%, phi2では10%, phi3では5%の有意水準で, 帰無仮説 (単位根なし) が棄却された. すなわち, 最後の結果は, このデータ期間においては, 確定的な線形トレンド (傾きが一定) に定常ノイズが加わっているモデルで 表現できる可能性 (長期間に渡っての債券利回り=長期金利の低下傾向) を示唆している. 企業成長に従って際限なく増加する可能性のある株価とは異なり, そもそも, 金利は上がっては下がり, 下がっては上がるという 平均回帰的 (mean reversion) な特性を持っている. さらに, 金利市場はマクロ経済環境だけでなく, 金融当局の政策の影響を受け, しかも, 金融政策は一貫性を保つようある程度長期に渡って 維持されることが期待されるものである (頻繁には変更されないものである) から, このような「線形トレンド+定常ノイズ」のモデルによるデータの記述は説得力を持つようにも見えるし, 予測への利用可能性も期待できそうである. しかしながら, もとより, 金融市場データにおいては, 確定的トレンドが長い期間, とりわけ将来にわたって続くことは考えにくいことから, このような推定結果に関する評価や, 将来予測への使用には注意が必要なのは当然である. 以上の例で示した通り, 分析対象の時系列データによっては, 確定トレンドの仮定に依存して, 単位根の有無に関する結論が逆転する可能性がある. 金融市場等, そのデータを生成しているメカニズムや, 外部環境に関する専門知識や経験をフルに活用したモデリングや 分析が求められる. 5.4 ADF検定以外の検定法 Phillips-Perron (PP) 検定, KPSS検定について, 先に使用したみずほFGの日次株価データ (8411) に対して実行する. 上で得られたADF検定の結果と比較してみよう. PP検定やKPSS検定においては, 確定的トレンドは, (i) 定数項のみ, (ii) 定数項+線形トレンド(傾き), の2つのケースがあり (注: ADF検定では3つのケースがあった), 実行に際してどちらかを指定して行う. Phillips-Perron (PP) 検定 PP検定では, 確定的トレンドに加わる誤差項として一般の線形過程を用いる. すなわち, ADF検定のような誤差項のモデル化 (AR(\\(p\\))モデルによるラグ構造の特定) をする必要がない. しかし, 標本数が十分大きくない状況では, PP検定も結果の信頼性の点で問題があることから, モデルに関する事前の情報を 使える場合には, ADF検定の方が望ましいと言える. 5.4.0.1 パッケージtseries内, 関数pp.test() 用法: pp.test(x, alternative = c(&quot;stationary&quot;, &quot;explosive&quot;), type = c(&quot;Z(alpha)&quot;, &quot;Z(t_alpha)&quot;), lshort = TRUE) 主要な引数: - 対立仮説alternative: &quot;stationary&quot;, &quot;explosive&quot; - 検定の種類type: &quot;Z(alpha)&quot;, &quot;Z(t_alpha)&quot; - ラグ次数の打ち切りlshort: T (→ 4(T/100)^(1/4)), F (→ 12(T/100)^(1/4)) ※ 確定的トレンドの仮定は, 定数項+線形トレンド #library(tseries) pp.test(p8411, type = &quot;Z(alpha)&quot;, lshort = T) # デフォルト ## ## Phillips-Perron Unit Root Test ## ## data: p8411 ## Dickey-Fuller Z(alpha) = -10.796, Truncation lag parameter = 7, p-value ## = 0.5075 ## alternative hypothesis: stationary pp.test(p8411, type = &quot;Z(alpha)&quot;, lshort = F) ## ## Phillips-Perron Unit Root Test ## ## data: p8411 ## Dickey-Fuller Z(alpha) = -8.9697, Truncation lag parameter = 21, ## p-value = 0.6094 ## alternative hypothesis: stationary pp.test(p8411, type = &quot;Z(t_alpha)&quot;) ## ## Phillips-Perron Unit Root Test ## ## data: p8411 ## Dickey-Fuller Z(t_alpha) = -2.3166, Truncation lag parameter = 7, ## p-value = 0.4443 ## alternative hypothesis: stationary #pp.test(p8411, alternative = &quot;explosive&quot;) パッケージurca内, 関数ur.pp() 用法: ur.pp(x, type = c(&quot;Z-alpha&quot;, &quot;Z-tau&quot;), model = c(&quot;constant&quot;, &quot;trend&quot;), lags = c(&quot;short&quot;, &quot;long&quot;), use.lag = NULL) 主要な引数: - 確定的トレンドの種類model: &quot;constant&quot;(定数項), &quot;trend&quot;(線形トレンド) - 検定の種類type: &quot;Z-alpha&quot;, &quot;Z-tau&quot; - 誤差修正項のラグ長lag: &quot;short&quot;, &quot;long&quot; library(urca) #lags: ラグの長さの指定. 4(T/100)^(1/4) or 12(T/100)^(1/4) #model: トレンドを持つ(&quot;trend&quot;), 定数項を持つ(&quot;constant&quot;) ur.pp(p8411, type = &quot;Z-alpha&quot;, model = &quot;trend&quot;, lags = &quot;short&quot;) %&gt;% summary() ## ## ################################## ## # Phillips-Perron Unit Root Test # ## ################################## ## ## Test regression with intercept and trend ## ## ## Call: ## lm(formula = y ~ y.l1 + trend) ## ## Residuals: ## Min 1Q Median 3Q Max ## -591.00 -14.39 -1.19 15.50 210.85 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 25.857447 9.507682 2.720 0.00665 ** ## y.l1 0.987238 0.005064 194.936 &lt; 2e-16 *** ## trend 0.030160 0.011434 2.638 0.00848 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 39.77 on 997 degrees of freedom ## Multiple R-squared: 0.9963, Adjusted R-squared: 0.9963 ## F-statistic: 1.342e+05 on 2 and 997 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic, type: Z-alpha is: -10.7961 ## ## aux. Z statistics ## Z-tau-mu 3.3753 ## Z-tau-beta 2.4744 ur.pp(p8411, type = &quot;Z-alpha&quot;, model = &quot;trend&quot;, lags = &quot;long&quot;) %&gt;% summary() ## ## ################################## ## # Phillips-Perron Unit Root Test # ## ################################## ## ## Test regression with intercept and trend ## ## ## Call: ## lm(formula = y ~ y.l1 + trend) ## ## Residuals: ## Min 1Q Median 3Q Max ## -591.00 -14.39 -1.19 15.50 210.85 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 25.857447 9.507682 2.720 0.00665 ** ## y.l1 0.987238 0.005064 194.936 &lt; 2e-16 *** ## trend 0.030160 0.011434 2.638 0.00848 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 39.77 on 997 degrees of freedom ## Multiple R-squared: 0.9963, Adjusted R-squared: 0.9963 ## F-statistic: 1.342e+05 on 2 and 997 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic, type: Z-alpha is: -8.9705 ## ## aux. Z statistics ## Z-tau-mu 4.1289 ## Z-tau-beta 2.3138 ur.pp(p8411, type = &quot;Z-tau&quot;, model = &quot;trend&quot;, lags = &quot;long&quot;) %&gt;% summary() ## ## ################################## ## # Phillips-Perron Unit Root Test # ## ################################## ## ## Test regression with intercept and trend ## ## ## Call: ## lm(formula = y ~ y.l1 + trend) ## ## Residuals: ## Min 1Q Median 3Q Max ## -591.00 -14.39 -1.19 15.50 210.85 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 25.857447 9.507682 2.720 0.00665 ** ## y.l1 0.987238 0.005064 194.936 &lt; 2e-16 *** ## trend 0.030160 0.011434 2.638 0.00848 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 39.77 on 997 degrees of freedom ## Multiple R-squared: 0.9963, Adjusted R-squared: 0.9963 ## F-statistic: 1.342e+05 on 2 and 997 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic, type: Z-tau is: -2.1105 ## ## aux. Z statistics ## Z-tau-mu 4.1289 ## Z-tau-beta 2.3138 ## ## Critical values for Z statistics: ## 1pct 5pct 10pct ## critical values -3.9722 -3.416657 -3.130326 ur.pp(p8411, type = &quot;Z-tau&quot;, model = &quot;constant&quot;) %&gt;% summary() ## ## ################################## ## # Phillips-Perron Unit Root Test # ## ################################## ## ## Test regression with intercept ## ## ## Call: ## lm(formula = y ~ y.l1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -591.69 -14.89 -1.31 15.69 215.76 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.876595 3.817671 0.753 0.451 ## y.l1 0.999589 0.001935 516.511 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 39.89 on 998 degrees of freedom ## Multiple R-squared: 0.9963, Adjusted R-squared: 0.9963 ## F-statistic: 2.668e+05 on 1 and 998 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic, type: Z-tau is: -0.0316 ## ## aux. Z statistics ## Z-tau-mu 0.6446 ## ## Critical values for Z statistics: ## 1pct 5pct 10pct ## critical values -3.439528 -2.864846 -2.568542 Kwiatkowski-Phillips-Schmidt-Shin (KPSS) 検定 KPSS検定は, ADF検定やPP検定とは, 帰無仮説・対立仮説が入れ替わる: \\(H_{0}\\): 確定的トレンド付き定常過程 vs \\(H_{1}\\): 単位根過程 すなわち, \\(H_0\\) を棄却しない場合は, 確定的トレンド付き定常過程 (トレンド定常性) を結論として得ることに注意が必要である. 観測過程が \\(\\{X_{t}\\}=\\)確定的トレンド + ランダムウォーク + 定常過程, すなわち, \\[ X_{t} = \\alpha+\\beta \\cdot t + \\sum_{s=1}^{t}Z_{s} + \\epsilon_{t}, \\, \\{Z_t\\}\\sim IID(0,\\sigma_Z^2) \\] として生成されていると仮定, ランダムウォーク項の有無の検定を\\(Z_t\\)の分散が0か否かを調べることで行う. \\(H_{0}:\\,\\sigma_{Z}^{2}=0\\) (トレンド定常過程) vs \\(H_{1}:\\,\\sigma_{Z}^{2}\\ne0\\) (単位根過程) 具体的には, 確定的トレンド (\\(\\alpha+\\beta t\\)) を説明変数とするOLS回帰によって得られる残差部分和の大きさを使って検定を行う. パッケージurca内, 関数ur.kpss() 用法: ur.kpss(y, type = c(&quot;mu&quot;, &quot;tau&quot;), lags = c(&quot;short&quot;, &quot;long&quot;, &quot;nil&quot;), use.lag = NULL) 主要な引数: - 確定的トレンドの種類type: &quot;mu&quot;(定数項), &quot;tau&quot;(定数項+線形トレンド) - 誤差修正項のラグ長lags: &quot;short&quot;=4(T/100)^(1/4), &quot;long&quot;=12(T/100)^(1/4) ur.kpss(p8411, type = &quot;mu&quot;, lags = &quot;long&quot;) %&gt;% summary() ## ## ####################### ## # KPSS Unit Root Test # ## ####################### ## ## Test is of type: mu with 21 lags. ## ## Value of test-statistic is: 4.1558 ## ## Critical value for a significance level of: ## 10pct 5pct 2.5pct 1pct ## critical values 0.347 0.463 0.574 0.739 ur.kpss(p8411, type = &quot;tau&quot;, lags = &quot;long&quot;) %&gt;% summary() ## ## ####################### ## # KPSS Unit Root Test # ## ####################### ## ## Test is of type: tau with 21 lags. ## ## Value of test-statistic is: 0.9783 ## ## Critical value for a significance level of: ## 10pct 5pct 2.5pct 1pct ## critical values 0.119 0.146 0.176 0.216 ちなみに, forecastパッケージの関数ndiff()は, 時系列データが定常になるのに必要な差分操作の回数を求める関数で, 内部で単位根検定を繰り返し実行する. 用法: ndiffs(x, alpha = 0.05, test = c(&quot;kpss&quot;, &quot;adf&quot;, &quot;pp&quot;), type = c(&quot;level&quot;, &quot;trend&quot;), max.d = 2, ...) - 単位根検定の種類test: KPSS (デフォルト)/ADF/PP - 確定的トレンドの種類type: &quot;level&quot;(定数項のみ)/&quot;trend&quot;(定数項+線形トレンド) "],["長期記憶過程.html", "6 長期記憶過程 6.1 長期記憶過程のシミュレーション 6.2 Hurst指数の推定 6.3 ARFIMAモデルの推定 6.4 ARFIMAモデル: データ分析例 (1) 6.5 ARFIMAモデル: データ分析例 (2)", " 6 長期記憶過程 本章は, 長期記憶性 (long memory) (別名, 長期従属性 (long-range dependence)) を扱う. 長期記憶性は, 為替レート, 為替フォワード・プレミアム, 金利スプレッド, 株式の出来高, オーダー・フロー, ボラティリティなど, 様々な金融時系列において報告されている. 前章までで学んだARIMA(\\(p,d,q\\))モデルにおいて, 定常になるまでの差分の回数を表す\\(d\\)を, 非負の整数\\(d\\)から小数へと拡張したモデル, 自己回帰非整数平均 (Auto-Regressive Fractionally Integrated Moving Average) モデル, 略して, ARFIMA(\\(p,d,q\\)) モデルは, 離散時間の時系列解析における長期記憶過程の一つとして 重要なモデルクラスである. \\(d\\)を小数に取ることで, 長期記憶性を記述することができるようになっている. \\[ \\phi(B)(1-B)^d X_t = \\theta(B) Z_t \\tag{2}, \\quad -0.5&lt;d&lt;0.5\\] ただし, 前章までと同様に, Backward shift operator \\(B\\) AR多項式 \\(\\phi(z)=1 - \\phi_1 z - \\cdots - \\phi_p z^p\\) MA多項式 \\(\\theta(z)=1 + \\theta_1 z + \\cdots + \\theta_q z^q\\) このARFIMA(\\(p,d,q\\))過程は, “差分”パラメータの次数が \\(-1/2 &lt; d &lt; 1/2\\) の範囲の時, 定常 (かつ反転可能) となる. 特別な場合として, ARFIMA(\\(0,d,0\\))モデルがある (非整数和分白色ノイズ, fractionally integrated white noise). \\[ (1-B)^d X_t = Z_t \\tag{2}, \\quad -0.5&lt;d&lt;0.5\\] 一般のARFIMA(\\(p,d,q\\))モデルは, このARFIMA(\\(0,d,0\\))を駆動ノイズ (イノベーション過程) として持つようなARMA(\\(p,q\\))モデルであると解釈することができる. すなわち, \\(W \\sim ARFIMA(0,d,0)\\)とすると, \\((1-B)^d W_t = Z_t\\)であるから, \\[ \\phi(B) X_t = \\theta(B) W_t= \\theta(B) \\frac{Z_t}{(1-B)^d}, \\quad -0.5&lt;d&lt;0.5\\] また, 定常なARMA(\\(p,q\\))モデルに対して, それを1回和分した非定常な過程であるARIMA(\\(p,1,q\\))モデルがあるように, 定常なARFIMA(\\(p,d,q\\))モデル (\\(-1/2&lt;d&lt;1/2\\)) に対して, 非定常なARFIMA(\\(p,1+d,q\\))モデルも存在する. ARFIMAモデルにおける\\(d\\)の大きさの影響を知るには, このARFIMA(\\(p,1+d,q\\))のサンプルパスの持つ確率的トレンドの挙動をみると分かりやすい. すなわち, \\(d\\)大きさにより, 時系列は次のような性質を持つ: \\(0 &lt; d &lt; 1/2\\): ARFIMA(\\(p,d,q\\)): 正の長期従属性, または持続性 (persistency) ARFIMA(\\(p,1+d,q\\)): 持続的なトレンドのサンプルパス \\(-1/2 &lt; d &lt; 0\\): ARFIMA(\\(p,d,q\\)): 負の長期従属性, 反持続性 (anti-persistency) ARFIMA(\\(p,1+d,q\\)): トレンドが持続せず, 素早く平均回帰するようなサンプルパス \\(d = 0\\): ARFIMA(\\(p,d,q\\)) \\(\\equiv\\) ARMA(\\(p,q\\)) (短期記憶のみ) ARFIMA(\\(p,1+d,q\\)) \\(\\equiv\\) ARIMA(\\(p,1,q\\)) 本章ではまた, 長期記憶性を持つ, 連続時間の確率過程のクラス として重要な非整数ブラウン運動 fBM (fractional Brownian motion) についても簡単に触れる. ハースト指数\\(H\\)は, 時系列データの長期記憶性を示す 指標の一つであり, 理論的には, fBMの増分過程 (非整数ガウスノイズ, fGN) に対する長期記憶性を表現する パラメータとして導入される. 上の\\(d\\)の場合分けに対応し, \\(H\\)の大きさにより, \\(1/2 &lt; H &lt; 1\\): fGNに正の長期従属性, または持続性 fBMはトレンドの続くサンプルパス \\(0 &lt; H &lt; 1/2\\): fGNに負の長期従属性, または反持続性 fBMはトレンドが続かない, 素早く反転するサンプルパス \\(H = 1/2\\): fGNは無相関 (独立) fBMは通常のブラウン運動. 過去のサンプルパスと未来のサンプルパスは独立. この\\(H\\)と\\(d\\)の間には, \\(H = d + 1/2\\)なる関係が成立する. 本章では, Rを使用した, 所与の時系列データに対する\\(H\\)の推定方法についても紹介する. 6.1 長期記憶過程のシミュレーション まず, Rパッケージを用い, 長期記憶性を持つ確率過程のサンプルパスを生成し, 視覚的に特徴を捉えてみよう. パッケージfracdiffの利用 ARFIMA(\\(p,d,q\\))過程のシミュレーション パッケージfracdiffに含まれる関数fracdiff.sim()を 使うことで, ARFIMA(\\(p,d,q\\))過程のサンプルパスを生成することができる. ここで, fracdiffにおけるAR/MA多項式は, \\(\\phi(z) = 1 - \\phi_1 z - \\cdots - \\phi_p z^p\\), \\(\\theta(z) = 1 - \\theta_1 z - \\cdots - \\theta_q z^q\\) である. すなわち, MA多項式の各項の符号が講義内の表記と 反対になっていることに注意しよう. まず, ARFIMA(\\(p,d,q\\))過程の長期記憶性を理解するために, AR項やMA項に起因する短期記憶性の影響を排除した, サブクラスであるARFIMA(\\(0,d,0\\))過程の挙動と, これを和分したARFIMA(\\(0,1+d,0\\))過程の挙動をシミュレートする. 持続性の場合 (\\(d=0.4\\)) tlen &lt;- 300 seedv &lt;- 100; set.seed(seedv) library(fracdiff) fds_sim &lt;- fracdiff.sim(tlen, d = 0.4) # -0.5&lt;=d&lt;=0.5 x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(0,d,0)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(0,1+d,0)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 反持続性の場合 (\\(d=-0.4\\)) set.seed(seedv) fds_sim &lt;- fracdiff.sim(tlen, d = -0.4) x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(0,d,0)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(0,1+d,0)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 無相関の場合 (\\(d=0\\)) set.seed(seedv) fds_sim &lt;- fracdiff.sim(tlen, d = 0) x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(0,d,0)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(0,1+d,0)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 次に, AR項やMA項の入っている一般のARFIMA(\\(p,d,q\\))の場合についてシミュレートする. ここでは, \\(p=2,q=1\\)に設定する. また, ここでも, ARFIMA(\\(p,1+d,q\\))のパスも合わせて表示する. 持続性の場合 (\\(d=0.4\\)) tlen &lt;- 300 seedv &lt;- 100; set.seed(seedv) library(fracdiff) fds_sim &lt;- fracdiff.sim(tlen, ar = c(0.7, -0.2), ma = 0.1, d = 0.4) # -0.5&lt;=d&lt;=0.5 x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(p,d,q)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(p,1+d,q)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 反持続性の場合 (\\(d=-0.4\\)) set.seed(seedv) fds_sim &lt;- fracdiff.sim(tlen, ar = c(0.7, -0.2), ma = 0.1, d = -0.4) x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(p,d,q)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(p,1+d,q)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) ARMA/ARIMAの場合 (\\(d=0\\)) set.seed(seedv) fds_sim &lt;- fracdiff.sim(tlen, ar = c(0.7, -0.2), ma = 0.1, d = 0.1) x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(p,d,q)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(p,1+d,q)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) パッケージlongmemoの利用 ARFIMA, 非整数ガウス (fractional Gaussian) 過程の自己共分散関数 - ckARMA0(n, H): ARFIMA(0,d,0) 過程の自己共分散関数の理論計算 (大きなkでは近似) (d = H - 1/2). # install.packages(&quot;longmemo&quot;) library(longmemo) seedv &lt;- 1 tlen &lt;- 100 hval &lt;- 0.9 plot(ckARMA0(tlen, H = hval), type = &quot;h&quot;) # H &gt; 0.5の時のみ plot(x = 0:(tlen - 1), ckARMA0(tlen, H = hval), type = &quot;h&quot;, log = &quot;xy&quot;, main = paste0(&quot;Log-Log ACF for ARFIMA(0,d,0)\\nH = &quot;, hval)) - ckFGN0(n, H): 非整数ガウス過程の自己共分散関数の理論計算 # ckFGN0(n, H) # Compute the Autocovariances of a fractional Gaussian process plot(ckFGN0(tlen, H = hval), type = &quot;h&quot;) # (H &gt; 0.5の時のみ) plot(x = 0:(tlen-1), ckFGN0(tlen, H = hval), type = &quot;h&quot;, log = &quot;xy&quot;, main = paste0(&quot;Log-Log ACF for fGN\\nH = &quot;, hval)) ARFIMA, 非整数ガウス (fractional Gaussian) 過程のシミュレーション シミュレーションを行う関数として, ARFIMA(\\(0,d,0\\))にはsimARMA0()が, 非整数ガウス過程にはsimFGN0が用意されている. seedv &lt;- 1 set.seed(seedv) x1 &lt;- simFGN0(tlen, H = hval) # 非整数ガウス過程 x2 &lt;- simARMA0(tlen, H = hval) # ARFIMA(0,d,0) ts.plot(ts.union(x1, x2), col = 1:2, lty = 1:2, main = paste0(&quot;fGN vs ARFIMA(0,d,0): H = &quot;, hval)) # ts.plot(cbind(x1, x2), col = 1:2, lty = 1:2) 一般のARFIMA(\\(p,d,q\\)) (\\(-1/2&lt;d&lt;1/2\\)) のシミュレーションは, 以下のように, 関数simARMA0()を使ってイノベーション過程を生成し, それをarima.sim()に与えることで実現することもできる (AR/MAパラメータは数値ベクトルで指定する). # ARFIMA(2, 0.3, 1)の実行例 # AR係数: phi_1 = 0.9, phi_2 = -0.5 # MA係数: theta_1 = -0.2 phi &lt;- c(0.9, -0.5) theta &lt;- -0.2 d &lt;- 0.3 x3 &lt;- arima.sim(tlen, model = list(ar = phi, ma = theta), innov= simARMA0(tlen, H = d + 1/2), n.start = length(phi) + length(theta)) plot(x3, main = &quot;ARFIMA(p,d,q)&quot;) 非整数ブラウン運動 (fBM) は, 非整数ガウス過程 (fGN) を増分過程とする確率過程であることから, fGNのサンプルパスを 累積することで, fBMのサンプルパスを得ることができる. fBM_path &lt;- function(tlen = 100, H = 0.5, sd_val = 1) { set.seed(sd_val) cumsum(simFGN0(tlen, H)) } # plot(fBM_path(tlen, hval, seedv), type = &quot;l&quot;, main = &quot;fBM&quot;) Hurst指数を3通り (\\(0.1, 0.5, 0.8\\)) に変えてサンプルパスを生成し, 比較する. # 異なるHの値でのサンプルパスの比較 hvals &lt;- c(0.5, 0.1, 0.8) fBM1 &lt;- fBM_path(tlen, hvals[1], seedv) fBM2 &lt;- fBM_path(tlen, hvals[2], seedv) fBM3 &lt;- fBM_path(tlen, hvals[3], seedv) ts.plot(cbind(fBM1, fBM2, fBM3), col = c(&quot;#111111&quot;, &quot;darkgrey&quot;, &quot;lightgrey&quot;), lty = 1, lwd = c(1, 3, 3), main = paste0(&quot;fBM\\nH = &quot;, paste(hvals, collapse = &quot;,&quot;))) 次に, Hurst指数の推定や, ARFIMAモデルの推定を シミュレーションデータを用いて行う. 6.2 Hurst指数の推定 パッケージpracmaの利用 - hurstexp(): R/S分析によるHurst指数推定 (複数の方法を同時実行) - 出力: - Hs - simplified R over S approach - Hrs - corrected R over S Hurst exponent - He - empirical Hurst exponent - Hal - corrected empirical Hurst exponent - Ht - theoretical Hurst exponent 持続性, 系列無相関 (独立), 反持続性の3つの場合について, \\(H = 0.72, 0.50, 0.43\\) と設定された場合の サンプルパスを使う. x72はpracmaに収録されている予め生成された サンプルパスである. xlmの生成手順は, pracmaの マニュアルに従う. library(pracma) data(brown72) x72 &lt;- brown72 # H = 0.72 xgn &lt;- rnorm(1024) # H = 0.50 xlm &lt;- numeric(1024); xlm[1] &lt;- 0.1 # H = 0.43 for (i in 2:1024) { xlm[i] &lt;- 4 * xlm[i - 1] * (1 - xlm[i - 1]) } 持続性の場合 (\\(H = 0.72\\)) ここで, x72は平均が正の値を持っているため, 累積してfBMのパスを生成する際に 平均値を差し引いて (線形トレンドを除いてから) から可視化する. par(mfrow = c(2,1)) plot(x72, type = &quot;l&quot;, main = &quot;fGN&quot;) plot(cumsum(x72 - mean(x72)), type = &quot;l&quot;, main = &quot;fBM&quot;) ブラウン運動の場合 (\\(H = 0.50\\)) par(mfrow = c(2,1)) plot(xgn, type = &quot;l&quot;, main = &quot;fGN&quot;) plot(cumsum(xgn), type = &quot;l&quot;, main = &quot;fBM&quot;) 反持続性の場合 (\\(H = 0.43\\)) xlmはやはり平均値が正のため, fBMのパスを生成する際に 平均値を差し引いてから可視化する. par(mfrow = c(2,1)) plot(xlm, type = &quot;l&quot;, main = &quot;fGN&quot;) plot(cumsum(xlm - mean(xlm)), type = &quot;l&quot;,main = &quot;fBM&quot;) 各々のパスから推定されるハースト指数は以下の通りである. hurstexp(brown72) # d: smallest box size (default = 50) #&gt; Simple R/S Hurst estimation: 0.6628842 #&gt; Corrected R over S Hurst exponent: 0.7378703 #&gt; Empirical Hurst exponent: 0.6920439 #&gt; Corrected empirical Hurst exponent: 0.6577233 #&gt; Theoretical Hurst exponent: 0.5404756 hurstexp(xgn) #&gt; Simple R/S Hurst estimation: 0.4784489 #&gt; Corrected R over S Hurst exponent: 0.4898617 #&gt; Empirical Hurst exponent: 0.5041802 #&gt; Corrected empirical Hurst exponent: 0.4636032 #&gt; Theoretical Hurst exponent: 0.5404756 hurstexp(xlm) #&gt; Simple R/S Hurst estimation: 0.4762169 #&gt; Corrected R over S Hurst exponent: 0.4722421 #&gt; Empirical Hurst exponent: 0.4872281 #&gt; Corrected empirical Hurst exponent: 0.4460807 #&gt; Theoretical Hurst exponent: 0.5404756 パッケージfractalの利用 library(fractal) x &lt;- x72 hurstSpec(x) RoverS(x) hurstBlock(x, method=&quot;aggAbs&quot;) hurstBlock(x, method=&quot;aggVar&quot;) hurstBlock(x, method=&quot;diffvar&quot;) hurstBlock(x, method=&quot;higuchi&quot;) 6.3 ARFIMAモデルの推定 パッケージforecastの関数arfima()は, ARFIMAモデルの自動選択&amp;パラメータ推定を実行することができる. これについては本章の最後に紹介することとし, その前に, 手動でパラメータの推定を行う方法について幾つか紹介する. パッケージfracdiffの利用 真の確率過程がARFIMA(\\(2,d,0\\)) (\\(d=-0.49\\)) にも拘らず, 誤ってARモデルを選択し, ar()により推定した場合. # library(fracdiff) set.seed(seedv) fds_sim &lt;- fracdiff.sim(tlen, ar = c(0.7, -0.2), d = -0.49) x &lt;- fds_sim$series # 長期記憶系列 # (ar_fit &lt;- ar(x, method = &quot;mle&quot;)) # 最尤法 #&gt; #&gt; Call: #&gt; ar(x = x, method = &quot;mle&quot;) #&gt; #&gt; Coefficients: #&gt; 1 2 3 4 5 6 #&gt; 0.2060 -0.2321 -0.2082 -0.1717 -0.1534 -0.1875 #&gt; #&gt; Order selected 6 sigma^2 estimated as 0.7814 → 大きい\\(p\\)を選択 パッケージfracdiff内の関数fracdiff()により, AR係数, MA係数, 階差次数\\(d\\)を最尤推定する (以下, \\(p=2\\)を正しくしていたと仮定). # nar, nma # AR, MAパラメーター数 (fds_fit &lt;- fracdiff(x, nar = 2)) #&gt; #&gt; Call: #&gt; fracdiff(x = x, nar = 2) #&gt; #&gt; Coefficients: #&gt; d ar1 ar2 #&gt; 4.583013e-05 3.478729e-01 -2.143891e-01 #&gt; sigma[eps] = 0.9577181 #&gt; a list with components: #&gt; [1] &quot;log.likelihood&quot; &quot;n&quot; &quot;msg&quot; &quot;d&quot; #&gt; [5] &quot;ar&quot; &quot;ma&quot; &quot;covariance.dpq&quot; &quot;fnormMin&quot; #&gt; [9] &quot;sigma&quot; &quot;stderror.dpq&quot; &quot;correlation.dpq&quot; &quot;h&quot; #&gt; [13] &quot;d.tol&quot; &quot;M&quot; &quot;hessian.dpq&quot; &quot;length.w&quot; #&gt; [17] &quot;residuals&quot; &quot;fitted&quot; &quot;call&quot; → 通常は\\(p,q\\)は未知 → 引数nar, nmaは複数の候補を試すべき パッケージnsarfimaの利用 パッケージnsarfima内の関数mle.arfima()により, AR係数, MA係数, 階差次数\\(d\\)を最尤推定する. library(nsarfima) # p, q # AR, MAパラメーター数 (arfima_fit &lt;- mle.arfima(x, p = 2)) #&gt; $pars #&gt; mu sig2 d ar.1 ar.2 #&gt; -1.267263e-02 9.022758e-01 5.522776e-08 3.414323e-01 -2.625068e-01 #&gt; #&gt; $std.errs #&gt; mu sig2 d ar.1 ar.2 #&gt; 0.1016556 0.1395288 0.1733823 0.2163811 0.1612114 #&gt; #&gt; $cov.mat #&gt; sig2 d ar.1 ar.2 #&gt; sig2 0.019468294 0.00740705 -0.01170439 -0.004266261 #&gt; d 0.007407050 0.03006142 -0.03229578 -0.021628130 #&gt; ar.1 -0.011704389 -0.03229578 0.04682076 0.024479505 #&gt; ar.2 -0.004266261 -0.02162813 0.02447951 0.025989126 #&gt; #&gt; $fit.obj #&gt; $fit.obj$par #&gt; d ar.1 ar.2 #&gt; 5.522776e-08 3.414323e-01 -2.625068e-01 #&gt; #&gt; $fit.obj$value #&gt; [1] 89.3253 #&gt; #&gt; $fit.obj$counts #&gt; function gradient #&gt; 208 NA #&gt; #&gt; $fit.obj$convergence #&gt; [1] 0 #&gt; #&gt; $fit.obj$message #&gt; NULL #&gt; #&gt; #&gt; $p.val #&gt; [1] 0.8912225 #&gt; #&gt; $residuals #&gt; [1] -0.6764961052 -0.2968632520 -1.2310910722 1.4561378726 -0.0388534504 #&gt; [6] -0.8423204011 0.4686722844 0.4643382756 0.4107973532 -0.4309650411 #&gt; [11] 1.4299789135 -0.0006787575 -0.7857763053 -2.3890626204 1.1014635252 #&gt; [16] -0.3966402031 0.1652482404 1.0616568645 0.7446050471 0.5154245086 #&gt; [21] 0.7564241338 0.4668174692 -0.2693729499 -2.3064083881 0.5227350640 #&gt; [26] -0.4642720829 -0.1309552624 -1.4100725427 -0.2774497899 0.4650877267 #&gt; [31] 1.4649891568 -0.0290343810 0.5782727746 -0.1757284573 -1.4912805335 #&gt; [36] -0.3789621380 -0.4655630075 0.0738483187 1.2914770769 0.8336925539 #&gt; [41] -0.0737873115 -0.2251819617 0.5774490180 0.3286308280 -0.8047251630 #&gt; [46] -0.6986673145 0.2958393665 0.6510135686 -0.1339248247 0.9675384987 #&gt; [51] 0.2259759735 -0.7281405491 0.2716268869 -1.3784731074 1.4943394505 #&gt; [56] 1.7164276897 -0.5272803532 -1.0201592423 0.3729804733 -0.5359889283 #&gt; [61] 2.3350415888 -0.4086512940 0.6924717331 -0.3606512486 -1.0759283895 #&gt; [66] -0.0506511539 -2.1101132511 1.5976097508 -0.1172982949 2.3325016401 #&gt; [71] 0.2254993256 -0.8129057325 0.3788283790 -1.4331970583 -1.3747001462 #&gt; [76] 0.2411732472 -0.5537230862 0.2049218798 0.2004499504 -0.4766722677 #&gt; [81] -0.4042575452 -0.0270582246 1.2728679869 -1.5304518129 0.9624356049 #&gt; [86] 0.2186716228 1.1235112273 -0.3688834767 0.4233844401 0.0726586865 #&gt; [91] -0.6954346528 1.1689570269 0.8808727109 0.5369119812 1.3879840390 #&gt; [96] 0.0879308998 -1.6719344153 -0.8630402713 -1.6381541198 -0.5431240556 ARFIMAモデルの\\(d\\)を (再帰的に) 推定する方法 (ARFIMA(\\(p,d,g\\))過程から生成された) 時系列データ\\(\\{x_t\\}\\)が与えられた時に, 以下の手順に従うことで \\(d\\)を (再帰的に) 推定することができる: \\(x_t\\) (所与) と\\(d\\)の推定値 (初期値) があるとする 推定された\\(d\\)が正しい値ならば, \\(Y_t=(1-B)^d X_t\\)はARMA(\\(p,q\\))過程になるはず \\(x_t\\)より, パス\\(y_t\\)を (近似的に) 生成する (自作関数get_fracdiff_ts()使用) ARMAモデルを生成パス\\(y_t\\)に適合する. 得られる残差系列が白色ノイズか? (納得いくまで) 候補を変えて試す. ※ 参考: Cowpertwait and Metcalfe(2009), Ch.8 長期記憶過程xより非整数階差系列yを生成する自作関数: get_fracdiff_ts &lt;- function(x, d, l = 30) { # l: 項の打ち切り数 n &lt;- length(x) # 1. fdc: (1-B)^d の2項展開係数ベクトルを生成 frac_diff_coeffs &lt;- numeric(l) frac_diff_coeffs[1] &lt;- d for (k in 2:l) { frac_diff_coeffs[k] &lt;- frac_diff_coeffs[k - 1] * (d + 1 - k) / k } # 2. y: 非整数階差分系列 (fractionally differenced series) を生成 frac_diff_series &lt;- numeric(n) for (i in (l + 1):n) { current_sum &lt;- x[i] # 原系列 x for (j in 1:l) { current_sum &lt;- current_sum + ((-1) ^ j) * frac_diff_coeffs[j] * x[i - j] } frac_diff_series[i] &lt;- current_sum } # 3. l+1 以降の系列を返す frac_diff_series &lt;- frac_diff_series[(l + 1):n] return(frac_diff_series) } ここでは, (例示のため) AR(p)モデルに限定. 以下, 上で生成したパス\\(x_t\\)を所与, 得られた\\(d\\)の推定値を初期値として使用. (注: \\(x_t\\)は上で, ARFIMA(\\(2,d,0\\)), \\(d=-0.49\\)により生成されていた) # 先に得られたx, fds_fitをそのまま使用 y &lt;- get_fracdiff_ts(x, fds_fit$d) # {x_t}より非整数階差系列{y_t}を生成 (z_ar &lt;- ar(y)) # ARモデルを適合 #&gt; #&gt; Call: #&gt; ar(x = y) #&gt; #&gt; Coefficients: #&gt; 1 2 3 4 #&gt; 0.2598 -0.0943 -0.1637 -0.2469 #&gt; #&gt; Order selected 4 sigma^2 estimated as 0.8692 ns &lt;- 1 + z_ar$order z &lt;- z_ar$res [ns:length(y)] # z_ar$resの最初のns個は欠損 par(mfcol = c(2, 2)) plot(as.ts(x), ylab = &quot;x&quot;) acf(x) ; acf(y) ; acf(z) Box.test(z, lag = 30, type = &quot;Ljung&quot;) #&gt; #&gt; Box-Ljung test #&gt; #&gt; data: z #&gt; X-squared = 29.658, df = 30, p-value = 0.4833 階差次数\\(d\\)の代替的推定法 パッケージfracdiffにより, Geweke and Porter-Hudak(83), Reisen(94)の代替的な\\(d\\)の推定を行うことができる. これらは, 時系列データのperidogram (スペクトル密度の推定値) をベースにした方法である. # library(fracdiff) # Geweke and Porter-Hudak(83)の方法 (d_GPH &lt;- fdGPH(x)) #&gt; $d #&gt; [1] -0.7167363 #&gt; #&gt; $sd.as #&gt; [1] 0.2935592 #&gt; #&gt; $sd.reg #&gt; [1] 0.2232167 # Reisen(94)の方法 (d_Sper &lt;- fdSperio(x)) #&gt; $d #&gt; [1] -0.6491031 #&gt; #&gt; $sd.as #&gt; [1] 0.1334138 #&gt; #&gt; $sd.reg #&gt; [1] 0.08329104 先のget_fracdiff_ts()を使い\\(\\{y_t\\}\\)を生成し, これが白色ノイズになるかを確認する. # GPH推定値の使用 y &lt;- get_fracdiff_ts(x, d_GPH$d) # {x_t}より非整数階差系列{y_t}を生成 # ARMAモデルの適合に, パッケージforecastのauto.arima()関数使用 library(forecast) (y_fit &lt;- auto.arima(y)) # ARモデルをフィット #&gt; Series: y #&gt; ARIMA(0,0,3) with zero mean #&gt; #&gt; Coefficients: #&gt; ma1 ma2 ma3 #&gt; 0.8403 0.5521 0.2549 #&gt; s.e. 0.1171 0.1411 0.1297 #&gt; #&gt; sigma^2 = 0.8098: log likelihood = -90.83 #&gt; AIC=189.66 AICc=190.27 BIC=198.65 # y_resid &lt;- y_fit$res # par(mfcol = c(1, 2)) # acf(y_resid); pacf(y_resid) # Box.test(y_resid, lag = 30, type = &quot;Ljung&quot;) tsdiag(y_fit) # または accuracy(y_fit) #&gt; ME RMSE MAE MPE MAPE MASE #&gt; Training set 0.1063931 0.8803915 0.7113902 4.33671 171.6947 0.9058205 #&gt; ACF1 #&gt; Training set -0.01454969 checkresiduals(y_fit) #&gt; #&gt; Ljung-Box test #&gt; #&gt; data: Residuals from ARIMA(0,0,3) with zero mean #&gt; Q* = 1.6466, df = 7, p-value = 0.9768 #&gt; #&gt; Model df: 3. Total lags used: 10 ※ よりフォーマルなモデル同定・推定の手順は, 配布資料参照. 6.4 ARFIMAモデル: データ分析例 (1) Tsay, 2.11, pp.119–120 データ&amp;コードの出所: https://sites.google.com/site/econometricsr/home/rcode コードは一部改 # library(fracdiff) ifl &lt;- file.path(dir_introTS, &quot;d-ibm3dx7008.txt&quot;) da &lt;- read.table(ifl, header = T) head(da) #&gt; Date rtn vwretd ewretd sprtrn #&gt; 1 19700102 0.000686 0.012137 0.033450 0.010211 #&gt; 2 19700105 0.009596 0.006375 0.018947 0.004946 #&gt; 3 19700106 0.000679 -0.007233 -0.005776 -0.006848 #&gt; 4 19700107 0.000678 -0.001272 0.003559 -0.002047 #&gt; 5 19700108 0.002034 0.000564 0.002890 0.000540 #&gt; 6 19700109 -0.001353 -0.002797 -0.002923 -0.003021 ew &lt;- abs(da$vwretd) # daily abs ret&#39;s of value-weighted CRSP, 1970--2008 plot(as.ts(ew)) 次数dの推定 # pure fractionally differenced modelに対して(p=0, q=0) # Geweke-Porter-Hudak(83) estimate # (m3 &lt;- fdGPH(da$vwretd)) # d=0.05282 (m3 &lt;- fdGPH(ew)) #&gt; $d #&gt; [1] 0.372226 #&gt; #&gt; $sd.as #&gt; [1] 0.0698385 #&gt; #&gt; $sd.reg #&gt; [1] 0.06868857 → \\(0&lt;d&lt;0.5\\) ∴ 定常, かつ反転可能 (invertible) # Reisen (94) estimate # (m3.2 &lt;- fdSperio(ew)) # 0.3784656 # 最尤法 (nar, nmaの指定必要) # m3.0 &lt;- fracdiff(ew, nar = 0, nma = 0) # デフォルト: nar = 0, nma = 0 # summary(m3.0) # ARFIMA(1,d,1)の最尤推定 m2 &lt;- fracdiff(ew, nar = 1, nma = 1) summary(m2) #&gt; #&gt; Call: #&gt; fracdiff(x = ew, nar = 1, nma = 1) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; d 0.490938 0.007997 61.39 &lt;2e-16 *** #&gt; ar 0.113389 0.005988 18.94 &lt;2e-16 *** #&gt; ma 0.575895 0.005946 96.85 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; sigma[eps] = 0.0065619 #&gt; [d.tol = 0.0001221, M = 100, h = 0.0003742] #&gt; Log likelihood: 3.551e+04 ==&gt; AIC = -71021.02 [4 deg.freedom] coef(m2) #&gt; d ar ma #&gt; 0.4909382 0.1133893 0.5758949 confint(m2) #&gt; 2.5 % 97.5 % #&gt; d 0.4752637 0.5066127 #&gt; ar 0.1016536 0.1251250 #&gt; ma 0.5642407 0.5875491 注: MA係数の符号が, arima()の符号とは反対 Table 6.1: パラメータ推定値 2.5 % 97.5 % d 0.4909382 0.4752637 0.5066127 ar 0.1133893 0.1016536 0.1251250 ma 0.5758949 0.5642407 0.5875491 → dの値, 非定常境界 (d=0.5) に近い set.seed(101) m2_sim &lt;- fracdiff.sim(n = 512, ar = coef(m2)[&quot;ar&quot;], ma = -coef(m2)[&quot;ma&quot;], d = coef(m2)[&quot;d&quot;]) plot(as.ts(m2_sim$series)) hurstexp(ew) # ハースト指数 #&gt; Simple R/S Hurst estimation: 0.7368679 #&gt; Corrected R over S Hurst exponent: 0.8540535 #&gt; Empirical Hurst exponent: 0.9058207 #&gt; Corrected empirical Hurst exponent: 0.8784372 #&gt; Theoretical Hurst exponent: 0.5264069 6.5 ARFIMAモデル: データ分析例 (2) 日次ボラティリティ系列には, 長期記憶性があることが多くの実証分析で報告されている (stylized factsの一つ). ここでは, 実現ボラティリティ (RV) の日次系列に対して ARFIMAモデルの推定を試みる. データセットして, パッケージhighfrequencyに含まれている SPYRMデータセットを用いる. これはSPY (S&amp;P500 ETF)の高頻度 データより計算された日次のリスク・流動性指標を格納している データセットである. SPYRM - realized measuresの日次系列 - データ期間: 1/2/2014--12/31/2019 このSPYRM内の要素RV5は5分次リターンより計算された実現ボラティリティ (RV) である. 今回はこれに対してARFIMAモデルを適合する. # RV (Realized Volatility): 実現ボラティリティ library(highfrequency) data(SPYRM) # SPY (SPDR S&amp;P500 ETF) head(SPYRM) # realized measuresの日次系列 #&gt; Key: &lt;DT&gt; #&gt; DT RV1 RV5 BPV1 BPV5 medRV1 #&gt; &lt;Date&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; #&gt; 1: 2014-01-02 2.680770e-05 2.570763e-05 2.535726e-05 2.374001e-05 2.454129e-05 #&gt; 2: 2014-01-03 1.584448e-05 1.777932e-05 1.549670e-05 1.670686e-05 1.538273e-05 #&gt; 3: 2014-01-06 2.722618e-05 2.562549e-05 2.179050e-05 1.888701e-05 2.239435e-05 #&gt; 4: 2014-01-07 1.083393e-05 9.949228e-06 1.004319e-05 9.745236e-06 1.058696e-05 #&gt; 5: 2014-01-08 3.111775e-05 2.678386e-05 2.578336e-05 2.347057e-05 2.644604e-05 #&gt; 6: 2014-01-09 2.316577e-05 1.870702e-05 1.977435e-05 1.113170e-05 2.039378e-05 #&gt; medRV5 RK1 RK5 RQ1 RQ5 medRQ1 #&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; #&gt; 1: 1.933930e-05 2.586084e-05 2.639544e-05 0.05341515 0.05426241 0.04728122 #&gt; 2: 1.626439e-05 1.600491e-05 1.634770e-05 0.03020677 0.03037783 0.02960068 #&gt; 3: 1.638726e-05 3.195125e-05 2.586378e-05 0.06205223 0.05000808 0.04193434 #&gt; 4: 9.317152e-06 9.422459e-06 9.962419e-06 0.02134510 0.01695114 0.02069017 #&gt; 5: 2.323985e-05 1.978144e-05 1.942075e-05 0.08892314 0.05380877 0.08233854 #&gt; 6: 1.011690e-05 1.908528e-05 2.138626e-05 0.04709965 0.04329358 0.04527193 #&gt; medRQ5 CLOSE #&gt; &lt;num&gt; &lt;num&gt; #&gt; 1: 0.04728122 182.95 #&gt; 2: 0.02960068 182.80 #&gt; 3: 0.04193434 182.40 #&gt; 4: 0.02069017 183.45 #&gt; 5: 0.08233854 183.53 #&gt; 6: 0.04527193 183.63 # 1/2/2014--12/31/2019 ここでは, RV系列RV5に日付情報DTを加え, 関数as.xts()を使って, xtsクラスの時系列オブジェクトrv5を生成する. xtsオブジェクトにすることのメリットの一つとして, 例えば, 標準的なR関数であるplot()を適用すると, Rは見映えの良い時系列プロットを 作成する. library(xts) # 5分次リターンより計算された実現ボラティリティ (RV) rv5 &lt;- as.xts(SPYRM[, list(DT, RV5)]) * 10000 plot(rv5) 上で解説したように, まず, \\(d\\)の値を日次RV系列rv5より推定してみる. library(fracdiff) # Geweke-Porter-Hudak(83) estimate (d_gph = fdGPH(rv5)) #&gt; $d #&gt; [1] 0.2546147 #&gt; #&gt; $sd.as #&gt; [1] 0.1212817 #&gt; #&gt; $sd.reg #&gt; [1] 0.1234719 # Reisen (94) estimate (d_sperio = fdSperio(rv5)) #&gt; $d #&gt; [1] 0.2959239 #&gt; #&gt; $sd.as #&gt; [1] 0.04815862 #&gt; #&gt; $sd.reg #&gt; [1] 0.06010544 # 最尤法 (nar, nmaの指定必要) (fit_arfima &lt;- fracdiff(rv5, nar = 0, nma = 0)) #&gt; #&gt; Call: #&gt; fracdiff(x = rv5, nar = 0, nma = 0) #&gt; #&gt; Coefficients: #&gt; d #&gt; 0.3452906 #&gt; sigma[eps] = 0.7376825 #&gt; a list with components: #&gt; [1] &quot;log.likelihood&quot; &quot;n&quot; &quot;msg&quot; &quot;d&quot; #&gt; [5] &quot;ar&quot; &quot;ma&quot; &quot;covariance.dpq&quot; &quot;fnormMin&quot; #&gt; [9] &quot;sigma&quot; &quot;stderror.dpq&quot; &quot;correlation.dpq&quot; &quot;h&quot; #&gt; [13] &quot;d.tol&quot; &quot;M&quot; &quot;hessian.dpq&quot; &quot;length.w&quot; #&gt; [17] &quot;residuals&quot; &quot;fitted&quot; &quot;call&quot; # ARFIMA(1,d,1)の最尤推定 fit_arfima2 = fracdiff(rv5, nar = 1, nma = 1) summary(fit_arfima2) #&gt; #&gt; Call: #&gt; fracdiff(x = rv5, nar = 1, nma = 1) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; d 0.15971 0.01091 14.637 &lt;2e-16 *** #&gt; ar 0.74835 0.08420 8.888 &lt;2e-16 *** #&gt; ma 0.56622 0.06213 9.113 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; sigma[eps] = 0.7369145 #&gt; [d.tol = 0.0001221, M = 100, h = 1.755e-05] #&gt; Log likelihood: -1665 ==&gt; AIC = 3337.888 [4 deg.freedom] 最適なARFIMAモデルの選択および推定 パッケージforecastの関数arfima()は, 上記fracdiffの関数fracdiff()とforecastの auto.arima()を組合せて, ARFIMAモデルの自動選択&amp;パラメータ推定を実行することができる. モデル選択基準は, auto.arima()の引数icの選択肢 (“aicc”, “aic”, “bic”) から選ぶことができる (デフォルトは”aicc”). 関数arfima()はxtsオブジェクトをモデル推定する対象データセットとして 想定しない. R操作としては, 関数coredata()を先にrv5適用し, 日付情報を除いたデータの中身 (RV系列) を取り出す必要がある RV (分散表示) # RV fit_rv &lt;- forecast::arfima(coredata(rv5)) summary(fit_rv) #&gt; #&gt; Call: #&gt; forecast::arfima(y = coredata(rv5)) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; d 0.266671 0.009558 27.900 &lt; 2e-16 *** #&gt; ma.ma1 -0.063041 0.027422 -2.299 0.02151 * #&gt; ma.ma2 -0.084791 0.026271 -3.228 0.00125 ** #&gt; ma.ma3 -0.076951 0.026091 -2.949 0.00318 ** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; sigma[eps] = 0.7364955 #&gt; [d.tol = 0.0001221, M = 100, h = 1.755e-05] #&gt; Log likelihood: -1664 ==&gt; AIC = 3338.552 [5 deg.freedom] accuracy(fit_rv) #&gt; ME RMSE MAE MPE MAPE MASE #&gt; Training set -0.0007177275 0.7356355 0.2306756 -69.83532 87.93373 0.9842525 #&gt; ACF1 #&gt; Training set 0.001397451 RV (標準偏差表示) # sqrt(RV5) plot(sqrt(rv5)) fit_sqrtrv &lt;- forecast::arfima(coredata(sqrt(rv5))) summary(fit_sqrtrv) #&gt; #&gt; Call: #&gt; forecast::arfima(y = coredata(sqrt(rv5))) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; d 0.3353183 0.0009209 364.114 &lt; 2e-16 *** #&gt; ar.ar1 -0.2347200 0.0508590 -4.615 3.93e-06 *** #&gt; ar.ar2 0.6560776 0.0584624 11.222 &lt; 2e-16 *** #&gt; ma.ma1 -0.4738122 0.0668987 -7.083 1.42e-12 *** #&gt; ma.ma2 0.4597059 0.0603449 7.618 2.58e-14 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; sigma[eps] = 0.2161109 #&gt; [d.tol = 0.0001221, M = 100, h = 1.787e-06] #&gt; Log likelihood: 168.6 ==&gt; AIC = -325.1244 [6 deg.freedom] accuracy(fit_sqrtrv) #&gt; ME RMSE MAE MPE MAPE MASE #&gt; Training set -0.0004485554 0.2160546 0.136351 -9.742148 25.83164 0.9239617 #&gt; ACF1 #&gt; Training set 0.001251137 対数RV系列 # log(RV5) plot(log(rv5)) fit_lnrv &lt;- forecast::arfima(coredata(log(rv5))) summary(fit_lnrv) #&gt; #&gt; Call: #&gt; forecast::arfima(y = coredata(log(rv5))) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; d 0.422179 0.008266 51.074 &lt; 2e-16 *** #&gt; ar.ar1 0.674953 0.122455 5.512 3.55e-08 *** #&gt; ma.ma1 0.535849 0.103727 5.166 2.39e-07 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; sigma[eps] = 0.5985781 #&gt; [d.tol = 0.0001221, M = 100, h = 1.429e-05] #&gt; Log likelihood: -1355 ==&gt; AIC = 2717.863 [4 deg.freedom] accuracy(fit_rv) #&gt; ME RMSE MAE MPE MAPE MASE #&gt; Training set -0.0007177275 0.7356355 0.2306756 -69.83532 87.93373 0.9842525 #&gt; ACF1 #&gt; Training set 0.001397451 注) fracdiff()のAR/MA多項式は, \\(\\phi(z) = 1 - \\phi_1 z - \\cdots - \\phi_p z^p\\), \\(\\theta(z) = 1 - \\theta_1 z - \\cdots - \\theta_q z^q\\) であることに注意しよう. ARFIMAモデルによる外挿予測 forecastの関数arfima()による適合結果を 関数forecast()に与えることで外挿予測を行うことができる. RV (分散表示) fcast_rv &lt;- forecast(fit_rv, h = 20) autoplot(fcast_rv) RV (標準偏差表示) fcast_sqrtrv &lt;- forecast(fit_sqrtrv, h = 20) autoplot(fcast_sqrtrv) 対数RV系列 fcast_lnrv &lt;- forecast(fit_lnrv, h = 20) autoplot(fcast_lnrv) "],["レジームスイッチングモデル.html", "7 レジーム・スイッチング・モデル 7.1 自己回帰マルコフ・スイッチング・モデル (MSM-AR) 7.2 MSM-ARモデルの適合", " 7 レジーム・スイッチング・モデル 7.1 自己回帰マルコフ・スイッチング・モデル (MSM-AR) パッケージMSwM 出所: Jose A. Sanchez-Espigares and Alberto Lopez-Moreno (2018). “MSwM examples.” サンプルデータ (example): シミュレーションにより生成 \\[y_{t}=\\begin{cases} 8+2x_{t}+\\epsilon_{t}^{(1)} &amp; \\epsilon_{t}^{(1)}\\sim N(0,1),\\quad t=101:150,181:250\\\\ 1+0.9y_{t-1}+\\epsilon_{t}^{(2)} &amp; \\epsilon_{t}^{(2)}\\sim N(0,0.5),\\quad t=1:100,151:180,251:300 \\end{cases}\\] ここで, \\(x_t\\)は外生変数 (共変量). library(MSwM) data(example) #vignette(&quot;examples&quot;) # マニュアル参照 plot(ts(example)) mod &lt;- lm(y ~ x, example) summary(mod) ## ## Call: ## lm(formula = y ~ x, data = example) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.8998 -0.8429 -0.0427 0.7420 4.0337 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.0486 0.1398 64.709 &lt; 2e-16 *** ## x 0.8235 0.2423 3.398 0.00077 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.208 on 298 degrees of freedom ## Multiple R-squared: 0.03731, Adjusted R-squared: 0.03408 ## F-statistic: 11.55 on 1 and 298 DF, p-value: 0.0007701 par(mfrow = c(1, 2)) qqnorm(resid(mod)); qqline(resid(mod), col = 2); acf(resid(mod)) par(mfrow = c(1, 1)) plot(resid(mod), type = &quot;l&quot;); abline(v=c(100, 150, 180, 250), lty = &quot;dotted&quot;, col = &quot;red&quot;) → 単回帰係数は有意. が, 残差は正規分布から乖離&amp; 有意な自己相関が持続 7.2 MSM-ARモデルの適合 - 関数msmFit(): Fitting Markov Switching Models using the EM algorithm - msmFit(object, k, sw, p, data, family, control) - k: numeric, レジーム数 - sw: a logical vector, スイッチングする係数の指定 ← intercept, sigmaはベクトルの両端に配置 - p: integer, AR次数 (デフォルト値=0) - p&gt;0のケース → the last values of sw have to contain the AR coefficients which have switching - family: モデルのクラス (It is only required when the object is a &quot;General linear formula&quot;) 正しいレジーム数 (\\(k=2\\)), 正しいモデル構造を想定出来たものとして推定した場合: mod.mswm &lt;- msmFit(mod, k = 2, p = 1, sw = c(T, T, T, T), control = list(parallel = F)) summary(mod.mswm) ## Markov Switching Model ## ## Call: msmFit(object = mod, k = 2, sw = c(T, T, T, T), p = 1, control = list(parallel = F)) ## ## AIC BIC logLik ## 637.0736 693.479 -312.5368 ## ## Coefficients: ## ## Regime 1 ## --------- ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept)(S) 8.6393 0.7445 11.6042 &lt; 2.2e-16 *** ## x(S) 1.8771 0.3111 6.0338 1.601e-09 *** ## y_1(S) -0.0569 0.0821 -0.6931 0.4882 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9339683 ## Multiple R-squared: 0.2408 ## ## Standardized Residuals: ## Min Q1 Med Q3 Max ## -2.31102193 -0.03317755 0.01034138 0.04509105 2.85245597 ## ## Regime 2 ## --------- ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept)(S) 0.8417 0.3043 2.7660 0.005675 ** ## x(S) -0.0533 0.1482 -0.3596 0.719146 ## y_1(S) 0.9208 0.0306 30.0915 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5034675 ## Multiple R-squared: 0.8375 ## ## Standardized Residuals: ## Min Q1 Med Q3 Max ## -1.5153667011 -0.0906543253 0.0001873641 0.1656717257 1.2020898982 ## ## Transition probabilities: ## Regime 1 Regime 2 ## Regime 1 0.97709116 0.01500272 ## Regime 2 0.02290884 0.98499728 par(mfrow = c(1, 2)) qqnorm(mod.mswm@Fit@error[, 1]); qqline(mod.mswm@Fit@error[, 1], col = 2); qqnorm(mod.mswm@Fit@error[, 2]); qqline(mod.mswm@Fit@error[, 2],col = 2); plot(ts(mod.mswm@Fit@error)) → モデルは2つのレジームを良く検出: 共変量\\(x\\)が有意なレジーム, 1期前ラグ変数\\(y_{t-1}\\)が有意なレジームを推定. 状態推定確率の対角要素(同じレジームに留まる確率)は, いずれも約0.98 レジーム#1にある状態確率の推定値 (smoothed/ filtered probabilities) par(&quot;mar&quot; = c(1, 1, 1, 1)) plotProb(mod.mswm, which = 1) レジーム#2にある状態確率の推定値 (平滑化 (smoothed) 確率, フィルター化 (filtered) 確率) par(&quot;mar&quot; = c(1, 1, 1, 1)) plotProb(mod.mswm, which = 2) 指定のレジームにおける, 反応変数, 説明変数, 状態確率の推定値 (平滑化確率) の同時プロット par(&quot;mar&quot; = c(1, 1, 1, 1)) plotReg(mod.mswm, expl = &quot;x&quot;) "],["garchモデル.html", "8 GARCHモデル 8.1 収益率データとARCH効果 8.2 ARCH/GARCHモデル 8.3 ARCH/GARCHモデルのシミュレーション 8.4 ARCH/GARCHモデルの適合 8.5 GARCHモデル: データ分析例 (Tsay, Ch4)", " 8 GARCHモデル 8.1 収益率データとARCH効果 みずほFG (8411) の日次データを使って, ボラティリティ・クラスタリング (volatility clustering) 現象を確認する. library(quantmod) ## Loading required package: xts ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## Loading required package: TTR ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo # みずほフィナンシャルグループのデータを取得 getSymbols(&quot;8411.T&quot;, src = &quot;yahoo&quot;, from = &quot;2003-03-01&quot;) ## [1] &quot;8411.T&quot; # availability, 200303〜 # 結果の確認 # head(`8411.T`, 3) 日次収益率の計算 (2020年4月1日–2024年3月31日) 時系列プロット mizuho_close &lt;- Ad(`8411.T`) # 2003/3/12-- mizuho_ret &lt;- diff(log(mizuho_close)) # Adjusted price x &lt;- mizuho_ret[&quot;2020-04-01/2024-03-31&quot;] tlen = nrow(x) plot(x) # 日次収益率の自己相関 par(mfrow = c(1,3)) acf(x, main = &quot;return&quot;, xlab = &quot;h&quot;, na.action = na.pass) # 日次収益率2乗の自己相関 acf(x ^ 2, main = &quot;return^2&quot;, xlab = &quot;h&quot;, na.action = na.pass) # 日次絶対収益率の自己相関 acf(abs(x), main = &quot;abs(return)&quot;, xlab = &quot;h&quot;, na.action = na.pass) 収益率系列は自己相関が小さくおおむね 白色ノイズの性質を示している一方, 2乗収益率や絶対収益率は, 非ゼロの 自己相関を持った時系列であることが分かる. ボラティリティには持続性, すなわち, 一旦市場のボラティリティが多くなると 暫くそのような状態が続き, 反対に, ボラティリティが 低下すると暫くそれが続く性質のあることが, 経験的に知られている. 所与の収益率系列データに対して, このようなボラティリティ・クラスタリング現象は, 2乗収益率の自己相関構造 (「ARCH効果」) の有無を調べることで定量的に評価することができる. そして, 金融市場における収益率系列において一般的に観察されるボラティリティ・クラスタリング現象を記述する時系列モデルのクラスとしてEngle (82) によって提案されたのが「ARCHモデル」である. ARCHは, Autoregressive Conditional Heteroskedasticity (自己回帰条件付不均一分散性) の略であり, ARCHモデルを提案したRobert Engleは その功績に対して2003年にノーベル経済学賞を受賞した. Tsayの作成したパッケージMTS内に, ARCH効果を検定する関数archTest()が また, FTSには, ArchTest()が 用意されている. ARCH/GARCHモデルに関するパッケージは たくさんあるので, どのパッケージのどの関数を 使用しているのか注意を払う必要がある. Rコーディング上のヒント: 異なるパッケージが同一の名前を持つ関数を持っている ことがあり, それが原因で, コード作成者が意図した R関数とは異なる別の関数が呼び出され, エラーとなってしまうことがある. これを未然に防ぐためには, 「パッケージ名::関数名」(例, fGarch::volatility()) のシンタックスによってRにどのパッケージ内のR関数かを明示的に指示すると良い. # 例. ラグ$p=5$を指定した場合 # パッケージ**MTS**使用 library(MTS) # archTest() archTest(as.numeric(na.omit(x) - mean(x, na.rm = T)), lag = 5) # MTS内 ## Q(m) of squared series(LM test): ## Test statistic: 72.23538 p-value: 3.508305e-14 ## Rank-based Test: ## Test statistic: 29.85953 p-value: 1.571784e-05 # archTest(as.numeric(na.omit(x)), lag = 5) # MTS内 注) archTest()は, NAを受け付けない. また, 数値ベクトル化して与える必要 # パッケージ**FTS**使用 library(&quot;FinTS&quot;) # ArchTest() ## ## Attaching package: &#39;FinTS&#39; ## The following object is masked from &#39;package:MTS&#39;: ## ## apca ArchTest(x, lags = 5, demean = TRUE) # FinTS内 ## ## ARCH LM-test; Null hypothesis: no ARCH effects ## ## data: x ## Chi-squared = 53.339, df = 5, p-value = 2.865e-10 # ArchTest(x, lags = 5, demean = FALSE) # FinTS 8.2 ARCH/GARCHモデル GARCH（Generalized ARCH）モデルは, Bollerslev (86) によって提案されたARCH(\\(p\\)) モデルを一般化した モデルクラスである. ボラティリティ方程式の右辺に\\(u_t\\)のラグ項 (ARCH項) しか持たないARCH(\\(p\\)) に対して, \\(\\sigma_t^2\\)のラグ項 (GARCH項) を導入することで, 記述力を持ちながら, パラメータ数の少ない (倹約的な) モデルを実現できる. 実践上は, \\(p=1,q=1\\)がごく一般的であり, 時々, \\(p=2\\) や \\(q=2\\) が取られる程度である. GARCH(p,q)モデル ボラティリティ方程式 \\[ \\sigma_t^2=\\omega+\\alpha_1 u_{t-1}^2+\\cdots+\\alpha_p u_{t-p}^2+\\beta_1 \\sigma_{t-1}^2+\\cdots+\\beta_q \\sigma_{t-q}^2\\] 上式内で, 係数\\(\\alpha_i\\)が掛かっている項をARCH項, 係数\\(\\beta_j\\)が掛かっている項をGARCH項と呼ぶ. 文献では, ARCH項の次数は\\(q\\), GARCH項の次数は\\(p\\)が 使われることもあり, その時には, GARCHモデルはGARCH(\\(q,p\\)), GARCH項を持たない (純粋な) ARCHモデルはARCH(\\(q\\))と表記される. GARCHモデリング GARCH（Generalized ARCH）モデルの標準的な構築手順は以下の通りである. 1. 平均収益率のモデル化 &amp; ARCH効果の有無の確認 前処理・探索的分析 資産価格データを収益率系列に変換する 収益率\\(r_t\\)の時系列プロットより, 平均的傾向に時間変動や特定のパターンがあるかを確認する 時系列プロットの目視により, ボラティリティの時間変化 (不均一分散性) やクラスタリング等のパターンの有無を確認する 平均収益率のモデリング 平均収益率のモデルとしてARMAモデル, あるいはその他のモデルを特定し (暫定的に) 適合する (例えば, Tsayにて解説されている”Two-Pass推定法” (p.210): ARCH効果を無視して平均収益率のモデルを推定) ARCH効果の検定 得られた (暫定的な) 残差\\(\\tilde{u}_t=r_t - \\hat{\\mu}_t\\)に対して, ARCH効果の検定 (Lagrange Multiplier検定) を行い有無を確認 → ARCH(\\(p\\))モデルを採用する場合, PACFにより適切なラグ次数\\(p\\)を同定 ARCH効果が確認されれば, GARCHモデルの構築 (ステップ2) へと進む 2. ボラティリティ・モデルの特定 (仕様の設定, スペシフィケーション) 分散方程式 (条件付分散\\(\\sigma_t^2\\)のモデル構造) を特定する GARCH(\\(p,q\\))構造の特定 デフォルトは, GARCH(\\(1,1\\)). 必要に応じて, GARCH(\\(2,1\\))やGARCH(\\(1,2\\))も検討 標準化誤差項\\(\\epsilon_t\\)の従う分布の特定 デフォルトは, 標準正規分布\\(N(0,1)\\) 必要に応じたバリエーションの検討. 非対称性, レバレッジ効果, 長期記憶性が見られる場合, EGARCH, GJR-GARCH, FIGARCHなどのファミリーを検討 3. モデル適合とモデル選択 ステップ2で特定したモデルを収益率データに適合させる. 複数の候補モデルがあれば, その中で最良のモデルを選択する 最尤推定（MLE）によりパラメータ(例, GARCH(1,1)の場合, \\((\\omega,\\alpha_1, \\beta_1)\\))を推定する 標準的には, ボラティリティ方程式のパラメータだけでなく, 平均方程式のパラメータも同時に推定する (R関数の引数として指定) 複数の候補モデルがあれば, その中から最良のGARCHモデルを選択する 情報量基準 (AICc, BIC等) 尤度比検定: 入れ子構造を持つモデルを比較し、追加パラメータがモデル適合性を改善するかを確認 ※ ここで一つに絞り込まずにボラティリティ予測の精度比較で選択することも可 (ステップ5) 4. モデル診断 適合モデルの (標準化済) 残差系列\\(\\{\\tilde{\\epsilon}_t=\\frac{\\tilde{u}_t}{\\hat{\\sigma}_t}\\}\\)を用いて, モデル診断を行う 残差系列に自己相関 (系列従属性) が残っていないか \\(\\{\\tilde{\\epsilon}_t\\}\\)の自己相関の有無 (残差プロット, ACF/PACFのコレログラム, Ljung-Box検定等) \\(\\{\\tilde{\\epsilon}_t^2\\}\\)の自己相関の有無 (残差プロット, ACF/PACFのコレログラム, Ljung-Box検定等) 残差\\(\\epsilon_t\\)に関する分布の仮定が適切だったか \\(\\{\\tilde{\\epsilon}_t\\}\\)の正規性 (Q-Qプロット, Jarque-Bera検定, Shapiro-Wilk検定, Kolmogorov-Smirnov検定等) → 残差に有意な自己相関が残る場合には, モデルの改良を試みる (ステップ2へ戻る) GARCH(\\(p,q\\))の次数を上げる(\\(p,q\\le2\\)) \\(\\epsilon_t\\)の分布の仮定を変更する 別のGARCHファミリーを試みる 外生変数の導入も検討する 5. ボラティリティ予測 得られた適合GARCHモデルを用いてボラティリティ予測を行う 複数のGARCHモデルで予測を行う場合, パフォーマンスを比較する (MSE, MAE等) 6. モデルの見直し・改良 モデル診断が好ましくない結果となった場合や予測精度が不十分な場合などの場合は, モデルの特定 (ステップ2, または, ステップ1)に戻る 8.3 ARCH/GARCHモデルのシミュレーション パッケージfGarchの利用 参考: https://www.rdocumentation.org/packages/fGarch/versions/3042.83.2/topics/garchSim ボラティリティ方程式 \\[ \\sigma_t^2=\\omega+\\alpha_1 u_{t-1}^2+\\cdots+\\alpha_p u_{t-p}^2+\\beta_1 \\sigma_{t-1}^2+\\cdots+\\beta_q \\sigma_{t-q}^2\\] garchSpec() - model: 以下のパラメータをリスト要素して指定: - omega: (分散方程式の) 定数項 (alpha0) (デフォルトは1e-6) - alpha: (同) ARCH項ベクトル (デフォルトは0.1, 次数p=1) - beta: GARCH項ベクトル (デフォルトは0,8, q=1) - cond.dist: &quot;norm&quot;, &quot;ged&quot;, &quot;std&quot;, &quot;snorm&quot;, &quot;sged&quot;, (デフォルトは&quot;norm&quot;) ARCH(p)モデル パラメータ設定例 ボラティリティ方程式 (\\(p=2, q=0\\)): \\(\\omega=10^{-6}\\) (デフォルト), \\(\\alpha_1=0.5, \\alpha_2=0.1\\) seedv &lt;- 10 tlen &lt;- 300 library(fGarch) ## NOTE: Packages &#39;fBasics&#39;, &#39;timeDate&#39;, and &#39;timeSeries&#39; are no longer ## attached to the search() path when &#39;fGarch&#39; is attached. ## ## If needed attach them yourself in your R script by e.g., ## require(&quot;timeSeries&quot;) ## ## Attaching package: &#39;fGarch&#39; ## The following object is masked from &#39;package:TTR&#39;: ## ## volatility # ARCH(2) - use default omega and specify alpha, set beta=0! spec &lt;- garchSpec(model = list(alpha = c(0.5, 0.1), beta = 0)) set.seed(seedv) x &lt;- garchSim(spec, n = tlen) plot(x) par(mfrow = c(1, 2)) acf(x); pacf(x) acf(x ^ 2); pacf(x ^ 2) acf(abs(x)); pacf(abs(x)) GARCH(p,q)モデル パラメータ設定例 ボラティリティ方程式 (次数\\(p=2,q=1\\)): \\(\\omega=10^{-6}\\)(デフォルト), \\(\\alpha_1=0.5, \\alpha_2=0.1, \\beta_1=0.35\\) spec &lt;- garchSpec(model = list(alpha = c(0.5, 0.1), beta = 0.35)) set.seed(seedv) x &lt;- garchSim(spec, n = tlen) plot(x) par(mfrow = c(1, 2)) acf(x); pacf(x) acf(x ^ 2); pacf(x ^ 2) acf(abs(x)); pacf(abs(x)) ARMA(p’,q’)-GARCH(p,q)モデル パラメータ設定例 平均方程式 (\\(p&#39;=1,q&#39;=2\\)): \\(\\phi_1=0.7,\\theta_1=0.3,\\theta_2=-0.3\\) ボラティリティ方程式 (\\(p=1,q=1\\)): \\(\\omega=10^{-6}\\)(デフォルト), \\(\\alpha_1=0.5, \\alpha_2=0.1, \\beta_1=0.35\\) spec &lt;- garchSpec(model = list(ar = 0.7, ma = c(0.3, -0.3), alpha = c(0.5, 0.1), beta = 0.35)) set.seed(seedv) x &lt;- garchSim(spec, n = tlen) plot(x) par(mfrow = c(1, 2)) acf(x); pacf(x) acf(x ^ 2); pacf(x ^ 2) acf(abs(x)); pacf(abs(x)) 8.4 ARCH/GARCHモデルの適合 先に作成したみずほFG (8411) の日次収益率データセットを使い, ARCH/GARCHモデリングを行う. garchFit関数: 1変量ARMA-GARCHモデルを適合 最尤法 ARMAおよびGARCHのモデル次数を引数に与える (デフォルト, GARCH(1,1)) モデルがうまくデータに適合していれば, 得られる (標準済) 残差系列は, おおよそ i.i.dの (正規分布に) 近い挙動をすることが期待される. この性質を使うことでモデルの診断を行うことができる. ARCH効果の検定 ここでは, パッケージFinTSに含まれる関数ArchTest()を使用する. 例. ラグ\\(p=5\\)を指定した場合 # パッケージ**MTS**使用 # library(MTS) # archTest() # archTest(as.numeric(na.omit(x)), lag = 5) # MTS内 # パッケージ**FinTS**使用 library(&quot;FinTS&quot;) # ArchTest() ArchTest(x, lags = 5, demean = TRUE) # FinTS内 ## ## ARCH LM-test; Null hypothesis: no ARCH effects ## ## data: x ## Chi-squared = 164.89, df = 5, p-value &lt; 2.2e-16 → 帰無仮説 (\\(\\alpha_1= \\ldots=\\alpha_{5}=0\\)) を棄却 例. ARCH(5)モデルの適合 fit_ARCH &lt;- garchFit(formula = ~ garch(5, 0), data = x, trace = FALSE, include.mean = TRUE) # fGarch ## Warning in sqrt(diag(fit$cvar)): NaNs produced summary(fit_ARCH) ## ## Title: ## GARCH Modelling ## ## Call: ## garchFit(formula = ~garch(5, 0), data = x, include.mean = TRUE, ## trace = FALSE) ## ## Mean and Variance Equation: ## data ~ garch(5, 0) ## &lt;environment: 0x1360c1e48&gt; ## [data = x] ## ## Conditional Distribution: ## norm ## ## Coefficient(s): ## mu omega alpha1 alpha2 alpha3 alpha4 ## 6.6138e-04 4.4052e-06 5.6620e-01 1.7058e-01 1.0000e-08 1.3281e-01 ## alpha5 ## 1.0000e-08 ## ## Std. Errors: ## based on Hessian ## ## Error Analysis: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 6.614e-04 2.660e-04 2.487 0.0129 * ## omega 4.405e-06 1.106e-06 3.982 6.83e-05 *** ## alpha1 5.662e-01 1.098e-01 5.159 2.48e-07 *** ## alpha2 1.706e-01 7.584e-02 2.249 0.0245 * ## alpha3 1.000e-08 5.446e-02 0.000 1.0000 ## alpha4 1.328e-01 6.695e-02 1.984 0.0473 * ## alpha5 1.000e-08 NaN NaN NaN ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Log Likelihood: ## 1223.356 normalized: 4.077854 ## ## Description: ## Sun Feb 2 21:06:51 2025 by user: ## ## ## Standardised Residuals Tests: ## Statistic p-Value ## Jarque-Bera Test R Chi^2 18.4174412 0.0001001621 ## Shapiro-Wilk Test R W 0.9886304 0.0189144276 ## Ljung-Box Test R Q(10) 149.7077696 0.0000000000 ## Ljung-Box Test R Q(15) 156.9174139 0.0000000000 ## Ljung-Box Test R Q(20) 158.0863031 0.0000000000 ## Ljung-Box Test R^2 Q(10) 11.2902883 0.3353536518 ## Ljung-Box Test R^2 Q(15) 12.9595174 0.6054249059 ## Ljung-Box Test R^2 Q(20) 18.3437964 0.5647719584 ## LM Arch Test R TR^2 12.1603947 0.4328856864 ## ## Information Criterion Statistics: ## AIC BIC SIC HQIC ## -8.109042 -8.022621 -8.110098 -8.074456 resd = residuals(fit_ARCH, standardize = T) # fGarch ts.plot(resd) 残差系列の2乗の偏自己相関を見ることで, 残差系列resdにARCH効果が残っているかを確かめることができる. (すなわち, AR(\\(p\\))モデルの偏自己相関は, ラグ\\(p\\)にて切断が起こるという性質を利用する) par(mfrow = c(1,2)) acf(resd); pacf(resd ^ 2) par(mfrow = c(1, 1)) # tsdiag(fit_ARCH) ## Please install package &#39;goftest&#39; for additional tests # ArchTest(resd, lags = 5, demean = T) 例. GARCH(1,1)モデルの適合 fit_GARCH &lt;- garchFit(formula = ~ garch(1, 1), data = x, trace = FALSE, include.mean = TRUE) # fGarch summary(fit_GARCH) ## ## Title: ## GARCH Modelling ## ## Call: ## garchFit(formula = ~garch(1, 1), data = x, include.mean = TRUE, ## trace = FALSE) ## ## Mean and Variance Equation: ## data ~ garch(1, 1) ## &lt;environment: 0x123cf1ca8&gt; ## [data = x] ## ## Conditional Distribution: ## norm ## ## Coefficient(s): ## mu omega alpha1 beta1 ## 5.5059e-04 4.2320e-06 6.0121e-01 2.5190e-01 ## ## Std. Errors: ## based on Hessian ## ## Error Analysis: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 5.506e-04 2.895e-04 1.902 0.057218 . ## omega 4.232e-06 1.222e-06 3.462 0.000536 *** ## alpha1 6.012e-01 1.083e-01 5.550 2.86e-08 *** ## beta1 2.519e-01 8.526e-02 2.954 0.003132 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Log Likelihood: ## 1223.751 normalized: 4.079169 ## ## Description: ## Sun Feb 2 21:06:51 2025 by user: ## ## ## Standardised Residuals Tests: ## Statistic p-Value ## Jarque-Bera Test R Chi^2 54.1300901 1.761147e-12 ## Shapiro-Wilk Test R W 0.9814896 6.392272e-04 ## Ljung-Box Test R Q(10) 144.3970498 0.000000e+00 ## Ljung-Box Test R Q(15) 152.2310819 0.000000e+00 ## Ljung-Box Test R Q(20) 153.8042641 0.000000e+00 ## Ljung-Box Test R^2 Q(10) 7.7493638 6.533037e-01 ## Ljung-Box Test R^2 Q(15) 9.6087572 8.436022e-01 ## Ljung-Box Test R^2 Q(20) 13.0794732 8.739482e-01 ## LM Arch Test R TR^2 8.2115410 7.683883e-01 ## ## Information Criterion Statistics: ## AIC BIC SIC HQIC ## -8.131670 -8.082287 -8.132020 -8.111907 coef(fit_GARCH) ## mu omega alpha1 beta1 ## 5.505949e-04 4.231971e-06 6.012138e-01 2.518998e-01 resd &lt;- residuals(fit_GARCH, standardize = T) # 標準化残差 tail(resd, 10) ## [1] -0.86077681 -0.97468295 -0.41946506 -0.84915092 -0.78191126 -0.39765003 ## [7] 0.06257979 1.46594118 0.36737687 0.79955945 par(mfcol = c(1, 1)) ts.plot(resd) par(mfrow = c(1,2)) acf(resd); pacf(resd ^ 2) par(mfrow = c(1, 1)) # tsdiag(fit_GARCH) ## Please install package &#39;goftest&#39; for additional tests → ARCHより若干改善? 非正規性残る → 更なる改善の余地有り Tsay, Ch.4を参照のこと ボラティリティ推定値 (内挿予測) # ボラティリティ推定値 vola &lt;- fGarch::volatility(fit_GARCH) # 標準偏差表示, fGarch tail(vola, 10) ## [1] 0.002761729 0.003090444 0.003477479 0.002925302 0.003177623 0.003238359 ## [7] 0.002805460 0.002496619 0.003722264 0.002974284 par(mfcol = c(2, 1)) ts.plot(x); ts.plot(vola) par(mfrow = c(1,1)) \\(l\\)期先予測 (外挿予測) # n.ahead(=20)期先予測 # nx:表示する観測データ数 # 収益率系列xの予測 (&amp; 95%信頼区間) x_pred &lt;- predict(fit_GARCH, n.ahead = 20, plot = TRUE, conf = .95, nx = 300) # ボラティリティのl期先予測値 (標準偏差表示) (v_pred &lt;- x_pred[, &quot;standardDeviation&quot;]) ## [1] 0.003140143 0.003555854 0.003875412 0.004128527 0.004332789 0.004499725 ## [7] 0.004637393 0.004751687 0.004847063 0.004926971 0.004994130 0.005050719 ## [13] 0.005098500 0.005138911 0.005173136 0.005202157 0.005226787 0.005247708 ## [19] 0.005265490 0.005280613 # プロット (実績値&amp;予測値) v_pred &lt;- c(vola[(tlen - 99):tlen], v_pred) #; length(v_pred) plot(v_pred, type = &quot;l&quot;, ylab = &quot;vola&quot;); abline(v = 101, col = &quot;orange&quot;, lty = &quot;dotted&quot;) GARCH(1,1)モデルの\\(l\\)-期先ボラティリティ予測値 \\(T\\): データ期間 (モデル推定に使用) の最終時点 (予測の起点) \\(u_T, \\sigma_T^2\\): モデル適合による時点\\(T\\)における推定値 (所与) \\(l=1\\)のケース: \\[\\sigma_T^2 (1) = \\omega + \\alpha_1 u_T^2 + \\beta_1 \\sigma_T^2\\] \\(l\\ge2\\)のケース: \\[\\sigma_T^2 (l) = \\omega \\frac{1-(\\alpha_1 + \\beta_1)^{l-1}}{1-(\\alpha_1 + \\beta_1)} + (\\alpha_1 + \\beta_1)^{l-1} \\sigma_T^2 (1)\\] 参考: Tsay, pp.200-201 次に, みずほFGのデータセットに対して, 代替パッケージrugarchを使用した GARCHモデルの適合, および予測の例を示す. rugarchの使い方については, この後で紹介する. library(rugarch) ## Loading required package: parallel ## ## Attaching package: &#39;rugarch&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## sigma # モデルの特定: GARCH(1,1)を指定 spec &lt;- ugarchspec(variance.model = list(garchOrder = c(1, 1))) # モデルの適合 fit_GARCH &lt;- ugarchfit(data = x, spec = spec) # 収益率系列, ボラティリティの予測 (→ x_predに2系列を格納) (x_pred &lt;- ugarchforecast(fitORspec = fit_GARCH, n.ahead = 20)) ## ## *------------------------------------* ## * GARCH Model Forecast * ## *------------------------------------* ## Model: sGARCH ## Horizon: 20 ## Roll Steps: 0 ## Out of Sample: 0 ## ## 0-roll forecast [T0=2025-02-01]: ## Series Sigma ## T+1 3.651e-03 0.003180 ## T+2 1.854e-03 0.003277 ## T+3 9.629e-04 0.003367 ## T+4 5.210e-04 0.003453 ## T+5 3.018e-04 0.003533 ## T+6 1.931e-04 0.003609 ## T+7 1.392e-04 0.003682 ## T+8 1.125e-04 0.003750 ## T+9 9.919e-05 0.003816 ## T+10 9.262e-05 0.003878 ## T+11 8.935e-05 0.003937 ## T+12 8.774e-05 0.003993 ## T+13 8.693e-05 0.004047 ## T+14 8.654e-05 0.004098 ## T+15 8.634e-05 0.004147 ## T+16 8.624e-05 0.004194 ## T+17 8.619e-05 0.004239 ## T+18 8.617e-05 0.004282 ## T+19 8.616e-05 0.004324 ## T+20 8.615e-05 0.004363 # 別々に表示 # 収益率系列の予測値 # fitted(x_pred) # x_pred@forecast$seriesFor # 同 # ボラティリティ(条件付標準偏差)の予測値 sigma(x_pred) ## 2025-02-01 ## T+1 0.003180496 ## T+2 0.003276746 ## T+3 0.003367257 ## T+4 0.003452574 ## T+5 0.003533163 ## T+6 0.003609427 ## T+7 0.003681714 ## T+8 0.003750330 ## T+9 0.003815546 ## T+10 0.003877603 ## T+11 0.003936717 ## T+12 0.003993080 ## T+13 0.004046868 ## T+14 0.004098240 ## T+15 0.004147340 ## T+16 0.004194300 ## T+17 0.004239243 ## T+18 0.004282278 ## T+19 0.004323510 ## T+20 0.004363034 # x_pred@forecast$sigmaFor # 同 # plot(x_pred) fGarch::plot(x_pred, which = 1) # plot(x_pred, which = 2) plot(x_pred, which = 3) # plot(x_pred, which = 4) 注) rugarch::rugarchforecast()の出力x_predに対するプロットと, 先のfGarch::predict()の出力x_predとは異なる. パッケージrugarchの利用 - ugarchspec(): 一変量GARCHモデルの特定 (specification) - modelの選択肢: “sGARCH”, “fGARCH”, “eGARCH”, “gjrGARCH”, “apARCH”, “iGARCH”, “csGARCH” - submodelの選択肢(model=“fGARCH”の場合): “GARCH”, “TGARCH”, “AVGARCH”, “NGARCH”, “NAGARCH”, “APARCH”, “GJRGARCH”, “ALL- GARCH”. - distribution.mpdel(イノベーションに用いる条件付確率密度)の選択肢: &quot;norm&quot;, &quot;snorm&quot;(skew-normal), &quot;std&quot;(student t), &quot;sstd&quot;(skew-student), &quot;ged&quot;(generalized error), &quot;sged&quot;(skew-ged), &quot;nig&quot;(normal inverse gaussian), &quot;ghyp&quot;(Generalized Hyperbolic), &quot;jsu&quot;(Johnson&#39;s SU). - ugarchfit(): 一変量GARCHモデルの適合 - solverの選択肢: “nlminb”, “solnp”, “lbfgs”, “gosolnp”, “nloptr” or “hybrid” - 注): 本パッケージでは, &quot;NAGARCH (Nonlinear Asymmetric GARCH)&quot;, &quot;NGARCH (Nonlinear GARCH)&quot;である. Tsay, 4.12で紹介されているEngle and Ng (1993)の&quot;NGARCH (Nonsymmetric GARCH)&quot;は, 前者に対応する. https://www.rdocumentation.org/packages/rugarch/versions/1.4-4 データセット: spyreal - SPDR Standard and Poors 500 Open-Close Daily Return and Realized Kernel Volatility - SPDR(スパイダー) S\\&amp;P500インデックス: 始値-終値(open-close)収益率, 実現カーネル(realized kernel)ボラティリティ. - 期間: 2002-01-02 〜 2008-08-29 - Reference: Hansen, P. R., Huang, Z., and Shek, H. H. (2012). Realized GARCH: a joint model for returns and realized measures of volatility. Journal of Applied Econometrics, 27(6), 877–906. library(rugarch) ## Loading required package: parallel ## ## Attaching package: &#39;rugarch&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## sigma data(spyreal) head(spyreal) ## SPY_OC SPY_RK ## 2002-01-02 0.0051151007 0.010044750 ## 2002-01-03 0.0101514981 0.005342828 ## 2002-01-04 0.0009369278 0.007978535 ## 2002-01-07 -0.0097245499 0.005772834 ## 2002-01-08 -0.0033463500 0.006452759 ## 2002-01-09 -0.0078317023 0.007684824 IARCH(1,1) spec1 &lt;- ugarchspec( variance.model = list(model = &quot;iGARCH&quot;, garchOrder = c(1, 1)), mean.model = list(armaOrder = c(0, 0), include.mean = TRUE), distribution.model = &quot;norm&quot;, fixed.pars = list(omega = 0)) # 平均方程式にARMA(1,1)の場合: mean.model=list(armaOrder = c(1, 1) mod_igarch &lt;- ugarchfit(spec = spec1, data = spyreal[, 1], solver = &#39;hybrid&#39;) mod_igarch ## ## *---------------------------------* ## * GARCH Model Fit * ## *---------------------------------* ## ## Conditional Variance Dynamics ## ----------------------------------- ## GARCH Model : iGARCH(1,1) ## Mean Model : ARFIMA(0,0,0) ## Distribution : norm ## ## Optimal Parameters ## ------------------------------------ ## Estimate Std. Error t value Pr(&gt;|t|) ## mu -0.000028 0.000177 -0.15908 0.8736 ## omega 0.000000 NA NA NA ## alpha1 0.043186 0.006677 6.46763 0.0000 ## beta1 0.956814 NA NA NA ## ## Robust Standard Errors: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu -0.000028 0.000212 -0.13345 0.893837 ## omega 0.000000 NA NA NA ## alpha1 0.043186 0.010297 4.19426 0.000027 ## beta1 0.956814 NA NA NA ## ## LogLikelihood : 5630.331 ## ## Information Criteria ## ------------------------------------ ## ## Akaike -6.7730 ## Bayes -6.7664 ## Shibata -6.7730 ## Hannan-Quinn -6.7705 ## ## Weighted Ljung-Box Test on Standardized Residuals ## ------------------------------------ ## statistic p-value ## Lag[1] 5.479 0.019252 ## Lag[2*(p+q)+(p+q)-1][2] 8.207 0.005702 ## Lag[4*(p+q)+(p+q)-1][5] 10.148 0.008436 ## d.o.f=0 ## H0 : No serial correlation ## ## Weighted Ljung-Box Test on Standardized Squared Residuals ## ------------------------------------ ## statistic p-value ## Lag[1] 0.07752 0.7807 ## Lag[2*(p+q)+(p+q)-1][5] 0.87181 0.8880 ## Lag[4*(p+q)+(p+q)-1][9] 1.85043 0.9221 ## d.o.f=2 ## ## Weighted ARCH LM Tests ## ------------------------------------ ## Statistic Shape Scale P-Value ## ARCH Lag[3] 0.9841 0.500 2.000 0.3212 ## ARCH Lag[5] 1.3879 1.440 1.667 0.6223 ## ARCH Lag[7] 2.0139 2.315 1.543 0.7144 ## ## Nyblom stability test ## ------------------------------------ ## Joint Statistic: 0.1404 ## Individual Statistics: ## mu 0.02297 ## alpha1 0.08852 ## ## Asymptotic Critical Values (10% 5% 1%) ## Joint Statistic: 0.61 0.749 1.07 ## Individual Statistic: 0.35 0.47 0.75 ## ## Sign Bias Test ## ------------------------------------ ## t-value prob sig ## Sign Bias 1.24939 0.2117 ## Negative Sign Bias 0.07504 0.9402 ## Positive Sign Bias 0.78468 0.4328 ## Joint Effect 5.84998 0.1191 ## ## ## Adjusted Pearson Goodness-of-Fit Test: ## ------------------------------------ ## group statistic p-value(g-1) ## 1 20 40.09 0.0031807 ## 2 30 58.61 0.0009158 ## 3 40 63.78 0.0073916 ## 4 50 83.13 0.0016808 ## ## ## Elapsed time : 0.01805997 GJR-GARCH(1,1) spec2 &lt;- ugarchspec( variance.model = list(model = &quot;gjrGARCH&quot;, garchOrder = c(1, 1)), mean.model = list(armaOrder = c(0, 0), include.mean = TRUE), distribution.model = &quot;norm&quot;) mod_gjr &lt;- ugarchfit(spec = spec2, data = spyreal[, 1], solver = &#39;hybrid&#39;) mod_gjr ## ## *---------------------------------* ## * GARCH Model Fit * ## *---------------------------------* ## ## Conditional Variance Dynamics ## ----------------------------------- ## GARCH Model : gjrGARCH(1,1) ## Mean Model : ARFIMA(0,0,0) ## Distribution : norm ## ## Optimal Parameters ## ------------------------------------ ## Estimate Std. Error t value Pr(&gt;|t|) ## mu -0.000232 0.000167 -1.39077 0.16430 ## omega 0.000001 0.000001 1.08402 0.27836 ## alpha1 0.000001 0.001445 0.00088 0.99930 ## beta1 0.945775 0.009517 99.37954 0.00000 ## gamma1 0.091684 0.015390 5.95719 0.00000 ## ## Robust Standard Errors: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu -0.000232 0.000394 -0.588064 0.556489 ## omega 0.000001 0.000003 0.180739 0.856573 ## alpha1 0.000001 0.067568 0.000019 0.999985 ## beta1 0.945775 0.079656 11.873176 0.000000 ## gamma1 0.091684 0.025262 3.629353 0.000284 ## ## LogLikelihood : 5665.742 ## ## Information Criteria ## ------------------------------------ ## ## Akaike -6.8120 ## Bayes -6.7957 ## Shibata -6.8120 ## Hannan-Quinn -6.8059 ## ## Weighted Ljung-Box Test on Standardized Residuals ## ------------------------------------ ## statistic p-value ## Lag[1] 5.707 0.016897 ## Lag[2*(p+q)+(p+q)-1][2] 7.488 0.008842 ## Lag[4*(p+q)+(p+q)-1][5] 8.808 0.018510 ## d.o.f=0 ## H0 : No serial correlation ## ## Weighted Ljung-Box Test on Standardized Squared Residuals ## ------------------------------------ ## statistic p-value ## Lag[1] 3.931 0.0474 ## Lag[2*(p+q)+(p+q)-1][5] 5.298 0.1309 ## Lag[4*(p+q)+(p+q)-1][9] 6.808 0.2158 ## d.o.f=2 ## ## Weighted ARCH LM Tests ## ------------------------------------ ## Statistic Shape Scale P-Value ## ARCH Lag[3] 0.1600 0.500 2.000 0.6892 ## ARCH Lag[5] 0.4441 1.440 1.667 0.9000 ## ARCH Lag[7] 1.9455 2.315 1.543 0.7289 ## ## Nyblom stability test ## ------------------------------------ ## Joint Statistic: 290.3363 ## Individual Statistics: ## mu 0.04567 ## omega 55.56522 ## alpha1 0.23320 ## beta1 0.17887 ## gamma1 0.20104 ## ## Asymptotic Critical Values (10% 5% 1%) ## Joint Statistic: 1.28 1.47 1.88 ## Individual Statistic: 0.35 0.47 0.75 ## ## Sign Bias Test ## ------------------------------------ ## t-value prob sig ## Sign Bias 1.1005 0.2713 ## Negative Sign Bias 0.9316 0.3517 ## Positive Sign Bias 0.5905 0.5550 ## Joint Effect 2.7718 0.4282 ## ## ## Adjusted Pearson Goodness-of-Fit Test: ## ------------------------------------ ## group statistic p-value(g-1) ## 1 20 37.28 0.007323 ## 2 30 53.63 0.003566 ## 3 40 65.89 0.004534 ## 4 50 81.56 0.002401 ## ## ## Elapsed time : 0.1312039 APARCH spec3 &lt;- ugarchspec( variance.model = list(model = &quot;apARCH&quot;, garchOrder = c(1, 1)), mean.model = list(armaOrder = c(0, 0), include.mean = TRUE), distribution.model = &quot;std&quot;) # 一般誤差分布使用の場合: distribution.model=&quot;ged&quot;) mod_aparch &lt;- ugarchfit(spec = spec3, data = spyreal[, 1], solver = &#39;hybrid&#39;) mod_aparch ## ## *---------------------------------* ## * GARCH Model Fit * ## *---------------------------------* ## ## Conditional Variance Dynamics ## ----------------------------------- ## GARCH Model : apARCH(1,1) ## Mean Model : ARFIMA(0,0,0) ## Distribution : std ## ## Optimal Parameters ## ------------------------------------ ## Estimate Std. Error t value Pr(&gt;|t|) ## mu -0.000125 0.000172 -0.72558 0.468095 ## omega 0.000027 0.000031 0.84447 0.398409 ## alpha1 0.041593 0.012343 3.36986 0.000752 ## beta1 0.951154 0.008781 108.32565 0.000000 ## gamma1 1.000000 0.000756 1323.25696 0.000000 ## delta 1.226539 0.100320 12.22626 0.000000 ## shape 15.206077 4.915288 3.09363 0.001977 ## ## Robust Standard Errors: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu -0.000125 NaN NaN NaN ## omega 0.000027 NaN NaN NaN ## alpha1 0.041593 NaN NaN NaN ## beta1 0.951154 NaN NaN NaN ## gamma1 1.000000 NaN NaN NaN ## delta 1.226539 NaN NaN NaN ## shape 15.206077 NaN NaN NaN ## ## LogLikelihood : 5675.851 ## ## Information Criteria ## ------------------------------------ ## ## Akaike -6.8217 ## Bayes -6.7989 ## Shibata -6.8218 ## Hannan-Quinn -6.8133 ## ## Weighted Ljung-Box Test on Standardized Residuals ## ------------------------------------ ## statistic p-value ## Lag[1] 5.897 0.015169 ## Lag[2*(p+q)+(p+q)-1][2] 7.942 0.006702 ## Lag[4*(p+q)+(p+q)-1][5] 9.441 0.012792 ## d.o.f=0 ## H0 : No serial correlation ## ## Weighted Ljung-Box Test on Standardized Squared Residuals ## ------------------------------------ ## statistic p-value ## Lag[1] 4.401 0.03591 ## Lag[2*(p+q)+(p+q)-1][5] 5.693 0.10616 ## Lag[4*(p+q)+(p+q)-1][9] 7.268 0.17774 ## d.o.f=2 ## ## Weighted ARCH LM Tests ## ------------------------------------ ## Statistic Shape Scale P-Value ## ARCH Lag[3] 0.03824 0.500 2.000 0.8450 ## ARCH Lag[5] 0.17686 1.440 1.667 0.9709 ## ARCH Lag[7] 1.85909 2.315 1.543 0.7471 ## ## Nyblom stability test ## ------------------------------------ ## Joint Statistic: NaN ## Individual Statistics: ## mu 0.06091 ## omega 0.10146 ## alpha1 0.19399 ## beta1 0.19340 ## gamma1 NaN ## delta 0.12319 ## shape 0.59096 ## ## Asymptotic Critical Values (10% 5% 1%) ## Joint Statistic: 1.69 1.9 2.35 ## Individual Statistic: 0.35 0.47 0.75 ## ## Sign Bias Test ## ------------------------------------ ## t-value prob sig ## Sign Bias 0.9890 0.3228 ## Negative Sign Bias 1.4526 0.1465 ## Positive Sign Bias 0.8097 0.4182 ## Joint Effect 3.4469 0.3277 ## ## ## Adjusted Pearson Goodness-of-Fit Test: ## ------------------------------------ ## group statistic p-value(g-1) ## 1 20 29.36 0.060532 ## 2 30 41.10 0.067430 ## 3 40 46.74 0.184496 ## 4 50 82.04 0.002153 ## ## ## Elapsed time : 0.8511481 係数の推定値 coef(mod_aparch) ## mu omega alpha1 beta1 gamma1 ## -1.250371e-04 2.655665e-05 4.159318e-02 9.511535e-01 1.000000e+00 ## delta shape ## 1.226539e+00 1.520608e+01 # infocriteria(mod_aparch)[&quot;Akaike&quot;,] infocriteria(mod_aparch) ## ## Akaike -6.821722 ## Bayes -6.798912 ## Shibata -6.821758 ## Hannan-Quinn -6.813268 推定されたボラティリティ系列 # dat &lt;- spyreal[, 1] dat &lt;- spyreal dat$GARCH &lt;- sigma(mod_aparch) プロット library(ggplot2) library(xts) #library(zoo) autoplot(dat) # 時系列プロット # ボラティリティ推定値同士の比較 plot(as.vector(sqrt(dat$SPY_RK)), as.vector(dat$GARCH)) # plot(as.vector(dat$SPY_RK), as.vector(dat$GARCH)) Bootstrap法に基づく予測 GARCHモデルによるn期先予測には2種類の不確実性: 予測確率分布に起因するもの &amp; パラメータ推定誤差に起因するもの. Bootstrap法: 適合GARCHモデルの経験分布よりイノベーションをリサンプルすることで, 将来の時系列(series)と標準偏差(sigma)を生成. “full”法(Pascual et al (2006)): パラメータのシミュレーション分布を発生させることで, パラメータ不確実性を考慮(実行時間がかかる). “partial”法: 分布の不確実性のみ考慮 dat_pred &lt;- ugarchboot(mod_aparch, n.ahead = 30, method = &quot;Partial&quot;) # plot(dat_pred, which = &quot;all&quot;) # 時系列(収益率) plot(dat_pred, which = 2) # 標準偏差(ボラティリティ) plot(dat_pred, which = 3) # which=1は, &quot;full&quot;法のみ (Parameter Density Plots生成) dat_pred ## ## *-----------------------------------* ## * GARCH Bootstrap Forecast * ## *-----------------------------------* ## Model : apARCH ## n.ahead : 30 ## Bootstrap method: partial ## Date (T[0]): 2008-08-29 ## ## Series (summary): ## min q.25 mean q.75 max forecast[analytic] ## t+1 -0.027612 -0.004537 0.000898 0.007065 0.033169 -0.000125 ## t+2 -0.030993 -0.006106 0.000649 0.007182 0.034373 -0.000125 ## t+3 -0.037395 -0.007267 -0.000186 0.006481 0.025507 -0.000125 ## t+4 -0.025444 -0.006788 0.000205 0.006764 0.026999 -0.000125 ## t+5 -0.042502 -0.006311 -0.000170 0.006117 0.030182 -0.000125 ## t+6 -0.029604 -0.005857 0.000076 0.005887 0.030241 -0.000125 ## t+7 -0.031843 -0.007039 -0.000994 0.004694 0.029260 -0.000125 ## t+8 -0.028054 -0.008419 -0.001489 0.005106 0.029484 -0.000125 ## t+9 -0.031538 -0.006050 -0.000193 0.005816 0.026813 -0.000125 ## t+10 -0.033130 -0.003944 0.001027 0.006453 0.041161 -0.000125 ## ..................... ## ## Sigma (summary): ## min q0.25 mean q0.75 max forecast[analytic] ## t+1 0.010004 0.010004 0.010004 0.010004 0.010004 0.010004 ## t+2 0.009666 0.009666 0.009919 0.009958 0.012351 0.009985 ## t+3 0.009342 0.009342 0.009884 0.010128 0.013861 0.009967 ## t+4 0.009031 0.009139 0.009871 0.010321 0.013364 0.009949 ## t+5 0.008733 0.009062 0.009844 0.010317 0.014903 0.009931 ## t+6 0.008447 0.008964 0.009810 0.010455 0.015332 0.009913 ## t+7 0.008174 0.008819 0.009764 0.010417 0.014775 0.009895 ## t+8 0.007912 0.008818 0.009785 0.010474 0.015443 0.009877 ## t+9 0.007660 0.008810 0.009836 0.010660 0.016013 0.009860 ## t+10 0.007420 0.008737 0.009807 0.010652 0.017007 0.009842 ## ..................... 8.5 GARCHモデル: データ分析例 (Tsay, Ch4) 出所: http://faculty.chicagobooth.edu/ruey.tsay/teaching/introTS/ (一部改変) 必要な関数やデータセットの入手 教科書ホームページからのRコードへの直接の読み込みの方法 # 教科書著者(Tsay)の関数 fctns &lt;- c(&quot;igarch.r&quot;, &quot;garchm.r&quot;, &quot;egarch.r&quot;, &quot;ngarch.r&quot;, &quot;tgarch11.r&quot;, &quot;vold2m.r&quot;) url_home &lt;- &quot;https://faculty.chicagobooth.edu/-/media/faculty/ruey-s-tsay/teaching/introts/&quot; for (fct in fctns) { url_tmp &lt;- file.path(url_home, fct) source(url_tmp) } # データセット # 単一テキストファイルの入手 # library(rio) # url_tmp &lt;- &quot;https://faculty.chicagobooth.edu/-/media/faculty/ruey-s-tsay/teaching/introts/d-spy-0111.txt&quot; # rio::import(url_tmp) # 複数データセットの入った圧縮フォルダ(*.zip)からのデータセット入手 url_tmp &lt;- &quot;https://faculty.chicagobooth.edu/-/media/faculty/ruey-s-tsay/teaching/introts/ch4data.zip&quot; tmp &lt;- tempfile() tmp2 &lt;- tempfile() download.file(url_tmp, tmp) unzip(tmp, exdir = tmp2) dir(tmp2, recursive = T) ## [1] &quot;d-pg-0111.txt&quot; &quot;d-sp58010.txt&quot; &quot;d-spy-0111.txt&quot; &quot;d-useu9910.txt&quot; ## [5] &quot;m-ibmsp6709.txt&quot; &quot;m-intcsp7309.txt&quot; &quot;m-ko-6111.txt&quot; &quot;m-sp56710.txt&quot; setwd(tmp2) unlink(tmp) Integrated GARCH モデル Tsay 4.7, pp.211–212 Igarch(): Estimation of a Gaussian IGARCH(1,1) model. - Igarch(rtn, include.mean = F, volcnt = F) - rtn: return series - include.mean: flag for the constant in the mean equation. - volcnt: flag for the constant term of the volatility equation. # source(&quot;Igarch.R&quot;) # da &lt;- read.table(&quot;m-intcsp7309.txt&quot;, header = T) head(da) # monthly returns of Intel &amp; S&amp;P, Jan73--Dec09 ## date intc sp ## 1 19730131 0.010050 -0.017111 ## 2 19730228 -0.139303 -0.037490 ## 3 19730330 0.069364 -0.001433 ## 4 19730430 0.086486 -0.040800 ## 5 19730531 -0.104478 -0.018884 ## 6 19730629 0.133333 -0.006575 intc &lt;- log(da$intc + 1) # monthly log-returns of Intel # mm &lt;- Igarch(intc, include.mean = T, volcnt = T) # --&gt; エラー # mm &lt;- Igarch(intc, include.mean = T) # --&gt; mu, beta # mm &lt;- Igarch(intc, volcnt = T) # --&gt; omega, beta mm &lt;- Igarch(intc) # --&gt; beta ## Estimates: 0.9217433 ## Maximized log-likehood: -301.412 ## ## Coefficient(s): ## Estimate Std. Error t value Pr(&gt;|t|) ## beta 0.9217433 0.0155534 59.2633 &lt; 2.22e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 names(mm) ## [1] &quot;par&quot; &quot;volatility&quot; mm$par # --&gt; beta ## beta ## 0.9217433 head(mm$volatility) ## [1] 0.1275742 0.1225127 0.1248833 0.1213562 0.1187993 0.1181597 summary(mm) ## Length Class Mode ## par 1 -none- numeric ## volatility 444 ts numeric –&gt; 教科書の記載と出力が相違(??) plot(mm$vola) GARCH-M モデル Tsay 4.8, pp.213–214 garchM(): Estimation of a Gaussian GARCH(1, 1)-M model. - The program uses GARCH(1, 1) results as initial values. - garchM(rtn, type = 1) - rtn: return series - type = 1 for Variance-in-mean - = 2 for volatility-in-mean - = 3 for log(variance)-in-mean # source(&quot;garchM.R&quot;) # Compile the script y &lt;- intc * 100 # Intel stock returns in percentages garchM(y) ## Maximized log-likehood: -1731.983 ## ## Coefficient(s): ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 0.07760772 1.32247094 0.05868 0.9532039 ## gamma 0.00794321 0.00919788 0.86359 0.3878123 ## omega 9.45892353 3.94083066 2.40024 0.0163845 * ## alpha 0.08761598 0.02673486 3.27722 0.0010484 ** ## beta 0.84933808 0.03948749 21.50904 &lt; 2.22e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 –&gt; 教科書の記載と出力が相違(??) リスクプレミアム(gamma), 有意でない garchM(y, type = 2) garchM(y, type = 3) ## 注: (最適化にnlminb()使用) 実行時間かかる –&gt; 通常のGARCH(1,1)へ #&gt; library(fGarch) #&gt; fGarch::garchFit(~ garch(1, 1), data = y, trace = F) # sp5 &lt;- scan(file = &quot;sp500.txt&quot;) # &lt;-- データ無. 誤植? da &lt;- read.table(&quot;m-intcsp7309.txt&quot;, header = T) # &lt;-- 代わりに使用. --&gt; 教科書と結果が異なる # head(da) # monthly returns of Intel &amp; S&amp;P, Jan73--Dec09 # da &lt;- read.table(&quot;m-ibmsp-2611.txt&quot;, header = T) # da &lt;- da[da$data&lt; = 20091231, ] # head(da) # monthly returns of IBM &amp; S&amp;P, Jan26--Sep11 sp5 &lt;- log(da$sp + 1) # monthly log-returns of S&amp;P # library(fGarch) sp5 &lt;- sp5 * 100 m2 &lt;- fGarch::garchFit(~ 1 + garch(1, 1), data = sp5, trace = F) summary(m2) ## ## Title: ## GARCH Modelling ## ## Call: ## fGarch::garchFit(formula = ~1 + garch(1, 1), data = sp5, trace = F) ## ## Mean and Variance Equation: ## data ~ 1 + garch(1, 1) ## &lt;environment: 0x117da6f60&gt; ## [data = sp5] ## ## Conditional Distribution: ## norm ## ## Coefficient(s): ## mu omega alpha1 beta1 ## 0.56091 0.72752 0.11733 0.85910 ## ## Std. Errors: ## based on Hessian ## ## Error Analysis: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 0.56091 0.18951 2.960 0.003078 ** ## omega 0.72752 0.45322 1.605 0.108447 ## alpha1 0.11733 0.03157 3.717 0.000202 *** ## beta1 0.85910 0.03023 28.415 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Log Likelihood: ## -1289.671 normalized: -2.904663 ## ## Description: ## Sun Feb 2 21:07:06 2025 by user: ## ## ## Standardised Residuals Tests: ## Statistic p-Value ## Jarque-Bera Test R Chi^2 175.7288601 0.000000e+00 ## Shapiro-Wilk Test R W 0.9655541 1.058946e-08 ## Ljung-Box Test R Q(10) 10.2148008 4.218546e-01 ## Ljung-Box Test R Q(15) 12.7646773 6.204685e-01 ## Ljung-Box Test R Q(20) 15.3249362 7.575226e-01 ## Ljung-Box Test R^2 Q(10) 5.0820118 8.856326e-01 ## Ljung-Box Test R^2 Q(15) 6.7788883 9.634974e-01 ## Ljung-Box Test R^2 Q(20) 7.6653472 9.938604e-01 ## LM Arch Test R TR^2 5.2952187 9.473846e-01 ## ## Information Criterion Statistics: ## AIC BIC SIC HQIC ## 5.827345 5.864244 5.827184 5.841896 Estimate Std. Error t value Pr(&gt;|t|) mu 0.5609132 0.1895067 2.959859 0.0030778 omega 0.7275158 0.4532207 1.605213 0.1084469 alpha1 0.1173334 0.0315668 3.716989 0.0002016 beta1 0.8590999 0.0302342 28.414853 0.0000000 –&gt; GARCH(1,1), \\(\\alpha_1,\\beta_1\\)とも (5%) 有意. plot(m2, which = 1:13) –&gt; モデル診断, 正規性を除き, データによく適合 garchM(sp5) ## Maximized log-likehood: -1289.449 ## ## Coefficient(s): ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 0.3467741 0.3848750 0.90100 0.36758602 ## gamma 0.0122469 0.0188770 0.64877 0.51648627 ## omega 0.7612141 0.4796077 1.58716 0.11247646 ## alpha 0.1163726 0.0317725 3.66268 0.00024959 *** ## beta 0.8581959 0.0308425 27.82506 &lt; 2.22e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 –&gt; リスクプレミアム (gamma), 有意でない (5%水準) –&gt; GARCH(1,1)を選択せよ Exponential GARCH Model Tsay 4.9, pp.218–220 Egarch(): Estimation of an EGARCH(1, 1) model. Assume normal innovations - Egarch(rtn) # source(&quot;Egarch.R&quot;) # Compile R script da &lt;- read.table(&quot;m-ibmsp6709.txt&quot;, header = T) # Load data dim(da) # Check sample size of the data ## [1] 516 3 ibm &lt;- log(da$ibm + 1) # Take log transformation Box.test(ibm, lag = 12, type = &#39;Ljung&#39;) # Check serial correlations ## ## Box-Ljung test ## ## data: ibm ## X-squared = 7.4042, df = 12, p-value = 0.8298 m1 &lt;- Egarch(ibm) # Model fitting ## ## Estimation results of EGARCH(1,1) model: ## estimates: 0.006732418 -0.5983265 0.2176024 -0.4243194 0.9201499 ## std.errors: 0.002877668 0.2349184 0.05916505 0.1683056 0.03886579 ## t-ratio: 2.339539 -2.546954 3.677888 -2.521125 23.67506 names(m1) ## [1] &quot;residuals&quot; &quot;volatility&quot; 上記出力の見方: Estimation results of EGARCH(1, 1) model: estimates: 0.006732389 -0.5983263 0.217603 -0.4243245 0.92015 std.errors: 0.002877666 0.2349172 0.05916528 0.1683064 0.0388656 t-ratio: 2.339531 -2.546967 3.677882 -2.521144 23.67518 &lt;– mu, omega, alpha1, gamma1, beta1の順に出力 –&gt; 値が教科書(p.220)と若干相違 モデル診断 stresi &lt;- m1$residuals/m1$volatility # Obtain standardized residuals tdx &lt;- c(1:516)/12 + 1967 # Compute time index par(mfcol = c(2, 1)) # Plotting plot(tdx, ibm, xlab = &#39;year&#39;, ylab = &#39;logrtn&#39;, type = &#39;l&#39;) plot(tdx, stresi, xlab = &#39;year&#39;, ylab = &#39;stresi&#39;, type = &#39;l&#39;) Box.test(stresi, lag = 10, type = &#39;Ljung&#39;) # Model checking ## ## Box-Ljung test ## ## data: stresi ## X-squared = 5.2866, df = 10, p-value = 0.8712 Box.test(stresi, lag = 20, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: stresi ## X-squared = 20.983, df = 20, p-value = 0.3981 Box.test(stresi^2, lag = 10, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: stresi^2 ## X-squared = 5.0469, df = 10, p-value = 0.888 Box.test(stresi^2, lag = 20, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: stresi^2 ## X-squared = 14.261, df = 20, p-value = 0.817 –&gt; Tsay, “The model fits the data reasonably well.” Threshold GARCH モデル Tsay 4.10, pp.222–223 Tgarch(): Estimation of TGARCH(1, 1) model with Gaussian or Student-t innovations - Tgarch11(x, cond.dist = &quot;norm&quot;) da &lt;- read.table(&quot;d-useu9910.txt&quot;, header = T) # daily USD/EUR, Jan/4/99--Aug/20/10 fx &lt;- log(da$rate) eu &lt;- diff(fx) * 100 # # source(&#39;Tgarch11.R&#39;) m1 &lt;- Tgarch11(eu) ## Log likelihood at MLEs: ## [1] -2731.832 ## ## Coefficient(s): ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 0.012241330 0.010728802 1.14098 0.253879 ## omega 0.001275051 0.000618455 2.06167 0.039239 * ## alpha 0.022347139 0.005249351 4.25712 2.0707e-05 *** ## gam1 0.012516442 0.007062297 1.77229 0.076346 . ## beta 0.968720272 0.004357856 222.29288 &lt; 2.22e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 –&gt; muは有意でない volatility方程式の係数は有意 特に, レバレッジ効果 (H0: gamma&lt;=0, H1: gamma&gt;0)は(片側) 5%で有意. t=1.772, p=0.038. # モデル診断 names(m1) ## [1] &quot;residuals&quot; &quot;volatility&quot; &quot;par&quot; at &lt;- m1$residuals sigt &lt;- m1$volatility resi &lt;- at/sigt Box.test(resi, lag = 10, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: resi ## X-squared = 13.382, df = 10, p-value = 0.2031 Box.test(resi, lag = 20, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: resi ## X-squared = 22.873, df = 20, p-value = 0.2951 Box.test(resi ^ 2, lag = 10, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: resi^2 ## X-squared = 12.894, df = 10, p-value = 0.2297 Box.test(resi ^ 2, lag = 20, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: resi^2 ## X-squared = 27.23, df = 20, p-value = 0.1289 # 追加 plot(sigt, xlab = &#39;year&#39;, ylab = &#39;volatility&#39;, type = &#39;l&#39;) plot(resi, xlab = &#39;year&#39;, ylab = &#39;residuals&#39;, type = &#39;l&#39;) → 残差プロット, heavy tailの存在? Asymmetric Power ARCH モデル Tsay 4.11, pp.224–225 m1 &lt;- fGarch::garchFit(~ 1 + aparch(1, 1), data = eu, trace = F) summary(m1) ## ## Title: ## GARCH Modelling ## ## Call: ## fGarch::garchFit(formula = ~1 + aparch(1, 1), data = eu, trace = F) ## ## Mean and Variance Equation: ## data ~ 1 + aparch(1, 1) ## &lt;environment: 0x127255bd8&gt; ## [data = eu] ## ## Conditional Distribution: ## norm ## ## Coefficient(s): ## mu omega alpha1 gamma1 beta1 delta ## 0.0127647 0.0015919 0.0313680 0.1135336 0.9689155 1.6743076 ## ## Std. Errors: ## based on Hessian ## ## Error Analysis: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 0.0127647 0.0107626 1.186 0.2356 ## omega 0.0015919 0.0007226 2.203 0.0276 * ## alpha1 0.0313680 0.0053350 5.880 4.11e-09 *** ## gamma1 0.1135336 0.0711911 1.595 0.1108 ## beta1 0.9689155 0.0038405 252.292 &lt; 2e-16 *** ## delta 1.6743076 0.4057109 4.127 3.68e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Log Likelihood: ## -2731.172 normalized: -0.9324587 ## ## Description: ## Sun Feb 2 21:07:10 2025 by user: ## ## ## Standardised Residuals Tests: ## Statistic p-Value ## Jarque-Bera Test R Chi^2 50.2052714 1.253331e-11 ## Shapiro-Wilk Test R W 0.9956711 1.608387e-07 ## Ljung-Box Test R Q(10) 13.3768880 2.033561e-01 ## Ljung-Box Test R Q(15) 20.1963426 1.645294e-01 ## Ljung-Box Test R Q(20) 22.8473644 2.963513e-01 ## Ljung-Box Test R^2 Q(10) 13.1561129 2.150739e-01 ## Ljung-Box Test R^2 Q(15) 16.5800862 3.445799e-01 ## Ljung-Box Test R^2 Q(20) 27.4488680 1.231012e-01 ## LM Arch Test R TR^2 14.3573871 2.784707e-01 ## ## Information Criterion Statistics: ## AIC BIC SIC HQIC ## 1.869014 1.881269 1.869006 1.873428 m1 ## ## Title: ## GARCH Modelling ## ## Call: ## fGarch::garchFit(formula = ~1 + aparch(1, 1), data = eu, trace = F) ## ## Mean and Variance Equation: ## data ~ 1 + aparch(1, 1) ## &lt;environment: 0x127255bd8&gt; ## [data = eu] ## ## Conditional Distribution: ## norm ## ## Coefficient(s): ## mu omega alpha1 gamma1 beta1 delta ## 0.0127647 0.0015919 0.0313680 0.1135336 0.9689155 1.6743076 ## ## Std. Errors: ## based on Hessian ## ## Error Analysis: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 0.0127647 0.0107626 1.186 0.2356 ## omega 0.0015919 0.0007226 2.203 0.0276 * ## alpha1 0.0313680 0.0053350 5.880 4.11e-09 *** ## gamma1 0.1135336 0.0711911 1.595 0.1108 ## beta1 0.9689155 0.0038405 252.292 &lt; 2e-16 *** ## delta 1.6743076 0.4057109 4.127 3.68e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Log Likelihood: ## -2731.172 normalized: -0.9324587 ## ## Description: ## Sun Feb 2 21:07:10 2025 by user: Estimate Std. Error t value Pr(&gt;|t|) mu 0.0127647 0.0107626 1.186030 0.2356103 omega 0.0015919 0.0007226 2.203007 0.0275943 alpha1 0.0313680 0.0053350 5.879689 0.0000000 gamma1 0.1135336 0.0711911 1.594772 0.1107631 beta1 0.9689155 0.0038405 252.291937 0.0000000 delta 1.6743076 0.4057109 4.126849 0.0000368 –&gt; モデル診断, データに良く適合. delta = 1.67の解釈難. –&gt; delta = 2とは、有意に乖離していない(標準誤差0.406) –&gt; delta = 2 (TGARCH(1, 1))でも良い? m2 &lt;- fGarch::garchFit(~ 1 + aparch(1, 1), data = eu, delta = 2, include.delta = F, trace = F) summary(m2) ## ## Title: ## GARCH Modelling ## ## Call: ## fGarch::garchFit(formula = ~1 + aparch(1, 1), data = eu, delta = 2, ## include.delta = F, trace = F) ## ## Mean and Variance Equation: ## data ~ 1 + aparch(1, 1) ## &lt;environment: 0x1279d0da0&gt; ## [data = eu] ## ## Conditional Distribution: ## norm ## ## Coefficient(s): ## mu omega alpha1 gamma1 beta1 ## 0.0122646 0.0012745 0.0282723 0.1100237 0.9687115 ## ## Std. Errors: ## based on Hessian ## ## Error Analysis: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 0.0122646 0.0107289 1.143 0.2530 ## omega 0.0012745 0.0005752 2.216 0.0267 * ## alpha1 0.0282723 0.0038637 7.317 2.53e-13 *** ## gamma1 0.1100237 0.0649051 1.695 0.0900 . ## beta1 0.9687115 0.0039421 245.735 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Log Likelihood: ## -2731.85 normalized: -0.9326902 ## ## Description: ## Sun Feb 2 21:07:11 2025 by user: ## ## ## Standardised Residuals Tests: ## Statistic p-Value ## Jarque-Bera Test R Chi^2 49.9767787 1.405009e-11 ## Shapiro-Wilk Test R W 0.9956803 1.655878e-07 ## Ljung-Box Test R Q(10) 13.3828454 2.030470e-01 ## Ljung-Box Test R Q(15) 20.2983309 1.607846e-01 ## Ljung-Box Test R Q(20) 22.8726490 2.950909e-01 ## Ljung-Box Test R^2 Q(10) 12.8958586 2.295529e-01 ## Ljung-Box Test R^2 Q(15) 16.5528834 3.462875e-01 ## Ljung-Box Test R^2 Q(20) 27.2403647 1.286360e-01 ## LM Arch Test R TR^2 14.2966159 2.821694e-01 ## ## Information Criterion Statistics: ## AIC BIC SIC HQIC ## 1.868795 1.879007 1.868789 1.872472 plot(m2, which = 1:13) m2 ## ## Title: ## GARCH Modelling ## ## Call: ## fGarch::garchFit(formula = ~1 + aparch(1, 1), data = eu, delta = 2, ## include.delta = F, trace = F) ## ## Mean and Variance Equation: ## data ~ 1 + aparch(1, 1) ## &lt;environment: 0x1279d0da0&gt; ## [data = eu] ## ## Conditional Distribution: ## norm ## ## Coefficient(s): ## mu omega alpha1 gamma1 beta1 ## 0.0122646 0.0012745 0.0282723 0.1100237 0.9687115 ## ## Std. Errors: ## based on Hessian ## ## Error Analysis: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 0.0122646 0.0107289 1.143 0.2530 ## omega 0.0012745 0.0005752 2.216 0.0267 * ## alpha1 0.0282723 0.0038637 7.317 2.53e-13 *** ## gamma1 0.1100237 0.0649051 1.695 0.0900 . ## beta1 0.9687115 0.0039421 245.735 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Log Likelihood: ## -2731.85 normalized: -0.9326902 ## ## Description: ## Sun Feb 2 21:07:11 2025 by user: Estimate Std. Error t value Pr(&gt;|t|) mu 0.0122646 0.0107289 1.143135 0.2529826 omega 0.0012745 0.0005752 2.215691 0.0267127 alpha1 0.0282723 0.0038637 7.317489 0.0000000 gamma1 0.1100237 0.0649051 1.695148 0.0900474 beta1 0.9687115 0.0039421 245.735397 0.0000000 –&gt; m1と結果類似 Nonsymmetric GARCH モデル Tsay 4.12, pp.227–228 Ngarch(): Estimation of a non-symmertic GARCH, NGARCH(1, 1), model. - Assume normal innovations - Ngarch(rtn) da &lt;- read.table(&quot;d-useu9910.txt&quot;, header = T) fx &lt;- log(da$rate) eu &lt;- diff(fx) * 100 # source(&quot;Ngarch.R&quot;) m1 &lt;- Ngarch(eu) ## ## Estimation results of NGARCH(1,1) model: ## estimates: -0.001094043 0.002366721 0.9618047 0.02118565 0.7309616 ## std.errors: 0.01080893 0.000580552 0.006045803 0.003604727 0.2501548 ## t-ratio: -0.1012166 4.076674 159.0863 5.877186 2.922037 res &lt;- m1$residuals vol &lt;- m1$volatility resi &lt;- res / vol Box.test(resi, lag = 10, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: resi ## X-squared = 14.776, df = 10, p-value = 0.1404 Box.test(resi^2, lag = 10, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: resi^2 ## X-squared = 12.943, df = 10, p-value = 0.2269 # Estimation results of NGARCH(1, 1) model: # estimates: -0.001094043 0.002366721 0.9618047 0.02118565 0.7309616 # std.errors: 0.01080893 0.000580552 0.006045803 0.003604727 0.2501548 # t-ratio: -0.1012166 4.076674 159.0863 5.877186 2.922037 # &lt;-- mu, beta0, beta1, beta2, thetaの順 –&gt; muを除いて(5%)有意 特に, レバレッジ効果(theta), t=2.92で(5%)有意 –&gt; 上記TGARCH(1, 1)の結果と同様 # 追加 plot(vol, xlab = &#39;year&#39;, ylab = &#39;volatility&#39;, type = &#39;l&#39;) plot(resi, xlab = &#39;year&#39;, ylab = &#39;residuals&#39;, type = &#39;l&#39;) → 両モデルは, 類似のvolatility推定値 代替的アプリーチ間の比較 Tsay 4.15.1, pp.234–235 (日次データから)月次ボラティリティの推定 “ルートT・ルール”の適用 da &lt;- read.table(&quot;d-sp58010.txt&quot;, header = T) x &lt;- da[, c(1:3, 9)] dim(x) ## [1] 7737 4 方法1: 日次対数収益率使用 (white noiseを仮定) # source(&quot;vold2m.R&quot;) ## Compile the script m1 &lt;- vold2m(x) names(m1) ## [1] &quot;volatility&quot; &quot;ndays&quot; v1 &lt;- m1$volatility cnt &lt;- m1$ndays cnt[1:5] ## [1] 20 20 21 21 21 方法2: 日次対数収益率使用 (MA過程を仮定) m2 &lt;- vold2m(x, ma = 1) # Use MA(1) dependence names(m2) ## [1] &quot;volatility&quot; &quot;ndays&quot; v2 &lt;- m2$volatility 月次データの使用 da1 &lt;- read.table(&quot;m-sp56710.txt&quot;, header = T) sp &lt;- log(da1[, 9]) sp5 &lt;- diff(sp) 方法3: GARCH(1,1)を月次対数収益率に適用 # library(fGarch) m3 &lt;- fGarch::garchFit(~ 1 + garch(1, 1), data = sp5, trace = F) summary(m3) ## ## Title: ## GARCH Modelling ## ## Call: ## fGarch::garchFit(formula = ~1 + garch(1, 1), data = sp5, trace = F) ## ## Mean and Variance Equation: ## data ~ 1 + garch(1, 1) ## &lt;environment: 0x1074b7668&gt; ## [data = sp5] ## ## Conditional Distribution: ## norm ## ## Coefficient(s): ## mu omega alpha1 beta1 ## 5.3471e-03 9.3263e-05 1.1422e-01 8.4864e-01 ## ## Std. Errors: ## based on Hessian ## ## Error Analysis: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu 5.347e-03 1.742e-03 3.069 0.002149 ** ## omega 9.326e-05 4.859e-05 1.919 0.054942 . ## alpha1 1.142e-01 3.003e-02 3.804 0.000142 *** ## beta1 8.486e-01 3.186e-02 26.634 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Log Likelihood: ## 899.7817 normalized: 1.717141 ## ## Description: ## Sun Feb 2 21:07:26 2025 by user: ## ## ## Standardised Residuals Tests: ## Statistic p-Value ## Jarque-Bera Test R Chi^2 172.5211023 0.000000e+00 ## Shapiro-Wilk Test R W 0.9690782 4.639274e-09 ## Ljung-Box Test R Q(10) 11.1732915 3.441774e-01 ## Ljung-Box Test R Q(15) 15.4509983 4.194449e-01 ## Ljung-Box Test R Q(20) 17.5646909 6.160600e-01 ## Ljung-Box Test R^2 Q(10) 5.4667953 8.578981e-01 ## Ljung-Box Test R^2 Q(15) 7.0315432 9.567685e-01 ## Ljung-Box Test R^2 Q(20) 8.2004251 9.904566e-01 ## LM Arch Test R TR^2 5.6298797 9.335791e-01 ## ## Information Criterion Statistics: ## AIC BIC SIC HQIC ## -3.419014 -3.386484 -3.419129 -3.406275 v3 &lt;- fGarch::volatility(m3) v3 &lt;- v3[158:524] Estimate Std. Error t value Pr(&gt;|t|) mu 0.0053471 0.0017424 3.068779 0.0021494 omega 0.0000933 0.0000486 1.919333 0.0549423 alpha1 0.1142231 0.0300281 3.803878 0.0001424 beta1 0.8486414 0.0318635 26.633651 0.0000000 3つの方法の比較 v1 &lt;- ts(v1, frequency = 12, start = c(1980, 1)) v2 &lt;- ts(v2, frequency = 12, start = c(1980, 1)) v3 &lt;- ts(v3, frequency = 12, start = c(1980, 1)) max(v1, v2, v3) ## [1] 0.2870294 # # par(mfcol=c(3,1)) # plot(v1, xlab=&#39;year&#39;, ylab=&#39;vol&#39;, type=&#39;l&#39;, ylim=c(0,.3)) # title(main=&#39;(a) No correlations&#39;) # plot(v2, xlab=&#39;year&#39;, ylab=&#39;vol&#39;, type=&#39;l&#39;, ylim=c(0,.3)) # title(main=&#39;(b) Lag-1 correlation&#39;) # plot(v3, xlab=&#39;year&#39;, ylab=&#39;vol&#39;, type=&#39;l&#39;, ylim=c(0,.3)) # title(main=&#39;(c) GARCH(1,1)&#39;) plot(ts.intersect(v1, v2, v3)) "],["varモデル.html", "9 VARモデル 9.1 VAR(\\(p\\))モデルのシミュレーション 9.2 VAR(\\(p\\))モデルの構築 9.3 VAR解析 9.4 VAR解析 (データ分析例) 9.5 補足: 分散共分散行列のコレスキー分解", " 9 VARモデル 9.1 VAR(\\(p\\))モデルのシミュレーション パッケージMTS, varsの利用 本章では主に, Tsayが作成した多変量時系列解析用のパッケージMTS および, パッケージvarsを利用する. https://www.rdocumentation.org/packages/MTS/versions/1.0 https://www.rdocumentation.org/packages/vars/versions/1.5-3 関数MTS::VARMAsim() (VARMA(\\(p,q\\))モデルのパス生成) VAR(2)モデル例: \\[Y_{1,t}=0.3 + 0.2 Y_{1,t-1} + 0.3 Y_{2,t-1} - 0.5 Y_{1,t-2} (+0 \\cdot Y_{2,t-2}) + \\epsilon_{1,t}\\] \\[Y_{2,t}=-0.3 -0.6 Y_{1,t-1} + 1.1 Y_{2,t-1} (+0 \\cdot Y_{1,t-2}) - 0.6 Y_{2,t-2} + \\epsilon_{2,t}\\] \\[ \\left[ \\begin{array}{r} \\epsilon_{1,t} \\\\ \\epsilon_{2,t} \\end{array} \\right] \\sim_{\\it i.i.d.} N \\Big(\\left[ \\begin{array}{r} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{rr} 4 &amp; 0.8 \\\\ 0.8 &amp; 1 \\end{array} \\right]\\Big) \\] 上記VAR(2)モデルのサンプルパスの生成 library(MTS) nlen &lt;- 300 seed_val &lt;- 1 set.seed(seed_val) p0 &lt;- c(0.3, -0.3) # Phi0 (定数項) p1 &lt;- matrix(c(0.2, -0.6, 0.3, 1.1), 2, 2) # Phi1 (ラグ1のVAR係数行列) p2 &lt;- matrix(c(-0.5, 0, 0, -0.6), 2, 2) # Phi2 (ラグ2のVAR係数行列) p_mat &lt;- cbind(p1, p2) # VAR係数行列を重ねた行列 sig_mat &lt;- matrix(c(4, 0.8, 0.8, 1), 2, 2) # イノベーションの分散共分散行列 (正値定符号) p_mat; sig_mat ## [,1] [,2] [,3] [,4] ## [1,] 0.2 0.3 -0.5 0.0 ## [2,] -0.6 1.1 0.0 -0.6 ## [,1] [,2] ## [1,] 4.0 0.8 ## [2,] 0.8 1.0 ysim &lt;- VARMAsim(nlen, arlags = 2, cnst = p0, phi = p_mat, sigma = sig_mat) Yt &lt;- ysim$series MTSplot(Yt) # 時系列プロット 生成パス\\(y_t\\)の標本自己共分散行列 対角成分: 各成分の自己相関 \\(\\hat{\\rho}_1(h), \\hat{\\rho}_2(h)\\) 非対角成分: \\(y^1_t,y^2_t\\)間のクロス相関 行列の(1,2)成分: \\(\\hat{\\rho}_{1,2}(h),\\,h\\ge0\\) 行列の(2,1)成分: \\(\\hat{\\rho}_{1,2}(h)\\equiv\\hat{\\rho}_{2,1}(-h), \\,h\\le0\\) acf(Yt)   # 標本自己共分散行列 (2x2-行列) # acf()の出力結果の非対角成分の確認 # cor(Y1(t+h), Y2(t)) # h&gt;0 cor(Yt[2:nlen, 1], Yt[1:(nlen-1), 2]) # Y1(t+1) vs Y2(t) ## [1] -0.2491788 cor(Yt[3:nlen, 1], Yt[1:(nlen-2), 2]) # Y1(t+2) vs Y2(t) ## [1] 0.5855889 # h&lt;0 cor(Yt[1:(nlen-1), 1], Yt[2:nlen, 2]) # Y1(t) vs Y2(t+1) ## [1] -0.2269957 cor(Yt[1:(nlen-2), 1], Yt[3:nlen, 2]) # y1(t) vs Y2(t+2) ## [1] 0.2156902 9.2 VAR(\\(p\\))モデルの構築 ここでは, VAR(\\(p\\))モデル構築の中核のステップである, 同定・推定・予測の方法について示す. VAR(\\(p\\))モデルの次数同定 分析者による最適なラグ次数の選択を支援 - 関数MTS::VARorder() - maxp: ラグ次数の最大値 (デフォルト=13) - 出力: BIC, HQ (Hannan and Quinn情報量規準), M(p), p-value (カイ二乗検定統計量 &amp; p値) VARorder(Yt, maxp = 10, output = T) ## selected order: aic = 2 ## selected order: bic = 2 ## selected order: hq = 2 ## Summary table: ## p AIC BIC HQ M(p) p-value ## [1,] 0 4.2159 4.2159 4.2159 0.0000 0.0000 ## [2,] 1 3.8924 3.9418 3.9122 100.3170 0.0000 ## [3,] 2 1.5169 1.6157 1.5564 683.4158 0.0000 ## [4,] 3 1.5299 1.6781 1.5892 3.8619 0.4250 ## [5,] 4 1.5434 1.7409 1.6224 3.6978 0.4484 ## [6,] 5 1.5325 1.7794 1.6313 10.4626 0.0333 ## [7,] 6 1.5548 1.8511 1.6734 1.2025 0.8777 ## [8,] 7 1.5575 1.9032 1.6958 6.5850 0.1595 ## [9,] 8 1.5799 1.9750 1.7381 1.1470 0.8867 ## [10,] 9 1.5896 2.0340 1.7674 4.6092 0.3298 ## [11,] 10 1.6099 2.1037 1.8075 1.7109 0.7887 - 関数vars::VARselect() - lag.max: ラグ次数の最大値 (デフォルト=10) - type: 確定的な(定数・トレンド)項の種類 &quot;const&quot;(定数項有), &quot;trend&quot;(トレンド有), &quot;both&quot;(定数項・トレンド共有), &quot;none&quot;(両方無) - 出力: AIC, HQ, SC (Schwarz情報量規準), FPE (forecast prediction error) library(vars) vars::VARselect(Yt, lag.max = 10, type = &quot;const&quot;) ## $selection ## AIC(n) HQ(n) SC(n) FPE(n) ## 2 2 2 2 ## ## $criteria ## 1 2 3 4 5 6 7 8 ## AIC(n) 3.907125 1.532547 1.546463 1.560866 1.550885 1.574122 1.577719 1.601096 ## HQ(n) 3.937546 1.583248 1.617444 1.652128 1.662427 1.705945 1.729823 1.773480 ## SC(n) 3.983054 1.659094 1.723629 1.788652 1.829289 1.903146 1.957362 2.031358 ## FPE(n) 49.755778 4.629985 4.694921 4.763133 4.715983 4.827081 4.844789 4.959798 ## 9 10 ## AIC(n) 1.611643 1.632857 ## HQ(n) 1.804307 1.845802 ## SC(n) 2.092524 2.164357 ## FPE(n) 5.012920 5.121076 VAR(\\(p\\))モデルの推定 最小2乗法によるパラメータ推定 - 関数MTS::VAR() - p: ラグ次数 - include.mean: 平均ベクトルを加える(推定する)か (デフォルト=T) - fixed: パラメータに制約を付与する論理値行列. 制約付推定 (主に有意でない推定値の除去) に使用 est_VAR1 &lt;- MTS::VAR(Yt, p = 2, output = T, include.mean = T, fixed = NULL) ## Constant term: ## Estimates: 0.7010694 -0.4390955 ## Std.Error: 0.2935926 0.1458662 ## AR coefficient matrix ## AR( 1 )-matrix ## [,1] [,2] ## [1,] -0.0928 0.0954 ## [2,] -0.0197 -0.0286 ## standard error ## [,1] [,2] ## [1,] 0.0575 0.0462 ## [2,] 0.0286 0.0230 ## AR( 2 )-matrix ## [,1] [,2] ## [1,] 0.105 0.402 ## [2,] -0.616 1.117 ## standard error ## [,1] [,2] ## [1,] 0.0575 0.0465 ## [2,] 0.0285 0.0231 ## ## Residuals cov-mtx: ## [,1] [,2] ## [1,] 4.4990390 0.8786783 ## [2,] 0.8786783 1.1105526 ## ## det(SSE) = 4.224344 ## AIC = 1.494197 ## BIC = 1.592965 ## HQ = 1.533724 - 関数vars::VAR() - p: ラグ次数 - type: 確定的な(定数・トレンド)項の種類 &quot;const&quot;(定数項有), &quot;trend&quot;(トレンド有), &quot;both&quot;(定数項・トレンド共有), &quot;none&quot;(両方無) - season: 中心化済の季節性ダミー変数の追加 (frequencyを表す整数を指定) - exogen: 外生変数の追加 - lag.max: ラグ次数の最大値 (ラグ次数選択において) - in: 情報量規準 (lag.maxを指定している場合) est_VAR2 &lt;- vars::VAR(Yt, p = 2, type = &quot;const&quot;) # 最小2乗法によるパラメータ推定 # type: &quot;const&quot;(定数項有), trend:(&quot;トレンド有&quot;), &quot;both&quot;, &quot;none&quot; summary(est_VAR2) ## ## VAR Estimation Results: ## ========================= ## Endogenous variables: y1, y2 ## Deterministic variables: const ## Sample size: 298 ## Log Likelihood: -1060.376 ## Roots of the characteristic polynomial: ## 0.9308 0.7541 0.7541 0.6891 ## Call: ## vars::VAR(y = Yt, p = 2, type = &quot;const&quot;) ## ## ## Estimation results for equation y1: ## =================================== ## y1 = y1.l1 + y2.l1 + y1.l2 + y2.l2 + const ## ## Estimate Std. Error t value Pr(&gt;|t|) ## y1.l1 -0.09285 0.05751 -1.614 0.1075 ## y2.l1 0.09536 0.04624 2.062 0.0401 * ## y1.l2 0.10498 0.05745 1.827 0.0687 . ## y2.l2 0.40175 0.04645 8.648 3.49e-16 *** ## const 0.70107 0.29359 2.388 0.0176 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ## Residual standard error: 2.139 on 293 degrees of freedom ## Multiple R-Squared: 0.3636, Adjusted R-squared: 0.3549 ## F-statistic: 41.86 on 4 and 293 DF, p-value: &lt; 2.2e-16 ## ## ## Estimation results for equation y2: ## =================================== ## y2 = y1.l1 + y2.l1 + y1.l2 + y2.l2 + const ## ## Estimate Std. Error t value Pr(&gt;|t|) ## y1.l1 -0.01967 0.02857 -0.688 0.49185 ## y2.l1 -0.02859 0.02297 -1.244 0.21435 ## y1.l2 -0.61604 0.02854 -21.583 &lt; 2e-16 *** ## y2.l2 1.11695 0.02308 48.395 &lt; 2e-16 *** ## const -0.43910 0.14587 -3.010 0.00284 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ## Residual standard error: 1.063 on 293 degrees of freedom ## Multiple R-Squared: 0.9232, Adjusted R-squared: 0.9222 ## F-statistic: 880.9 on 4 and 293 DF, p-value: &lt; 2.2e-16 ## ## ## ## Covariance matrix of residuals: ## y1 y2 ## y1 4.5758 0.8937 ## y2 0.8937 1.1295 ## ## Correlation matrix of residuals: ## y1 y2 ## y1 1.0000 0.3931 ## y2 0.3931 1.0000 VAR(\\(p\\))モデル予測 - 関数MTS::VARpred() - h: 予測期間の長さ - orig: 予測の起点 (デフォルト=0, 最終のデータ点) - Out.level: 出力の詳細のコントロール (T/F) pred_VAR1 &lt;- VARpred(est_VAR1, h = 20, orig = 0, Out.level = F, output = T) ## orig 300 ## Forecasts at origin: 300 ## [,1] [,2] ## [1,] -1.6935 -4.659 ## [2,] -1.5588 -2.224 ## [3,] -1.4159 -4.506 ## [4,] -0.6541 -1.806 ## [5,] -1.3692 -4.535 ## [6,] -0.3984 -1.896 ## [7,] -1.4084 -4.599 ## [8,] -0.4105 -2.153 ## [9,] -1.4616 -4.638 ## [10,] -0.5135 -2.429 ## [11,] -1.4999 -4.640 ## [12,] -0.6321 -2.674 ## [13,] -1.5169 -4.609 ## [14,] -0.7383 -2.875 ## [15,] -1.5155 -4.556 ## [16,] -0.8252 -3.035 ## [17,] -1.5012 -4.491 ## [18,] -0.8939 -3.163 ## [19,] -1.4795 -4.423 ## [20,] -0.9480 -3.266 ## Standard Errors of predictions: ## [,1] [,2] ## [1,] 2.121 1.054 ## [2,] 2.129 1.056 ## [3,] 2.199 1.729 ## [4,] 2.205 1.734 ## [5,] 2.269 2.315 ## [6,] 2.270 2.333 ## [7,] 2.357 2.728 ## [8,] 2.358 2.760 ## [9,] 2.432 3.010 ## [10,] 2.435 3.050 ## [11,] 2.488 3.207 ## [12,] 2.493 3.249 ## [13,] 2.528 3.349 ## [14,] 2.535 3.388 ## [15,] 2.557 3.453 ## [16,] 2.564 3.486 ## [17,] 2.579 3.530 ## [18,] 2.586 3.557 ## [19,] 2.596 3.588 ## [20,] 2.602 3.609 ## Root mean square errors of predictions: ## [,1] [,2] ## [1,] 2.139 1.063 ## [2,] 2.154 1.061 ## [3,] 2.408 2.994 ## [4,] 2.226 1.751 ## [5,] 2.460 3.586 ## [6,] 2.275 2.391 ## [7,] 2.616 3.717 ## [8,] 2.359 2.859 ## [9,] 2.656 3.698 ## [10,] 2.444 3.174 ## [11,] 2.649 3.664 ## [12,] 2.510 3.378 ## [13,] 2.636 3.650 ## [14,] 2.557 3.508 ## [15,] 2.628 3.653 ## [16,] 2.587 3.591 ## [17,] 2.626 3.667 ## [18,] 2.607 3.643 ## [19,] 2.627 3.683 ## [20,] 2.620 3.678 - 関数predict() (`vars::VAR`の出力に対して適用) - n.ahead: 予測期間の長さ - ci: 予測信頼区間 pred_VAR2 &lt;- predict(est_VAR2, n.ahead = 10) plot(pred_VAR2) pred_VAR2$fcst ## $y1 ## fcst lower upper CI ## [1,] -1.6935489 -5.886138 2.499040 4.192589 ## [2,] -1.5588289 -5.766916 2.649258 4.208087 ## [3,] -1.4158594 -5.761805 2.930087 4.345946 ## [4,] -0.6541053 -5.012838 3.704628 4.358733 ## [5,] -1.3691744 -5.853357 3.115008 4.484182 ## [6,] -0.3983955 -4.885523 4.088732 4.487127 ## [7,] -1.4084408 -6.067917 3.251035 4.659476 ## [8,] -0.4104564 -5.070912 4.250000 4.660456 ## [9,] -1.4615648 -6.269351 3.346221 4.807786 ## [10,] -0.5135316 -5.326625 4.299561 4.813093 ## ## $y2 ## fcst lower upper CI ## [1,] -4.659151 -6.742164 -2.57613758 2.083013 ## [2,] -2.223532 -4.309952 -0.13711248 2.086420 ## [3,] -4.505606 -7.922276 -1.08893531 3.416670 ## [4,] -1.805711 -5.233098 1.62167648 3.427387 ## [5,] -4.534908 -9.110020 0.04020335 4.575112 ## [6,] -1.896451 -6.507997 2.71509585 4.611547 ## [7,] -4.598833 -9.990735 0.79306982 5.391903 ## [8,] -2.152730 -7.607556 3.30209602 5.454826 ## [9,] -4.638479 -10.588832 1.31187382 5.950353 ## [10,] -2.429372 -8.458542 3.59979824 6.029170 MTSパッケージは, 外生変数有りのVARXモデル, VMAモデル, さらには, 一般のVARMAモデルに対しても, 次数同定, モデル推定, 予測のための関数を用意. 9.3 VAR解析 VARモデルによる変数間の動学的関係性の分析を行う方法論として, グレンジャー因果性分析, インパルス応答分析, 分散分解の三つがある. グレンジャー因果性分析: ある変数のラグ値が他の変数の予測に有用かを調べる インパルス応答関数（IRF): 一変数の撹乱項に1単位のショックを与えた場合の他の変数への伝播の様子を調べる 分散分解: 各変数の予測誤差分散を各ショックからの相対的寄与の大きさに分解する これらの分析により, 以下について包括的な理解が得られる: - 変数間の動的な関係 - ショックの伝播メカニズム - システム内の互いに動的に影響を与える各変数の相対的な重要性 VAR(\\(p\\)) モデルの構築 (復習) VAR解析を行うには, 事前に分析対象の多変量時系列データに対して 前節までに解説してきたように, 適切な定常VARモデルを構築し推定することが重要である. モデル特定・推定 - 分析の目的や, 経済理論や専門知識等に基づいてモデリングに使用する変数 (内生変数) を選択 - 変数の定常性を確認. 必要に応じて, 差分を取る, 分解する等データ加工 - 情報量基準等を用いて適切なラグ次数を決定 - モデルを推定 モデル診断 - 残差の自己相関検定 - 不均一分散 (ARCH効果) の確認 - 残差の正規性検定, 等 - 必要に応じて, モデルの特定・推定をやり直す 以下では, 引き続き, MTSパッケージ, varsパッケージを利用する https://www.rdocumentation.org/packages/MTS/versions/1.0 https://www.rdocumentation.org/packages/vars/versions/1.5-3 以下では, シミュレーションデータを使用する MTSパッケージの関数VARsim()でパスを生成 varパッケージの関数VARselect(),VAR()を使って, 次数同定およびモデル推定 \\[Y_{1,t}=1.0 + 0.6 Y_{1,t-1} + 0.1 Y_{2,t-1} + \\epsilon_{1,t}\\] \\[Y_{2,t}=-1.0 +0.5 Y_{1,t-1} + 0.7 Y_{2,t-1} + \\epsilon_{2,t}\\] \\[ \\left[ \\begin{array}{r} \\epsilon_{1,t} \\\\ \\epsilon_{2,t} \\end{array} \\right] \\sim_{\\it i.i.d.} N \\Big(\\left[ \\begin{array}{r} 0 \\\\ 0 \\end{array} \\right], \\left[ \\begin{array}{rr} 4 &amp; 1 \\\\ 1 &amp; 1 \\end{array} \\right]\\Big) \\] library(MTS) nlen &lt;- 300 seed_val &lt;- 1 set.seed(seed_val) p0 &lt;- c(1, -1) # Phi0 (定数項) p_mat &lt;- matrix(c(0.6, 0.5, 0.1, 0.7), 2, 2) # Phi1 (ラグ1のVAR係数行列) sig_mat &lt;- matrix(c(4, 1, 1, 1), 2, 2) # イノベーションの分散共分散行列 (正値定符号) p_mat; sig_mat ## [,1] [,2] ## [1,] 0.6 0.1 ## [2,] 0.5 0.7 ## [,1] [,2] ## [1,] 4 1 ## [2,] 1 1 ysim &lt;- VARMAsim(nlen, arlags = 1, cnst = p0, phi = p_mat, sigma = sig_mat) Yt &lt;- ysim$series acf(Yt)   # クロス相関 MTSplot(Yt) # 時系列プロット VAR(\\(p\\))モデルの次数同定 関数vars::VARselect() library(vars) ## Loading required package: MASS ## Loading required package: strucchange ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## Loading required package: sandwich ## Loading required package: urca ## Loading required package: lmtest ## ## Attaching package: &#39;vars&#39; ## The following object is masked from &#39;package:MTS&#39;: ## ## VAR Yt &lt;- data.frame(Y1 = Yt[,1], Y2 = Yt[,2]) VARselect(Yt, lag.max = 5, type = &quot;const&quot;) ## $selection ## AIC(n) HQ(n) SC(n) FPE(n) ## 1 1 1 1 ## ## $criteria ## 1 2 3 4 5 ## AIC(n) 1.417189 1.432965 1.454790 1.471126 1.460469 ## HQ(n) 1.447216 1.483011 1.524855 1.561208 1.570570 ## SC(n) 1.492178 1.557947 1.629765 1.696094 1.735430 ## FPE(n) 4.125512 4.191134 4.283662 4.354299 4.308277 VAR(\\(p\\))モデルの推定 関数vars::VAR() est_VAR1 &lt;- vars::VAR(Yt, p = 1, type = &quot;const&quot;) summary(est_VAR1) ## ## VAR Estimation Results: ## ========================= ## Endogenous variables: Y1, Y2 ## Deterministic variables: const ## Sample size: 299 ## Log Likelihood: -1051.693 ## Roots of the characteristic polynomial: ## 0.8123 0.3886 ## Call: ## vars::VAR(y = Yt, p = 1, type = &quot;const&quot;) ## ## ## Estimation results for equation Y1: ## =================================== ## Y1 = Y1.l1 + Y2.l1 + const ## ## Estimate Std. Error t value Pr(&gt;|t|) ## Y1.l1 0.50728 0.06004 8.449 1.35e-15 *** ## Y2.l1 0.07759 0.04514 1.719 0.0866 . ## const 1.08864 0.17861 6.095 3.40e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ## Residual standard error: 2.133 on 296 degrees of freedom ## Multiple R-Squared: 0.3322, Adjusted R-squared: 0.3277 ## F-statistic: 73.64 on 2 and 296 DF, p-value: &lt; 2.2e-16 ## ## ## Estimation results for equation Y2: ## =================================== ## Y2 = Y1.l1 + Y2.l1 + const ## ## Estimate Std. Error t value Pr(&gt;|t|) ## Y1.l1 0.46669 0.03001 15.55 &lt;2e-16 *** ## Y2.l1 0.69357 0.02256 30.74 &lt;2e-16 *** ## const -0.97716 0.08928 -10.95 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ## Residual standard error: 1.066 on 296 degrees of freedom ## Multiple R-Squared: 0.9054, Adjusted R-squared: 0.9048 ## F-statistic: 1417 on 2 and 296 DF, p-value: &lt; 2.2e-16 ## ## ## ## Covariance matrix of residuals: ## Y1 Y2 ## Y1 4.551 1.096 ## Y2 1.096 1.137 ## ## Correlation matrix of residuals: ## Y1 Y2 ## Y1 1.000 0.482 ## Y2 0.482 1.000 次に, 上で推定されたVAR(1)モデルを使用して, VARモデルによる変数間の動学的関係性の分析を行う. グレンジャーの因果性検定 - 関数vars::causality() - x: 関数VAR()により生成された&#39;varest&#39;クラスのオブジェクト - cause: cause変数 (デフォルトは入力x$yの第1列の変数) - vcov.: 推定係数の共分散行列の指定 - boot: 棄却点を計算する際にwildブートストラップを使用するか否か(T/F) - boot.runs: boot=TRUEの場合のブートストラップの反復数 vars::causality(est_VAR1, cause = &quot;Y1&quot;) ## $Granger ## ## Granger causality H0: Y1 do not Granger-cause Y2 ## ## data: VAR object est_VAR1 ## F-Test = 241.8, df1 = 1, df2 = 592, p-value &lt; 2.2e-16 ## ## ## $Instant ## ## H0: No instantaneous causality between: Y1 and Y2 ## ## data: VAR object est_VAR1 ## Chi-squared = 56.374, df = 1, p-value = 5.995e-14 # VAR(1)の推定結果var1を用い, Y1に関するGranger因果性検定 vars::causality(est_VAR1, cause = &quot;Y2&quot;) ## $Granger ## ## Granger causality H0: Y2 do not Granger-cause Y1 ## ## data: VAR object est_VAR1 ## F-Test = 2.9555, df1 = 1, df2 = 592, p-value = 0.08611 ## ## ## $Instant ## ## H0: No instantaneous causality between: Y2 and Y1 ## ## data: VAR object est_VAR1 ## Chi-squared = 56.374, df = 1, p-value = 5.995e-14 # 同, Y2に関するGranger因果性検定 インパルス応答 直交インパルス応答 - 関数vars::irf() - x: 関数VAR()により生成された&#39;varest&#39;クラスのオブジェクト等 - impulse: インパルス変数 (デフォルト=全変数) - response: 応答変数 (デフォルト=全変数) - n.ahead: 将来区間の長さ - ortho: 直交インパルス応答か (デフォルト=T) - cumulative: 累積インパルス応答か (デフォルト=F) - boot: インパルス応答係数のブートストラップ誤差バンド計算の有無 (T/F) - ci: bootstrap誤差バンドの信頼区間 - runs: bootstrap回数 # vars::irf()関数 (ortho = T (デフォルト)) ip1 &lt;- vars::irf(est_VAR1, impulse = c(&quot;Y1&quot;), response = c(&quot;Y1&quot;, &quot;Y2&quot;), n.ahead = 5, boot = T) ip2 &lt;- vars::irf(est_VAR1, impulse = c(&quot;Y2&quot;), response = c(&quot;Y1&quot;, &quot;Y2&quot;), n.ahead = 5, boot = T) plot(ip1) plot(ip2) # 破線は信頼区間 # ip1; ip2 非直交インパルス応答 # vars::irf()関数 (ortho = F) ip1 &lt;- vars::irf(est_VAR1, impulse = c(&quot;Y1&quot;), response = c(&quot;Y1&quot;, &quot;Y2&quot;), ortho = F, n.ahead = 5, boot = T) ip2 &lt;- vars::irf(est_VAR1, impulse = c(&quot;Y2&quot;), response = c(&quot;Y1&quot;, &quot;Y2&quot;), ortho = F, n.ahead = 5, boot = T) plot(ip1) plot(ip2) # ip1; ip2 累積インパルス応答 ip1_cum &lt;- vars::irf(est_VAR1, impulse = c(&quot;Y1&quot;), response = c(&quot;Y1&quot;,&quot;Y2&quot;), n.ahead = 5, boot = TRUE, cumulative=T) ip2_cum &lt;- vars::irf(est_VAR1, impulse = c(&quot;Y2&quot;), response = c(&quot;Y2&quot;,&quot;Y1&quot;), n.ahead = 5, boot = TRUE, cumulative=T) plot(ip1_cum) plot(ip2_cum) 予測誤差分散分解 (forecast error variance decomposition) - 関数vars::fevd() - x: 関数VAR()により生成された&#39;varest&#39;クラスのオブジェクト等 - n.ahead: 予測区間の長さ 直交化インパルス応答関数を使い, 第\\(j(=1,2)\\)変数の第\\(k(=1,2)\\)変数の\\(h(=1,\\ldots,10)\\)先予測誤差分散への寄与を評価 res_fevd &lt;- vars::fevd(est_VAR1, n.ahead = 10) # 10期先まで評価する plot(res_fevd) 9.4 VAR解析 (データ分析例) VARモデルによる変数間の動学的関係性の分析 事例1: ソフトバンク(9434) vs ソフトバンクグループ(9984) ソフトバンク(9434): 上場日 2018年12月19日 親会社ソフトバンクG (9984) 保有比率(%): 66.49 (2019.03), 67.13 (2020.03), 40.86 (2021.03), 40.68 (2022.03), 40.47 (2023.03) cf. https://www.buffett-code.com/company/9434/mainshareholder データをYahoo!ファイナンスより入手 library(quantmod) ## Loading required package: xts ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## Loading required package: TTR ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo s9984 &lt;- getSymbols(&#39;9984.T&#39;, from = &#39;2018-12-19&#39;, auto.assign = FALSE) s9434 &lt;- getSymbols(&#39;9434.T&#39;, from = &#39;2018-12-19&#39;, auto.assign = FALSE) s9984ret &lt;- diff(log(s9984$`9984.T.Adjusted`))[-1] s9434ret &lt;- diff(log(s9434$`9434.T.Adjusted`))[-1] sb &lt;- merge.xts(s9984ret, s9434ret, join = &quot;inner&quot;) colnames(sb) &lt;- c(&quot;s9984&quot;, &quot;s9434&quot;) 各変数の単位根検定 library(fUnitRoots) # unitrootTest(s9984, type = &quot;c&quot;, lags = 1) # type: &quot;nc&quot;, &quot;c&quot;, &quot;ct&quot; unitrootTest(s9984ret, type = &quot;c&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## DF: -26.4993 ## P VALUE: ## t: &lt; 2.2e-16 ## n: 0.00225 ## ## Description: ## Sun Feb 2 21:07:33 2025 by user: unitrootTest(s9434ret, type = &quot;c&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## DF: -28.6841 ## P VALUE: ## t: &lt; 2.2e-16 ## n: 0.0013 ## ## Description: ## Sun Feb 2 21:07:33 2025 by user: –&gt; 帰無仮説(\\(\\phi_1 = 1\\))を棄却 (単位根なし) 標本自己共分散行列 acf(sb) VARモデルの推定 以下, パッケージvarsを利用 VAR(p)モデルの次数の決定 library(vars) ## Loading required package: MASS ## Loading required package: strucchange ## Loading required package: sandwich ## Loading required package: urca ## ## Attaching package: &#39;urca&#39; ## The following objects are masked from &#39;package:fUnitRoots&#39;: ## ## punitroot, qunitroot, unitrootTable ## Loading required package: lmtest vars::VARselect(sb, lag.max = 5, type = &quot;const&quot;) # &quot;const&quot;(定数項有), trend:(&quot;トレンド有&quot;), &quot;both&quot;, &quot;none&quot; ## $selection ## AIC(n) HQ(n) SC(n) FPE(n) ## 2 1 1 2 ## ## $criteria ## 1 2 3 4 5 ## AIC(n) -1.635228e+01 -1.635230e+01 -1.635201e+01 -1.635033e+01 -1.634695e+01 ## HQ(n) -1.634429e+01 -1.633899e+01 -1.633338e+01 -1.632637e+01 -1.631766e+01 ## SC(n) -1.633085e+01 -1.631659e+01 -1.630202e+01 -1.628605e+01 -1.626838e+01 ## FPE(n) 7.912162e-08 7.911970e-08 7.914264e-08 7.927601e-08 7.954477e-08 –&gt; AIC, FPEでは3, HQ, SCでは1が最適 VAR(1)モデルの推定 (OLS推定) var1 &lt;- vars::VAR(sb, p = 1, type = &quot;const&quot;) summary(var1) ## ## VAR Estimation Results: ## ========================= ## Endogenous variables: s9984, s9434 ## Deterministic variables: const ## Sample size: 1489 ## Log Likelihood: 7945.405 ## Roots of the characteristic polynomial: ## 0.03819 0.0218 ## Call: ## vars::VAR(y = sb, p = 1, type = &quot;const&quot;) ## ## ## Estimation results for equation s9984: ## ====================================== ## s9984 = s9984.l1 + s9434.l1 + const ## ## Estimate Std. Error t value Pr(&gt;|t|) ## s9984.l1 0.0532595 0.0265472 2.006 0.04501 * ## s9434.l1 -0.2322491 0.0716430 -3.242 0.00121 ** ## const 0.0006904 0.0007248 0.953 0.34097 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ## Residual standard error: 0.02794 on 1486 degrees of freedom ## Multiple R-Squared: 0.008114, Adjusted R-squared: 0.006779 ## F-statistic: 6.078 on 2 and 1486 DF, p-value: 0.00235 ## ## ## Estimation results for equation s9434: ## ====================================== ## s9434 = s9984.l1 + s9434.l1 + const ## ## Estimate Std. Error t value Pr(&gt;|t|) ## s9984.l1 0.0048691 0.0098772 0.493 0.622 ## s9434.l1 -0.0368631 0.0266556 -1.383 0.167 ## const 0.0004377 0.0002697 1.623 0.105 ## ## ## Residual standard error: 0.0104 on 1486 degrees of freedom ## Multiple R-Squared: 0.001306, Adjusted R-squared: -3.837e-05 ## F-statistic: 0.9715 on 2 and 1486 DF, p-value: 0.3788 ## ## ## ## Covariance matrix of residuals: ## s9984 s9434 ## s9984 7.807e-04 6.776e-05 ## s9434 6.776e-05 1.081e-04 ## ## Correlation matrix of residuals: ## s9984 s9434 ## s9984 1.0000 0.2332 ## s9434 0.2332 1.0000 –&gt; 2式とも, 9984_{t-1}の係数, 有意でない. 一方, 9434_{t-1} → 9984_tの係数, 有意 インパルス応答 直交化インパルス応答 # s9434 --&gt; 将来のs9434, s9984の変動を調べる ip &lt;- vars::irf(var1, impulse = c(&quot;s9434&quot;), response = c(&quot;s9434&quot;, &quot;s9984&quot;), n.ahead = 5, boot = TRUE) # ip &lt;- vars::irf(var1, impulse = c(&quot;s9984&quot;), response = c(&quot;s9984&quot;, &quot;s9434&quot;), # n.ahead = 5, boot = TRUE) # ortho = T (デフォルト): 直交化インパルス応答; ortho = F: 非直交化インパルス応答 # boot = T: ブートストラップ法により, 信頼区間計算 # cumulative = T: 累積インパルス応答. デフォルトはF. plot(ip) # 破線は信頼区間 ip ## ## Impulse response coefficients ## $s9434 ## s9984 s9434 ## [1,] 0.000000e+00 1.010933e-02 ## [2,] -2.347883e-03 -3.726614e-04 ## [3,] -3.849675e-05 2.305365e-06 ## [4,] -2.585736e-06 -2.724278e-07 ## [5,] -7.444386e-08 -2.547692e-09 ## [6,] -3.373143e-09 -2.685594e-10 ## ## ## Lower Band, CI= 0.95 ## $s9434 ## s9984 s9434 ## [1,] 0.000000e+00 9.425850e-03 ## [2,] -3.617266e-03 -9.136907e-04 ## [3,] -2.181689e-04 -4.546795e-05 ## [4,] -1.937801e-05 -5.436000e-06 ## [5,] -1.044188e-06 -1.218145e-07 ## [6,] -9.795633e-08 -3.423524e-08 ## ## ## Upper Band, CI= 0.95 ## $s9434 ## s9984 s9434 ## [1,] 0.000000e+00 1.075027e-02 ## [2,] -1.103634e-03 9.810869e-05 ## [3,] 1.167937e-04 6.444257e-05 ## [4,] 9.473575e-06 1.321163e-06 ## [5,] 8.945084e-07 4.176101e-07 ## [6,] 4.814741e-09 6.348973e-09 ip_2 &lt;- vars::irf(var1, impulse = c(&quot;s9984&quot;), response = c(&quot;s9984&quot;, &quot;s9434&quot;), n.ahead = 5, boot = TRUE) plot(ip_2) ip_2 ## ## Impulse response coefficients ## $s9984 ## s9984 s9434 ## [1,] 2.794180e-02 2.424868e-03 ## [2,] 9.249922e-04 4.666343e-05 ## [3,] 3.842707e-05 2.783727e-06 ## [4,] 1.400087e-06 8.448866e-08 ## [5,] 5.494551e-08 3.702661e-09 ## [6,] 2.066430e-09 1.310440e-10 ## ## ## Lower Band, CI= 0.95 ## $s9984 ## s9984 s9434 ## [1,] 2.606510e-02 1.481330e-03 ## [2,] -3.038462e-04 -4.849896e-04 ## [3,] -1.090658e-04 -1.138736e-05 ## [4,] -6.743739e-06 -3.696761e-06 ## [5,] -2.687894e-07 -8.944996e-08 ## [6,] -3.414813e-08 -2.512465e-08 ## ## ## Upper Band, CI= 0.95 ## $s9984 ## s9984 s9434 ## [1,] 3.015528e-02 3.227032e-03 ## [2,] 2.126164e-03 5.237760e-04 ## [3,] 2.108518e-04 2.887267e-05 ## [4,] 1.745960e-05 1.497322e-06 ## [5,] 1.799664e-06 2.155274e-07 ## [6,] 1.578947e-07 8.799614e-09 非直交化インパルス応答 ip_3 &lt;- vars::irf(var1, impulse = c(&quot;s9434&quot;), response = c(&quot;s9434&quot;, &quot;s9984&quot;), ortho = F, n.ahead = 5, boot = TRUE) plot(ip_3) ip_3 ## ## Impulse response coefficients ## $s9434 ## s9984 s9434 ## [1,] 0.000000e+00 1.000000e+00 ## [2,] -2.322491e-01 -3.686312e-02 ## [3,] -3.808042e-03 2.280433e-04 ## [4,] -2.557772e-04 -2.694816e-05 ## [5,] -7.363877e-06 -2.520139e-07 ## [6,] -3.336663e-07 -2.656550e-08 ## ## ## Lower Band, CI= 0.95 ## $s9434 ## s9984 s9434 ## [1,] 0.000000e+00 1.000000e+00 ## [2,] -3.501680e-01 -9.216831e-02 ## [3,] -2.386410e-02 -3.152640e-03 ## [4,] -2.400241e-03 -6.949547e-04 ## [5,] -2.477588e-04 -9.013060e-06 ## [6,] -2.770858e-05 -5.879464e-06 ## ## ## Upper Band, CI= 0.95 ## $s9434 ## s9984 s9434 ## [1,] 0.000000e+00 1.000000e+00 ## [2,] -8.606093e-02 1.561076e-02 ## [3,] 1.179410e-02 7.867517e-03 ## [4,] 5.924906e-04 2.849073e-04 ## [5,] 1.060999e-04 6.831511e-05 ## [6,] 6.902372e-07 2.785490e-06 累積インパルス応答 ip_cum &lt;- vars::irf(var1, impulse = c(&quot;s9434&quot;), response = c(&quot;s9434&quot;, &quot;s9984&quot;), n.ahead = 5, boot = TRUE, cumulative = T) plot(ip_cum) Grangerの因果性検定 vars::causality(var1, cause = &quot;s9434&quot;) # VAR(1)の推定結果var1を用い, 9434をcauseとするGranger因果性検定 ## $Granger ## ## Granger causality H0: s9434 do not Granger-cause s9984 ## ## data: VAR object var1 ## F-Test = 10.509, df1 = 1, df2 = 2972, p-value = 0.001201 ## ## ## $Instant ## ## H0: No instantaneous causality between: s9434 and s9984 ## ## data: VAR object var1 ## Chi-squared = 76.829, df = 1, p-value &lt; 2.2e-16 –&gt; 帰無仮説(因果性なし)棄却 → 9434をcauseとするGranger因果性の存在を示唆 vars::causality(var1, cause = &quot;s9984&quot;) ## $Granger ## ## Granger causality H0: s9984 do not Granger-cause s9434 ## ## data: VAR object var1 ## F-Test = 0.24301, df1 = 1, df2 = 2972, p-value = 0.6221 ## ## ## $Instant ## ## H0: No instantaneous causality between: s9984 and s9434 ## ## data: VAR object var1 ## Chi-squared = 76.829, df = 1, p-value &lt; 2.2e-16 –&gt; 帰無仮説(因果性なし)棄却できず → 9984をcauseとするGranger因果性存在せず 一方、Grangerの瞬時因果性, 9984, 9434, いずれの方向も棄却できず → 存在を示唆 事例2: 米英日3株式市場 (S&amp;P500, FTSE, 日経平均) データをquantmodパッケージを使って, Yahoo!ファイナンスより入手 gspc &lt;- getSymbols(&#39;^GSPC&#39;, periodicity = &quot;monthly&quot;, from = &#39;1999-12-01&#39;, to = &#39;2024-11-30&#39;, auto.assign = FALSE) ftse &lt;- getSymbols(&#39;^FTSE&#39;, periodicity = &quot;monthly&quot;, from = &#39;1999-12-01&#39;, to = &#39;2024-11-30&#39;, auto.assign = FALSE) n225 &lt;- getSymbols(&#39;^N225&#39;, periodicity = &quot;monthly&quot;, from = &#39;1999-12-01&#39;, to = &#39;2024-11-30&#39;, auto.assign = FALSE) # gspc: 1999-12-01-- (月末株価なのに, 1日表示) # ftse: 1999-12-01-- (同) # n225: 1999-12-31-- (月末表示) # → n225に合わせる # 月次終値 (調整済) より対数収益率を計算 us &lt;- diff(log(gspc$GSPC.Adjusted))[-1] uk &lt;- diff(log(ftse$FTSE.Adjusted))[-1] jp &lt;- diff(log(n225$N225.Adjusted))[-1] # 3市場データの結合 mkt &lt;- cbind(coredata(us), coredata(uk), coredata(jp)) colnames(mkt) &lt;- c(&quot;us&quot;, &quot;uk&quot;, &quot;jp&quot;) mkt &lt;- xts(mkt, index(jp)) mkt &lt;- mkt[-nrow(mkt), ] # 最終行は月中時点 (未完) # 結果の表示 head(mkt) ## us uk jp ## 1999-12-31 -0.05224485 -0.100351609 0.03147106 ## 2000-01-31 -0.02031300 -0.005743495 0.02125795 ## 2000-02-29 0.09232375 0.048174179 0.01875144 ## 2000-03-31 -0.03127991 -0.033078382 -0.12354810 ## 2000-04-30 -0.02215875 0.005044624 -0.09575560 ## 2000-05-31 0.02365163 -0.007370510 0.06395117 plot(cumsum(mkt), type = &quot;l&quot;, col = c(&quot;black&quot;, &quot;lightblue&quot;, &quot;orange&quot;), main = &quot;S&amp;P500 (black), FTSE (lightblue), NK225 (orange)&quot;) VARモデルの推定 以下, 引き続きパッケージvarsを利用 3変量VAR(2)モデルを仮定した場合の推定 usukjp &lt;- data.frame(mkt$us, mkt$uk, mkt$jp) head(usukjp, 5) ## us uk jp ## 1999-12-31 -0.05224485 -0.100351609 0.03147106 ## 2000-01-31 -0.02031300 -0.005743495 0.02125795 ## 2000-02-29 0.09232375 0.048174179 0.01875144 ## 2000-03-31 -0.03127991 -0.033078382 -0.12354810 ## 2000-04-30 -0.02215875 0.005044624 -0.09575560 var2usukjp &lt;- vars::VAR(usukjp, p = 2, type = &quot;const&quot;) # summary(var2usukjp) # 係数推定値 (値のみ） coef(var2usukjp) ## $us ## Estimate Std. Error t value Pr(&gt;|t|) ## us.l1 -0.100789381 0.104185184 -0.96740609 0.33414994 ## uk.l1 0.045868853 0.110362568 0.41561966 0.67799677 ## jp.l1 0.114750906 0.063975226 1.79367723 0.07391004 ## us.l2 -0.133893130 0.104714293 -1.27865190 0.20204551 ## uk.l2 0.008473531 0.109109720 0.07766065 0.93815174 ## jp.l2 0.055752503 0.063474022 0.87835150 0.38048265 ## const 0.005481561 0.002653987 2.06540610 0.03977602 ## ## $uk ## Estimate Std. Error t value Pr(&gt;|t|) ## us.l1 0.077801084 0.090443271 0.8602197 0.3903810 ## uk.l1 -0.143021810 0.095805864 -1.4928294 0.1365727 ## jp.l1 0.081557621 0.055536963 1.4685286 0.1430483 ## us.l2 -0.144458741 0.090902591 -1.5891598 0.1131177 ## uk.l2 0.059647469 0.094718266 0.6297357 0.5293651 ## jp.l2 0.010718471 0.055101867 0.1945210 0.8459046 ## const 0.001059086 0.002303929 0.4596871 0.6460865 ## ## $jp ## Estimate Std. Error t value Pr(&gt;|t|) ## us.l1 -0.019909207 0.127544318 -0.1560964 0.8760660 ## uk.l1 0.100071793 0.135106719 0.7406870 0.4594846 ## jp.l1 0.078471208 0.078318972 1.0019438 0.3172089 ## us.l2 -0.183655004 0.128192057 -1.4326551 0.1530372 ## uk.l2 0.076219074 0.133572973 0.5706175 0.5687024 ## jp.l2 0.075815442 0.077705394 0.9756780 0.3300400 ## const 0.002701346 0.003249032 0.8314311 0.4064165 # 係数推定値の行列表示 (t値や標準誤差は非表示) vars::Acoef(var2usukjp) # as a list of matrices ## [[1]] ## us.l1 uk.l1 jp.l1 ## us -0.10078938 0.04586885 0.11475091 ## uk 0.07780108 -0.14302181 0.08155762 ## jp -0.01990921 0.10007179 0.07847121 ## ## [[2]] ## us.l2 uk.l2 jp.l2 ## us -0.1338931 0.008473531 0.05575250 ## uk -0.1444587 0.059647469 0.01071847 ## jp -0.1836550 0.076219074 0.07581544 vars::Bcoef(var2usukjp) # as a matrix ## us.l1 uk.l1 jp.l1 us.l2 uk.l2 jp.l2 ## us -0.10078938 0.04586885 0.11475091 -0.1338931 0.008473531 0.05575250 ## uk 0.07780108 -0.14302181 0.08155762 -0.1444587 0.059647469 0.01071847 ## jp -0.01990921 0.10007179 0.07847121 -0.1836550 0.076219074 0.07581544 ## const ## us 0.005481561 ## uk 0.001059086 ## jp 0.002701346 次数\\(p\\)を選択する場合 関数VAR()によって, 情報量規準により最適な次数を選択 最大次数lag.maxと採用する情報量規準icを指定 varusukjp &lt;- vars::VAR(usukjp, type = &quot;const&quot;, lag.max = 5, ic = &quot;AIC&quot;) summary(varusukjp) ## ## VAR Estimation Results: ## ========================= ## Endogenous variables: us, uk, jp ## Deterministic variables: const ## Sample size: 297 ## Log Likelihood: 1727.17 ## Roots of the characteristic polynomial: ## 0.1921 0.1145 0.08493 ## Call: ## vars::VAR(y = usukjp, type = &quot;const&quot;, lag.max = 5, ic = &quot;AIC&quot;) ## ## ## Estimation results for equation us: ## =================================== ## us = us.l1 + uk.l1 + jp.l1 + const ## ## Estimate Std. Error t value Pr(&gt;|t|) ## us.l1 -0.085850 0.102719 -0.836 0.4040 ## uk.l1 0.047703 0.106645 0.447 0.6550 ## jp.l1 0.101421 0.063066 1.608 0.1089 ## const 0.004874 0.002611 1.867 0.0629 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ## Residual standard error: 0.0445 on 293 degrees of freedom ## Multiple R-Squared: 0.01079, Adjusted R-squared: 0.0006629 ## F-statistic: 1.065 on 3 and 293 DF, p-value: 0.364 ## ## ## Estimation results for equation uk: ## =================================== ## uk = us.l1 + uk.l1 + jp.l1 + const ## ## Estimate Std. Error t value Pr(&gt;|t|) ## us.l1 0.0960686 0.0893126 1.076 0.2830 ## uk.l1 -0.1543287 0.0927260 -1.664 0.0971 . ## jp.l1 0.0699508 0.0548350 1.276 0.2031 ## const 0.0003514 0.0022701 0.155 0.8771 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ## Residual standard error: 0.03869 on 293 degrees of freedom ## Multiple R-Squared: 0.01622, Adjusted R-squared: 0.006143 ## F-statistic: 1.61 on 3 and 293 DF, p-value: 0.1872 ## ## ## Estimation results for equation jp: ## =================================== ## jp = us.l1 + uk.l1 + jp.l1 + const ## ## Estimate Std. Error t value Pr(&gt;|t|) ## us.l1 0.006425 0.125600 0.051 0.959 ## uk.l1 0.068097 0.130400 0.522 0.602 ## jp.l1 0.077618 0.077114 1.007 0.315 ## const 0.002083 0.003192 0.653 0.515 ## ## ## Residual standard error: 0.05441 on 293 degrees of freedom ## Multiple R-Squared: 0.01366, Adjusted R-squared: 0.003559 ## F-statistic: 1.352 on 3 and 293 DF, p-value: 0.2576 ## ## ## ## Covariance matrix of residuals: ## us uk jp ## us 0.001980 0.001358 0.001589 ## uk 0.001358 0.001497 0.001206 ## jp 0.001589 0.001206 0.002960 ## ## Correlation matrix of residuals: ## us uk jp ## us 1.0000 0.7890 0.6564 ## uk 0.7890 1.0000 0.5729 ## jp 0.6564 0.5729 1.0000 # ic = AIC, HQ, SC, FPE # HQ: Hannan-Quinn 情報量規準, FPE: forecast prediction error 規準 –&gt; \\(p=1\\)を選択 推定されたVARモデルによる予測 predict(var2usukjp, n.ahead = 10, ci = 0.95) # 95%区間予測を 10期先まで ## $us ## fcst lower upper CI ## [1,] 0.005354386 -0.08196850 0.09267728 0.08732289 ## [2,] 0.007556693 -0.08033117 0.09544455 0.08788786 ## [3,] 0.004571038 -0.08365687 0.09279894 0.08822791 ## [4,] 0.004610780 -0.08361901 0.09284057 0.08822979 ## [5,] 0.004786821 -0.08344433 0.09301797 0.08823115 ## [6,] 0.004797814 -0.08343334 0.09302897 0.08823116 ## [7,] 0.004783284 -0.08344788 0.09301445 0.08823117 ## [8,] 0.004784083 -0.08344709 0.09301525 0.08823117 ## [9,] 0.004785395 -0.08344577 0.09301656 0.08823117 ## [10,] 0.004785293 -0.08344588 0.09301646 0.08823117 ## ## $uk ## fcst lower upper CI ## [1,] 0.0008720553 -0.07493304 0.07667715 0.07580510 ## [2,] 0.0019663688 -0.07445110 0.07838383 0.07641747 ## [3,] 0.0010561816 -0.07590648 0.07801884 0.07696266 ## [4,] 0.0005145362 -0.07645512 0.07748419 0.07696966 ## [5,] 0.0009359646 -0.07603696 0.07790889 0.07697293 ## [6,] 0.0008651470 -0.07610795 0.07783825 0.07697310 ## [7,] 0.0008779161 -0.07609521 0.07785104 0.07697312 ## [8,] 0.0008696381 -0.07610349 0.07784276 0.07697313 ## [9,] 0.0008733833 -0.07609974 0.07784651 0.07697313 ## [10,] 0.0008725149 -0.07610061 0.07784564 0.07697313 ## ## $jp ## fcst lower upper CI ## [1,] -0.002681770 -0.1095831 0.1042196 0.1069014 ## [2,] 0.005402640 -0.1022622 0.1130675 0.1076648 ## [3,] 0.002051416 -0.1060374 0.1101403 0.1080888 ## [4,] 0.002048665 -0.1060410 0.1101384 0.1080897 ## [5,] 0.002218337 -0.1058723 0.1103090 0.1080907 ## [6,] 0.002221528 -0.1058692 0.1103122 0.1080907 ## [7,] 0.002227127 -0.1058636 0.1103178 0.1080907 ## [8,] 0.002221959 -0.1058688 0.1103127 0.1080907 ## [9,] 0.002224775 -0.1058659 0.1103155 0.1080907 ## [10,] 0.002224175 -0.1058665 0.1103149 0.1080907 Granger因果性の検定 日本 (jp) をcauseとする因果性 var3usukjp &lt;- vars::VAR(usukjp, p = 3, type = &quot;const&quot;) head(var3usukjp$y) # ## us uk jp ## 1999-12-31 -0.05224485 -0.100351609 0.03147106 ## 2000-01-31 -0.02031300 -0.005743495 0.02125795 ## 2000-02-29 0.09232375 0.048174179 0.01875144 ## 2000-03-31 -0.03127991 -0.033078382 -0.12354810 ## 2000-04-30 -0.02215875 0.005044624 -0.09575560 ## 2000-05-31 0.02365163 -0.007370510 0.06395117 vars::causality(var3usukjp, cause = &quot;jp&quot;) # jp --&gt; us, uk ## $Granger ## ## Granger causality H0: jp do not Granger-cause us uk ## ## data: VAR object var3usukjp ## F-Test = 0.62058, df1 = 6, df2 = 855, p-value = 0.714 ## ## ## $Instant ## ## H0: No instantaneous causality between: jp and us uk ## ## data: VAR object var3usukjp ## Chi-squared = 89.743, df = 2, p-value &lt; 2.2e-16 –&gt; Gragnerの意味での因果性なし. 同時因果性あり 日英をcauseとする因果性 vars::causality(var3usukjp, cause = c(&quot;jp&quot;, &quot;uk&quot;)) # jp, uk --&gt; us ## $Granger ## ## Granger causality H0: uk jp do not Granger-cause us ## ## data: VAR object var3usukjp ## F-Test = 0.63403, df1 = 6, df2 = 855, p-value = 0.7031 ## ## ## $Instant ## ## H0: No instantaneous causality between: uk jp and us ## ## data: VAR object var3usukjp ## Chi-squared = 119.65, df = 2, p-value &lt; 2.2e-16 –&gt; Grangerの意味での因果性なし. 同時因果性あり - 関数vars::causality() - causeを指定なし (デフォルト) では, 第1列の変数がcause - K変量VARモデルに対する因果性検定 (対応する係数にゼロ制約を課す) - ← 特定の2変量のみの因果性を調べる検定ではない 予測誤差分散分解 (forecast error variance decomposition) 直交化インパルス応答関数を使い, 第j変数の第k変数のh先予測誤差分散への寄与 # library(vars) var3_fevd &lt;- vars::fevd(var3usukjp, n.ahead = 10) # 10期先まで評価する plot(var3_fevd) varmkt &lt;- vars::VAR(mkt, p = 3, type = &quot;const&quot;) varmkt_fevd &lt;- vars::fevd(varmkt, n.ahead = 10) # 10期先まで評価する plot(varmkt_fevd) 変数の順番の影響の確認 分散分解 (変数の順序入れ替え) usjpuk &lt;- data.frame(mkt$us, mkt$jp, mkt$uk) cov(usukjp) ## us uk jp ## us 0.001985518 0.001368410 0.001584889 ## uk 0.001368410 0.001535432 0.001192584 ## jp 0.001584889 0.001192584 0.002963727 cov(usjpuk) ## us jp uk ## us 0.001985518 0.001584889 0.001368410 ## jp 0.001584889 0.002963727 0.001192584 ## uk 0.001368410 0.001192584 0.001535432 var3usjpuk &lt;- vars::VAR(usjpuk, p = 3, type = &quot;const&quot;) var3_fevd_2 &lt;- vars::fevd(var3usjpuk, n.ahead = 10) # 10期先まで評価する plot(var3_fevd_2) 直交インパルス応答 米国 → 他市場 (米国, 英国, 日本)の順序 vs (米国, 日本, 英国)の順序 # (us, uk, jp) ip1 &lt;- vars::irf(var3usukjp, impulse = c(&quot;us&quot;), n.ahead = 5, boot = TRUE) # ortho = T (デフォルト): 直交化インパルス応答; ortho = F: 非直交化インパルス応答 # boot = T: ブートストラップ法により, 信頼区間計算 # cumulative = T: 累積インパルス応答. デフォルトはF. plot(ip1) # # (us, jp, uk) ip2 &lt;- vars::irf(var3usjpuk, impulse = c(&quot;us&quot;), n.ahead = 5, boot = TRUE) plot(ip2) 日本 → 他市場 # (us, uk, jp) # ip3 &lt;- vars::irf(var3usukjp, impulse = c(&quot;uk&quot;), n.ahead = 5, boot = TRUE) ip3 &lt;- vars::irf(var3usukjp, impulse = c(&quot;jp&quot;), n.ahead = 5, boot = TRUE) plot(ip3) 上図では, 日本が第三の変数 (外生性が一番低いと仮定) となっていることから, 日本固有のショックが\\(t=0\\)に生じた時点では, 日本より上位にある米, 英両市場は反応しておらず, \\(t=1\\)になってVAR係数を通じてショックが伝播する様子が 分かる. # (us, jp, uk) ip4 &lt;- vars::irf(var3usjpuk, impulse = c(&quot;jp&quot;), n.ahead = 5, boot = TRUE) plot(ip4) 他方, ここでは, 日本が第二の変数となっていることから, 日本固有のショックが\\(t=0\\)に生じた時点で, 日本より下位にある英市場もわずかながらであるがショックが同時発生しているが, 上位にある米はやはり\\(t=1\\)になってショックが伝播していることが分かる. 確認: Choleski分解: \\(\\Sigma = P P&#39;\\) # chol(cov(usjpuk)) # 上三角行列P&#39; # (us, uk, jp) t(chol(cov(usukjp))) # 下三角行列P&#39; ## us uk jp ## us 0.04455916 0.000000000 0.00000000 ## uk 0.03070996 0.024337838 0.00000000 ## jp 0.03556821 0.004120564 0.04100794 # (us, jp, uk) t(chol(cov(usjpuk))) # 下三角行列P&#39; ## us jp uk ## us 0.04455916 0.000000000 0.0000000 ## jp 0.03556821 0.041214439 0.0000000 ## uk 0.03070996 0.002433265 0.0242159 (参考) Tsay氏作成パッケージMTS library(MTS) # &#39;vars&#39;との同時使用は避ける (VAR()関数が重複) var3 &lt;- MTS::VAR(usukjp, p = 3) # include.mean = T (デフォルト), VAR係数の最小2乗推定 MTS::GrangerTest(usukjp, p = 3) # include.mean = T (デフォルト) MTS::VARMAirf(Phi = var3$Phi, Sigma = var3$Sigma) # Theta = NULL (デフォルト): VMA係数行列 その他: Granger因果性検定の関数 パッケージlmtest - 関数grangertest(): 2変量間のGranger因果性検定 - usage: grangertest(x, y, order = 1, na.action = na.omit, ...) # library(lmtest) data(ChickEgg) # mts, tsクラス plot(ChickEgg) lmtest::grangertest(egg ~ chicken, order = 3, data = ChickEgg) # → 有意でない ## Granger causality test ## ## Model 1: egg ~ Lags(egg, 1:3) + Lags(chicken, 1:3) ## Model 2: egg ~ Lags(egg, 1:3) ## Res.Df Df F Pr(&gt;F) ## 1 44 ## 2 47 -3 0.5916 0.6238 lmtest::grangertest(chicken ~ egg, order = 3, data = ChickEgg) # → 有意(1%) ## Granger causality test ## ## Model 1: chicken ~ Lags(chicken, 1:3) + Lags(egg, 1:3) ## Model 2: chicken ~ Lags(chicken, 1:3) ## Res.Df Df F Pr(&gt;F) ## 1 44 ## 2 47 -3 5.405 0.002966 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ccf(ChickEgg[, &quot;chicken&quot;], ChickEgg[, &quot;egg&quot;]) # 1: chicken, 2: egg パッケージNlinTS: 非線形時系列解析, 因果性検出 - 関数causality.test(): 2変量間のGranger因果性検定 - usage: causality.test(ts1, ts2, lag, diff = FALSE) library (NlinTS) # 非線形時系列解析, 因果性検出. causality.test() ## Loading required package: Rcpp res1 &lt;- NlinTS::causality.test(ChickEgg[, &quot;egg&quot;], ChickEgg[, &quot;chicken&quot;], lag = 3) res2 &lt;- NlinTS::causality.test(ChickEgg[, &quot;chicken&quot;], ChickEgg[, &quot;egg&quot;], lag = 3) res1$summary() ## -------------------- ## Test summary ## -------------------- ## The lag parameter: p = 3 ## The Granger causality Index: GCI = 0.0395451 ## The value of the F-test: 0.591615 ## The p_value of the F-test: 0.623786 ## The critical value with 5% of risk:: 2.822 res2$summary() ## -------------------- ## Test summary ## -------------------- ## The lag parameter: p = 3 ## The Granger causality Index: GCI = 0.313731 ## The value of the F-test: 5.40498 ## The p_value of the F-test: 0.0029664 ## The critical value with 5% of risk:: 2.822 –&gt; 上のgrangertst()の結果と同一 パッケージMTS - GrangerTest(): p変量のGranger因果性検定 - usage: GrangerTest(X,p=1,include.mean=T,locInput=c(1)) library(MTS) ## ## Attaching package: &#39;MTS&#39; ## The following object is masked from &#39;package:vars&#39;: ## ## VAR EggChick &lt;- data.frame(egg = ChickEgg[, &quot;egg&quot;], chicken = ChickEgg[, &quot;chicken&quot;]) MTS::GrangerTest(EggChick, p = 3) # カイ2乗検定 (F値x3 〜 (漸近的に)Chisq(3)) ## Number of targeted zero parameters: 3 ## Chi-square test for Granger Causality and p-value: 1.774846 0.620424 ## Constant term: ## Estimates: 306.1473 133544.6 ## Std.Error: 132.5194 41073.51 ## AR coefficient matrix ## AR( 1 )-matrix ## [,1] [,2] ## [1,] 1.3 0.000 ## [2,] 76.6 0.292 ## standard error ## [,1] [,2] ## [1,] 0.143 0.000 ## [2,] 25.279 0.184 ## AR( 2 )-matrix ## [,1] [,2] ## [1,] -0.361 0.000 ## [2,] -47.078 0.445 ## standard error ## [,1] [,2] ## [1,] 0.234 0.000 ## [2,] 39.387 0.186 ## AR( 3 )-matrix ## [,1] [,2] ## [1,] 0.0042 0.00000 ## [2,] -35.9327 0.00407 ## standard error ## [,1] [,2] ## [1,] 0.141 0.000 ## [2,] 28.538 0.174 ## ## Residuals cov-mtx: ## [,1] [,2] ## [1,] 22800.12 1843210 ## [2,] 1843210.37 412998788 ## ## det(SSE) = 6.018998e+12 ## AIC = 29.75928 ## BIC = 30.09077 ## HQ = 29.88712 # MTS::GrangerTest(ChickEgg, p = 3) –&gt; 上のgrangertst()の結果とやや異なる 9.5 補足: 分散共分散行列のコレスキー分解 直交化インパルス応答や予測誤差分散分解では, 事前に外生性の高い順に変数を配置しておく必要がある. 直交化する際には, VAR(\\(p\\))モデルの撹乱項の分散共分散行列に対してCholeskey分解が利用される. 分散共分散行列に対するコレスキー (Choleskey) 分解の計算例 以下, 簡単のため, VAR(\\(p\\))モデルは使わない ## Loading required package: MASS ## Loading required package: strucchange ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## Loading required package: sandwich ## Loading required package: urca ## Loading required package: lmtest ## Loading required package: xts ## Loading required package: TTR ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.5.1 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.1 ## ✔ purrr 1.0.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ stringr::boundary() masks strucchange::boundary() ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::first() masks xts::first() ## ✖ dplyr::lag() masks stats::lag() ## ✖ dplyr::last() masks xts::last() ## ✖ dplyr::select() masks MASS::select() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors ## us uk jp ## 1999-12-31 -0.05224485 -0.100351609 0.03147106 ## 2000-01-31 -0.02031300 -0.005743495 0.02125795 ## 2000-02-29 0.09232375 0.048174179 0.01875144 ## 2000-03-31 -0.03127991 -0.033078382 -0.12354810 ## 2000-04-30 -0.02215875 0.005044624 -0.09575560 ## 2000-05-31 0.02365163 -0.007370510 0.06395117 分散共分散行列\\({\\bf \\Sigma}\\)のCholeskey分解 \\[ {\\bf \\Sigma} = {\\bf P}{\\bf P&#39;} \\] 但し, \\({\\bf P}\\)は下三角行列. 上で使用した米英日3か国の株価指数データ (S&amp;P500, FTSE, 日経平均) をここでも使用して実際にCholeskey分解を行ってみよう. 米英日の日次収益率に対して分散共分散行列を計算 → Choleskey分解 # アメリカ、イギリス、日本市場 usukjp &lt;- data.frame(mkt$us, mkt$uk, mkt$jp) head(usukjp, 5) ## us uk jp ## 1999-12-31 -0.05224485 -0.100351609 0.03147106 ## 2000-01-31 -0.02031300 -0.005743495 0.02125795 ## 2000-02-29 0.09232375 0.048174179 0.01875144 ## 2000-03-31 -0.03127991 -0.033078382 -0.12354810 ## 2000-04-30 -0.02215875 0.005044624 -0.09575560 # 分散共分散行列: Sigma cov_usukjp &lt;- cov(usukjp) %&gt;% print(digits = 4) ## us uk jp ## us 0.001986 0.001368 0.001585 ## uk 0.001368 0.001535 0.001193 ## jp 0.001585 0.001193 0.002964 # Choleskey分解: Sigma = PP&#39; P &lt;- chol(cov_usukjp) %&gt;% t() %&gt;% print(digits = 4) # 下三角行列P ## us uk jp ## us 0.04456 0.000000 0.00000 ## uk 0.03071 0.024338 0.00000 ## jp 0.03557 0.004121 0.04101 # Sigmaの復元 (確認用) P %*% t(P) %&gt;% print(digits = 4) ## us uk jp ## us 0.001986 0.001368 0.001585 ## uk 0.001368 0.001535 0.001193 ## jp 0.001585 0.001193 0.002964 米日英の分散共分散行列を計算 → Choleskey分解 # アメリカ、日本, 英国市場 usjpuk &lt;- data.frame(mkt$us, mkt$jp, mkt$uk) head(usjpuk, 5) ## us jp uk ## 1999-12-31 -0.05224485 0.03147106 -0.100351609 ## 2000-01-31 -0.02031300 0.02125795 -0.005743495 ## 2000-02-29 0.09232375 0.01875144 0.048174179 ## 2000-03-31 -0.03127991 -0.12354810 -0.033078382 ## 2000-04-30 -0.02215875 -0.09575560 0.005044624 # 分散共分散行列: Sigma cov_usjpuk &lt;- cov(usjpuk) %&gt;% print(digits = 4) ## us jp uk ## us 0.001986 0.001585 0.001368 ## jp 0.001585 0.002964 0.001193 ## uk 0.001368 0.001193 0.001535 # Choleskey分解: Sigma = PP&#39; P &lt;- chol(cov_usjpuk) %&gt;% t() %&gt;% print(digits = 4) # 下三角行列P ## us jp uk ## us 0.04456 0.000000 0.00000 ## jp 0.03557 0.041214 0.00000 ## uk 0.03071 0.002433 0.02422 # Sigmaの復元 (確認用) P %*% t(P) %&gt;% print(digits = 4) ## us jp uk ## us 0.001986 0.001585 0.001368 ## jp 0.001585 0.002964 0.001193 ## uk 0.001368 0.001193 0.001535 "],["共和分分析.html", "10 共和分分析 10.1 見せかけの回帰 (再掲) 10.2 共和分分析 10.3 誤差修正モデル: データ分析例 (Tsay, MTS, Ch5)", " 10 共和分分析 共和分 (cointegration) と誤差修正モデル (error correction model, ECM) は, 非定常な時系列データを扱う際に重要な概念・手法である. 長期的な均衡関係と短期的な修正のプロセスを同時にモデル化する枠組みを提供し, 経済・金融分野で広く応用されている. 例として, 長短金利, 関連する商品価格のペア (例, ガソリン vs 原油), 家計の消費と所得, 為替レートと物価指数 (購買力平価説), …など. 個々には非定常だが, 連動して動く時系列に関する経済理論の実証分析に有用である. 2003年, Grangerは共和分に関する研究によりノーベル経済学賞を受賞した (ARCHを提案したEngleと同時受賞). 共和分分析の手順 概ね以下のような流れで行われる (幾つかの要素は前後するか繰り返し行われることがある). ステップ1：単位根検定 単位根検定 (Augmented Dickey-Fuller検定など) を用いて, 各時系列が非定常であるかを検定する 変数が同じ次数（通常 \\(I(1)\\)）の和分過程であることを確認する. 変数の和分の次数が異なる場合は, 次数を揃えるか, 別のアプローチを検討する ※) 単位根検定に際しては, 適切な確定項（定数項と線形トレンド) やラグ次数の選択を行う (時系列プロットやACFのコレログラム, AIC/BIC等の情報量基準等を利用) ステップ2：共和分検定 適切な検定方法を選択する： (共和分関係が一つの場合) Engle-Granger検定, Philips-Ouliaris検定 (共和分関係が複数あることが推察される場合) Johansen検定 確定項（定数項と線形トレンド) やラグ次数について適切なモデル仕様を特定する 共和分検定を実行し, 共和分関係の有無 (数) を決定する ステップ3：ECMモデルの推定 誤差修正モデル (ECM) を推定する 長期的 (均衡) 関係 (共和分ベクトル) の推定 短期的な調整スピードの推定 ステップ4: モデル診断 共和分方程式の残差 (誤差) をチェック (ステップ2の中でも) ECMの残差をチェック (自己相関, 多変量ARCH効果, 正規性等) パラメータの安定性をチェック 必要に応じてステップ1–3に戻る ステップ5: モデルの解釈 推定されたモデルを解釈する. 予想や直感に反しないか? 含意・洞察を引き出す モデリング上の留意点 モデルの仕様 確定項（定数, トレンド）の選択は検定統計量の分布 (→ 検定結果) に影響 ラグ長の選択も重要 検定の前提条件 データ生成に構造的な変化がないか サンプル・サイズは十分大きいか, 等 共和分・ECMの応用上の留意点 共和分・ECMの方法論を実践する場合には, 時間軸の不明瞭さに注意を払う必要がある. 共和分における「長期的」均衡は, 実際にどの程度の期間がかかって実現されるかについて提示しない. ECMにおける「短期的」修正は, 単位時間あたりに不均衡が修正される割合 (スピード) を示すだけで, 実際に均衡水準まで修正される保証はない 10.1 見せかけの回帰 (再掲) -「5.2 単位根検定と見せかけの回帰」の内容 (再掲) 単位根過程\\(y_{t}\\)を, 定数と\\(y_{t}\\)と``関係’’ (共和分関係) のない単位根過程\\(x_{t}\\)に対して回帰すると, \\(x_{t}\\)と\\(y_{t}\\)の間に有意な関係があり, 回帰の説明力が高いように見える現象が生じることが知られている. これを, 見せかけの回帰 (spurious regression) と呼ぶ. tlen &lt;- 300 seedv &lt;- 1 set.seed(seedv) w1 &lt;- rnorm(tlen) w2 &lt;- rnorm(tlen) x &lt;- cumsum(w1) y &lt;- cumsum(w2) matplot(cbind(x,y), type = &quot;l&quot;) reslm &lt;- lm(y ~ x) summary(reslm) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.0778 -3.6190 0.0812 3.9438 8.6039 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.13230 0.55381 0.239 0.8114 ## x 0.16810 0.06713 2.504 0.0128 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.284 on 298 degrees of freedom ## Multiple R-squared: 0.02061, Adjusted R-squared: 0.01733 ## F-statistic: 6.272 on 1 and 298 DF, p-value: 0.0128 plot(x, y); abline(reslm, col = &quot;red&quot;) 残差に自己相関が残ることの確認 reslm_resid = resid(reslm) plot(reslm_resid, type = &quot;l&quot;) acf(reslm_resid) Durbin-Watson検定 Durbin-Watson検定 (簡便法) 回帰残差の系列相関の有無を検定 \\(DW \\approx 2(1-\\rho)\\) \\(0&lt;DW&lt;4\\). 無相関 \\(\\Leftrightarrow DW=2\\) 見せかけの回帰の場合. DWが小さい傾向 (正の系列相関) library(lmtest) ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric dwtest(reslm) ## ## Durbin-Watson test ## ## data: reslm ## DW = 0.060411, p-value &lt; 2.2e-16 ## alternative hypothesis: true autocorrelation is greater than 0 代替法: Engle-Granger検定 Rで実行可能な主な単位根検定法 ADF検定: tseries内, adf.test(); fUnitRoots内, unitrootTest(), adfTest() Phillips-Perron(PP)検定: urca内, ur.pp(); tseries内, pp.test() PP検定は, 沖本, pp.118–120参照 KPSS検定: urca内, ur.kpss(); tseries内, kpss.test() KPSS検定は, 福地・伊藤, pp.139–140参照 その他の検定法: fUnitRoots内, urersTest() (Elliott-Rothenberg-Stock検定), urspTest() (Schmidt-Phillips検定), urzaTest() (Zivot-Andrews), 等 10.2 共和分分析 共和分分析の代表的な方法として, OLS回帰の残差をベースにしたEngle-Grangerの方法と, VARモデル (および多変量解析の一種である正準相関分析) をベースにしたJohansenの方法がある. 手順としては, 共和分関係を調べたい各変数が非定常であるかどうかを 単位根検定を使って確認することから始まる. 各変数が全て非定常である (通常は, \\(I(1)\\)) ことを確認した後, 変数間の共和分関係の有無やその本数を共和分検定法を使って調べる. 検定結果と共に, 共和分関係を記述する共和分ベクトルの推定値が得られる. 以下では, 沖本 (問題6.3, p.144) の設定を例に取り, 4系列 \\({\\bf y}_t=(y_{1,t},y_{2,t},y_{3,t},y_{4,t})&#39;\\) に対する共和分分析を行う \\(w_{1,t},w_{2,t}\\)は, 互いに独立な単位根過程 \\(u_{1,t},u_{2,t},u_{3,t},u_{4,t}\\)は互いに独立な定常過程. \\(w_{1,t},w_{2,t}\\)とも独立 \\[ \\left\\{ \\begin{split} y_{1,t} &amp;= w_{1,t}+u_{1,t} \\\\ y_{2,t} &amp;= 2 w_{1,t} + u_{1,t} \\\\ y_{3,t} &amp;= w_{2,t} + u_{3,t} \\\\ y_{4,t} &amp;= w_{1,t}+ 2 w_{2,t} + u_{4,t} \\end{split} \\right. \\] この時, 直ちに線形独立な共和分ベクトル \\(\\beta_1 = (1,-0.5,0,0)\\), \\(\\beta_2 = (1,0,2,-1)\\) が得られる. 任意の共和分ベクトルは\\(\\beta_1,\\beta_2\\)の線形和で表現される. 以下では, Rを使って, 正規乱数によりサンプルパスを生成する (長さ=300) tlen &lt;- 300 # 任意に変更可 seedv &lt;- 10 # 任意に変更可 set.seed(seedv) w1 &lt;- cumsum(rnorm(tlen)) w2 &lt;- cumsum(rnorm(tlen)) u1 &lt;- rnorm(tlen); u2 &lt;- rnorm(tlen) u3 &lt;- rnorm(tlen); u4 &lt;- rnorm(tlen) # y1 &lt;- w1 + u1 y2 &lt;- 2 * w1 + u2 y3 &lt;- w2 + u3 y4 &lt;- w1 + 2 * w2 + u4 # # beta1 = (1, -0.5, 0, 0) # beta2 = (1, 0, 2, -1) # ymat &lt;- cbind(y1, y2, y3, y4) matplot(ymat, type = &quot;l&quot;) まず, 各成分が単位根過程 \\(I(1)\\) であることを確認する fUnitRoots::adfTest(y1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -0.1277 ## P VALUE: ## 0.5756 ## ## Description: ## Sun Feb 2 21:07:41 2025 by user: fUnitRoots::adfTest(y2) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: 0.1048 ## P VALUE: ## 0.6497 ## ## Description: ## Sun Feb 2 21:07:41 2025 by user: fUnitRoots::adfTest(y3) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -0.1246 ## P VALUE: ## 0.5766 ## ## Description: ## Sun Feb 2 21:07:41 2025 by user: fUnitRoots::adfTest(y4) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -0.7516 ## P VALUE: ## 0.3768 ## ## Description: ## Sun Feb 2 21:07:41 2025 by user: Engle–Grangerの方法 (Philips-Ouliaris検定) 共和分検定の方法の一つであるPhilips-Ouliaris検定は, 共和分関係が想定される非定常な時系列同士のOLS回帰の残差の定常性を調べることで, これらの間の (一つの) 共和分関係の有無を判断するEngle–Grangerの検定法を改良したものである. Philips-Ouliaris検定はRパッケージのurcaに含まれる関数ca.po()で実行 することができる. - urca::ca.po() - demean (使用するランダムウォーク・モデルのトレンドの指定): &quot;none&quot;, &quot;const&quot;(定数項), &quot;trend&quot;(定数項+時間トレンド) - type (検定種類): &quot;Pu&quot;(デフォルト), &quot;Pz&quot; library(urca) test_po &lt;- ca.po(ymat[, 1:2], demean = &quot;const&quot;) summary(test_po) ## ## ######################################## ## # Phillips and Ouliaris Unit Root Test # ## ######################################## ## ## Test of type Pu ## detrending of series with constant only ## ## ## Call: ## lm(formula = z[, 1] ~ z[, -1]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.6576 -0.7442 -0.0535 0.7229 3.7571 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.552717 0.180515 -3.062 0.0024 ** ## z[, -1] 0.485335 0.004978 97.500 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.114 on 298 degrees of freedom ## Multiple R-squared: 0.9696, Adjusted R-squared: 0.9695 ## F-statistic: 9506 on 1 and 298 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic is: 250.2856 ## ## Critical values of Pu are: ## 10pct 5pct 1pct ## critical values 27.8536 33.713 48.0021 → 帰無仮説棄却. y1とy2には共和分関係あり 生成された時系列データによる係数の推定値は0.495997, すなわち, 推定された共和分ベクトルは\\((1, -0.50)\\)である (小数点以下第三位を四捨五入) 実際, 真のモデルは, \\(2 y_{1,t} - y_{2,t} = 2 u_{1,t} - u_{t,2} \\sim I(0)\\), すなわち, 理論的には, 2変数\\((y_{1,t}, y_{2,t})\\)は, \\((1, -0.5)\\)の共和分ベクトルとする共和分関係にあった 念のために残差の自己相関を確認する. # 残差診断 plot(test_po@testreg$residuals, type = &quot;l&quot;) acf(test_po@testreg$residuals) Box.test(test_po@testreg$residuals) ## ## Box-Pierce test ## ## data: test_po@testreg$residuals ## X-squared = 1.9295, df = 1, p-value = 0.1648 次に\\(y_{1,t}, y_{3,t}\\)の関係性を調べる. test_po &lt;- ca.po(ymat[, c(1, 3)], demean = &quot;const&quot;) summary(test_po) ## ## ######################################## ## # Phillips and Ouliaris Unit Root Test # ## ######################################## ## ## Test of type Pu ## detrending of series with constant only ## ## ## Call: ## lm(formula = z[, 1] ~ z[, -1]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.706 -3.851 1.099 4.190 11.736 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -5.79847 1.11523 -5.199 3.72e-07 *** ## z[, -1] -0.63880 0.06101 -10.470 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.463 on 298 degrees of freedom ## Multiple R-squared: 0.2689, Adjusted R-squared: 0.2665 ## F-statistic: 109.6 on 1 and 298 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic is: 17.1324 ## ## Critical values of Pu are: ## 10pct 5pct 1pct ## critical values 27.8536 33.713 48.0021 –&gt; 1%有意水準では帰無仮説棄却されず (y1とy3には共和分関係なし) しかし, 5%水準では棄却 (y1とy3には共和分関係あり) # 残差診断 plot(test_po@testreg$residuals, type = &quot;l&quot;) acf(test_po@testreg$residuals) Box.test(test_po@testreg$residuals) ## ## Box-Pierce test ## ## data: test_po@testreg$residuals ## X-squared = 256.9, df = 1, p-value &lt; 2.2e-16 –&gt; 残差に強い相関がある. 見せかけの回帰が生じていたことを示唆 実際, 真のモデルでは, \\(y_{1,t}\\)と\\(y_{2,t}\\)は独立であったことから, 両者間の回帰の有意性は見せかけの回帰現象であった この例は, ca.po()の出力のみで判断するのでは間違った判断をくだす 可能性もあることを示している. 残差系列の自己相関を調べるなど 見せかけの回帰が生じていないかを同時にチェックすることがのぞましい. 念のため, 線形トレンドを指定した場合を実行 test_po &lt;- ca.po(ymat[, c(1, 3)], demean = &quot;trend&quot;) summary(test_po) ## ## ######################################## ## # Phillips and Ouliaris Unit Root Test # ## ######################################## ## ## Test of type Pu ## detrending of series with constant and linear trend ## ## ## Call: ## lm(formula = z[, 1] ~ z[, -1] + trd) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.4928 -2.2329 0.0158 2.3622 8.2619 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -5.127606 0.683837 -7.498 7.51e-13 *** ## z[, -1] -0.192680 0.042395 -4.545 8.01e-06 *** ## trd -0.056427 0.002531 -22.296 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.347 on 297 degrees of freedom ## Multiple R-squared: 0.7266, Adjusted R-squared: 0.7247 ## F-statistic: 394.6 on 2 and 297 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic is: 57.3364 ## ## Critical values of Pu are: ## 10pct 5pct 1pct ## critical values 41.2488 48.8439 65.1714 # 残差診断 plot(test_po@testreg$residuals, type = &quot;l&quot;) acf(test_po@testreg$residuals) Box.test(test_po@testreg$residuals) ## ## Box-Pierce test ## ## data: test_po@testreg$residuals ## X-squared = 217.59, df = 1, p-value &lt; 2.2e-16 すなわち, 先に行ったdemean = \"const\"と同じ結論が得られる Johansenの方法 Johansen (88) によって提案されたVARモデルに基づく手法で, 複数の時系列間に存在し得る共和分関係の数やベクトルを同時に推定できる 前提条件として, 観測時系列がGaussian VAR(\\(p\\))に従うことを想定する. 上記のEngle-Granger等の回帰ベースのアプローチとは異なり, 目的変数・説明変数を区別しない対称的なアプローチである. Johansen検定は, 理論的にはもとのVAR(\\(p\\))モデルを誤差修正モデル (ECM) 表現する際に得られる係数行列\\(\\Pi\\)の性質を用いて行われる検定方法である. 最大固有値検定とトレース検定の2種類がある. Rパッケージurca内の関数ca.jo()により実行することができる. 上で生成したデータ行列ymatは, レベル変数でVAR(\\(p\\))のラグ\\(p=1\\)を持っている. 一方, 確定項は持っていなかった. 確認のため, 最適な次数\\(p\\)の大きさを情報量基準を使って選択させると, 次のようになる: # library(vars) vars::VARselect(ymat) ## $selection ## AIC(n) HQ(n) SC(n) FPE(n) ## 1 1 1 1 ## ## $criteria ## 1 2 3 4 5 6 7 ## AIC(n) 4.210712 4.255809 4.318613 4.384505 4.459940 4.527443 4.599661 ## HQ(n) 4.312115 4.438333 4.582259 4.729273 4.885831 5.034455 5.187795 ## SC(n) 4.463807 4.711380 4.976661 5.245029 5.522940 5.792919 6.067613 ## FPE(n) 67.405451 70.519454 75.102470 80.241682 86.570243 92.680559 99.717711 ## 8 9 10 ## AIC(n) 4.643317 4.687902 4.743021 ## HQ(n) 5.312574 5.438280 5.574522 ## SC(n) 6.313746 6.560806 6.818402 ## FPE(n) 104.300641 109.234243 115.659305 # library(MTS) MTS::VARorder(ymat) ## selected order: aic = 1 ## selected order: bic = 1 ## selected order: hq = 1 ## Summary table: ## p AIC BIC HQ M(p) p-value ## [1,] 0 9.5143 9.5143 9.5143 0.0000 0.0000 ## [2,] 1 4.1487 4.3462 4.2277 1540.4422 0.0000 ## [3,] 2 4.1932 4.5882 4.3513 17.2556 0.3692 ## [4,] 3 4.2538 4.8464 4.4909 12.5987 0.7018 ## [5,] 4 4.3220 5.1122 4.6382 10.3463 0.8479 ## [6,] 5 4.3937 5.3814 4.7890 9.2848 0.9012 ## [7,] 6 4.4566 5.6419 4.9310 11.4398 0.7816 ## [8,] 7 4.5251 5.9078 5.0785 9.8422 0.8747 ## [9,] 8 4.5610 6.1413 5.1934 17.9336 0.3278 ## [10,] 9 4.6057 6.3835 5.3172 15.4564 0.4915 ## [11,] 10 4.6583 6.6336 5.4488 13.2842 0.6519 ## [12,] 11 4.7242 6.8971 5.5938 9.8390 0.8749 ## [13,] 12 4.7830 7.1534 5.7317 11.3701 0.7861 ## [14,] 13 4.8310 7.3989 5.8587 13.7028 0.6208 # MTS::VARorderI(ymat) # 観測データとしてt=p+1,...,Tを使用して情報量基準を計算 (1) 最大固有値検定 \\(H_0\\): 共和分ランク\\(=r\\)以下, \\(H_1\\): 共和分ランク\\(=r+1\\) - urca::ca.jo(): - type (検定の種類): ‘eigen’(最大固有値検定) or ‘trace’(トレース検定) - ecdet (トレンド種類): ‘none’(切片項なし), ‘const’(定数項あり),‘trend’(トレンド項あり) - K (時系列(レベル変数)のVAR表現におけるラグ次数) (デフォルト=2) - spec (VECMの定式化の2つの方法の一つを選択): &quot;longrun&quot;(デフォルト), or &quot;transitory&quot; - season (季節ダミー): データの頻度を指定(例, 四半期の場合は4) 全変数に対して実行 レベル変数に対するラグ次数(\\(p\\))は引数Kで指定する. 真の次数は\\(p=1\\)であるがそのままK=1と ca.jo()に与えるとエラーを生じるため, デフォルト (K=2) のままにしておく. result_e1 &lt;- ca.jo(ymat, ecdet = &quot;none&quot;, type = &quot;eigen&quot;, spec = &quot;longrun&quot;) summary(result_e1) ## ## ###################### ## # Johansen-Procedure # ## ###################### ## ## Test type: maximal eigenvalue statistic (lambda max) , with linear trend ## ## Eigenvalues (lambda): ## [1] 0.39399267 0.35373609 0.04001843 0.01669478 ## ## Values of teststatistic and critical values of test: ## ## test 10pct 5pct 1pct ## r &lt;= 3 | 5.02 6.50 8.18 11.65 ## r &lt;= 2 | 12.17 12.91 14.90 19.19 ## r &lt;= 1 | 130.09 18.90 21.07 25.75 ## r = 0 | 149.26 24.78 27.14 32.14 ## ## Eigenvectors, normalised to first column: ## (These are the cointegration relations) ## ## y1.l2 y2.l2 y3.l2 y4.l2 ## y1.l2 1.0000000 1.0000000 1.00000000 1.000000 ## y2.l2 -0.6347789 -0.1341194 0.74761830 24.357249 ## y3.l2 -0.5785340 1.4100169 -0.01803175 -6.710469 ## y4.l2 0.2788528 -0.6893143 -1.62504044 48.535783 ## ## Weights W: ## (This is the loading matrix) ## ## y1.l2 y2.l2 y3.l2 y4.l2 ## y1.d -0.51186630 -0.320181456 -0.00621887 -2.424265e-04 ## y2.d 0.63903190 0.008777047 -0.01134031 -4.269731e-04 ## y3.d 0.44326372 -0.453798733 0.01223929 -9.786591e-05 ## y4.d -0.06251362 0.124762555 0.01714466 -5.047995e-04 \\(r=0\\)棄却. \\(r \\le 1\\)棄却, \\(r \\le 2\\)棄却されず. → 共和分ベクトルの個数\\(=2\\) (2) トレース検定 \\(H_0\\): 共和分ランク\\(=r\\)以下, \\(H_1\\): 共和分ランク\\(=m\\) (原系列は定常) result_t1 &lt;- ca.jo(ymat, ecdet = &quot;none&quot;, type = &quot;trace&quot;, spec = &quot;longrun&quot;) #result_t1 &lt;- ca.jo(ymat, ecdet = &quot;const&quot;, type = &quot;trace&quot;, spec = &quot;longrun&quot;) summary(result_t1) ## ## ###################### ## # Johansen-Procedure # ## ###################### ## ## Test type: trace statistic , with linear trend ## ## Eigenvalues (lambda): ## [1] 0.39399267 0.35373609 0.04001843 0.01669478 ## ## Values of teststatistic and critical values of test: ## ## test 10pct 5pct 1pct ## r &lt;= 3 | 5.02 6.50 8.18 11.65 ## r &lt;= 2 | 17.19 15.66 17.95 23.52 ## r &lt;= 1 | 147.28 28.71 31.52 37.22 ## r = 0 | 296.54 45.23 48.28 55.43 ## ## Eigenvectors, normalised to first column: ## (These are the cointegration relations) ## ## y1.l2 y2.l2 y3.l2 y4.l2 ## y1.l2 1.0000000 1.0000000 1.00000000 1.000000 ## y2.l2 -0.6347789 -0.1341194 0.74761830 24.357249 ## y3.l2 -0.5785340 1.4100169 -0.01803175 -6.710469 ## y4.l2 0.2788528 -0.6893143 -1.62504044 48.535783 ## ## Weights W: ## (This is the loading matrix) ## ## y1.l2 y2.l2 y3.l2 y4.l2 ## y1.d -0.51186630 -0.320181456 -0.00621887 -2.424265e-04 ## y2.d 0.63903190 0.008777047 -0.01134031 -4.269731e-04 ## y3.d 0.44326372 -0.453798733 0.01223929 -9.786591e-05 ## y4.d -0.06251362 0.124762555 0.01714466 -5.047995e-04 \\(r=0\\)棄却. \\(r \\le 1\\)棄却, \\(r \\le 2\\)棄却されず. → 共和分ベクトルの個数\\(=2\\) 共和分ベクトルをウェイトとする\\(Yt\\)の各成分の線形和計算 → 定常性の確認 coint_resid &lt;- ymat %*% summary(result_t1)@V fUnitRoots::adfTest(coint_resid[, 1]) ## Warning in fUnitRoots::adfTest(coint_resid[, 1]): p-value smaller than printed ## p-value ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -10.3616 ## P VALUE: ## 0.01 ## ## Description: ## Sun Feb 2 21:07:42 2025 by user: fUnitRoots::adfTest(coint_resid[, 2]) ## Warning in fUnitRoots::adfTest(coint_resid[, 2]): p-value smaller than printed ## p-value ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -12.4858 ## P VALUE: ## 0.01 ## ## Description: ## Sun Feb 2 21:07:42 2025 by user: ##fUnitRoots::adfTest(coint_resid[, 3]) ##fUnitRoots::adfTest(coint_resid[, 4]) 共和分行列 (共和分ベクトル) の最尤推定値 beta_mat &lt;- summary(result_t1)@V 真のモデルより, 共和分ランク (共和分ベクトルの数) \\(r=2\\), 共和分ベクトルは, \\(\\beta_1 = (1, -0.5, 0, 0)&#39;\\), \\(\\beta_2 = (1, 0, 2, -1)\\)である. さらにこれらの任意の線形結合で 作られるベクトルも共和分ベクトルとなる. 上で得られたbeta_matは \\(\\beta_1,\\beta_2\\)の推定値の線形結合に なっている. Johansen検定は, モデル特定 (ラグ長, 定数項やトレンド項の扱い) に敏感 であることから, ca.joのパラメータには, 本来木目の細かい指定が求められる. 注) 残念ながら, ucraマニュアルはそれほど親切とは言えない. 補足: VECMにおける確定項の入り方について\\(^{*}\\) レベル変数に対するVAR(\\(p\\))モデルは, 定数項 (切片項) や線形トレンド, 季節性ダミー変数などを含んだモデルなどに対する共和分分析/ECMの方法が 研究されている. VAR/ECMにおける定数項と線形トレンドの扱いは, Johansen (1991) によって整理されている. (福地・伊藤本の10.7.3の説明も参照のこと) 定数や線形トレンドの, 長期的共和分関係 (\\(\\beta\\)に関する式), および短期的VAR方程式 (差分系列に対するECM) への入り方で, 5つに分類される. ケース ECM 表現 説明 1: 確定項一切なし \\(\\Delta \\mathbf{Y}_t = \\alpha\\,\\beta^\\top \\mathbf{Y}_{t-1} + \\sum_{i=1}^{p-1} \\Gamma_i \\Delta \\mathbf{Y}_{t-i} + \\varepsilon_t\\) 共和分関係は定数項なし (ゼロの回りで均衡) レベル変数に線形トレンドなし 2: 制約付き定数項 \\(\\Delta \\mathbf{Y}_t = \\alpha(\\beta^\\top \\mathbf{Y}_{t-1} + \\beta_0) + \\sum_{i=1}^{p-1} \\Gamma_i \\Delta \\mathbf{Y}_{t-i}+ \\varepsilon_t\\) 定数項は共和分関係に制限 短期方程式に定数項なし (レベル変数に線形トレンドなし) 3: 制約なし定数項 \\(\\Delta \\mathbf{Y}_t = c + \\alpha(\\beta^\\top \\mathbf{Y}_{t-1} + \\beta_0) + \\Gamma \\Delta \\mathbf{Y}_{t-1} + \\cdots + \\varepsilon_t\\) レベル変数に線形トレンド 共和分関係に定数項 多くの経済・金融時系列におけるアプローチ 4: 制約付き線形トレンド \\(\\Delta \\mathbf{Y}_t = c + \\alpha(\\beta^\\top \\mathbf{Y}_{t-1} + \\beta_0 + \\beta_1\\,t) + \\sum_{i=1}^{p-1} \\Gamma_i \\Delta \\mathbf{Y}_{t-i} + \\varepsilon_t\\) 線形トレンドは共和分関係に制限 (長期的均衡関係に定数項と線形トレンド) レベル変数に線形トレンド 5: 短期方程式に線形トレンドあり \\(\\Delta \\mathbf{Y}_t = c + \\Phi\\,t + \\alpha(\\beta^\\top \\mathbf{Y}_{t-1} + \\beta_0 + \\beta_1\\,t) + \\sum_{i=1}^{p-1} \\Gamma_i \\Delta \\mathbf{Y}_{t-i} + \\varepsilon_t\\) レベル変数に2次トレンド (強いトレンドの可能性) 補足: 関数ca.jo()の使い方について 出所: urcaマニュアル 引数specの選択 specはVECMモデルの形状を特定する引数である 選択肢: “longrun”, “transitory” 以下のような一般的なVARモデル \\[ \\mathbf{Y}_t = \\boldsymbol{\\Pi}_1 \\mathbf{Y}_{t-1} + \\cdots + \\boldsymbol{\\Pi}_p \\mathbf{Y}_{t-p} + \\boldsymbol{\\mu} + \\boldsymbol{\\Phi} \\boldsymbol{D}_t + \\mathbf{\\varepsilon}_t \\] を考える. spec = \"longrun\" (デフォルト) の場合 次の形式のVECM仕様に対する推論を行う. \\[ \\Delta \\mathbf{Y}_t = \\boldsymbol{\\Gamma}_1 \\Delta \\mathbf{Y}_{t-1} + \\cdots + \\boldsymbol{\\Gamma}_{p-1} \\Delta \\mathbf{Y}_{t-p+1} + \\boldsymbol{\\Pi} \\mathbf{Y}_{t-p} + \\boldsymbol{\\mu} + \\boldsymbol{\\Phi} \\boldsymbol{D}_t + \\mathbf{\\varepsilon}_t, \\] ここで, \\[ \\boldsymbol{\\Gamma}_i = - (\\boldsymbol{I} - \\boldsymbol{\\Pi}_1 - \\cdots - \\boldsymbol{\\Gamma}_i) \\, (i=1,...,p-1), \\quad \\boldsymbol{\\Pi} = - (\\boldsymbol{I} - \\boldsymbol{\\Pi}_1 - \\cdots - \\boldsymbol{\\Gamma}_p). \\] \\(\\boldsymbol{\\Gamma}_i\\)は累積の長期的インパクトを含む係数である. spec = \"transitory\"の場合 次の形式のVECM仕様に対する推論を行う. \\[ \\Delta \\mathbf{Y}_t = \\boldsymbol{\\Gamma}_1 \\Delta \\mathbf{Y}_{t-1} + \\cdots + \\boldsymbol{\\Gamma}_{p-1} \\Delta \\mathbf{Y}_{t-p+1} + \\boldsymbol{\\Pi} \\mathbf{Y}_{t-1} + \\boldsymbol{\\mu} + \\boldsymbol{\\Phi} \\boldsymbol{D}_t + \\mathbf{\\varepsilon}_t, \\] ここで, \\[ \\boldsymbol{\\Gamma}_i = - (\\boldsymbol{\\Pi}_{i+1} + \\cdots + \\boldsymbol{\\Gamma}_i) \\, (i=1,...,p-1), \\quad \\boldsymbol{\\Pi} = - (\\boldsymbol{I} - \\boldsymbol{\\Pi}_1 - \\cdots - \\boldsymbol{\\Gamma}_p). \\] \\(\\boldsymbol{\\Gamma}_i\\)は一時的なインパクトを測る係数である. なお, \\(\\boldsymbol{\\mu}\\) は確定項を, \\(\\boldsymbol{D}_t\\)はダミー変数項を表す. どちらの仕様においても, \\(\\boldsymbol{\\Pi}\\) に対する推論 (解釈も) 同じである. 10.3 誤差修正モデル: データ分析例 (Tsay, MTS, Ch5) 共和分 (cointegration)は非定常系列同士が長期的な均衡関係を有することを捉える概念であるが, 誤差修正モデルは, その共和分関係があるもとで, 変数間の長期的均衡からの乖離を考慮 し, 短期の動的な修正のプロセスを記述するモデルである. 誤差修正モデルによって, 一つのモデルの中で長期的均衡関係と短期的な動学的修正を統合的に記述することができる. 理論上は, 「Grangerの表現定理」によれば, 多変量時系列\\(\\mathbf{y}_t ∼ I(1)\\) の成分間に共和分関係があることと, \\(\\mathbf{y}_t\\) に対し (Π のランクを持つ) VECM (ベクトル誤差修正モデル) 表現が存在する ことは同値である. したがって, データ分析の手順としては, 前節で述べたように 多変量時系列の間に共和分関係の存在を確かめた上で, 誤差修正モデルを推定すれば良いことが分かる. ここでは, 誤差修正モデルの推定について, 教科書MTSに沿って Rコードと実行結果の要点を記載する. パッケージは, 上で使用したurcaと合わせて, Tsayが作成したMTSも使用する. 具体的には, urcaの関数ca.jo()によってJohansenの共和分検定を行った後に, MTSの関数ECMvar1(), ECMrefvar1(), ECMvar()を使ってECMを推定する. 教科書では, 単位根検定からECM推定までの作業フローが解説されている. 次数\\(p\\)の選択 や確定項の有無に関する判断 (どのタイミングでどのような理由によって) についても言及しているので参考にすると良い. 以下, Rコードや出力結果に関する解説は省略する. 必要に応じて教科書の当該箇所を参照のこと. 出所: Tsay, MTS, Ch5より抜粋（適宜, 補足説明挿入, または修正) https://faculty.chicagobooth.edu/ruey-s-tsay/research/multivariate-time-series-analysis-with-r-and-financial-applications 共和分検定 Tsay, 5.9, pp.310– require(fUnitRoots) # adfTest ## Loading required package: fUnitRoots require(urca) # ca.jo ## Loading required package: urca ## ## Attaching package: &#39;urca&#39; ## The following objects are masked from &#39;package:fUnitRoots&#39;: ## ## punitroot, qunitroot, unitrootTable require(MTS) # VARorder() ## Loading required package: MTS 分析に使用するデータ 月次社債イールド, 1954.7–2005.3 FRB St. Louisのデータ 系列(Aaa, Baa)が2変量VAR(\\(p\\))モデルに従うと仮定し. 次数\\(p\\)を決定: ifl &lt;- file.path(dir_MTS, &quot;m-bnd.txt&quot;) # dir_MTS: m-bnd.txtを格納しているディレクトリ da &lt;- read.table(ifl) head(da) ## V1 V2 V3 V4 V5 ## 1 1954 7 1 2.89 3.50 ## 2 1954 8 1 2.87 3.49 ## 3 1954 9 1 2.89 3.47 ## 4 1954 10 1 2.87 3.46 ## 5 1954 11 1 2.89 3.45 ## 6 1954 12 1 2.90 3.45 bnd &lt;- da[, 4:5] colnames(bnd) &lt;- c(&quot;Aaa&quot;, &quot;Baa&quot;) m1 &lt;- MTS::VARorder(bnd) # original function, now in &#39;MTS&#39; ## selected order: aic = 11 ## selected order: bic = 3 ## selected order: hq = 3 ## Summary table: ## p AIC BIC HQ M(p) p-value ## [1,] 0 -0.5697 -0.5697 -0.5697 0.0000 0.0000 ## [2,] 1 -7.8664 -7.8374 -7.8551 4331.0806 0.0000 ## [3,] 2 -8.1844 -8.1264 -8.1618 195.5266 0.0000 ## [4,] 3 -8.2589 -8.1720 -8.2251 51.6109 0.0000 ## [5,] 4 -8.2552 -8.1393 -8.2101 5.5112 0.2387 ## [6,] 5 -8.2481 -8.1032 -8.1917 3.5073 0.4768 ## [7,] 6 -8.2751 -8.1013 -8.2075 23.4161 0.0001 ## [8,] 7 -8.2803 -8.0775 -8.2014 10.6262 0.0311 ## [9,] 8 -8.2826 -8.0507 -8.1924 8.9080 0.0634 ## [10,] 9 -8.2784 -8.0176 -8.1769 5.1613 0.2711 ## [11,] 10 -8.2775 -7.9877 -8.1648 7.0457 0.1335 ## [12,] 11 -8.2840 -7.9652 -8.1600 11.2224 0.0242 ## [13,] 12 -8.2812 -7.9334 -8.1459 5.8956 0.2071 ## [14,] 13 -8.2716 -7.8949 -8.1251 2.0355 0.7292 → BIC, HQ(Nannan-Quinn情報量規準), \\(p=3\\)を選択 次に, 各系列の単位根検定 (ADF検定) \\(H_0\\): 単位根有り pacf(bnd[, 1]) pacf(bnd[, 2]) # または, # ar(bnd[, 1]) # --&gt; AIC, p = 3 # ar(bnd[, 2]) # --&gt; AIC, p = 2 # fUnitRoots::adfTest(bnd[, 1], lags = 3, type = &quot;c&quot;) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 3 ## STATISTIC: ## Dickey-Fuller: -1.7007 ## P VALUE: ## 0.425 ## ## Description: ## Sun Feb 2 21:07:44 2025 by user: fUnitRoots::adfTest(bnd[, 2], lags = 2, type = &quot;c&quot;) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 2 ## STATISTIC: ## Dickey-Fuller: -1.6221 ## P VALUE: ## 0.4544 ## ## Description: ## Sun Feb 2 21:07:44 2025 by user: –&gt; Aaa, Baa系列のADF検定、棄却されない (H0: 単位根非定常) matplot(bnd, type=&quot;l&quot;) # Tsay本の内容に沿って, 以下を挿入 apply(apply(bnd, 2, diff), 2, mean)/ apply(apply(bnd, 2, diff), 2, sd) ## Aaa Baa ## 0.01862195 0.02077461 #apply(apply(bnd, 2, diff), 2, fBasics::stdev) 階階差列の平均値ベクトルは, ゼロから有意に離れていない → 共和分検定に, 定数項入れない (Tsay, p.310) 共和分検定におけるトレンドの指定. Tsay, p.304を参照 Johansenの方法 Johansenの方法 → 共和分関係の検定, 共和分ベクトルや共和分ランク(個数)の推定 最大固有値法 \\(H_0\\): 多くても\\(r\\)個の共和分関係しか存在しない vs \\(H_1\\): \\((r+1)\\)個の共和分関係が存在する (\\(H_0\\): 共和分ランク\\(=r\\) vs \\(H_1\\): 共和分ランク\\(=r+1\\)) - urca::ca.jp関数 - x: 共和分を調べたいデータ行列 (原系列) - type: 検定方法の種類. &#39;eigen&#39;(最大固有値法), &#39;trace&#39; (トレース法) - ecdet: トレンド指定. &#39;none&#39; (なし), &#39;const&#39; (定数項有), &#39;trend&#39; (線形トレンド有) - $\\Delta {\\bf y}_t = {\\bf \\mu}_0 + {\\bf \\mu}_1 t+\\cdots$ - (→ 共和分関係にも定数項や線形トレンドが含まれる) - K: 系列(水準)のVARラグ次数 - spec: VECMの特定化. &quot;longrun&quot; ($ {\\bf Γ}_i , 長期的(累積)インパクト), &quot;transitory&quot; ((${\\bf Γ}_i$, 一時的インパクト) ) m2 &lt;- urca::ca.jo(bnd, K = 2, ecdet = c(&quot;none&quot;)) # spec = &quot;longrun&quot; (デフォルト) summary(m2) ## ## ###################### ## # Johansen-Procedure # ## ###################### ## ## Test type: maximal eigenvalue statistic (lambda max) , with linear trend ## ## Eigenvalues (lambda): ## [1] 0.054773196 0.004665298 ## ## Values of teststatistic and critical values of test: ## ## test 10pct 5pct 1pct ## r &lt;= 1 | 2.84 6.50 8.18 11.65 ## r = 0 | 34.19 12.91 14.90 19.19 ## ## Eigenvectors, normalised to first column: ## (These are the cointegration relations) ## ## Aaa.l2 Baa.l2 ## Aaa.l2 1.0000000 1.000000 ## Baa.l2 -0.8856789 -2.723912 ## ## Weights W: ## (This is the loading matrix) ## ## Aaa.l2 Baa.l2 ## Aaa.d -0.04696894 0.002477064 ## Baa.d 0.04046524 0.002139536 → \\(r=0\\)は棄却. \\(r=1\\)は棄却されず → \\(r=1\\) (共和分有. 共和分ベクトルの個数 (\\(\\Pi\\) 行列のランク)) #m3 &lt;- urca::ca.jo(bnd, K = 2, ecdet = c(&quot;none&quot;), spec = c(&quot;transitory&quot;)) #summary(m3) # 定数項有のケース m3 &lt;- urca::ca.jo(bnd, K = 2, ecdet = c(&quot;const&quot;), spec = c(&quot;longrun&quot;)) summary(m3) ## ## ###################### ## # Johansen-Procedure # ## ###################### ## ## Test type: maximal eigenvalue statistic (lambda max) , without linear trend and constant in cointegration ## ## Eigenvalues (lambda): ## [1] 5.477346e-02 4.878009e-03 6.308723e-20 ## ## Values of teststatistic and critical values of test: ## ## test 10pct 5pct 1pct ## r &lt;= 1 | 2.97 7.52 9.24 12.97 ## r = 0 | 34.19 13.75 15.67 20.20 ## ## Eigenvectors, normalised to first column: ## (These are the cointegration relations) ## ## Aaa.l2 Baa.l2 constant ## Aaa.l2 1.000000000 1.000000 1.000000 ## Baa.l2 -0.885675435 -2.701784 -3.315369 ## constant -0.003491742 16.399576 -13.776952 ## ## Weights W: ## (This is the loading matrix) ## ## Aaa.l2 Baa.l2 constant ## Aaa.d -0.04699903 0.002507156 1.086407e-18 ## Baa.d 0.04043910 0.002165681 -1.197343e-18 トレース法 \\(H_0\\): 多くても\\(r\\)個の共和分関係しか存在しない vs \\(H_1\\): 全ての変数が定常 (\\(H_0\\): 共和分ランク\\(=r\\) vs \\(H_1\\): 共和分ランク\\(=m\\) (原系列は定常)) m4 &lt;- urca::ca.jo(bnd, K = 2, ecdet = c(&quot;none&quot;), type = c(&quot;trace&quot;), spec = c(&quot;transitory&quot;)) summary(m4) ## ## ###################### ## # Johansen-Procedure # ## ###################### ## ## Test type: trace statistic , with linear trend ## ## Eigenvalues (lambda): ## [1] 0.054773196 0.004665298 ## ## Values of teststatistic and critical values of test: ## ## test 10pct 5pct 1pct ## r &lt;= 1 | 2.84 6.50 8.18 11.65 ## r = 0 | 37.03 15.66 17.95 23.52 ## ## Eigenvectors, normalised to first column: ## (These are the cointegration relations) ## ## Aaa.l1 Baa.l1 ## Aaa.l1 1.0000000 1.000000 ## Baa.l1 -0.8856789 -2.723912 ## ## Weights W: ## (This is the loading matrix) ## ## Aaa.l1 Baa.l1 ## Aaa.d -0.04696894 0.002477064 ## Baa.d 0.04046524 0.002139536 → \\(r=0\\)は棄却. \\(r=1\\)は棄却されず → \\(r=1\\) (同) (coint_vec &lt;- summary(m4)@V) ## Aaa.l1 Baa.l1 ## Aaa.l1 1.0000000 1.000000 ## Baa.l1 -0.8856789 -2.723912 → 共和分ベクトル: \\((1, -0.886)\\) 得られた``cointegration’’系列 \\(w_t=1 \\cdot Aaa_t - 0.886 \\cdot Baa_t\\)に対して単位根検定 # wt &lt;- bnd[, 1] - 0.886 * bnd[, 2] wt &lt;- as.matrix(bnd) %*% coint_vec[, 1] # fUnitRoots::adfTest(wt, lags = 3, type = &quot;c&quot;) ## Warning in fUnitRoots::adfTest(wt, lags = 3, type = &quot;c&quot;): p-value smaller than ## printed p-value ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 3 ## STATISTIC: ## Dickey-Fuller: -4.6052 ## P VALUE: ## 0.01 ## ## Description: ## Sun Feb 2 21:07:44 2025 by user: → \\(p\\)値\\(=0.01\\) (単位根無) plot(wt, type = &quot;l&quot;) → “定常時系列の特徴を示す” 誤差修正モデル (ECM) の推定 前提: VARモデルの次数\\(p\\),共和分ベクトルの数は既知 (上で得られた) ECMのOLS推定 共和分ベクトル\\(\\beta_t\\)が既知の場合: 上で得られた ``cointegrating系列’’wt=bnd[,1]-0.886*bnd[,2] を所与として \\((p=3, r=1)\\), ECMをOLS推定 - MTS::ECMvar1(x, p, wt=wt, include.const = FALSE, fixed = NULL, output = TRUE) - ECM VAR(p)モデルのOLS推定 (wtが既知の場合) - x: (Txk), k次元共和分VAR過程 - wt: (Txm), m次元共和分過程 - include.const: 定数項の有無 (デフォルト=F) m1 &lt;- MTS::ECMvar1(bnd, 3, wt) ## Given the co-integrated vector ## alpha: ## Aaa Baa ## [1,] -0.00122 0.0634 ## standard error ## [,1] [,2] ## [1,] 0.0347 0.0306 ## AR coefficient matrix ## AR( 1 )-matrix ## Aaa Baa ## Aaa 0.452 -0.00149 ## Baa 0.293 0.20380 ## standard error ## [,1] [,2] ## [1,] 0.0879 0.1008 ## [2,] 0.0774 0.0887 ## AR( 2 )-matrix ## Aaa Baa ## Aaa -0.300 0.0535 ## Baa -0.151 0.0274 ## standard error ## [,1] [,2] ## [1,] 0.0860 0.0940 ## [2,] 0.0757 0.0827 ## ----- ## Residuals cov-mtx: ## Aaa Baa ## Aaa 0.0400851 0.03167180 ## Baa 0.0316718 0.03105888 ## ## det(sse) = 0.0002418953 ## AIC = -8.294165 ## BIC = -8.221721 m1$coef # 表示の向きに注意 (xmtx調整行列, 左辺の各成分が列方向に, 右辺のARラグ項が行方向に) ## Aaa Baa ## xmtx -0.001217005 0.06339082 ## Aaa 0.451993390 0.29303941 ## Baa -0.001491101 0.20379673 ## Aaa -0.299907502 -0.15075817 ## Baa 0.053499341 0.02742606 m1$secoef # 同 ## [,1] [,2] ## [1,] 0.03471368 0.03055639 ## [2,] 0.08790257 0.07737541 ## [3,] 0.10080919 0.08873634 ## [4,] 0.08600254 0.07570293 ## [5,] 0.09396739 0.08271391 m1$coef / m1$secoef # 同 ## Aaa Baa ## xmtx -0.03505836 2.0745518 ## Aaa 5.14198170 3.7872419 ## Baa -0.01479132 2.2966546 ## Aaa -3.48719367 -1.9914443 ## Baa 0.56933946 0.3315773 推定されたECM (\\(w_t=\\beta&#39;{\\bf y}_t=(1,- 0.886){\\bf y}_t\\)) \\[ \\Delta {\\bf y}_t = \\left[\\begin{array}{r} -0.001 \\\\ 0.064 \\end{array}\\right] w_t + \\left[\\begin{array}{rr} 0.452 &amp; -0.001 \\\\ 0.293 &amp; 0.204 \\end{array} \\right] \\Delta {\\bf y}_{t-1} \\] \\[ +\\left[\\begin{array}{rr} -0.300 &amp; 0.054 \\\\ -0.151 &amp; 0.028 \\end{array} \\right] \\Delta {\\bf y}_{t-2} + \\epsilon_t,\\quad \\hat{\\Sigma}= \\frac{1}{100} \\left[\\begin{array}{rr} 4.01 &amp; 3.17 \\\\ 3.17 &amp; 3.11 \\end{array} \\right] \\] OLS推定されたECMの修正 ECMの修正 (パラメータ数削減) 有意でない係数を0に置く - MTS::refECMvar1(m1, thres = 1) - ECM VAR(p)モデルの制約付きOLS推定 (wtが既知の場合) - thres: t-ratioの閾値(デフォルト=1) - |t-ratio| &lt; thres の推定係数を0に置き換える m2 &lt;- MTS::refECMvar1(m1) ####### Refine the model fit ## Equation: 1 npar = 2 ## Equation: 2 npar = 4 ## alpha: ## [,1] [,2] ## [1,] 0 0.0625 ## standard error ## [,1] [,2] ## [1,] 1 0.0304 ## AR coefficient matrix ## AR( 1 )-matrix ## [,1] [,2] ## [1,] 0.448 0.000 ## [2,] 0.286 0.212 ## standard error ## [,1] [,2] ## [1,] 0.0393 1.0000 ## [2,] 0.0746 0.0855 ## AR( 2 )-matrix ## [,1] [,2] ## [1,] -0.256 0 ## [2,] -0.129 0 ## standard error ## [,1] [,2] ## [1,] 0.0393 1 ## [2,] 0.0382 1 ## ----- ## Residuals cov-mtx: ## [,1] [,2] ## [1,] 0.04010853 0.03168277 ## [2,] 0.03168277 0.03106450 ## ## det(sse) = 0.0002421536 ## AIC = -8.306234 ## BIC = -8.262768 推定されたECM (修正後) \\[ \\Delta {\\bf y}_t = \\left[\\begin{array}{r} 0.000 \\\\ 0.063 \\end{array}\\right] w_t + \\left[\\begin{array}{rr} 0.448 &amp; 0.000 \\\\ 0.286 &amp; 0.212 \\end{array} \\right] \\Delta {\\bf y}_{t-1} \\] \\[ +\\left[\\begin{array}{rr} -0.256 &amp; 0.000 \\\\ -0.129 &amp; 0.000 \\end{array} \\right] \\Delta {\\bf y}_{t-2} + \\epsilon_t,\\quad \\hat{\\Sigma}= \\frac{1}{100} \\left[\\begin{array}{rr} 4.01 &amp; 3.17 \\\\ 3.17 &amp; 3.11 \\end{array} \\right] \\] # pacf(m2$residuals) # --&gt; model checking, 若干の系列相関, 相互相関有り(教科書の記述と齟齬?) # --&gt; alpha(1,1)=0 &lt;-- Aaa系列の1階階差系列は定常 m2$coef ## [,1] [,2] ## [1,] 0.0000000 0.06250339 ## [2,] 0.4484522 0.28620026 ## [3,] 0.0000000 0.21172072 ## [4,] -0.2559947 -0.12908889 ## [5,] 0.0000000 0.00000000 m2$secoef ## [,1] [,2] ## [1,] 1.00000000 0.03044171 ## [2,] 0.03929053 0.07458234 ## [3,] 1.00000000 0.08546551 ## [4,] 0.03930742 0.03821387 ## [5,] 1.00000000 1.00000000 m2$coef / m1$secoef ## [,1] [,2] ## [1,] 0.000000 2.045509 ## [2,] 5.101696 3.698853 ## [3,] 0.000000 2.385953 ## [4,] -2.976594 -1.705203 ## [5,] 0.000000 0.000000 ECMのQML推定 共和分ベクトル\\(\\beta_t\\)が未知の場合: 仮定:イノベーション系列 \\({\\epsilon_t}\\) がGaussian - MTS::ECMvar(x,p,ibeta) - ECM VAR(p)モデルのQML推定 (wtが未知の場合) - ibeta: co-integrating matrix初期値 - alpha: alpha行列の初期値 (デフォルト=NULL) # beta &lt;- c(1, -0.886) ### Initial value of co-integration beta &lt;- coint_vec[, 1] m3 &lt;- MTS::ECMvar(bnd, p = 3, ibeta = beta, include.const = F) #### Joint estimation ## Order p: 3 Co-integrating rank: 1 ## Number of parameters: 11 ## initial estimates: -0.001217005 0.06339082 -0.8856789 0.4519934 -0.001491101 -0.2999075 0.05349934 0.2930394 0.2037967 -0.1507582 0.02742606 ## Par. Lower-bounds: -0.05328753 0.01755623 -0.9464619 0.3201395 -0.1527049 -0.4289113 -0.08745174 0.1769763 0.07069222 -0.2643126 -0.09664481 ## Par. Upper-bounds: 0.05085352 0.1092254 -0.8248958 0.5838472 0.1497227 -0.1709037 0.1944504 0.4091025 0.3369012 -0.03720378 0.1514969 ## Final Estimates: -0.0007844935 0.06377964 -0.8865271 0.451819 -0.001406126 -0.3000979 0.05359478 0.2928488 0.2039182 -0.150974 0.02759907 ## ## Coefficient(s): ## Estimate Std. Error t value Pr(&gt;|t|) ## -0.0007845 0.0359051 -0.022 0.982568 ## 0.0637796 0.0314069 2.031 0.042280 * ## Baa.l1 -0.8865271 0.0055004 -161.176 &lt; 2e-16 *** ## 0.4518190 0.0878174 5.145 2.68e-07 *** ## -0.0014061 0.1022704 -0.014 0.989030 ## -0.3000979 0.0864320 -3.472 0.000516 *** ## 0.0535948 0.0948894 0.565 0.572201 ## 0.2928488 0.0772944 3.789 0.000151 *** ## 0.2039182 0.0897482 2.272 0.023080 * ## -0.1509740 0.0760263 -1.986 0.047054 * ## 0.0275991 0.0833998 0.331 0.740701 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## alpha: ## [,1] ## [1,] -0.000784 ## [2,] 0.063780 ## standard error ## [,1] ## [1,] 0.0359 ## [2,] 0.0314 ## beta: ## [,1] ## [1,] 1.000 ## [2,] -0.887 ## standard error ## [,1] ## [1,] 1.0000 ## [2,] 0.0055 ## AR coefficient matrix ## AR( 1 )-matrix ## [,1] [,2] ## [1,] 0.452 -0.00141 ## [2,] 0.293 0.20392 ## standard error ## [,1] [,2] ## [1,] 0.0878 0.1023 ## [2,] 0.0773 0.0897 ## AR( 2 )-matrix ## [,1] [,2] ## [1,] -0.300 0.0536 ## [2,] -0.151 0.0276 ## standard error ## [,1] [,2] ## [1,] 0.0864 0.0949 ## [2,] 0.0760 0.0834 ## ----- ## Residuals cov-mtx: ## Aaa Baa ## Aaa 0.0399535 0.03156630 ## Baa 0.0315663 0.03095427 ## ## det(sse) = 0.0002403005 ## AIC = -8.297496 ## BIC = -8.217807 # m3$ncoint # 共和分ベクトル数 ## [1] 1 m3$alpha # 調整行列 ## [,1] ## [1,] -0.0007844935 ## [2,] 0.0637796425 m3$beta # 共和分行列 ## [,1] ## [1,] 1.0000000 ## [2,] -0.8865271 m3$Phip ## [,1] [,2] ## [1,] 0.451818972 0.29284885 ## [2,] -0.001406126 0.20391818 ## [3,] -0.300097916 -0.15097397 ## [4,] 0.053594777 0.02759907 m3$se.Phip ## [,1] [,2] ## [1,] 0.08781738 0.07729435 ## [2,] 0.10227039 0.08974821 ## [3,] 0.08643197 0.07602634 ## [4,] 0.09488937 0.08339984 推定されたECM (修正後) \\[ \\Delta {\\bf y}_t = \\left[\\begin{array}{r} -0.001 \\\\ 0.064 \\end{array}\\right] [1,-0.887] {\\bf y}_t + \\left[\\begin{array}{rr} 0.452 &amp; -0.001 \\\\ 0.293 &amp; 0.204 \\end{array} \\right] \\Delta {\\bf y}_{t-1} \\] \\[ +\\left[\\begin{array}{rr} -0.300 &amp; 0.054 \\\\ -0.151 &amp; 0.028 \\end{array} \\right] \\Delta {\\bf y}_{t-2} + \\epsilon_t,\\quad \\hat{\\Sigma}= \\frac{1}{100} \\left[\\begin{array}{rr} 4.00 &amp; 3.16 \\\\ 3.16 &amp; 3.10 \\end{array} \\right] \\] → 初期モデル(m1)と近い結果 ``サンプルサイズが比較的大きい一方で低次元であり, 驚くことでない’’ (補足): \\(w_t=1 \\cdot Aaa_t - 0.887 \\cdot Baa_t\\)が定常過程 \\(w_t&gt;0\\) → Aaa_tのイールドが相対高, Baa_tが相対安 → スプレッド”縮小”時 → \\({\\bf y}_t\\)への影響; \\([-0.001,0.064]&#39;w_t\\) 翌月のAaa_tイールドを\\(0.001\\cdot w_t\\)押し下げる 翌月のBaa_tイールドを\\(0.064\\cdot w_t\\)押し上げる → 翌月のスプレッドが”拡大”する方向に作用 "],["多変量ボラティリティモデル.html", "11 多変量ボラティリティ・モデル 11.1 ボラティリティ・スピルオーバー (volatility spillover) 11.2 多変量GARCHモデル: データ分析例 (Tsay, MTS, Ch.7)", " 11 多変量ボラティリティ・モデル 多変量ボラティリティ・モデルは, 複数のリスク資産で構成されるポートフォリオ構築や, リスクの評価に不可欠な分散共分散行列の推定や予測に有用である. 多変量ボラティリティ・モデルの中でも特に多変量GARCH型モデルは 重要なクラスであり, 実務でも多く使用されている. また, 多変量GARCH型モデルは, ファイナンス研究におけるボラティリティ・スピルオーバー現象を 計測する方法論としても重要である. 11.1 ボラティリティ・スピルオーバー (volatility spillover) ある資産・市場・セクターで観測される不安定性, 価格のボラティリテが, (時間の経過と伴に) 他の資産・市場・セクターに伝波する現象は ボラティリティ・スピルオーバー (volatility spillover)と呼ばれる. 例. 株式市場のボラティリティが高まったとき,債券市場や為替市場のボラティリティが連動して変化するような状況 主なメカニズムとして, 情報伝達が挙げられている. 具体的には, 重要な経済指標の発表や企業業績の変化等, ある特定の市場で新たな情報 が発生すると, 投資家のポートフォリオのリバランス行動等を通じて, ボラティリティが他商品や他市場に波及する可能性等が考えられる. ボラティリティ・スピルオーバーの計測の主要な方法論として, 多変量 GARCH型モデルが使われる. 多変量GARCHにより複数資産の分散共分散行列の動的な変化を同時モデリングできることから, どの資産・市場のボラティリティがどの程度他の資産・市場のボラティリティを波及させているかを評価することが可能となる. また, 代替的なアプローチとして, VARモデルをベースにした Diebold-Yilmaz Spillover Indexなどが挙げられる. Diebold and Yilmaz, (2009), Measuring Financial Asset Return and Volatility Spillovers, With Application to Global Equity Markets, Economic Journal, 119, 158-171. Diebold and Yilmaz, (2012), Better to give than to receive: Predictive directional measurement of volatility spillovers, International Journal of Forecasting, 28(1), 57-66. 多変量GARCHモデリングは, 二つの主要なチャンレジが存在する. すなわち, 次元の呪い (curse of dimensionality) 正定値性の維持 である. 11.2 多変量GARCHモデル: データ分析例 (Tsay, MTS, Ch.7) コードおよびデータの出所: http://faculty.chicagobooth.edu/ruey.tsay/teaching/introTS/ (一部改変) 教科書 (MTS) の著者Tsayが作成したパッケージMTSを利用する. MTSに含まれている関数群は, 出力結果が分かりにくかったり Rの操作上は必ずしも使い勝手は良くないが, 教科書の内容に即している点では学習用としてすぐれている. 多変量時系列データの条件付不均一分散性の検定 Tsay, pp.406– まず, 確認用にシミュレーション系列を生成する. library(MTS) zt &lt;- matrix(rnorm(2000), 400, 5) ### Another set of random noises MTS内のMarchTest()は, 多変量時系列データの 条件付き不均一分散性 (ARCH効果) を検定する関数である. 一変量のARCH検定 (LM検定) は, もとの一変量時系列の2乗系列の 自己相関の有無を調べていたいが, ここでは, それを多次元に 拡張したものである. 具体的には, \\(k\\)-次元の収益率系列 \\({\\bf y}_t = \\mu_t + {\\bf u}_t,\\, {\\bf u}_t \\sim ({\\bf 0}, {\\bf H}_t)\\)において, もし \\({\\bf u}_t\\) に条件付き不均一分散性がない, すなわち, \\({\\bf H}_t\\)が 時間を通じて一定であれば, \\({\\bf u}_t {\\bf u}_t&#39;\\) は, 自身のラグ \\({\\bf u}_{t-h} {\\bf u}&#39;_{t-h}\\) には依存しない. よって, \\({\\bf u}_t {\\bf u}_t&#39;\\)のクロス相関行列\\({\\bf R}(h)\\)において, 帰無仮説\\(H_0: {\\bf R}(1)={\\bf R}(2)=\\cdots={\\bf R}(m)={\\bf 0}_{k \\times k}\\) を 対立仮説$H_1: \\({\\bf R}(i)\\ne {\\bf 0}_{k \\times k} \\, (\\exists i \\in \\{1,...,m\\})\\) に対して検定すれば良い. なお, 時点\\(t\\)における条件付き分散共分散行列\\({\\bf H}_t=E[{\\bf u}_t {\\bf u}_t&#39;|\\mathcal{F}_{t-1}]\\)は, 一般には構成要素間の同時点相関は持ち得る (対角行列ではない) ことに注意したい. 多変量を同時に扱うことから, 2乗系列\\({\\bf u}_t {\\bf u}_t&#39;\\)や 元の系列\\({\\bf u}_t\\)の2次形式にて変換した1次元の (標準化) 系列\\(e_t = {\\bf u}&#39;_t {\\bf H}^{-1}_t {\\bf u}_t&#39; - k\\)を用いて, ARCH効果を検定することになる (教科書を参照). MarchTest()は, 4種類のかばん検定の結果が同時に出力される. - 検定方法 - (1) Ljung-Box検定 (1変量に変換した標準化系列{e_t}に対して) - Q(m) of squared series (LM test) - (2) 順位自己相関 (rank autocorrelation) を用いた検定 - Rank-based Test ({e_t}より各ラグの順位自己相関を計算し, それらを用いてχ2乗統計量を計算) - 教科書 (7.6) - (3) 多変量Ljung-Box検定 - Q_k(m) of squared series - 教科書 (7.4) - (4) 同, 上位5%のデータを刈込み (trim) - Robust Test (5%) - MTS::MarchTest - lag: かばん検定に使用するクロス相関行列のラグ数 MarchTest(zt) #### Multivariate volatility tests ## Q(m) of squared series(LM test): ## Test statistic: 4.588867 p-value: 0.9168987 ## Rank-based Test: ## Test statistic: 7.1943 p-value: 0.7069833 ## Q_k(m) of squared series: ## Test statistic: 254.9846 p-value: 0.4008207 ## Robust Test(5%) : 241.007 p-value: 0.6469863 → \\(p\\)値はいずれも大きく, 帰無仮説は棄却されない (ARCH効果なし) ことが確認される. これは, \\(z_t\\)が正規乱数から生成された \\(k=5\\)のデータセットであり, 当然の結果と言える. 実際の株価収益率系列に対して, ARCH効果の検定を行う. Tsay, pp.415– データ: IBM and S&amp;P 月次収益率系列 ifl &lt;- file.path(dir_MTS, &quot;m-ibmsp-6111.txt&quot;) da &lt;- read.table(ifl, header = T) rtn &lt;- log(da[, 2:3] + 1) # 対数収益率化 at &lt;- scale(rtn, scale = F) ## Remove sample means MarchTest(at) ## Q(m) of squared series(LM test): ## Test statistic: 38.06663 p-value: 3.695138e-05 ## Rank-based Test: ## Test statistic: 108.3798 p-value: 0 ## Q_k(m) of squared series: ## Test statistic: 109.4194 p-value: 2.276873e-08 ## Robust Test(5%) : 118.7134 p-value: 9.894441e-10 → \\(p\\)値がゼロに近い (帰無仮説棄却, ARCH効果有り) ことが確認される. 指数加重移動平均法 (EWMA) データ: CRSPの (1, 2, 5, 9, 10) 十分位ポートフォリオの月次対数収益率 ifl &lt;- file.path(dir_MTS, &quot;m-dec125910-6111.txt&quot;) da &lt;- read.table(ifl, header = T) # CRSP(1, 2, 5, 9, 10十分位ポートフォリオ)の月次対数収益率 head(da) ## date dec1 dec2 dec5 dec9 dec10 ## 1 19610131 0.058011 0.067392 0.081767 0.096754 0.087207 ## 2 19610228 0.029241 0.042784 0.055524 0.056564 0.060245 ## 3 19610330 0.025896 0.025474 0.041304 0.060563 0.071875 ## 4 19610428 0.005667 0.001365 0.000780 0.011911 0.023328 ## 5 19610531 0.019208 0.036852 0.049590 0.046248 0.050362 ## 6 19610630 -0.024670 -0.025225 -0.040046 -0.050651 -0.051434 rtn &lt;- log(da[, 2:4] + 1) # 1,2,5-分位取り出し &amp; 対数収益率化 平均方程式のモデルとしてVAR(1)採用. 予備分析で観察された系列相関除去. m1 &lt;- VAR(rtn, 1) ## Fit VAR(1) model to remove serial correlations ## Constant term: ## Estimates: 0.006376978 0.007034631 0.007342962 ## Std.Error: 0.001759562 0.001950008 0.002237004 ## AR coefficient matrix ## AR( 1 )-matrix ## [,1] [,2] [,3] ## [1,] -0.194 0.224 0.00836 ## [2,] -0.232 0.366 -0.04186 ## [3,] -0.313 0.452 0.00238 ## standard error ## [,1] [,2] [,3] ## [1,] 0.108 0.160 0.101 ## [2,] 0.120 0.177 0.111 ## [3,] 0.138 0.204 0.128 ## ## Residuals cov-mtx: ## [,1] [,2] [,3] ## [1,] 0.001814678 0.001859113 0.001962277 ## [2,] 0.001859113 0.002228760 0.002420858 ## [3,] 0.001962277 0.002420858 0.002933081 ## ## det(SSE) = 1.712927e-10 ## AIC = -22.45809 ## BIC = -22.39289 ## HQ = -22.43273 平均方程式からの残差系列に対して, ARCH効果の存在を確認する. at &lt;- m1$residuals ## ARCH test MarchTest(at) - MTS::EWMAvol(rtn, lambda = 0.96) # lambda: 減衰率 - lambda = 正値 --&gt; 固定値を指定して実行 (lambdaの推定なし) - lambda = 負値 --&gt; lambda推定 (QMLE推定) 減衰率lambdaをデータより推定させる場合 m2 &lt;- EWMAvol(at, lambda = -0.1) ### Estimation of decaying rate ## ## Coefficient(s): ## Estimate Std. Error t value Pr(&gt;|t|) ## lambda 0.946114 0.008997 105.2 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Sigma.t = m2$Sigma.t ### Volatility matrices MCHdiag(at, Sigma.t) # モデル診断 → \\(p\\)値がゼロに近い (帰無仮説棄却, ARCH効果有り) ことが確認される. EWMAはパラメータ数が少なく計算は容易だが, 一般にモデル診断に引っかかりやすい (データへの適合が良くない). - MTS::MCHdiag - 適合した多変量ボラティリティモデルの妥当性を検証 - 4種類のかばん検定を実施 (MarchTest()の内容) - at: k次元資産収益率系列に対する残差, (Txk)-行列 - Sigma.t: 適合した, (Txk^2)次元の分散共分散行列 (ボラティリティ行列) - m: かばん検定に使用するラグ数 (デフォルト=10). (以下を追加) 減衰率lambdaを指定する場合 m2_2 &lt;- EWMAvol(at, lambda = 0.9) ### 減衰率 = 0.9に設定 matplot(m2$Sigma.t, type = &quot;l&quot;) matplot(m2_2$Sigma.t, type = &quot;l&quot;) CRSPの1, 2, 5十分位ポートフォリオ(dec1,dec2,dec5)の月次対数収益率のボラティリティ行列の各要素の時系列プロットは, 以下を実行すれば良い (p.415–). Rのmatrix型データセットSigma.tの1,5,9列は, 分散共分散行列\\({\\bf H}_t\\)の対角成分, すなわち, dec1,dec2,dec3の 分散(=ボラティリティの2乗)系列を, 2,3,6列は, それぞれ, dec1とdec2, dec1とdec5, dec2とdec5の共分散系列を表す. ここでは実行を省略. par(mfcol = c(3, 2)) ### Create Figure 7.3 of the text tdx &lt;- c(2:609)/12+1961 plot(tdx, Sigma.t[, 1], xlab = &#39;Year&#39;, ylab = &quot;Variance&quot;, type = &#39;l&#39;) title(main = &quot;(a) Dec 1&quot;) plot(tdx, Sigma.t[, 5], xlab = &#39;Year&#39;, ylab = &quot;Variance&quot;, type = &#39;l&#39;) title(main = &quot;(b) Dec 2&quot;) plot(tdx, Sigma.t[, 9], xlab = &#39;Year&#39;, ylab = &quot;Variance&quot;, type = &#39;l&#39;) title(main = &quot;(c) Dec 5&quot;) plot(tdx, Sigma.t[, 2], xlab = &#39;Year&#39;, ylab = &quot;Covariance&quot;, type = &#39;l&#39;) title(main = &quot;(d) Dec 1 vs Dec 2&quot;) plot(tdx, Sigma.t[, 3], xlab = &#39;Year&#39;, ylab = &quot;Covariance&quot;, type = &#39;l&#39;) title(main = &quot;(e) Dec 1 vs Dec 5&quot;) plot(tdx, Sigma.t[, 6], xlab = &#39;Year&#39;, ylab = &quot;Covariance&quot;, type = &#39;l&#39;) title(main = &quot;(f) Dec 2 vs Dec 5&quot;) BEKK(1, 1)モデル パラメータ数を抑制しながらも条件付き分散間の相互従属性を記述し, かつ, 分析共分散行列の正定値性を維持できる特徴を持つ. とは言え, BEKK(1,1)においてさえパラメータは多く (\\(n = 3\\)の場合, \\(6 + 9 + 9 = 24\\)個), \\(n&gt;3\\)となると, 推定が難しくなる. p.417– - MTS::BEKK11 - 注) 実行時間を要する (ここでは不実行) ifl &lt;- file.path(dir_MTS, &quot;m-ibmsp-6111.txt&quot;) da &lt;- read.table(ifl, header = T) # IBM株, S&amp;P, 月次収益率, 1961年1月--2011年12月 rtn &lt;- log(da[, 2:3] + 1) m1a &lt;- BEKK11(rtn) # 時間かかる names(m1a) Sigma_t &lt;- m1a$Sigma.t at &lt;- cbind(rtn[, 1] - - m1a$estimates[1], rtn[, 2] - - m1a$estimates[2]) MCHdiag(at, Sigma_t) Cholesky分解を利用したボラティリティ・モデリングおよび推定 Tsay, p.426– (授業では扱わなかった内容. 詳細な解説は教科書Ch.7を参照せよ) 互いに相関を持つ, 観測収益率の残差系列\\({\\bf u}_t\\) が, 各々が1変量GARCHモデルに従って時間変動する, 互いに無相関な残差系列 \\({\\bf b}_t\\)の線形結合で生成されている (ある下三角行列\\({\\bf A}_t\\)を使って\\({\\bf u}_t={\\bf A}_t {\\bf b}_t\\)と書ける) と仮定するモデル. \\({\\bf u}_t\\)と\\({\\bf b}_t\\)の間の線形変換に, Cholesky分解が利用される. データ: IBM, S&amp;P, KO (コカ・コーラ) の月次収益率系列 ifl &lt;- file.path(dir_MTS, &quot;m-ibmspko-6111.txt&quot;) da &lt;- read.table(ifl, header = T) # IBM, S&amp;P指数, KO # 月次収益率, 1961年1月--2011年12月 rtn &lt;- log(da[, 2:4] + 1) # 対数収益率化 多変量Choleskyボラティリティ・モデル - MTS::MCholV 再帰的最小二乗法により, 時変コレスキー分解を実行. 次に, EWMA (lamda=0.96) により, 最小二乗法推定値を平滑化. 各線形回帰のイノベーション系列に対して1変量GARCHを適用 - size: 初期値計算に使う標本数 (デフォルト=36) - lambda: 減衰係数 (デフォルト=0.96) - p: 収益率モデルのVAR(p)の次数 (デフォルト=0) #library(fGarch) m3 &lt;- MCholV(rtn) ## Sample means: 0.007728 0.005024 0.010595 ## Estimation of the first component ## Estimate (alpha0, alpha1, beta1): 0.000356 0.117515 0.810288 ## s.e. : 0.000157 0.037004 0.057991 ## t-value : 2.262897 3.175772 13.97261 ## Component 2 Estimation Results (residual series): ## Estimate (alpha0, alpha1, beta1): 6.4e-05 0.099156 0.858354 ## s.e. : 3.1e-05 0.027785 0.037238 ## t-value : 2.034528 3.568616 23.05076 ## Component 3 Estimation Results (residual series): ## Estimate (alpha0, alpha1, beta1): 0.000173 0.117506 0.818722 ## s.e. : 6.2e-05 0.028651 0.038664 ## t-value : 2.808075 4.101297 21.17521 names(m3) ## [1] &quot;betat&quot; &quot;bt&quot; &quot;Vol&quot; &quot;Sigma.t&quot; # betat: コレスキー分解における線形変換の係数の再帰的最小二乗推定値 (EWMAによる平滑化済) # bt: 互いに無相関の残差系列. 各々に1変量GARCHを適合 (線形変換により相関のある残差系列u_t) # Vol: 各イノベーションのボラティリティ系列 # Sigma.t: 分散共分散行列 (ボラティリティ行列) 最初の36ヶ月使用して初期値計算 (デフォルト) しているため, これを除いてモデル診断. at &lt;- scale(rtn[-(1:36), ], center = T, scale = F) Sigma_t &lt;- m3$Sigma.t MCHdiag(at, Sigma_t) ## Test results: ## Q(m) of et: ## Test and p-value: 15.94978 0.1010791 ## Rank-based test: ## Test and p-value: 21.99727 0.01511849 ## Qk(m) of epsilon_t: ## Test and p-value: 123.7687 0.01057302 ## Robust Qk(m): ## Test and p-value: 95.49626 0.3259654 MCHdiag(at, Sigma_t, m = 5) ## Test results: ## Q(m) of et: ## Test and p-value: 5.717035 0.3347333 ## Rank-based test: ## Test and p-value: 5.579834 0.3492711 ## Qk(m) of epsilon_t: ## Test and p-value: 59.837 0.06842123 ## Robust Qk(m): ## Test and p-value: 58.97874 0.07891472 matplot(Sigma_t, type = &quot;l&quot;) matplot(m3$Vol, type = &quot;l&quot;) matplot(m3$betat, type = &quot;l&quot;) matplot(m3$bt, type = &quot;l&quot;) 関数MCholV()の出力はそれぞれ, btが\\({\\bf b}_t\\), betatが\\({\\bf b}_t\\)から\\({\\bf u}_t\\)への線形変換 (回帰係数), Volが\\({\\bf b}_t\\)に対して1変量GARCHを適合した結果得られたボラティリティ系列, Sigma.tが観測系列 (すなわち, 変換前の残差系列) \\({\\bf u}_t\\)の条件付き分散共分散行列 (ボラティリティ行列) \\({\\bf H}_t\\)の全要素 (\\(k=3\\)の場合, \\(k^2=3^2=9\\)列) である. すなわち, Volは各銘柄固有の (互いに無相関な) イノベーションに 対する推定ボラティリティ系列を表す (データの並び上では, IBM, S&amp;P指数, KOの順). なお, ボラティリティを標準偏差表示するには, 平方根を取る必要があることに注意しよう. par(mfrow = c(3,1)) plot(m3$Vol[, 1]^0.5, type = &quot;l&quot;) plot(m3$Vol[, 2]^0.5, type = &quot;l&quot;) plot(m3$Vol[, 3]^0.5, type = &quot;l&quot;) 一方, \\(k=3\\)におけるSigma.tの1,5,9番目の要素は, それぞれ, \\({\\bf H}_t\\)の(1,1), (2,2), (3,3)に対応し, これらは, IBM, S&amp;P指数, KOの観測系列 (の残差系列) のボラティリティである. これらは, Cholesky分解の特性上, 並び順に依存して大きさが変化する. ここでは, IBM株を第1要素に置いたため (“外生性”が一番高い), Volの第1成分m3$Vol[, 1]とSigma.t[, 1]の値が一致していることに注意しよう. 平方根を取る必要があることに注意しよう. par(mfrow = c(3,1)) plot(Sigma_t[, 1]^0.5, type = &quot;l&quot;) plot(Sigma_t[, 5]^0.5, type = &quot;l&quot;) plot(Sigma_t[, 9]^0.5, type = &quot;l&quot;) DCC (Dynamic Conditional Correlation) モデル Engle(2002)らによって提案された, 操作性が高く記述性もあるモデルであり, 学術, 実務両面において広く利用されている. DCCでは, \\({\\bf H}_t=(\\sigma_{ij,t})\\)の対角成分\\(\\sigma_{ii,t}\\), すなわち, 各系列のボラティリティが 1変量GARCHに従って変化する一方, 条件付き相関係数\\({\\bf R}_t\\)も時間と伴に動的に変化することを仮定する (Tsay本では\\(\\rho_t\\)と表記). ここで, \\[{\\bf H}_t = {\\bf D}_t {\\bf R}_t {\\bf D}_t,\\] 但し, \\({\\bf D}_t = diag\\{\\sigma_{11,t},\\ldots, \\sigma_{kk,t}\\}\\) である. \\({\\bf R}_t\\)の動的変化を表すモデリングとして, 教科書では Engle(2002), Tse and Tsui (2002)を取り上げている. MTS, p.432– データ: (引き続き) IBM, SP, KO 対数収益率の使用 事前フィッティング 各成分に単変量GARCHを適合 → DCC推定のための標準化残差系列の生成 - MTS::dccPre - 注) 実行時間ややかかる m1 &lt;- dccPre(rtn, include.mean = T, p = 0) ## Sample mean of the returns: 0.00772774 0.005023909 0.01059521 ## Component: 1 ## Estimates: 0.000419 0.126739 0.788307 ## se.coef : 0.000162 0.035405 0.055645 ## t-value : 2.593448 3.57973 14.16662 ## Component: 2 ## Estimates: 9e-05 0.127725 0.836053 ## se.coef : 4.1e-05 0.03084 0.031723 ## t-value : 2.20126 4.141592 26.35486 ## Component: 3 ## Estimates: 0.000256 0.098705 0.830358 ## se.coef : 8.5e-05 0.022361 0.033441 ## t-value : 3.015321 4.414112 24.83088 names(m1) ## [1] &quot;marVol&quot; &quot;sresi&quot; &quot;est&quot; &quot;se.coef&quot; rtn1 &lt;- m1$sresi # 標準化残差系列 Vol &lt;- m1$marVol Tse and Tsui (2002) モデル - MTS::docFit (rt, type = &quot;TseTsui&quot;) (デフォルト) - 標準化残差系列に対してDCCモデルを適合 m2 &lt;- dccFit(rtn1) ### Use Tse and Tsui model ## Estimates: 0.8087994 0.04027416 7.959064 ## st.errors: 0.1491731 0.02259899 1.135905 ## t-values: 5.421884 1.782122 7.006802 names(m2) ## [1] &quot;estimates&quot; &quot;Hessian&quot; &quot;rho.t&quot; S2_t &lt;- m2$rho.t Engle (2002) モデル - MTS::docFit (rt, type = &quot;Engle&quot;) (デフォルト) - 注) 実行時間ややかかる m3 &lt;- dccFit(rtn1, type = &quot;Engle&quot;) ## Use Engle model ## Estimates: 0.9126534 0.04531519 8.624321 ## st.errors: 0.02947897 0.01274031 1.33269 ## t-values: 30.95947 3.556835 6.471362 S3_t &lt;- m3$rho.t → rho.tは, 時点\\(t\\)の相関行列\\(R_t\\) (\\(3 \\times 3\\)-対称行列) を, \\(3^2=9\\)個の成分を一行に配置したmatrix型データ (以下のコードを追加) \\(R_t\\)の全ての非対角成分である (1,2), (1,3), (2,3)成分 (対称行列ゆえ, (2,1), (3,1), (3,2)と等価) を取り出して (rho.tの2,3,6列) 時系列プロットする. これらは, IBMとS&amp;P, IBMとKO, S&amp;PとKOの 相関係数にそれぞれ対応している. なお, rho.tの1,5,9列目は\\(R_t\\)の対角成分に対応していることから, 常時1となっている (自分自身との相関\\(=1\\)). head(S2_t) # Tse and Tsui model ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## [1,] 1 0.5842955 0.2772491 0.5842955 1 0.5600389 0.2772491 0.5600389 1 ## [2,] 1 0.5842955 0.2772491 0.5842955 1 0.5600389 0.2772491 0.5600389 1 ## [3,] 1 0.5842955 0.2772491 0.5842955 1 0.5600389 0.2772491 0.5600389 1 ## [4,] 1 0.5842955 0.2772491 0.5842955 1 0.5600389 0.2772491 0.5600389 1 ## [5,] 1 0.5930112 0.2898027 0.5930112 1 0.5485945 0.2898027 0.5485945 1 ## [6,] 1 0.5867309 0.3016936 0.5867309 1 0.5596515 0.3016936 0.5596515 1 head(S3_t) # Engle model ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## [1,] 1 0.5842955 0.2772491 0.5842955 1 0.5600389 0.2772491 0.5600389 1 ## [2,] 1 0.6037264 0.2712637 0.6037264 1 0.5383299 0.2712637 0.5383299 1 ## [3,] 1 0.6081221 0.3065183 0.6081221 1 0.5405505 0.3065183 0.5405505 1 ## [4,] 1 0.6095527 0.3048562 0.6095527 1 0.5392283 0.3048562 0.5392283 1 ## [5,] 1 0.6065274 0.2795197 0.6065274 1 0.5274868 0.2795197 0.5274868 1 ## [6,] 1 0.6077643 0.2881606 0.6077643 1 0.5297445 0.2881606 0.5297445 1 matplot(S2_t[, c(2, 3, 6)], type = &quot;l&quot;, main = &quot;Tse and Tsui model&quot;) matplot(S3_t[, c(2, 3, 6)], type = &quot;l&quot;, main = &quot;Engle model&quot;) MCHdiag(rtn1, S2_t) ### Model checking ## Test results: ## Q(m) of et: ## Test and p-value: 20.74249 0.02296253 ## Rank-based test: ## Test and p-value: 30.20662 0.0007924436 ## Qk(m) of epsilon_t: ## Test and p-value: 132.4228 0.002425954 ## Robust Qk(m): ## Test and p-value: 109.9671 0.07501572 MCHdiag(rtn1, S3_t) ## Test results: ## Q(m) of et: ## Test and p-value: 20.02928 0.02897696 ## Rank-based test: ## Test and p-value: 27.60836 0.002084952 ## Qk(m) of epsilon_t: ## Test and p-value: 131.9812 0.002626131 ## Robust Qk(m): ## Test and p-value: 111.3537 0.06306805 GO-GARCHモデル データ系列に直交変換を適用することでデータの次元を 下げる方法も提案されている. 代表的なものが, Alexnderらによって提案された, 主成分分析 (PCA) を利用したモデルであるO-GARCHや, van der Weideらによって一般化されたGO-GARCHである. - gogarch::gogarch - estby: &quot;ica&quot;(Independent Component Analysis), &quot;mm&quot; (モーメント法), &quot;ml&quot; (最尤法), &quot;nls&quot; (非線形最小二乗法) Tsay, p.437– library(gogarch) ## Loading required package: fGarch ## NOTE: Packages &#39;fBasics&#39;, &#39;timeDate&#39;, and &#39;timeSeries&#39; are no longer ## attached to the search() path when &#39;fGarch&#39; is attached. ## ## If needed attach them yourself in your R script by e.g., ## require(&quot;timeSeries&quot;) ## Loading required package: fastICA crtn &lt;- scale(rtn, center = T, scale = F) m1 &lt;- gogarch::gogarch(crtn, ~garch(1, 1), estby = &quot;ica&quot;) # &quot;ica&quot;: Independent Component Analysisx (非正規データの場合) m1 ## ## **************** ## *** GO-GARCH *** ## **************** ## ## Components estimated by: fast ICA ## Dimension of data matrix: (612 x 3). ## Formula for component GARCH models: ~ garch(1, 1) ## ## Orthogonal Matrix U: ## [,1] [,2] [,3] ## [1,] -0.3723439 -0.4866190 -0.7902923 ## [2,] 0.7627565 0.3246645 -0.5592812 ## [3,] 0.5287367 -0.8110456 0.2502850 ## ## Linear Map Z: ## [,1] [,2] [,3] ## [1,] -0.008734108 -0.033226028 -0.060667554 ## [2,] 0.030423782 -0.007310938 -0.030686595 ## [3,] 0.039766454 -0.047130721 0.001242973 ## ## Estimated GARCH coefficients: ## omega alpha1 beta1 ## y1 0.32198686 0.13517369 0.7163590 ## y2 0.21644553 0.09060893 0.8578056 ## y3 0.01843073 0.09212147 0.8475376 ## ## Convergence codes of component GARCH models: ## y1 y2 y3 ## 1 1 1 # Convergence codes of component GARCH models: Sigma_t &lt;- NULL ### obtain the volatility matrix for (i in 1:612){ Sigma_t &lt;- rbind(Sigma_t, c(m1@H[[i]])) } MCHdiag(crtn, Sigma_t) ### Model checking ## Test results: ## Q(m) of et: ## Test and p-value: 18.0754 0.05370503 ## Rank-based test: ## Test and p-value: 17.46676 0.06465296 ## Qk(m) of epsilon_t: ## Test and p-value: 140.7063 0.0005075642 ## Robust Qk(m): ## Test and p-value: 122.2405 0.01345963 M &lt;- m1@Z Minv &lt;- solve(M) # 逆行列 bt &lt;- crtn %*% t(Minv) cor(bt^2) ## [,1] [,2] [,3] ## [1,] 1.0000000 0.1743661 0.3426167 ## [2,] 0.1743661 1.0000000 0.1063766 ## [3,] 0.3426167 0.1063766 1.0000000 matplot(Sigma_t[, c(1, 5, 9)], type = &quot;l&quot;) # 追加 コピュラに基づくアプローチ 相関係数では捉えられない, 変数間の非線形の従属性をコピュラによって 表現するアプローチ. Tsay, p.452– データ: (引き続き) IBM, SP, KO 月次収益率の使用 ifl &lt;- file.path(dir_MTS, &quot;m-ibmspko-6111.txt&quot;) da &lt;- read.table(ifl, header = T) rtn &lt;- log(da[, -1] + 1) # 対数収益率化 m1 &lt;- dccPre(rtn, cond.dist = &quot;std&quot;) ## Sample mean of the returns: 0.00772774 0.005023909 0.01059521 ## Component: 1 ## Estimates: 0.000388 0.115626 0.805129 9.209269 ## se.coef : 0.000177 0.036827 0.059471 3.054813 ## t-value : 2.195398 3.139719 13.5382 3.014675 ## Component: 2 ## Estimates: 0.00012 0.130898 0.814531 7.274928 ## se.coef : 5.7e-05 0.037012 0.046044 1.913331 ## t-value : 2.102768 3.536655 17.69028 3.802231 ## Component: 3 ## Estimates: 0.000216 0.104706 0.837217 7.077138 ## se.coef : 8.9e-05 0.028107 0.037157 1.847527 ## t-value : 2.437323 3.725341 22.53208 3.830601 names(m1) ## [1] &quot;marVol&quot; &quot;sresi&quot; &quot;est&quot; &quot;se.coef&quot; Vol &lt;- m1$marVol eta &lt;- m1$sresi matplot(Vol, type = &quot;l&quot;) # 追加 多変量 t-Copula ボラティリティ・モデル - MTS::mtCopula - Fits a t-copula to a k-dimensional standardized return series. The correlation matrices are parameterized by angles and the angles evolve over time via a DCC-type equation. - 注) 実行時間ややかかる m2 &lt;- mtCopula(eta, g1 = 0.8, g2 = 0.04) # -&gt; 時間ややかかる names(m2) MCHdiag(eta, m2$rho.t) m3 &lt;- mtCopula(eta, g1 = 0.8, g2 = 0.04, include.th0 = F) Example 7.6 {-} データ: Exxon-mobile, S&amp;P, IBM, 日次収益率 ifl &lt;- file.path(dir_MTS, &quot;d-xomspaapl.txt&quot;) da &lt;- read.table(ifl, header = T) head(da) rtn &lt;- log(da[, -1] + 1) * 100 # 対数収益率化 # 日次収益率, 2007.9--2012.9, Exxon Mobil, S&amp;P, Apple mm1 &lt;- dccPre(rtn, cond.dist = &quot;std&quot;) rtn1 &lt;- mm1$sresi Vol &lt;- mm1$marVol dim(rtn1) matplot(Vol, type = &quot;l&quot;) # 追加 mm2 &lt;- mtCopula(rtn1, 0.8, 0.04) # -&gt; 時間ややかかる MCHdiag(rtn1, mm2$rho.t) "],["動的線形モデル.html", "12 動的線形モデル 12.1 局所水準 (local level) モデル 12.2 local level plus seasonal componentモデル 12.3 動的回帰モデル 12.4 SUR (Seemingly Unrelated Regression) モデル (3.3.3)", " 12 動的線形モデル 本章では, 動的線形モデル (Dynamic Linear Models) を取り上る. Rパッケージとしては, dlmを利用する. 出所: Petris, Petrone, and Campagnoli (2009). Dynamic Linear Models with R. Springer (“PPC”) dlmは, PPCを手元で参照しながらでないと使いこなすことが難しい. 本セクションのRコード実行結果の詳しい解説については, PPCを参照のこと. Nileデータ - アスワン (Aswan) におけるナイル川の年間流量の計測量 - 1871--1970年 (単位 10^8立方メートル) - 1898年付近に変化点が見られる (Cobb(1978), Table 1, p.249） パッケージdlm 動的線形モデル (DLM) のベイズ分析用パッケージ DLMのパラメータの最尤推定とカルマン・フィルターの関数を含む DLMの特定化に関係する主要な関数 - dlm(): Dynamic Linear Objectsの生成 - dlmModReg(): 線形回帰モデルのDLM表現 - dlmModPoly(): $n$-次多項式DLM表現 - dlmModSeas(): 季節成分のDLM表現 - dlmModTrig(): 周期成分のDLM表現 - dlmModARMA(): (多変量)ARMA過程のDLM表現 状態の推定に先立ち, 動的線形モデル (DLM) の特定化は, 関数dlmModReg()によって行う. - dlmModReg() - dV: 観測ノイズ$V$ - dW: システムノイズの共分散行列$W$対角成分 - m0: 状態ベクトル初期値の期待値$m0$ - C0: 状態ベクトル初期値の共分散行列$C0$ 正規乱数により生成した\\(10 \\times 2\\)の説明変数行列\\(x\\)を dlmModReg()に代入した場合の出力 library(dlm) ## Linear regression as a DLM x &lt;- matrix(rnorm(10),ncol = 2) # 説明変数 (デザイン行列) mod &lt;- dlmModReg(x) # is.dlm(mod) mod #&gt; $FF #&gt; [,1] [,2] [,3] #&gt; [1,] 1 1 1 #&gt; #&gt; $V #&gt; [,1] #&gt; [1,] 1 #&gt; #&gt; $GG #&gt; [,1] [,2] [,3] #&gt; [1,] 1 0 0 #&gt; [2,] 0 1 0 #&gt; [3,] 0 0 1 #&gt; #&gt; $W #&gt; [,1] [,2] [,3] #&gt; [1,] 0 0 0 #&gt; [2,] 0 0 0 #&gt; [3,] 0 0 0 #&gt; #&gt; $JFF #&gt; [,1] [,2] [,3] #&gt; [1,] 0 1 2 #&gt; #&gt; $X #&gt; [,1] [,2] #&gt; [1,] -0.2047 -1.042 #&gt; [2,] 0.4413 0.7456 #&gt; [3,] ... #&gt; #&gt; $m0 #&gt; [1] 0 0 0 #&gt; #&gt; $C0 #&gt; [,1] [,2] [,3] #&gt; [1,] 1e+07 0e+00 0e+00 #&gt; [2,] 0e+00 1e+07 0e+00 #&gt; [3,] 0e+00 0e+00 1e+07 ## Adding dlm&#39;s # dlmModPoly() + dlmModSeas(4) # linear trend plus quarterly seasonal component 一方, \\(n\\)-次多項式DLMの場合は, dlmModPoly()を用いる. - dlmModPoly(): $n$-次多項式DLMの生成 - order=1: local level(ランダムウォーク+ノイズ) - order=2: stochastic linear trend (局所線形トレンドモデル) (デフォルト) 観測ノイズ\\(V=0.3\\), システムノイズ (の分散共分散行列の対角成分) \\(W=0.01\\)に持つ局所水準 (ランダムウォーク+ノイズ) モデルの特定化の場合の出力 ## the default dlmModPoly() #&gt; $FF #&gt; [,1] [,2] #&gt; [1,] 1 0 #&gt; #&gt; $V #&gt; [,1] #&gt; [1,] 1 #&gt; #&gt; $GG #&gt; [,1] [,2] #&gt; [1,] 1 1 #&gt; [2,] 0 1 #&gt; #&gt; $W #&gt; [,1] [,2] #&gt; [1,] 0 0 #&gt; [2,] 0 1 #&gt; #&gt; $m0 #&gt; [1] 0 0 #&gt; #&gt; $C0 #&gt; [,1] [,2] #&gt; [1,] 1e+07 0e+00 #&gt; [2,] 0e+00 1e+07 ## random walk plus noise dlmModPoly(1, dV = .3, dW = .01) #&gt; $FF #&gt; [,1] #&gt; [1,] 1 #&gt; #&gt; $V #&gt; [,1] #&gt; [1,] 0.3 #&gt; #&gt; $GG #&gt; [,1] #&gt; [1,] 1 #&gt; #&gt; $W #&gt; [,1] #&gt; [1,] 0.01 #&gt; #&gt; $m0 #&gt; [1] 0 #&gt; #&gt; $C0 #&gt; [,1] #&gt; [1,] 1e+07 12.1 局所水準 (local level) モデル 最も単純なDLMの一つとしてランダムウォーク+ノイズモデル (local level model) をナイル川流量データのモデリングに使用する. local levelモデル. 観測変数 \\(Y_t\\) に対して, \\[ \\begin{align} Y_t &amp;= \\mu_t + v_t, \\quad v_t \\sim_{i.i.d.} N(0,V), \\\\ \\mu_{t} &amp;= \\mu_{t-1} + w_t, \\quad w_t \\sim_{i.i.d.} N(0,W). \\end{align} \\] ここで, \\(\\mu_t\\)は時点\\(t\\)における状態変数であり, 観測不能 (潜在的な) 水準 (level), \\(v_t,w_t\\)は攪乱項である. 状態変数 \\(\\mu_t\\) はKalman filterを用いることで推定できる. 二つのパラメータ\\(V,W\\) (攪乱項の分散) は既知の定数として扱われる. 実際には, 通常これらのパラメータは事前に分かっていないため, データより推定する必要がある. 最尤推定やベイズ推定により求めることができる. cf. https://kevinkotze.github.io/ts-4-tut/ ts.plot(Nile) # local level model NilePoly &lt;- dlmModPoly(order = 1, dV = 15100, dW = 1468) unlist(NilePoly) #&gt; m0 C0 FF V GG W #&gt; 0 10000000 1 15100 1 1468 フィルタリング 最新の観測値に基づいて, 現在の状態を (“オンライン”で) 推定する. Kalman filterによる, 状態空間ベクトルのフィルター値と, (特異値分解(SVD)に基づいて) 分散共分散行列の計算 NileFilt &lt;- dlmFilter(Nile, NilePoly) # str(NileFilt, 1) n &lt;- length(Nile) attach(NileFilt) #dlmSvd2var(U.C[[n + 1]], D.C[n + 1, ]) # 特異値分解(SVD)から非負定値行列 (u d^2 u&#39;) 計算 S/N比 (\\(W/V\\)), Kalman”ゲイン”を決める重要な要因 観測値の変動に対する状態の(事前→事後)更新の感応度合い plot(Nile, type = &#39;o&#39;, col = c(&quot;darkgrey&quot;), xlab = &quot;&quot;, ylab = &quot;Level&quot;) mod1 &lt;- dlmModPoly(order = 1, dV = 15100, dW = 755) NileFilt1 &lt;- dlmFilter(Nile, mod1) lines(dropFirst(NileFilt1$m), lty = &quot;longdash&quot;) mod2 &lt;- dlmModPoly(order = 1, dV = 15100, dW = 7550) NileFilt2 &lt;- dlmFilter(Nile, mod2) lines(dropFirst(NileFilt2$m), lty = &quot;dotdash&quot;) leg &lt;- c(&quot;data&quot;, paste(&quot;filtered, W/V =&quot;, format(c(W(mod1) / V(mod1), W(mod2) / V(mod2))))) legend(&quot;bottomright&quot;, legend = leg, col=c(&quot;darkgrey&quot;, &quot;black&quot;, &quot;black&quot;), lty = c(&quot;solid&quot;, &quot;longdash&quot;, &quot;dotdash&quot;), pch = c(1, NA, NA), bty = &quot;n&quot;) 状態方程式の誤差分散 (dW) の大きさが 755 と 7550 の2つの場合を比較する: dW が大きいほど, 真の状態 (流量の水準) の変動が大きく許容されるモデルとなりフィルター系列 (状態の推定値) もよりデータの急激な変動に追従しやすい dW が小さいほど, 状態方程式側の変動を小さく仮定しているためフィルター系列は元データよりも滑らかになりやすい スムージング (平滑化) 最新時点までの全観測値を使い, 過去の全時点の状態を (“オフライン”で) 推定する (平滑化推定値の計算) NileSmooth &lt;- dlmSmooth(NileFilt) str(NileSmooth, 1) #&gt; List of 3 #&gt; $ s : Time-Series [1:101] from 1870 to 1970: 1111 1111 1111 1105 1113 ... #&gt; $ U.S:List of 101 #&gt; $ D.S: num [1:101, 1] 74.1 63.5 56.9 53.1 50.9 ... attach(NileSmooth) # dlmSvd2var() により共分散行列を再構築: # 各要素を drop() でスカラーに落とす # U.S, D.S: フィルタ・平滑化結果（状態側）のSVD分解要素 # U.C, D.C は観測側のSVD要素。 # ここでは, 特定の時点 (n+1, n/2+1) の分散を取り出して確認 drop(dlmSvd2var(U.S[[n + 1]], D.S[n + 1,])) #&gt; [1] 4031.035 drop(dlmSvd2var(U.C[[n + 1]], D.C[n + 1,])) #&gt; [1] 4031.035 drop(dlmSvd2var(U.S[[n / 2 + 1]], D.S[n / 2 + 1,])) #&gt; [1] 2325.985 drop(dlmSvd2var(U.C[[n / 2 + 1]], D.C[n / 2 + 1,])) #&gt; [1] 4031.035 # 平滑化した状態sの分散をもとに, 95%信頼区間の (半分の) 幅 (hwid)を算出 # qnorm(0.025, lower = FALSE): 片側 (上側) 2.5%点を取得 --&gt; 95%区間に対応 # dlmSvd2var(U.S, D.S) の結果 (unlist()でベクトル化) の平方根 --&gt; 標準偏差 hwid &lt;- qnorm(0.025, lower = FALSE) * sqrt(unlist(dlmSvd2var(U.S, D.S))) # cbind()により3列からなる行列smooth作成: # 平滑化推定値(s), 推定値-hwid (下側信頼区間), 推定値+hwid (上側信頼区間) smooth &lt;- cbind(s, as.vector(s) + hwid %o% c(-1, 1)) plot(dropFirst(smooth), plot.type = &quot;s&quot;, type = &quot;l&quot;, lty = c(1, 5, 5), ylab = &quot;Level&quot;, xlab = &quot;&quot;, ylim = range(Nile)) lines(Nile, type = &quot;o&quot;, col = &quot;darkgrey&quot;) legend(&quot;bottomleft&quot;, col = c(&quot;darkgrey&quot;, rep(&quot;black&quot;, 2)), lty = c(1, 1, 5), pch = c(1, NA, NA), bty = &quot;n&quot;, legend = c(&quot;data&quot;, &quot;smoothed level&quot;, &quot;95% probability limits&quot;)) 状態予測 a &lt;- window(cbind(Nile, NileFilt1$f, NileFilt2$f), start = 1880, end = 1920) plot(a[, 1], type = &#39;o&#39;, col = &quot;darkgrey&quot;, xlab = &quot;&quot;, ylab = &quot;Level&quot;) lines(a[, 2], lty = &quot;longdash&quot;) lines(a[, 3], lty = &quot;dotdash&quot;) leg &lt;- c(&quot;data&quot;, paste(&quot;one-step-ahead forecast, W/V =&quot;, format(c(W(mod1) / V(mod1), W(mod2) / V(mod2))))) legend(&quot;bottomleft&quot;, legend = leg, col = c(&quot;darkgrey&quot;, &quot;black&quot;, &quot;black&quot;), lty = c(&quot;solid&quot;, &quot;longdash&quot;, &quot;dotdash&quot;), pch = c(1, NA, NA), bty = &quot;n&quot;) つぎの2つのモデルを比較する. mod0: 通常のローカルレベルモデル modDam: 1898–1899年にダム建設によって変動が増大した (あるいは別の構造変化があった) ことを想定したモデル mod0 &lt;- dlmModPoly(order = 1, dV = 15100, dW = 1468) # ローカルレベルモデル (order=1) を生成 # dV = 観測誤差の分散, dW = 状態方程式誤差の分散 X &lt;- ts(matrix(mod0$W, nc = 1, nr = length(Nile)), start = start(Nile)) # 1列だけの行列 mod0$W を # Nile と同じ長さ・開始時点を持つ時系列 X に変換 window(X, 1898, 1899) &lt;- 12 * mod0$W # 1898--1899年のプロセス分散（状態方程式誤差）を12倍 # -&gt; この期間に大きな構造変化があるとみなし, 変動が増す設定 modDam &lt;- mod0 modDam$X &lt;- X modDam$JW &lt;- matrix(1, 1, 1) # modDam: &quot;Dam model&quot; として、 # 上で作成した時系列 X (時間変化する分散) を組み込む # JWは状態方程式側の分散を X で置き換えるために設定する行列 damFilt &lt;- dlmFilter(Nile, modDam) mod0Filt &lt;- dlmFilter(Nile, mod0) # Nileデータに対してフィルタリングを実行 # damFilt: ダム建設による影響を考慮したモデル # mod0Filt: 通常のローカルレベルモデル a &lt;- window(cbind(Nile, mod0Filt$f, damFilt$f), start = 1880, end = 1920) # Nile実測値, mod0(通常モデル)の1ステップ先予測 # modDam(ダム有りモデル)の1ステップ先予測 # を時系列 a としてまとめ, 可視化のため 1880~1920年に切り出す plot(a[, 1], type = &#39;o&#39;, col = &quot;darkgrey&quot;, xlab = &quot;&quot;, ylab = &quot;Level&quot;) lines(a[, 2], lty = &quot;longdash&quot;) lines(a[, 3], lty = &quot;dotdash&quot;) abline(v = 1898, lty = 2) leg &lt;- c(&quot;data&quot;, paste(&quot;one-step-ahead forecast -&quot;, c(&quot;mod0&quot;, &quot;modDam&quot;))) legend(&quot;bottomleft&quot;, legend = leg, col = c(&quot;darkgrey&quot;, &quot;black&quot;, &quot;black&quot;), lty = c(&quot;solid&quot;, &quot;longdash&quot;, &quot;dotdash&quot;), pch = c(1, NA, NA), bty = &quot;n&quot;) モデル診断 qqnorm(residuals(damFilt, sd = FALSE)) qqline(residuals(damFilt, sd = FALSE)) tsdiag(damFilt) モデル・パラメータの推定 未知のモデル・パラメータ, 例えば, dlmModPoly() が生成するローカルレベルモデル（あるいはローカルトレンドモデルなど）においては, dV = 観測方程式のノイズ（観測誤差）の分散 dW = 状態方程式のノイズ（状態・トレンドの変動）の分散 を事前に指定する必要がある. これらは, データから最尤推定 (MLE) やベイズ推定により推定することができる. 詳細は, PPC, Ch.4を参照のこと. 具体的には, dlmには最尤推定を行うための関数dlmMLE()が用意されている. dlmMLE(): モデルパラメータの最尤推定 ここでは, ナイルデータに対して, ローカルレベルモデルを仮定し, MLEを使用してdV, dWの最尤推定値を計算する. # p.145 buildFun &lt;- function(parm) { dlmModPoly(order = 1, dV = exp(parm[1]), dW = exp(parm[2])) } # 初期値を適当に設定して最尤推定 fit &lt;- dlmMLE(Nile, parm = c(log(1000), log(1000)), build = buildFun) fit$conv # 0 なら収束 #&gt; [1] 0 fit$par # 推定された log(dV), log(dW) #&gt; [1] 9.622441 7.291932 exp(fit$par) # dV, dW の推定値 #&gt; [1] 15099.857 1468.404 より複雑なDLMに対しても, 上記buidFun()に対応する 自作関数を用意すれば, それをdlmMLE()の引数buildに 与えることで未知パラメータの最尤推定ができる. ただし, この自作関数を適切に作成するには, ある程度 このdlmに慣れておく必要がある. 12.2 local level plus seasonal componentモデル 次に, 局所水準モデル (ランダムウォーク+ノイズ) に (独立な) 季節性成分が加わったDLMを取り上げる. データ2: 英国における耐久消費財の消費支出 (四半期ベース), 1957Q1–1967Q4, Time Series Data Library: https://robjhyndman.com/tsdl/) 出所: Petris, etal (2009), p.64– - qconsum.dat - quarterly consumer expenditure - durable goods - all other goods and services - investment - inventory investment - imports of goods and services - gross domestic product - personal disposable income - Source: (Hyndman (n.d.) ifl &lt;- file.path(dir_PPC, &quot;qconsum.dat&quot;) expd &lt;- ts(read.table(ifl, skip = 4, colClasses = &quot;numeric&quot;)[, 1], start = c(1957, 1), frequency = 4) expd.dlm &lt;- dlm(m0 = rep(0,4), C0 = 1e8 * diag(4), FF = matrix(c(1, 1, 0, 0), nr = 1), V = 1e-3, GG = bdiag(matrix(1), matrix(c(-1, -1, -1, 1, 0, 0, 0, 1, 0), nr = 3, byrow = TRUE)), W = diag(c(771.35, 86.48, 0, 0), nr = 4)) plot(expd, xlab = &quot;&quot;, ylab = &quot;Expenditures&quot;, type = &#39;o&#39;, col = &quot;darkgrey&quot;) ### Filter expdFilt &lt;- dlmFilter(expd, expd.dlm) lines(dropFirst(expdFilt$m[, 1]), lty = &quot;dotdash&quot;) ### Smooth expdSmooth &lt;- dlmSmooth(expdFilt) lines(dropFirst(expdSmooth$s[,1]), lty = &quot;longdash&quot;) legend(&quot;bottomright&quot;, col = c(&quot;darkgrey&quot;, rep(&quot;black&quot;, 2)), lty = c(&quot;solid&quot;, &quot;dotdash&quot;, &quot;longdash&quot;), pch = c(1, NA, NA), bty = &quot;n&quot;, legend = c(&quot;data&quot;, &quot;filtered level&quot;, &quot;smoothed level&quot;)) ### Seasonal component plot(dropFirst(expdSmooth$s[, 3]), type = &#39;o&#39;, xlab = &quot;&quot;, ylab = &quot;Expenditure - Seasonal component&quot;) abline(h = 0) 状態予測 set.seed(1) expdFore &lt;- dlmForecast(expdFilt, nAhead = 12, sampleNew = 10) plot(window(expd, start = c(1964, 1)), type = &#39;o&#39;, xlim = c(1964, 1971), ylim = c(350, 850), xlab = &quot;&quot;, ylab = &quot;Expenditures&quot;) names(expdFore) #&gt; [1] &quot;a&quot; &quot;R&quot; &quot;f&quot; &quot;Q&quot; &quot;newStates&quot; &quot;newObs&quot; attach(expdFore) invisible(lapply(newObs, function(x) lines(x, col = &quot;darkgrey&quot;, type = &#39;o&#39;, pch = 4))) lines(f, type = &#39;o&#39;, lwd = 2, pch = 16) abline(v = mean(c(time(f)[1], time(expd)[length(expd)])), lty = &quot;dashed&quot;) detach() 12.3 動的回帰モデル 1変量の目的変数\\(Y_t\\)に対して, \\(p\\)個の説明変数\\(x_t=[x_{1,t} \\, \\cdots x_{p,t}]&#39;\\)が 時間と共に動的に変化する回帰モデルは以下のようにDLM表現可能である: \\[ \\begin{align} Y_t &amp;= F \\theta_t + v_t, \\quad v_t \\sim_{i.i.d.} N(0,V_t),\\label{eq:Y} \\\\ \\theta_{t} &amp;= G \\theta_{t-1} + w_{t}, \\quad w_{t} \\sim_{i.i.d.} N(0,W_t), \\label{eq:mu} \\end{align} \\] ここで, 回帰的係数\\(\\theta_t = [\\theta_{0,t} \\,\\theta_{1,t} \\, \\cdots \\theta_{p,t}]&#39;\\), (\\(\\theta_{0,t}\\)は切片項) が動的に変化する状態変数, また, 観測方程式の係数行列\\(F = [1 \\, x_t], V_t = \\sigma_t^2\\)である. 一方, 状態推移を記述する状態方程式の係数行列\\(G\\)は, 単位行列\\({\\bf I}_{(p+1) \\times (p+1)}\\), 撹乱項\\(w_t\\)の分散共分散行列\\(W_t\\)は対角行列に設定されることが多い. この設定は, 各成分\\(theta_i\\)が互いに独立なランダムウォークに従って推移すると仮定することを意味する. DLMでは\\(F,G,V_t,W_t\\)は既知であると想定する. 特に, \\(V_t,W_t\\)に関して未知である場合には, データより推定する必要がある. 線形回帰モデルの具体例として, \\(Y_t\\)をIBM, \\(X_t\\)をMarketの月次超過リターンにおいて, 静的, 動的2種類のCAPMモデルを推定する. データ3: 米国株式月次収益率 - 1978.1--1987.12, 月次 - Mobile, IBM, Weyer, Citicorp, Market (NY+アメリカン全上場株式の時価加重), 30日T-Bill(無リスク金利) - 注) 1999年, ExxonとMobile合併 --&gt; Exxon Mobile (XOM) ifl &lt;- file.path(dir_PPC, &quot;P.dat&quot;) capm &lt;- read.table(ifl, header = TRUE) capm.ts &lt;- ts(capm, start = c(1978, 1), frequency = 12) colnames(capm) #&gt; [1] &quot;MOBIL&quot; &quot;IBM&quot; &quot;WEYER&quot; &quot;CITCRP&quot; &quot;MARKET&quot; &quot;RKFREE&quot; par(cex = 0.5) require(zoo) plot(as.zoo(capm.ts), main = &quot;&quot;, xlab = &quot;&quot;, cex.lab = 0.7, oma = c(2, 0, 1, 0), mar = c(0, 4.1, 0, 1.1)) 回帰に先立ち, あらかじめ月次リターン系列から無リスク金利を控除し IBM, Market, それぞれの超過リターンを計算しておく. # 以下, 1変量 (IBM) に絞って実行 IBM &lt;- capm.ts[, &quot;IBM&quot;] - capm.ts[, &quot;RKFREE&quot;] x &lt;- capm.ts[, &quot;MARKET&quot;] - capm.ts[, &quot;RKFREE&quot;] outLM &lt;- lm(IBM ~ x) outLM$coef #&gt; (Intercept) x #&gt; -0.0004895937 0.4568207721 summary(outLM) #&gt; #&gt; Call: #&gt; lm(formula = IBM ~ x) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -0.11850 -0.03327 -0.00263 0.03332 0.15042 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) -0.0004896 0.0046400 -0.106 0.916 #&gt; x 0.4568208 0.0675477 6.763 5.49e-10 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.05055 on 118 degrees of freedom #&gt; Multiple R-squared: 0.2793, Adjusted R-squared: 0.2732 #&gt; F-statistic: 45.74 on 1 and 118 DF, p-value: 5.489e-10 acf(outLM$res) qqnorm(outLM$res) # 以下, 追加 summary(outLM)$sigma^2 #&gt; [1] 0.002555574 # --&gt; 0.002555574 # --&gt; 教科書では, dV=0.00254と設定 静的CAPM 通常の線形回帰モデル \\[ Y_t = \\alpha + \\beta x_t + v_t, \\quad v_t \\sim_{i.i.d.} N(0,\\sigma^2), \\\\ \\] は,上記回帰モデルのDLM表現(\\(\\ref{eq:Y}\\),\\(\\ref{eq:mu}\\))において, 回帰係数が時間不変の特殊な場合に位置付けられるすなわち, \\(F_t = [1 \\ x_t]\\) \\(\\theta_t = [\\alpha \\ \\beta]&#39;\\) \\(V = \\sigma^2\\), \\(W_t = {\\bf 0}_{2 \\times 2}\\) さらに, Bayes推論を行うための事前分布 (平均\\(m_0\\), 分散共分散行列\\(C_0\\)) を与える. \\([\\alpha \\ \\beta] \\sim N(m_0, C_0)\\) パッケージdlmでは, dlmModReg()を使用して, モデルを特定化する. \\(V,W\\)は, 引数dV, dWとして与える. 以下のコードでは, dW=0 (デフォルト. \\(diag(W)=(0,0)\\)に対応), dV=0.00254とおいている. 一方, 状態変数\\([\\alpha \\ \\beta]\\)の事前平均および事前分散共分散行列は m0=c(0,1.5), C0=diag(c(1e+0.7, 1))と設定している. これは, \\(\\alpha\\)には”vague prior”, \\(\\beta\\)にはN(1.5,1)を指定していることを表す (1.5→“aggressive investment”, 1→“fairly small variance”). mod &lt;- dlmModReg(x, dV = 0.00254, m0 = c(0, 1.5), C0 = diag(c(1e+07, 1))) # Kalmanフィルター適用 outF &lt;- dlmFilter(IBM, mod) # 状態変数 (theta) のフィルター値 outF$m[1 + length(IBM), ] #&gt; [1] -0.0005232801 0.4615301204 動的CAPM 次に, 回帰係数が動的に変化する回帰モデルを扱う. 回帰係数がランダムウォークするモデル \\[ \\begin{align} Y_t &amp;= \\alpha_t + \\beta_t x_t + v_t, \\quad v_t \\sim_{i.i.d.} N(0,\\sigma^2), \\\\ \\alpha_{t} &amp;= \\alpha_{t-1} + w_{1,t}, \\quad w_{1,t} \\sim_{i.i.d.} N(0,\\sigma_{w_1}^2), \\\\ \\beta_{t} &amp;= \\beta_{t-1} + w_{2,t}, \\quad w_{2,t} \\sim_{i.i.d.} N(0,\\sigma_{w_2}^2), \\\\ \\end{align} \\] ここでは, 状態変数\\(\\theta_t = (\\alpha_t, \\beta_t)\\)がそれぞれランダムウォークし 動的に変化している. 最尤推定 (MLE) により, 観測方程式&amp;状態方程式の分散 (V,W) を推定する. それに先立ち, dlmMLE()に渡す関数を定義する (引数uは推定対象パラメータを格納する数値ベクトル–ここでは3次元. uを渡すとDLM (dlmクラスオブジェクト) を返す). buildCapm &lt;- function(u) { dlmModReg(x, dV = exp(u[1]), dW = exp(u[2:3])) } # 注) dV, dWは分散なので非負 # dlmMLE(): # 状態空間モデルの特定化における未知パラメータのMLEを返す関数 # (内部で最適化計算を行うoptim()を呼び出して計算) # parm: 初期パラメータ outMLE &lt;- dlmMLE(IBM, parm = rep(0, 3), build = buildCapm) # V,WのMLE exp(outMLE$par) #&gt; [1] 2.328401e-03 1.100131e-05 6.496219e-04 # 最適化計算に呼び出されたoptim()の戻り値 # outMLE$value # MLEを使ってDLMを定義 (特定化) mod &lt;- buildCapm(outMLE$par) スムージング # 状態変数のスムージング推定値 (平滑化推定値) outS &lt;- dlmSmooth(IBM, mod) # require(zoo) # alpha, betaのスムージング推定値のプロット plot(as.zoo(dropFirst(outS$s)), main = &quot;&quot;, mar = c(0, 2.1, 0, 1.1), oma = c(2.1, 0, .1, .1), cex.axis = 0.5) 12.4 SUR (Seemingly Unrelated Regression) モデル (3.3.3) 多変量動的回帰モデルの例を取り上げる. 上記, 米国株式4銘柄 (Mobile, IBM, Weyer, Citicorp) の動的CAPM (\\(\\beta\\)) の同時推定を行う. 説明変数\\(x_t\\)は, 一変量の時と同じく, Marketの超過リターンである. \\[ \\begin{align} Y_{i,t} &amp;= \\alpha_{i,t} + \\beta_{i,t} x_t + v_{i,t}, \\\\ \\alpha_{i,t} &amp;= \\alpha_{i,t-1} + w_{1i,t}, \\\\ \\beta_{i,t} &amp;= \\beta_{i,t-1} + w_{2i,t}, \\\\ \\end{align} \\] 切片項や傾きは\\(m(=4)\\)個の株式間で互いに相関があると仮定する (–&gt; SUR, Seemingly Unrelated Regression). このモデルは, 以下のように表記できる. \\[ \\begin{align} Y_{t} &amp;= (F_t \\otimes I_m) \\theta_t + v_{t}, \\quad v_t \\sim_{i.i.d.}N(0,V)\\\\ \\theta_{t} &amp;= (G \\otimes I_m) \\theta_{t-1} + w_{t}, \\quad w_t \\sim_{i.i.d.}N(0,W)\\\\ \\end{align} \\] 但し, \\[ Y_t = \\left[\\begin{smallmatrix} Y_{1,t} \\\\ \\vdots \\\\ Y_{m,t} \\end{smallmatrix}\\right],\\ \\theta_t = \\left[\\begin{smallmatrix} \\alpha_{1,t} \\\\ \\vdots \\\\ \\alpha_{m,t}\\\\ \\beta_{1,t} \\\\ \\vdots \\\\ \\beta_{m,t}\\\\ \\end{smallmatrix}\\right], \\ v_t = \\left[\\begin{smallmatrix} v_{1,t} \\\\ \\vdots \\\\ v_{m,t}\\\\ \\end{smallmatrix}\\right], \\ w_t = \\left[\\begin{smallmatrix} w_{1,t} \\\\ \\vdots \\\\ w_{2m,t}\\\\ \\end{smallmatrix}\\right], \\ \\] \\(F_t = [1 \\ x_t]\\), \\(G={\\bf I}_{2 \\times 2}\\), \\[ W=\\left[\\begin{smallmatrix} W_{\\alpha} &amp; 0\\\\ 0 &amp; W_{\\beta}\\\\ \\end{smallmatrix}\\right] \\] である. なお, 上述の銘柄間の相関性は, \\(V,W\\)を非対角行列に取ることで表現される. 動的CAPM 目的変数として個別4銘柄と, 説明変数としてMarketの, 各々の超過リターンを計算する. ifl &lt;- file.path(dir_PPC, &quot;P.dat&quot;) tmp &lt;- ts(read.table(ifl, header = TRUE), start = c(1978, 1), frequency = 12) * 100 y &lt;- tmp[, 1:4] - tmp[, &quot;RKFREE&quot;] colnames(y) &lt;- colnames(tmp)[1:4] market &lt;- tmp[, &quot;MARKET&quot;] - tmp[, &quot;RKFREE&quot;] rm(&quot;tmp&quot;) # m &lt;- NCOL(y) m &lt;- ncol(y) まず, 上記SURモデルのDLM表現をdlmModReg()を用いて行う. PPCでは, 簡単のため, \\(\\alpha\\)は定数 (時間固定) (–&gt; 対応する\\(W_{\\alpha}=0\\)) データより別途計算しておいた\\(W_{\\beta},V\\)の推定値を使用 # Marketを使って初期設定 CAPM &lt;- dlmModReg(market) # 4変量の特定化のために手入力 CAPM$FF &lt;- CAPM$FF %x% diag(m) # ブロック対角行列 # 注) %x%: クロネッカー積 CAPM$GG &lt;- CAPM$GG %x% diag(m) CAPM$JFF &lt;- CAPM$JFF %x% diag(m) # PPCでは, データより別途計算しておいたW,Vの推定値を使用 CAPM$W &lt;- CAPM$W %x% matrix(0, m, m) CAPM$W[-(1:m), -(1:m)] &lt;- c(8.153e-07, -3.172e-05, -4.267e-05, -6.649e-05, -3.172e-05, 0.001377, 0.001852, 0.002884, -4.267e-05, 0.001852, 0.002498, 0.003884, -6.649e-05, 0.002884, 0.003884, 0.006057) CAPM$V &lt;- CAPM$V %x% matrix(0, m, m) CAPM$V[] &lt;- c(41.06, 0.01571, -0.9504, -2.328, 0.01571, 24.23, 5.783, 3.376, -0.9504, 5.783, 39.2, 8.145, -2.328, 3.376, 8.145, 39.29) CAPM$m0 &lt;- rep(0, 2 * m) CAPM$C0 &lt;- diag(1e7, nr = 2 * m) スムージング ## Smooth # Kalmanスムージング実行 CAPMsmooth &lt;- dlmSmooth(y, CAPM) ## plots # 4銘柄のbetaのスムージング推定値のplot par(mar = c(3, 4, 1, 2) + 0.1, cex = 0.7) plot(dropFirst(CAPMsmooth$s[, m + 1:m]), lty = c(&quot;13&quot;, &quot;6413&quot;, &quot;431313&quot;, &quot;B4&quot;), plot.type = &quot;s&quot;, xlab = &quot;&quot;, ylab = &quot;Beta&quot;) abline(h = 1, col = &quot;darkgrey&quot;) legend(&quot;bottomright&quot;, legend = colnames(y), bty = &quot;n&quot;, lty = c(&quot;13&quot;, &quot;6413&quot;, &quot;431313&quot;, &quot;B4&quot;), inset = 0.05) 参考文献 Giovanni Petris (2010). An R Package for Dynamic Linear Models. Journal of Statistical Software, 36(12), 1-16. http://www.jstatsoft.org/v36/i12/. "],["高頻度データ分析.html", "13 高頻度データ分析 13.1 ボラティリティ推定 13.2 共分散・相関の推定 13.3 ACDモデル", " 13 高頻度データ分析 1日内の取引の記録を収録したデータである 「高頻度データ」を分析するためには, それに先立つ適切な前処理の実施や そのためのコーディングなど, 分析に要する工数が 通常の日次以上のサンプリング頻度 and/or 等間隔データに 比べて多い. 特に, タイムスタンプ非同期性等に対する対応をする場合には, 前処理が面倒となる. 高頻度データは, zoo and/or xtsパッケージを使って, 時系列データをzooやxtsクラスのオブジェクトに変換して分析する. なお, データ処理段階でミリ秒以上の精度が必要の場合, xtsの他, パッケージdata.table, , nanotimeを使う等の方法あり. 高頻度データ分析の領域で最も研究が進んでいる領域が 実現ボラティリティ (realized volatility, RV) 研究である. 本章は, 主にこのRVを使ったボラティリティ推定の方法, それを多変量に拡張した共分散・相関係数の推定方法について 取り上げる. 高頻度の価格時系列データの実証的特徴 高頻度の価格時系列データは, 日次以上の時系列データの 実証的特徴 (stylized facts) に加えて, 通常, 以下のような特徴を持つことが知られている: ティック単位での動きが観察される 値段が動かない時間も散発的に発生 (たまに起きる) ジャンプ (ティックデータの場合) 1変量は非等間隔観察. 2変量間では非同期観察 これらは, 連続時間に連続的に変化する拡散型確率過程 (連続Itoセミマルチンゲール過程) に従う (対数) 価格過程の 離散時点における実現値とみる立場から乖離する特徴であり, 拡散型確率過程の離散観測としてデータセットを扱って 計算するRVの推定精度を悪化させる要因となる. そこで, これらの要因に対処するための処理が必要となってくる: “マーケット・マイクロストラクチャ・ノイズ”への対応 ジャンプへの対応 13.1 ボラティリティ推定 一日内の取引データ (高頻度データ) を使って, 日次ボラティリティを推定したい. データセット1: TOPIX指数データ 1日分 (2018年2月5日), 1秒間隔の東証株価指数 (TOPIX) データ データセット1: TOPIX指数データ - 2018年2月5日前場・後場. 1秒間隔 - 各8998件 (共通) - 9:00:05 -- 11:30:02, 12:30:05--15:00:02 . library(zoo) idir &lt;- file.path(&quot;./&quot;) # TOPIX指数 ifl1 &lt;- file.path(idir, &quot;topix1s_20180205_1.csv&quot;) topix1s_1 &lt;- read.csv(ifl1) ifl2 &lt;- file.path(idir, &quot;topix1s_20180205_2.csv&quot;) topix1s_2 &lt;- read.csv(ifl2) # zooクラスに変換 # 注) 日付情報を加えない topix_1_zoo &lt;- zoo(topix1s_1$price, topix1s_1$sec) topix_2_zoo &lt;- zoo(topix1s_2$price, topix1s_2$sec) par(mfrow=c(1,2)) plot(topix_1_zoo, xlab = &quot;sec&quot;, ylab = &quot;TOPIX&quot;) plot(topix_2_zoo, xlab = &quot;sec&quot;, ylab = &quot;TOPIX&quot;) 株価指数そのものは取引されていないが, 現実に取引されている証券の高頻度データを使ってボラティリティを推定する場合には, マイクロストラクチャノイズに対する対応が必要となる. 簡便法としては, 実現ボラティリティの代わりに始値と終値のみや, 四本値のみを使う推定法 (例, Parkinsonボラティリティ) を用いる, 実現ボラティリティの計算に 用いる取引データの間隔を間引き (5分間隔程度) するやり方がある. さらには, 実現ボラティリティを改良し, マイクロストラクチャノイズに対応したより”精緻な”推定法が 数多く提案されている. これらは, パッケージyuimaの中で 関数cce()として実装されている (以下の「共分散・相関の推定」パート参照). 実現ボラティリティの計算 真の価格系列が連続時間の拡散過程 (伊藤過程) に従っていて それが離散時間で観測されていると仮定. 価格系列を使用した自作関数の例. # 実現ボラティリティの計算 # 分散ではなく標準偏差表示. 年率換算せず # 全ティック (prcvec全体を使用, 間引きせず) # prcvec: (対数を取る前の) 価格系列 calc_RV &lt;- function(prcvec, dgts = 6){ prcvec2 &lt;- na.omit(prcvec) if(length(prcvec2) == 0 || any(prcvec &lt;= 0)) return(NA) # -Infを回避 rv &lt;- sum(diff(log(prcvec2))^2) ** 0.5 return(round(rv, dgts)) } calc_RV(topix_1_zoo) #&gt; [1] 0.004188 calc_RV(topix_2_zoo) #&gt; [1] 0.002204 # 以下も結果は同一 # calc_RV(topix1s_1$price) # calc_RV(topix1s_2$price) Parkinsonボラティリティの計算 # Parkionsonボラティリティの計算 # 分散ではなく標準偏差表示. 年率換算せず calc_vParkinson &lt;- function(prcvec, freq = 1){ prcvec2 &lt;- na.omit(prcvec) if(length(prcvec2) == 0) return(NA) # -Infを回避 LH &lt;- range(prcvec2) if (LH[1] * LH[2] &lt;= 0) return(F) vola &lt;- abs(log(LH[2] / LH[1])) / sqrt(4 * freq * log(2)) return(vola) } calc_vParkinson(topix_1_zoo) #&gt; [1] 0.006450344 calc_vParkinson(topix_2_zoo) #&gt; [1] 0.002763914 # 以下も結果は同一 # calc_vParkinson(topix1s_1$price) # calc_vParkinson(topix1s_2$price) calc_RV()は全データセット (価格, あるいは対数収益率) を 使用してRVを計算する仕様となっている. もし, RVを5分間隔データに基づいて計算する場合には, あらかじめ, 5分間隔にサブサンプル (“間引き”) しておく必要がある. ここでは, タイムスタンプに日付情報を追加しておくやり方を示す. # 等間隔に&quot;間引き&quot; library(lubridate) # ymd_hms library(xts) # last ymdhms_vec &lt;- ymd_hms(paste(&quot;2018-02-05&quot;, hms::as_hms(index(topix_1_zoo)))) topix_1_zoo2 &lt;- zoo(topix_1_zoo, order.by = ymdhms_vec) ymdhms_vec &lt;- ymd_hms(paste(&quot;2018-02-05&quot;, hms::as_hms(index(topix_2_zoo)))) topix_2_zoo2 &lt;- zoo(topix_2_zoo, order.by = ymdhms_vec) # aggregate()を使うやり方 # グリッド点は, データの開始時点から5分間隔に (秒以下は丸めて) 取る reg_grid &lt;- function(x_zoo, interval = &quot;5 min&quot;){ aggregate(x = x_zoo, by = function(tt) as.POSIXct(cut(tt, interval)), FUN = last # mean # tail, 1 ) } topix_5m_zoo2 &lt;- reg_grid(topix_1_zoo2, &quot;5 min&quot;) topix_3m_zoo2 &lt;- reg_grid(topix_1_zoo2, &quot;3 min&quot;) topix_1m_zoo2 &lt;- reg_grid(topix_1_zoo2, &quot;1 min&quot;) それぞれ, 5分, 3分, 1分間隔RVの計算: calc_RV(topix_5m_zoo2) # ** 2 #&gt; [1] 0.005457 calc_RV(topix_3m_zoo2) # ** 2 #&gt; [1] 0.006226 calc_RV(topix_1m_zoo2) # ** 2 #&gt; [1] 0.005988 次に, パッケージhighfrequencyを利用して, RVを計算する. rRVar: 実現分散の計算 - Usage: rRVar(rData, alignBy = NULL, alignPeriod = NULL, makeReturns = FALSE, ...) - rData: xts or data.tableオブジェクト. 収益率 or 価格. 複数資産・複数日OK - alignBy: alignPeriodの表示の時間スケール: &quot;ticks&quot;, &quot;secs&quot;, &quot;seconds&quot;, &quot;mins&quot;, &quot;minutes&quot;, &quot;hours&quot; - alignPeriod: 時間集約 (合算) する区間数 - makeReturns: rDataが価格の場合はTRUEに設定 (デフォルトはF) 上でみたように, topix_1_zoo, topix_2_zooは1秒間隔で収録されている. 上でzooクラスに変換した際に, 日付情報を付与しなかった. 一方, 取引日のタイムスタンプはintegerで保持していた (深夜0時を起点として各時刻を秒表示). パッケージhighfrequencyを使用するにあたり, 時系列データをxtsクラス・オブジェクトに変換しておく. library(xts) # library(lubridate) # ymd_hms ymdhms_vec &lt;- ymd_hms(paste(&quot;2018-02-05&quot;, hms::as_hms(index(topix_1_zoo)))) topix_1_xts &lt;- xts(topix_1_zoo, order.by = ymdhms_vec) ymdhms_vec &lt;- ymd_hms(paste(&quot;2018-02-05&quot;, hms::as_hms(index(topix_2_zoo)))) topix_2_xts &lt;- xts(topix_2_zoo, order.by = ymdhms_vec) plot(topix_1_xts) plot(topix_2_xts) library(highfrequency) # 価格系列を使用 --&gt; makeReturns=Tを選択する必要 # 5分間隔 (300s) RV rRVar(topix_1_xts, alignBy = &quot;secs&quot;, alignPeriod = 300, makeReturns = T) #&gt; x #&gt; 3.024702e-05 rRVar(topix_2_xts, alignBy = &quot;secs&quot;, alignPeriod = 300, makeReturns = T) #&gt; x #&gt; 1.855628e-05 # 同一 # rRVar(topix_1_xts, alignBy = &quot;mins&quot;, alignPeriod = 5, makeReturns = T) # rRVar(topix_2_xts, alignBy = &quot;mins&quot;, alignPeriod = 5, makeReturns = T) # 1分間隔 (60s) RV rRVar(topix_1_xts, alignBy = &quot;secs&quot;, alignPeriod = 60, makeReturns = T) #&gt; x #&gt; 3.910369e-05 # rRVar(topix_2_xts, alignBy = &quot;secs&quot;, alignPeriod = 60, makeReturns = T) # 1秒間隔 (間引きなし) RV rRVar(topix_1_xts, makeReturns = T) #&gt; x #&gt; 1.753612e-05 # rRVar(topix_2_xts, makeReturns = T) なお, 価格系列の代わりに, 収益率系列を使用することも可能. この場合には, makeReturns=Fを選択する必要がある. HAR-RVモデルによる予測 HAR-RVモデルは, 日次RV時系列の示す長期記憶性をうまく近似し, ボラティリティ予測性能が高いとされるモデルである. パッケージhighfrequencyの関数HARmodel()により, HARモデルの推定, ボラティリティの予測が可能である. パラメータ指定により, HARモデルのバリエーションの指定や, 説明変数に使う日次・週次・月次の合算日数の変更, RV以外の有用な実現測度 (realized measures) の推定・予測も可能である. ジャンプ検定も可能である. HARmodel(): HARモデルの推定. 過去の高頻度データより1日先のボラティリティ予測 - usage: HARmodel( data, # xtsオブジェクト. 日内対数収益率, または計算済の実現測度 (realized measures) periods = c(1, 5, 22), # 実現測度の合算 (集約) 日数のベクトル (1 day, 1 week, 1 monthに対応) periodsJ = c(1, 5, 22), # ジャンプ項の合算日数のベクトル periodsQ = c(1), # 実現4乗量 (quarticity) の合算日数のベクトル leverage = NULL, # 負の収益率を合算する日数のベクトル RVest = c(&quot;rCov&quot;, &quot;rBPCov&quot;, &quot;rQuar&quot;), # 出力の種類: デフォルトは, 日次累積分散 (ジャンプ-robust), 実現bi-power変動, 実現4乗量. それ以外の指定はマニュアルを見よ. inputType = &quot;RM&quot;, # 入力dataの形式]: realized measure (デフォルト). それ以外は, 収益率 jumpTest = &quot;ABDJumptest&quot;, # ジャンプ検定 alpha = 0.05, # ジャンプ検定の有意水準 h = 1, # 従属変数を合算する日数 transform = NULL, # 従属変数や説明変数を(同時に)変換する関数. 典型例, &quot;log&quot;, &quot;sqrt&quot; externalRegressor = NULL, # 外部説明変数 periodsExternal = c(1), # 外部説明変数を合算する日数 ... 以下では, highfrequencyに収録されているデータセットSPYRMを使用する. これは, S&amp;P500 (SPY) ETFの各種の実現測度 (realized measures) が 1分および5分間隔データを使って計算された日次時系列データセットである # library(highfrequency) # library(xts) # Forecasting daily Realized volatility for the S&amp;P 500 using the basic HARmodel: HAR str(SPYRM) # S&amp;P500 (SPY) ETFの各種実現測度 (１分, 5分) #&gt; Classes &#39;data.table&#39; and &#39;data.frame&#39;: 1495 obs. of 14 variables: #&gt; $ DT : Date, format: &quot;2014-01-02&quot; &quot;2014-01-03&quot; ... #&gt; $ RV1 : num 2.68e-05 1.58e-05 2.72e-05 1.08e-05 3.11e-05 ... #&gt; $ RV5 : num 2.57e-05 1.78e-05 2.56e-05 9.95e-06 2.68e-05 ... #&gt; $ BPV1 : num 2.54e-05 1.55e-05 2.18e-05 1.00e-05 2.58e-05 ... #&gt; $ BPV5 : num 2.37e-05 1.67e-05 1.89e-05 9.75e-06 2.35e-05 ... #&gt; $ medRV1: num 2.45e-05 1.54e-05 2.24e-05 1.06e-05 2.64e-05 ... #&gt; $ medRV5: num 1.93e-05 1.63e-05 1.64e-05 9.32e-06 2.32e-05 ... #&gt; $ RK1 : num 2.59e-05 1.60e-05 3.20e-05 9.42e-06 1.98e-05 ... #&gt; $ RK5 : num 2.64e-05 1.63e-05 2.59e-05 9.96e-06 1.94e-05 ... #&gt; $ RQ1 : num 0.0534 0.0302 0.0621 0.0213 0.0889 ... #&gt; $ RQ5 : num 0.0543 0.0304 0.05 0.017 0.0538 ... #&gt; $ medRQ1: num 0.0473 0.0296 0.0419 0.0207 0.0823 ... #&gt; $ medRQ5: num 0.0473 0.0296 0.0419 0.0207 0.0823 ... #&gt; $ CLOSE : num 183 183 182 183 184 ... #&gt; - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; #&gt; - attr(*, &quot;sorted&quot;)= chr &quot;DT&quot; RVSPY &lt;- as.xts(SPYRM$RV5, order.by = SPYRM$DT) x &lt;- highfrequency::HARmodel(data = RVSPY, periods = c(1,5,22), RVest = c(&quot;rCov&quot;), type = &quot;HAR&quot;, h = 1, transform = NULL, inputType = &quot;RM&quot;) class(x) #&gt; [1] &quot;HARmodel&quot; &quot;lm&quot; plot(x) HARモデルの適合 (推定) と予測の例. # Estimate the HAR model of type HARQ dat &lt;- as.xts(sampleOneMinuteData[, makeReturns(STOCK), by = list(DATE = as.Date(DT))]) x &lt;- highfrequency::HARmodel(dat, periods = c(1,5,10), periodsJ = c(1,5,10), periodsQ = c(1), RVest = c(&quot;rCov&quot;, &quot;rQuar&quot;), type=&quot;HARQ&quot;, inputType = &quot;returns&quot;) class(x) #&gt; [1] &quot;HARmodel&quot; &quot;lm&quot; x #&gt; #&gt; Model: #&gt; RV1 = beta0 + beta1 * RV1 + beta2 * RV5 + beta3 * RV10 + beta4 * RQ1 #&gt; Coefficients: #&gt; beta0 beta1 beta2 beta3 beta4 #&gt; 7.046e-05 -1.545e-01 1.686e-01 3.025e-01 1.023e+03 #&gt; Newey-West Standard Errors: #&gt; beta0 beta1 beta2 beta3 beta4 #&gt; 1.471e-05 9.588e-02 1.061e-01 9.461e-02 2.886e+02 #&gt; r.squared adj.r.squared #&gt; 0.6944 0.5198 plot(x) predict(x) #&gt; [1] 0.0001071019 13.2 共分散・相関の推定 2つの証券の一日内の取引データを使って, 両者の共分散や相関係数を推定したい. しかし, 個別取引のデータは等間隔に並んでないことから, データが同時観測されていない (非同期) 点を考慮する必要がある. 上記, highfrequencyパッケージの他, yuimaパッケージも利用可能である. データセット2: 株価指数先物データ データセット2: 株価指数先物データ - データ日付: 2018年2月5日 - TOPIXおよび, 日経平均のそれぞれの株価指数先物データ (中心限月, ラージサイズ) - ティックデータ - 時間解像度: 1ミリ秒 同時点タイムスタンプを持つ複数レコードが存在するため, ここでは, 1タイムスタンプ1レコードに集約する (集約の際の価格は単純平均を使用). yyyymmdd &lt;- 20180205 ifl1_0 &lt;- paste0(&quot;TXFTL-&quot;, yyyymmdd, &quot;-D.csv&quot;) ifl1 &lt;- file.path(idir, ifl1_0) txftl &lt;- read.csv(ifl1, header = F) ifl2_0 &lt;- paste0(&quot;NKFTL-&quot;, yyyymmdd, &quot;-D.csv&quot;) ifl2 &lt;- file.path(idir, ifl2_0) nkftl &lt;- read.csv(ifl2, header = F) 共分散・相関の推定 highfrequencyのrCov()を利用して 実現共分散・実現相関を計算する. rCov()の使用に先立ち, 2銘柄のタイムスタンプの同期化が必要である. refreshTime(): 非同期時系列の, リフレッシュ・タイムによるタイムスタンプの同期化 - usage: refreshTime(pData, sort = FALSE, criterion = &quot;squared duration&quot;) - pData: xts or data.tableオブジェクト (1列はDT (datetime)). 1日のみ. 典型的には価格系列 - sort: criterionによりインデックスを降順にソート (デフォルトはF) - criterion: 使用する規準, &quot;squared duration&quot;(デフォルト), &quot;duration&quot; tx_zoo &lt;- zoo(txftl$V2, txftl$V1 / 1000) # Warning: uniqueでない nk_zoo &lt;- zoo(nkftl$V2, nkftl$V1 / 1000) # 時系列のxtsオブジェクト化 # library(lubridate) # ymd_hms ymdhms_vec &lt;- ymd_hms(paste(&quot;2018-02-05&quot;, hms::as_hms(index(tx_zoo)))) tx_xts &lt;- xts(tx_zoo, order.by = ymdhms_vec) ymdhms_vec &lt;- ymd_hms(paste(&quot;2018-02-05&quot;, hms::as_hms(index(nk_zoo)))) nk_xts &lt;- xts(nk_zoo, order.by = ymdhms_vec) # refresh timeによる同期化 tx_nk_sync &lt;- refreshTime(list(tx_xts, nk_xts)) # rRVar(tx_nk_sync) # 各RVの計算 rCov(): 実現共分散・実現相関の計算 - rData: xts or data.tableオブジェクト. 収益率 or 価格. 複数資産・複数日OK - cor: 相関はT, 共分散はF (デフォルト) - alignBy: alignPeriodの表示の時間スケール: &quot;ticks&quot;, &quot;secs&quot;, &quot;seconds&quot;, &quot;mins&quot;, &quot;minutes&quot;, &quot;hours&quot; - alignPeriod: 時間集約 (合算) する区間数 - makeReturns: rDataが価格の場合はTRUEに設定 (デフォルトはF) # 5分間隔 # rCov(tx_nk_sync, cor = T, alignBy = &quot;secs&quot;, alignPeriod = 300, # makeReturns = T) # 相関 rCov(tx_nk_sync, cor = T, alignBy = &quot;minutes&quot;, alignPeriod = 5, makeReturns = T) # 相関 #&gt; [,1] [,2] #&gt; [1,] 1.0000000 0.9020108 #&gt; [2,] 0.9020108 1.0000000 # 1分間隔 # rCov(tx_nk_sync, cor = T, alignBy = &quot;secs&quot;, alignPeriod = 60, # makeReturns = T) # 相関 rCov(tx_nk_sync, cor = T, alignBy = &quot;minutes&quot;, alignPeriod = 1, makeReturns = T) # 相関 #&gt; [,1] [,2] #&gt; [1,] 1.0000000 0.8546437 #&gt; [2,] 0.8546437 1.0000000 # 全ティック使用 # rCov(tx_nk_sync, makeReturns = T) # 共分散 rCov(tx_nk_sync, cor = T, makeReturns = T) # 相関 #&gt; [,1] [,2] #&gt; [1,] 1.0000000 0.2355344 #&gt; [2,] 0.2355344 1.0000000 # --&gt; Epps効果 全般に, 5分間隔, 1分間隔, 全ティック使用と高頻度になるにつれて 相関係数の値が小さくなっていく傾向が観察される (Epps効果). マイクロストラクチャ・ノイズを除去するための様々な 推定法が提案されている. いくつかを取り上げて計算してみる. rMRCov: Modulated realized covariance (Hautsch and Podolskij(2013) - プレ・アベレージ (pre-averaging) を用いる推定法 - pairwise: refresh timesが資産ペアに基づいている場合はT. デフォルトはF - makePsd: 正定値バージョンはT. デフォルトはF - theta: preaveragingの区間幅. デフォルトは0.8 - crossAssetNoiseCorrection: 非対角成分 (共分散) のバイアス修正するか. デフォルトはF 注) 間引きせず全データ使用 (preaveraing) rMRCov(tx_nk_sync) #&gt; [1] 0.0001769088 rTSCov: Two time scale covariance estimation (ZMA(05), Zhang(10)) 注) 間引きせず全データ使用 (preaveraing) - K = 300 - J = 1 - makePsd: 正定値バージョンはT. デフォルトはF rTSCov(list(tx_nk_sync[, 1], tx_nk_sync[, 2]), cor = T) #&gt; [,1] [,2] #&gt; [1,] 1.0000000 0.9878281 #&gt; [2,] 0.9878281 1.0000000 # topix2_xts &lt;- merge(topix_1_xts, topix_2_xts, all = T) Hayashi-Yoshida共分散推定量 タイムスタンプの同期化が不要な推定法. highfrequencyの関数rHYCov()を使用する. highfrequency::rHYCov(): Hayashi-Yoshida共分散推定量の計算 - 用法: rHYCov( rData, cor = FALSE, period = 1, alignBy = &quot;seconds&quot;, alignPeriod = 1, makeReturns = FALSE, makePsd = TRUE, ... ) - rData: (複数日・複数銘柄の) 収益率または価格系列 (xts, またはdata.frame) - cor: 返す値は, 相関か共分散か - period: サンプル期間 - alignBy: alignPeriodの時間スケール. &quot;ticks&quot;, &quot;secs&quot;, &quot;seconds&quot;, &quot;mins&quot;, &quot;minutes&quot;, &quot;hours&quot; - alignPeriod: 合算する期間長. 例えば, alighnPeriod = 5, alighBy = &quot;mins&quot;なら５分間隔に集約 - makeReturns: 収益率に変換するか. rDataが価格系列ならTを指定のこと. デフォルトはF - makePsd: Tならば, 正定値行列に修正. デフォルトはF rHYCov()を実行する場合には, あらかじめ異なるタイムスタンプを持つ非同期のxtsオブジェクトを一つ (共通のタイムスタンプを持つ) オブジェクトにマージしておく必要. 関数xts()には日付/時間のクラス (POSIXct等) に変換しておいたタイムスタンプをorder.byで指定する必要. 非同期な状態のまま2つの時系列はマージされるため, 各タイムスタンプにおいて, 一方の資産の価格にNAが入る可能性がある. 価格系列ではなく, 収益率系列を使用する場合. 同時点タイムスタンプの複数レコードを1レコードに集約する 必要がある. ここでは, 平均値を使用し, 1タイムスタンプ1レコード化する. # 収益率系列を使用する場合 # 前処理: 同時点タイムスタンプの複数レコードを # 1レコードに集約. 価格は平均値使用 # 1タイムスタンプ1レコード化 topixFTL &lt;- aggregate(tx_zoo, index(tx_zoo), mean) # unique timestamp nk225FTL &lt;- aggregate(nk_zoo, index(nk_zoo), mean) # unique timestamp par(mfrow=c(2, 1)) plot(topixFTL) plot(nk225FTL) # 対数収益率化 topixFTL_ret &lt;- diff(log(topixFTL)) nk225FTL_ret &lt;- diff(log(nk225FTL)) # 関数に入力する系列が, 価格か対数収益率かに注意すること # マージ ftl2_zoo &lt;- merge(topixFTL_ret, nk225FTL_ret, all = T) # xts化 # library(lubridate) # ymd_hms ymdhms_vec &lt;- ymd_hms(paste(&quot;2018-02-05&quot;, hms::as_hms(index(ftl2_zoo)))) ftl2_xts &lt;- xts(ftl2_zoo, order.by = ymdhms_vec) # HY推定量の計算 rHYCov(ftl2_xts, cor = T, period = 5, alignBy = &quot;minutes&quot;, alignPeriod = 5, makeReturns = F) #&gt; [,1] [,2] #&gt; [1,] 1.000000 0.160519 #&gt; [2,] 0.160519 1.000000 highfrequencyのrCov()やrHYCov()の代替的関数としてyuima のcce()を使うこともできる. cce()は, 高頻度データより累積共分散・相関を推定するための万能な関数であり, 1変量, 2変量の両方に対応 (1変量 → 累積分散推定) 主要な推定量を広くカバー 非同期データにも対応. refresh timeを使う同期化もサポート yuima::cce: (非同期なタイムスタンプを持つ) 伊藤過程間の共分散を推定 - 用法: cce(x, method=&quot;HY&quot;, theta, kn, g=function(x)min(x,1-x), refreshing = TRUE, cwise = TRUE, delta = 0, adj = TRUE, K, c.two, J = 1, c.multi, kernel, H, c.RK, eta = 3/5, m = 2, ftregion = 0, vol.init = NA, covol.init = NA, nvar.init = NA, ncov.init = NA, mn, alpha = 0.4, frequency = 300, avg = TRUE, threshold, utime, psd = FALSE) - 詳細はマニュアル参照のこと - 一変量の時系列データを引数xに指定すれば, ボラティリティを推定することができる. # cf. https://cran.r-project.org/web/packages/yuima/yuima.pdf # yuima class data library(yuima) ft2 &lt;- Quote(yuima::setData(list(topixFTL_ret, nk225FTL_ret))) 注) 執筆時点でのsetData()の仕様に基づいたコード (変更される可能性) # Hayashi-Yoshida estimator; Hayashi and Yoshida (2005) yuima::cce(eval(ft2)) # the Hayashi-Yoshida estimator; Hayashi and Yoshida (2005) #&gt; $covmat #&gt; [,1] [,2] #&gt; [1,] 5.141391e-04 2.891806e-05 #&gt; [2,] 2.891806e-05 8.303162e-04 #&gt; #&gt; $cormat #&gt; [,1] [,2] #&gt; [1,] 1.00000000 0.04425956 #&gt; [2,] 0.04425956 1.00000000 Hayashi-Yoshida推定量は, マイクロストラクチャ・ノイズに対応しないことから, 代替的な累積共分散推定法が提案されている. cce()は主要な推定法を カバーしている. 注) yuimaの仕様変更により, cce()の引数の与え方や結果の取り出し方が 変わっている可能性がある. # the Pre-averaged Hayashi-Yoshida estimator; Christensen et al. (2010) yuima::cce(eval(ft2), method = &quot;PHY&quot;) # #&gt; $covmat #&gt; [,1] [,2] #&gt; [1,] 1.594766e-08 3.374205e-07 #&gt; [2,] 3.374205e-07 -8.806117e-09 #&gt; #&gt; $cormat #&gt; [,1] [,2] #&gt; [1,] 1 NaN #&gt; [2,] NaN 1 yuima::cce(eval(ft2), method = &quot;PHY&quot;, psd = T) #&gt; $covmat #&gt; [,1] [,2] #&gt; [1,] 3.377783e-07 3.568370e-09 #&gt; [2,] 3.568370e-09 3.375165e-07 #&gt; #&gt; $cormat #&gt; [,1] [,2] #&gt; [1,] 1.00000000 0.01056833 #&gt; [2,] 0.01056833 1.00000000 # the Pre-averaged Truncated Hayashi-Yoshida estimator yuima::cce(eval(ft2), method = &quot;PTHY&quot;) #&gt; $covmat #&gt; [,1] [,2] #&gt; [1,] 1.747555e-08 3.358151e-07 #&gt; [2,] 3.358151e-07 4.373767e-08 #&gt; #&gt; $cormat #&gt; [,1] [,2] #&gt; [1,] 1.00000 12.14666 #&gt; [2,] 12.14666 1.00000 # the Modulated Realized Covariance based on refresh time sampling; Christensen et al. (2010) yuima::cce(eval(ft2), method = &quot;MRC&quot;) #&gt; $covmat #&gt; [,1] [,2] #&gt; [1,] -1.332644e-07 8.895279e-08 #&gt; [2,] 8.895279e-08 -3.428603e-07 #&gt; #&gt; $cormat #&gt; [,1] [,2] #&gt; [1,] 1 NaN #&gt; [2,] NaN 1 yuima::cce(eval(ft2), method = &quot;MRC&quot;, psd = T) #&gt; $covmat #&gt; [,1] [,2] #&gt; [1,] 1.332644e-07 -8.895279e-08 #&gt; [2,] -8.895279e-08 3.428603e-07 #&gt; #&gt; $cormat #&gt; [,1] [,2] #&gt; [1,] 1.0000000 -0.4161442 #&gt; [2,] -0.4161442 1.0000000 # the nonparametric Quasi Maximum Likelihood Estimator; Ait-Sahalia et al. (2010) yuima::cce(eval(ft2), method = &quot;QMLE&quot;) #&gt; $covmat #&gt; [,1] [,2] #&gt; [1,] 1.413960e-09 3.728559e-10 #&gt; [2,] 3.728559e-10 1.153782e-10 #&gt; #&gt; $cormat #&gt; [,1] [,2] #&gt; [1,] 1.0000000 0.9231251 #&gt; [2,] 0.9231251 1.0000000 # the Separating Information Maximum Likelihood estimator in Kunitomo and Sato (2013), with the basis of refresh time sampling yuima::cce(eval(ft2), method = &quot;SIML&quot;) #&gt; $covmat #&gt; [,1] [,2] #&gt; [1,] 9.378068e-09 6.055064e-09 #&gt; [2,] 6.055064e-09 1.130735e-08 #&gt; #&gt; $cormat #&gt; [,1] [,2] #&gt; [1,] 1.0000000 0.5880057 #&gt; [2,] 0.5880057 1.0000000 # the Truncated Hayashi-Yoshida estimator; Mancini and Gobbi (2012) yuima::cce(eval(ft2), method = &quot;THY&quot;) #&gt; $covmat #&gt; [,1] [,2] #&gt; [1,] 5.141391e-04 2.891806e-05 #&gt; [2,] 2.891806e-05 8.303162e-04 #&gt; #&gt; $cormat #&gt; [,1] [,2] #&gt; [1,] 1.00000000 0.04425956 #&gt; [2,] 0.04425956 1.00000000 # 注) 仕様変更により以下は修正必要 # Generalized multiscale estimator # yuima::cce(eval(ft2), method = &quot;GME&quot;) # Multivariate realized kernel # yuima::cce(eval(ft2), method = &quot;RK&quot;) # An implementation of the previous tick Two Scales realized CoVariance based on refresh time sampling; Zhang (2011) # yuima::cce(eval(ft2), method = &quot;TSCV&quot;) # An implementation of the calendar time Subsampled realized BiPower Covariation # yuima::cce(eval(ft2), method = &quot;SBPC&quot;) 13.3 ACDモデル ランダムに到着する取引の間隔データの持つ時系列構造を表現するモデルとして, 自己回帰条件付デュレーション (ACD) モデルを取り上げる. ここでは, 上で使用した株価指数先物データセット (topixFTL, nk225FTL) を使用する. デュレーション (取引間隔) 系列: library(tidyverse) library(lubridate) library(stringr) options(digits = 3) # デュレーション (取引間隔) dur_tx &lt;- diff(index(topixFTL)) dur_nk &lt;- diff(index(nk225FTL)) head(dur_tx) #&gt; [1] 0.030 0.336 0.001 0.002 0.001 0.003 head(dur_nk) #&gt; [1] 0.030 0.001 0.001 0.092 0.062 0.019 length(dur_tx) #&gt; [1] 10899 length(dur_nk) #&gt; [1] 7501 plot(dur_tx[1:300], type = &quot;l&quot;, main = &quot;duration (first 300)&quot;) ランダムに到着する取引の間隔データにおいても, クラスタリング現象が観察される. これを表現するためのモデルが自己回帰条件付デュレーション (ACD) モデルである. ACDモデルやそのバリエーションは, 取引が活発 (取引間隔が短く) なると, さらにそれがあらたな取引を呼び込むといった, 自己励起 (self-excitment) の現象を表現することができる. モデルの適合: acdFit: ACDモデルの適合 - 用法: acdFit(durations = NULL, model = &quot;ACD&quot;, dist = &quot;exponential&quot;, order = NULL, startPara = NULL, dailyRestart = 0, optimFnc = &quot;optim&quot;, method = &quot;Nelder-Mead&quot;, output = TRUE, bootstrapErrors = FALSE, forceErrExpec = TRUE, fixedParamPos = NULL, bp = NULL, exogenousVariables = NULL, control = list()) - model: 条件付平均の特定. &quot;ACD&quot;, &quot;LACD1&quot;, &quot;LACD2&quot;, &quot;AMACD&quot;, &quot;BACD&quot;, &quot;ABACD&quot;, &quot;SNIACD&quot;, &quot;LSNIACD&quot;の中から一つ選択. - dist: 誤差項の確率分布. &quot;exponential&quot;, &quot;weibull&quot;, &quot;burr&quot;, &quot;gengamma&quot;, &quot;genf&quot;, &quot;qweibull&quot;, &quot;mixqwe&quot;, &quot;mixqww&quot;, &quot;mixinvgauss&quot;の中から一つ選択. - order: ACDモデルの次数. 例えば, ACD(p, q)ならば, order = c(p, q)を指定. 以下では, 誤差項の確率分布として指数分布を, モデルとしてACD(1,1), LACD1(1,1), LACD2(1,1)の3つを選択. モデルは定常性を仮定することから, 実際に実証分析を行う際には, “非定常”な時間帯, 具体的には市場のオープン後やクローズ前の一定期間 (５分間, 10分間等) のデータを除いたり, また1日内の非確率的な季節性変動予め除去した系列に対して, これらのモデルの適合が行われる (diurnal adjustmentと呼ばれる). library(ACDm) distn &lt;- &quot;exponential&quot; mod0 &lt;- &quot;ACD&quot; mod1 &lt;- &quot;LACD1&quot; mod2 &lt;- &quot;LACD2&quot; # TOPIX先物 # ACD(1,1) fit_acd_tx &lt;- ACDm::acdFit(durations = dur_tx, model = mod0, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; ACD model estimation by (Quasi) Maximum Likelihood #&gt; #&gt; Call: #&gt; ACDm::acdFit(durations = dur_tx, model = mod0, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; Model: #&gt; ACD(1, 1) #&gt; #&gt; Distribution: #&gt; exponential #&gt; #&gt; N: 10899 #&gt; #&gt; Parameter estimate: #&gt; Coef SE PV robustSE #&gt; omega 1.4904 0.0523 0 0.373 #&gt; alpha1 0.6144 0.0334 0 0.281 #&gt; beta1 0.0871 0.0222 0 0.067 #&gt; #&gt; #&gt; The fixed/unfree mean distribution parameter: #&gt; lambda: 1 #&gt; #&gt; QML robust correlations: #&gt; omega alpha1 beta1 #&gt; omega 1.000 -0.217 -0.387 #&gt; alpha1 -0.217 1.000 -0.313 #&gt; beta1 -0.387 -0.313 1.000 #&gt; #&gt; #&gt; Goodness of fit: #&gt; value #&gt; LogLikelihood -19293 #&gt; AIC 38592 #&gt; BIC 38614 #&gt; MSE 1895 #&gt; #&gt; Convergence: 0 #&gt; #&gt; Number of log-likelihood function evaluations: 193 #&gt; #&gt; Estimation time: 0.0397 secs #&gt; #&gt; Description: Estimated at 2025-02-02 21:08:00.177543 by user takaki # LACD1(1,1) fit_lacd1_tx &lt;- ACDm::acdFit(durations = dur_tx, model = mod1, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; ACD model estimation by (Quasi) Maximum Likelihood #&gt; #&gt; Call: #&gt; ACDm::acdFit(durations = dur_tx, model = mod1, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; Model: #&gt; LACD1(1, 1) #&gt; #&gt; Distribution: #&gt; exponential #&gt; #&gt; N: 10899 #&gt; #&gt; Parameter estimate: #&gt; Coef SE PV #&gt; omega 0.940 0.02007 0 #&gt; alpha1 0.161 0.00371 0 #&gt; beta1 0.349 0.01807 0 #&gt; #&gt; #&gt; The fixed/unfree mean distribution parameter: #&gt; lambda: 1 #&gt; #&gt; Goodness of fit: #&gt; value #&gt; LogLikelihood -18491 #&gt; AIC 36987 #&gt; BIC 37009 #&gt; MSE 1373 #&gt; #&gt; Convergence: 0 #&gt; #&gt; Number of log-likelihood function evaluations: 140 #&gt; #&gt; Estimation time: 0.111 secs #&gt; #&gt; Description: Estimated at 2025-02-02 21:08:00.219977 by user takaki # LACD2(1,1) fit_lacd2_tx &lt;- ACDm::acdFit(durations = dur_tx, model = mod2, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; ACD model estimation by (Quasi) Maximum Likelihood #&gt; #&gt; Call: #&gt; ACDm::acdFit(durations = dur_tx, model = mod2, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; Model: #&gt; LACD2(1, 1) #&gt; #&gt; Distribution: #&gt; exponential #&gt; #&gt; N: 10899 #&gt; #&gt; Parameter estimate: #&gt; Coef SE PV #&gt; omega 0.0832 0.012233 0 #&gt; alpha1 -0.0019 0.000276 0 #&gt; beta1 0.8975 0.015240 0 #&gt; #&gt; #&gt; The fixed/unfree mean distribution parameter: #&gt; lambda: 1 #&gt; #&gt; Goodness of fit: #&gt; value #&gt; LogLikelihood -19540 #&gt; AIC 39085 #&gt; BIC 39107 #&gt; MSE 1373 #&gt; #&gt; Convergence: 0 #&gt; #&gt; Number of log-likelihood function evaluations: 192 #&gt; #&gt; Estimation time: 0.0887 secs #&gt; #&gt; Description: Estimated at 2025-02-02 21:08:00.333421 by user takaki # 日経平均先物 # ACD(1,1) fit_acd_nk &lt;- ACDm::acdFit(durations = dur_nk, model = mod0, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; ACD model estimation by (Quasi) Maximum Likelihood #&gt; #&gt; Call: #&gt; ACDm::acdFit(durations = dur_nk, model = mod0, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; Model: #&gt; ACD(1, 1) #&gt; #&gt; Distribution: #&gt; exponential #&gt; #&gt; N: 7501 #&gt; #&gt; Parameter estimate: #&gt; Coef SE PV robustSE #&gt; omega 0.00734 0.00153 0 0.00612 #&gt; alpha1 0.14555 0.00761 0 0.02283 #&gt; beta1 0.91804 0.00310 0 0.00858 #&gt; #&gt; #&gt; The fixed/unfree mean distribution parameter: #&gt; lambda: 1 #&gt; #&gt; QML robust correlations: #&gt; omega alpha1 beta1 #&gt; omega 1.000 -0.410 -0.692 #&gt; alpha1 -0.410 1.000 -0.137 #&gt; beta1 -0.692 -0.137 1.000 #&gt; #&gt; #&gt; Goodness of fit: #&gt; value #&gt; LogLikelihood -14762 #&gt; AIC 29531 #&gt; BIC 29552 #&gt; MSE 2277 #&gt; #&gt; Convergence: 0 #&gt; #&gt; Number of log-likelihood function evaluations: 184 #&gt; #&gt; Estimation time: 0.0251 secs #&gt; #&gt; Description: Estimated at 2025-02-02 21:08:00.429745 by user takaki # LACD1(1,1) fit_lacd1_nk &lt;- ACDm::acdFit(durations = dur_nk, model = mod1, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; ACD model estimation by (Quasi) Maximum Likelihood #&gt; #&gt; Call: #&gt; ACDm::acdFit(durations = dur_nk, model = mod1, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; Model: #&gt; LACD1(1, 1) #&gt; #&gt; Distribution: #&gt; exponential #&gt; #&gt; N: 7501 #&gt; #&gt; Parameter estimate: #&gt; Coef SE PV #&gt; omega 0.1423 0.004049 0 #&gt; alpha1 0.0508 0.001426 0 #&gt; beta1 1.0041 0.000623 0 #&gt; #&gt; #&gt; The fixed/unfree mean distribution parameter: #&gt; lambda: 1 #&gt; #&gt; Goodness of fit: #&gt; value #&gt; LogLikelihood -13235 #&gt; AIC 26476 #&gt; BIC 26496 #&gt; MSE 2001 #&gt; #&gt; Convergence: 0 #&gt; #&gt; Number of log-likelihood function evaluations: 182 #&gt; #&gt; Estimation time: 0.0905 secs #&gt; #&gt; Description: Estimated at 2025-02-02 21:08:00.457069 by user takaki # LACD2(1,1) fit_lacd2_nk &lt;- ACDm::acdFit(durations = dur_nk, model = mod2, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; ACD model estimation by (Quasi) Maximum Likelihood #&gt; #&gt; Call: #&gt; ACDm::acdFit(durations = dur_nk, model = mod2, dist = distn, order = c(1, 1), output = T) #&gt; #&gt; Model: #&gt; LACD2(1, 1) #&gt; #&gt; Distribution: #&gt; exponential #&gt; #&gt; N: 7501 #&gt; #&gt; Parameter estimate: #&gt; Coef SE PV #&gt; omega 0.0229 0.001847 0 #&gt; alpha1 0.0028 0.000278 0 #&gt; beta1 0.9779 0.001666 0 #&gt; #&gt; #&gt; The fixed/unfree mean distribution parameter: #&gt; lambda: 1 #&gt; #&gt; Goodness of fit: #&gt; value #&gt; LogLikelihood -16185 #&gt; AIC 32377 #&gt; BIC 32398 #&gt; MSE 2003 #&gt; #&gt; Convergence: 0 #&gt; #&gt; Number of log-likelihood function evaluations: 160 #&gt; #&gt; Estimation time: 0.0555 secs #&gt; #&gt; Description: Estimated at 2025-02-02 21:08:00.549321 by user takaki 推定パラメータ: # TOPIX先物 # summary(fit_acd_tx) # summary(fit_lacd1_tx) # summary(fit_lacd2_tx) fit_acd_tx$mPara #&gt; omega alpha1 beta1 #&gt; 1.4904 0.6144 0.0871 fit_lacd1_tx$mPara #&gt; omega alpha1 beta1 #&gt; 0.940 0.161 0.349 fit_lacd2_tx$mPara #&gt; omega alpha1 beta1 #&gt; 0.0832 -0.0019 0.8975 # 日経平均先物 fit_acd_nk$mPara #&gt; omega alpha1 beta1 #&gt; 0.00734 0.14555 0.91804 fit_lacd1_nk$mPara #&gt; omega alpha1 beta1 #&gt; 0.1423 0.0508 1.0041 fit_lacd2_nk$mPara #&gt; omega alpha1 beta1 #&gt; 0.0229 0.0028 0.9779 補足: 等間隔データを作成するための方法 (1) aggregate()を使うやり方 # インデックスが POSIXctの場合, cut()により # 作成されるグリッドの確認 test_cut &lt;- cut(index(topix_1_zoo2), breaks = &quot;5 min&quot;) head(test_cut) table(test_cut) # グリッド点は, データの開始時点から5分間隔に (秒以下は丸めて) 取る topix_5m_zoo &lt;- aggregate( x = topix_1_zoo2, by = function(tt) as.POSIXct(cut(tt, &quot;5 min&quot;)), FUN = last # mean ) (2) 5分間隔の等間隔POSIXct列を手で作成 # 所与のデータを使用する場合 start_time &lt;- start(topix_1_zoo2) # 最初のタイムスタンプ end_time &lt;- end(topix_1_zoo2) # 最後のタイムスタンプ # 開始・終了時刻を手入力の場合 # 代替案: tz = &quot;Asia/Tokyo&quot; start_time &lt;- as.POSIXct(&quot;2018-02-05 09:00:00&quot;, tz = &quot;UTC&quot;) end_time &lt;- as.POSIXct(&quot;2018-02-05 11:30:00&quot;, tz = &quot;UTC&quot;) attr(index(topix_1_zoo2), &quot;tzone&quot;) attr(start_time, &quot;tzone&quot;) # class(start_time) idx_5min &lt;- seq(from = start_time, to = end_time, by = &quot;5 min&quot;) # 不定間隔のデータを 5分間隔の時刻にあわせてマージ # 注) 取引のない時刻への対応のため, all=T (デフォルト) に設定しておく topix_5m_zoo_ &lt;- merge(topix_1_zoo2, zoo(, idx_5min)) # NA補間. ここでは, &quot;previous-tick interpolation&quot; # na.locf()（Last Observation Carried Forward）で直近値で補完 topix_5m_filled &lt;- na.locf(topix_5m_zoo_) topix_5min_zoo &lt;- topix_5m_filled[idx_5min] # → 9:00丁度のデータが欠損のため, 9:05からスタート (3) xtsを併用する方法 (マイクロ秒刻みに対応) endpoint(): - Extract index locations for an xts object that correspond to the last observation in each period specified by on and k. (その区間の最後のインデックスを返す. 例, 5分間隔の秒刻みデータ → 最後の4分59秒) - Usage: endpoints(x, on = &quot;months&quot;, k = 1) - on: “us” (microseconds), “microseconds”, “ms” (milliseconds), “milliseconds”, “secs” (seconds), “seconds”, “mins” (minutes), “minutes”, “hours”, “days”, “weeks”, “months”, “quarters”, and “years”. library(zoo) library(xts) x &lt;- as.xts(topix_1_zoo2) # zoo -&gt; xts 変換 # 5分毎に集計. データ # 5秒間隔 --&gt; endpoints(x, &quot;seconds&quot;, 5) # 5秒毎のインデックス生成 z_5min_xts &lt;- period.apply( x, INDEX = endpoints(x, &quot;min&quot;, 5), FUN = last # mean ) # --&gt; 5分毎のhh:mm:59を返す # 必要に応じて zoo に戻す: topix_5min_zoo &lt;- as.zoo(z_5min_xts) "],["バブル-生成崩壊-検出.html", "A バブル (生成・崩壊) 検出 A.1 検定法に関する最近のレビュー論文 A.2 Supreme ADF検定/SADF (PWY, 2011), Generalized supreme ADF 検定/GSADF (PSY, 2015) A.3 実証分析", " A バブル (生成・崩壊) 検出 論文多数. 一部の紹介. A.1 検定法に関する最近のレビュー論文 Skrobotov, A.(2021). Testing for Explosive Bubbles: A Review, preprint. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3779111 A.2 Supreme ADF検定/SADF (PWY, 2011), Generalized supreme ADF 検定/GSADF (PSY, 2015) Phillips, P.C.B., Wu, Y., Yu, J. (2011). Explosive behavior in the 1990s Nasdaq: when did exuber- ance escalate asset values? Int. Econ. Rev. 52 (1), 201–226. Phillips, P. C. B., Shi, S., &amp; Yu, J. (2015a). Testing for multiple bubbles: Historical episodes of exuberance and collapse in the S&amp;P 500. International Economic Review, 56(4), 1034–1078. Phillips, P. C. B., Shi, S., &amp; Yu, J. (2015b). Testing for multiple bubbles: Limit Theory for Real- Time Detectors. International Economic Review, 56(4), 1079–1134. Phillips, P. C. B., &amp; Shi, S.(2020) Real time monitoring of asset markets: Bubbles and crisis. In Hrishikesh D. Vinod and C.R. Rao (Eds.), Handbook of Statistics Volume 41 - Econometrics Using R. Rパッケージ psymonitor: https://cran.r-project.org/web/packages/psymonitor/psymonitor.pdf MultiBubbles: https://cran.r-project.org/web/packages/MultipleBubbles/MultipleBubbles.pdf exuber: https://www.dallasfed.org/~/media/documents/institute/wpapers/2020/0383.pdf https://cran.rstudio.com/web/packages/exuber/vignettes/exuber.html A.2.1 数理ファイナンス (Jarrow, Protterら) Jarrow, R., Protter P., and Shimbo, K. (2007), Asset price bubbles in complete markets, in Advances in Mathematical Finance, Birkha ̈user Boston, Cambridge, MA, 97–121. Jarrow, R., Protter P., and Shimbo, K. (2010). Asset price bubbles in incomplete markets, Math. Finance, 20, 145–185. Jarrow, R., Kchia, Y., and Protter, P. (2011). How to Detect an Asset Bubble, SIAM Journal on Financial Mathematics, 2-1, 839-865. Protter P. (2013) A Mathematical Theory of Financial Bubbles. In: Paris-Princeton Lectures on Mathematical Finance 2013. Lecture Notes in Mathematics, vol 2081. Springer, Cham. https://doi.org/10.1007/978-3-319-00413-6_1 A.2.2 経済物理学 (Sornetteら) Johansen, A., Ledoit, O., Sornette, D. (2000). Crashes as critical points, International Journal of Theoretical and Applied Finance 3, 219–255. https://arxiv.org/pdf/cond-mat/9810071.pdf Sornette, D., Woodard, R., Yan, W., and Zhou, W.X. (2013). Clarifications to Questions and Criticisms on the Johansen-Ledoit-Sornette Financial Bubble Model, Physica A, 392-19, Pages 4417-4428. https://arxiv.org/pdf/1107.3171.pdf Sornette, D. (2017) Why Stock Markets Crash: Critical Events in Complex Financial Systems, Revised ed., Princeton Science Library. ISBN-10: 0691175950 A.3 実証分析 株式市場の例 Breitung, J. and Kruse, R. (2013) ‘When bubbles burst: econometric tests based on structural breaks’, Statistical Papers, 54(4), pp. 911–930. Available at: https://doi.org/10.1007/s00362-012-0497-3. Monschang, V. and Wilfling, B. (2021) ‘Sup-ADF-style bubble-detection methods under test’, Empirical Economics, 61(1), pp. 145–172. Available at: https://doi.org/10.1007/s00181-020-01859-7. Shi, S. and Song, Y. (2014) ‘Identifying Speculative Bubbles Using an Infinite Hidden Markov Model’, Journal of Financial Econometrics, p. nbu025. Available at: https://doi.org/10.1093/jjfinec/nbu025. 暗号資産市場の例 Cross, J.L., Hou, C. and Trinh, K. (2021) ‘Returns, volatility and the cryptocurrency bubble of 2017–18’, Economic Modelling, 104, p. 105643. Available at: https://doi.org/10.1016/j.econmod.2021.105643. Yao, C.-Z. and Li, H.-Y. (2021) ‘A study on the bursting point of Bitcoin based on the BSADF and LPPLS methods’, The North American Journal of Economics and Finance, 55, p. 101280. Available at: https://doi.org/10.1016/j.najef.2020.101280. "],["長期記憶過程-1.html", "B 長期記憶過程 B.1 理論・概説 B.2 株式市場 B.3 外国為替市場 B.4 コモディティ・暗号資産 B.5 VIX B.6 高頻度データ (ボラティリティ, 注文フロー等) B.7 長期記憶性の発生要因, 非長期記憶モデルによる近似", " B 長期記憶過程 ダウンロード可能なものを中心に紹介します (ワーキングペーパー含む). 文献多数あり, 重要なものをカバーしている訳ではありません. ここにないものについては, 電子ジャーナル等を通じて適宜入手してください B.1 理論・概説 Gennady Samorodnitsky (2006). Long Range Dependence. Foundations and Trends in Stochastic Systems, 1(3), 163–257. https://people.orie.cornell.edu/gennady/techreports/LRD-NOW.pdf https://pdfs.semanticscholar.org/f182/3f5bcc8524d73af14ba3e29e7bbdcc50545e.pdf Rama Cont (2005). Long range dependence in financial markets, In: Lévy-Véhel J., Lutton E. (eds) Fractals in Engineering. Springer, London. https://doi.org/10.1007/1-84628-048-6_11 https://www.researchgate.net/publication/226697823_Long_range_dependence_in_financial_market Thomas Mikosch and Ca ̆ta ̆lin Sta ̆rica ̆ (2004). Nonstationarities in Financial Time Series, the Long-range Dependence, and the IGARCH Effects. The Review of Economics and Statistics, 86(1), 378–390. https://gec.cr.usgs.gov/outgoing/threshold_articles/Mikosch_Starica2004.pdf Richard T. Baillie (1996). Long memory processes and fractional integration in econometrics, Journal of Econometrics, 73, 5-59. http://long-memory.com/Baillie1996.pdf B.2 株式市場 Andrew W. Lo (1991). Long term memory in stock market prices, Econometrica 59 1279–313. https://www.nber.org/system/files/working_papers/w2984/w2984.pdf Walter Willinger, Murad S. Taqqu, Vadim Teverovsky (1999). Stock market prices and long-range dependence, Finance &amp; Stochastics, 3, 1–13. http://www.long-memory.com/returns/WillingerTaqquTeverovsky1999.pdf B.3 外国為替市場 Yin-Wong Cheung (1993). Long Memory in Foreign-Exchange Rates, Journal of Business &amp; Economic Statistics, 11(1), 93-101, DOI: 10.1080/07350015.1993.10509935. https://people.ucsc.edu/~cheung/JBES/LongMemoryFX_JBES1993.pdf Richard T. Baillie and Tim Bollerslev(1994). The long memory of the forward premium, Journal of International Money and Finance, 13(5), 565-571. https://dukespace.lib.duke.edu/dspace/bitstream/handle/10161/1965/Bollerslev_the_long_memory.pdf?sequence=1 Dominique M. Guillaume, Michel M. Dacorogna, Rakhal R. Davé, Ulrich A. Müller, Richard B. Olsen &amp; Olivier V. Pictet (1997). From the bird’s eye to the microscope: A survey of new stylized facts of the intra-daily foreign exchange markets. Finance and Stochastics, 1, pages95–129. https://link.springer.com/article/10.1007%2Fs007800050018 B.4 コモディティ・暗号資産 Mohamed El Hedi Arouri, Shawkat Hammoudeh, Amine Lahiani, Duc Khuong Nguyen(2012). Long memory and structural breaks in modeling the return and volatility dynamics of precious metals, The Quarterly Review of Economics and Finance, 52-2, 207-218. https://hal.archives-ouvertes.fr/file/index/docid/798033/filename/Arouri_et_al_QREF_R3-1.pdf Guglielmo Maria Caporale, Luis Gil-Alana, Alex Plastun (2018), Persistence in the cryptocurrency market, Research in International Business and Finance, 46, pp. 141-148. https://www.sciencedirect.com/science/article/pii/S0275531917309200 B.5 VIX Guglielmo Maria Caporale, Luis Gil-Alana, Alex Plastun (2018). Is market fear persistent? A long-memory analysis. Finance Research Letters, 27, 140-147. https://doi.org/10.1016/j.frl.2018.02.007. https://www.sciencedirect.com/science/article/pii/S1544612317303793 B.6 高頻度データ (ボラティリティ, 注文フロー等) Lillo, F. and Farmer, J. D. (2004). The Long Memory of the Efficient Market, Studies in Nonlinear Dynamics &amp; Econometrics, 8(3). doi: https://doi.org/10.2202/1558-3708.1226 https://arxiv.org/pdf/cond-mat/0311053 Torben G Andersen and Tim Bollerslev (1997), Heterogeneous Information Arrivals and Return Volatility Dynamics: Uncovering the Long‐Run in High Frequency Returns. The Journal of Finance, 52, 975-1005. https://doi.org/10.1111/j.1540-6261.1997.tb02722.x https://www.nber.org/system/files/working_papers/w5752/w5752.pdf Torben G Andersen, Tim Bollerslev, Francis X Diebold &amp; Paul Labys (2001). The Distribution of Realized Exchange Rate Volatility, Journal of the American Statistical Association, 96, 42-55. https://www.nber.org/system/files/working_papers/w6961/w6961.pdf B.7 長期記憶性の発生要因, 非長期記憶モデルによる近似 Chevillon, G. and Mavroeidis, S. (2018) ‘Perpetual learning and apparent long memory’, Journal of Economic Dynamics and Control, 90, pp. 343–365. Available at: https://doi.org/10.1016/j.jedc.2018.03.012. Corsi, F. (2004) ‘A Simple Long Memory Model of Realized Volatility’, SSRN Electronic Journal [Preprint]. Available at: https://doi.org/10.2139/ssrn.626064. Corsi, F., Audrino, F. and Renò, R. (2012) ‘HAR Modeling for Realized Volatility Forecasting’, in L. Bauwens, C. Hafner, and S. Laurent (eds) Handbook of Volatility Models and Their Applications. 1st edn. Wiley, pp. 363–382. Available at: https://doi.org/10.1002/9781118272039.ch15. Granger, C.W.J. (1980) ‘LONG MEMORY RELATIONSHIPS AND THE AGGREGATION OF DYNAMIC MODELS’, Journal of Econometrics, 14(2), pp. 227–238. Available at: https://www.sciencedirect.com/science/article/pii/0304407680900925. Granger, C.W.J. and Hyung, N. (2004) ‘Occasional structural breaks and long memory with an application to the S&amp;P 500 absolute stock returns’, Journal of Empirical Finance, 11(3), pp. 399–421. Available at: https://doi.org/10.1016/j.jempfin.2003.03.001. "],["markov-switching-regime-switchingモデル.html", "C Markov switching/ regime switchingモデル C.1 理論・概説 C.2 株式市場 C.3 金利・債券市場 C.4 外国為替市場 C.5 アセット・アロケーション", " C Markov switching/ regime switchingモデル 論文多数につき, ごく一部のみ紹介. ダウンロード可能なもの中心に紹介 (ワーキングペーパー含む) C.1 理論・概説 Hamilton, J. D. (1989). A New Approach to the Economic Analysis of Nonstationary Time Series and the Business Cycle. Econometrica, 57, 357–384. https://www.ssc.wisc.edu/~bhansen/718/Hamilton1989.pdf Hamilton J.D. (2008) Regime Switching Models. In: Durlauf S.N., Blume L.E. (eds) The New Palgrave Dictionary of Economics. Palgrave Macmillan, London. https://doi.org/10.1007/978-1-349-58802-2_1408 https://econweb.ucsd.edu/~jhamilto/palgrav1.pdf Timmermann, Allan (2000). Moments of Markov switching models, Journal of Econometrics, 96(1), 75-111. https://ideas.repec.org/a/eee/econom/v96y2000i1p75-111.html C.2 株式市場 Lunde, A. and Timmermann, A. (2004). Duration dependence in stock prices: An analysis of bull and bear markets. Journal of Business &amp; Economic Statistics, 22(3), 253–273. https://www.tandfonline.com/doi/pdf/10.1198/073500104000000136?casa_token=rx5Tgip1JfUAAAAA:VVHIVFY86vzPzWi-05QLaeEa3Inkb8Wo70zQI9OQaiUCAtbkj57H3r3b2uSftk9sUq6nADGUjRY54wg Maheu, J. M. and McCurdy, T. H. (2000). Identifying bull and bear markets in stock returns. Journal of Business &amp; Economic Statistics, 18(1), 100–112. https://www.tandfonline.com/doi/abs/10.1080/07350015.2000.10524851#aHR0cHM6Ly93d3cudGFuZGZvbmxpbmUuY29tL2RvaS9wZGYvMTAuMTA4MC8wNzM1MDAxNS4yMDAwLjEwNTI0ODUxP25lZWRBY2Nlc3M9dHJ1ZUBAQDA= C.3 金利・債券市場 Ang, A. and Bekaert, G. (2002). Regime switches in interest rates. Journal of Business and Economic Statistics 20, 163–82. https://www.nber.org/system/files/working_papers/w6508/w6508.pdf Dai, Qiang, Singleton, Kenneth J. and Yang, Wei (2007). Regime Shifts in a Dynamic Term Structure Model of U.S. Treasury Bond Yields. The Review of Financial Studies, 20(5), 1669-1706. https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.409.8573&amp;rep=rep1&amp;type=pdf C.4 外国為替市場 Dueker, Michael and Neely, Christopher J. (2007). Can Markov Switching Models Predict Excess Foreign Exchange Returns? Journal of banking &amp; finance, 31(2), 279-296. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.197.9927&amp;rep=rep1&amp;type=pdf Cheung, Yin-Wong and Erlandsson, Ulf G. (2005). Exchange Rates and Markov Switching Dynamics, Journal of Business &amp; Economic Statistics, 23(3), 314-320. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=637163 C.5 アセット・アロケーション Ang, A. and Bekaert, G. (2002). International asset allocation with regime shifts. Review of Financial Studies, 15(4), 1137–1187. https://pdfs.semanticscholar.org/2521/155069503babc51b65fae22ee7281674ea4a.pdf Guidolin, M. and Timmermann, A. (2007). Asset allocation under multivariate regime switching. Journal of Economics Dynamics &amp; Control, 31(11), 3503–3544. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=940652 "],["archgarchモデル-1.html", "D ARCH/GARCHモデル D.1 概説 D.2 ARCH model D.3 GARCH model D.4 ARCH-M Model D.5 GJR model D.6 APARCH model", " D ARCH/GARCHモデル 論文多数. ダウンロード可能なものごく一部の紹介. D.1 概説 Tim Bollerslev, Ray Y. Chou and Kenneth F. Kroner (1992). “ARCH modeling in finance: A review of the theory and empirical evidence”, Journal of Econometrics, 52, 1–2, 5-59. http://www-stat.wharton.upenn.edu/~steele/Courses/434/434Context/GARCH/BollerslevReview.pdf Tim Bollerslev, Robert F. Engle, Danile B. Nelson(1994). “ARCH models”, in Handbook of Econometrics, Volume IV (Edited by R.F. Engle and D.L. McFadden). https://d1wqtxts1xzle7.cloudfront.net/43834885/arch-with-cover-page-v2.pdf?Expires=1639120389&amp;Signature=ImncR825Ozi~78eBe4x-ZZPU0pp9cebOmIEaGK06oLukIeZ8uviF3xhkW1~4SJkc4GWLQMrcFR1~C-Uc218lxMhj1bgt8lFtaVOhuvDPuXyUEkf~WpC4zFmFnC3Re20YzFmx7CQEOPbmCmPWiwOcO4SZvw~CwebW4Q2f~2eRj7xKzVYJn-59E66cuk3chFx3xCeH47QVZwd959Nq55ncW4CA7CsTi2CHCNCZesdznpZBsC4xd-F-GaKHuFN9O7O2qDataXJkvPhRqYMJV2SwHcBGfYp3ASXXwDNgsmKl7PJD7XwMQ9Aqj2H61rXo12lg6-dH4-r7mFdGGS~G~BE5tw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA Robert Engle(2003). “Risk and Volatility: Econometric Models and Financial Practice”, Nobel Lecture, December 8, 2003. https://www.nobelprize.org/uploads/2018/06/engle-lecture.pdf https://www.nobelprize.org/prizes/economic-sciences/2003/engle/lecture/ D.2 ARCH model Robert F. Engle (1982). “Autoregressive Conditional Heteroskedasticity with Estimates of the Variance of U.K. Inflation”, Econometrica, 50, 987-1008. http://www.econ.uiuc.edu/~econ508/Papers/engle82.pdf D.3 GARCH model Tim Bollerslev (1986). “Generalized Autoregressive Conditional Heteroskedasticity”, Journal of Eco- nometrics, 31, 307 327. http://public.econ.duke.edu/~boller/Published_Papers/joe_86.pdf D.4 ARCH-M Model Robert Engle, David M. Lilien and Russell P. Robins (1987). “Estimating Time Varying Risk Premia in the Term Structure: The Arch-M Model”, Econometrica, 1987, 55(2), 391-407. https://econpapers.repec.org/article/ecmemetrp/v_3a55_3ay_3a1987_3ai_3a2_3ap_3a391-407.htm D.5 GJR model Lawrence R. Glosten, Ravi Jagannathan and David E. Runkle(1993). “On the Relation between the Expected Value and the Volatility of the Nominal Excess Return on Stocks”, Journal of Finance, 48(5), 1779-1801. http://finance.martinsewell.com/stylized-facts/volatility/GlostenJagannathanRunkle1993.pdf D.6 APARCH model Zhuanxin Ding, Clive W.J. Granger and Robert F. Engle(1993). “A long memory property of stock market returns and a new model”, Journal of Empirical Finance 1 (1), 83-106. https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.471.7587&amp;rep=rep1&amp;type=pdf "],["共和分-誤差修正モデル.html", "E 共和分/ 誤差修正モデル E.1 株式市場とマクロ変数, 国際株式市場間の分析 E.2 個別株式の複数取引所株価間の分析 E.3 高頻度データ (bid/ask価格) の分析 E.4 統計的アービトラージ / ペアトレード E.5 国際株式市場間のヘッジ E.6 クレジット・スプレッド (株式, CDS, 債券) の分析", " E 共和分/ 誤差修正モデル 金融/経済時系列の分析, 近年, 新興市場に関する実証研究多数. (確立された方法論, 論文書き易い) 金融市場における応用例: 統計的アービトラージ・ペア・トレード, 現物–先物裁定取引, 指数トラッキング, 信用スプレッド取引, ヘッジ取引, … E.1 株式市場とマクロ変数, 国際株式市場間の分析 Ramin Cooper Maysami, Tiong Sim Koh (2000). A vector error correction model of the Singapore stock market, International Review of Economics &amp; Finance, 9(1), 79-96. https://doi.org/10.1016/S1059-0560(99)00042-8. (https://www.sciencedirect.com/science/article/pii/S1059056099000428) E.2 個別株式の複数取引所株価間の分析 deB. Harris F.H., McInish T.H., Shoesmith G.L., Wood R.A. (1995). Cointegration, Error Correction, and Price Discovery on Informationally Linked Security Markets. Journal of Financial and Quantitative Analysis, 30(4):563-579. https//doi.org.10.2307/2331277 E.3 高頻度データ (bid/ask価格) の分析 Robert F. Engle, Andrew J. Patton (2004). Impacts of trades in an error-correction model of quote prices, Journal of Financial Markets, 7(1), 1-25. https://doi.org/10.1016/S1386-4181(03)00018-1.(https://www.sciencedirect.com/science/article/pii/S1386418103000181) https://archive.nyu.edu/bitstream/2451/26697/2/FIN-00-033.pdf E.4 統計的アービトラージ / ペアトレード Krauss, Christopher (2017). Statistical arbitrage pairs trading strategies: Review and outlook, Journal of Economic Surveys, 31(2), 513–545. https://doi.org/10.1111/joes.12153. E.5 国際株式市場間のヘッジ Alexander Carol (1999). Optimal hedging using cointegration, Phil. Trans. R. Soc. A. 3572039–2058. http://doi.org/10.1098/rsta.1999.0416 E.6 クレジット・スプレッド (株式, CDS, 債券) の分析 Santiago Forte, Juan Ignacio Peña (2009). Credit spreads: An empirical analysis on the informational content of stocks, bonds, and CDS, Journal of Banking &amp; Finance, 33(11), 2013-2025. https://doi.org/10.1016/j.jbankfin.2009.04.015. (https://www.sciencedirect.com/science/article/pii/S037842660900096X) "],["今後の学習のために.html", "F 今後の学習のために F.1 AI/機械学習と時系列解析 F.2 カテゴリーデータや整数値データ等に対する時系列解析 F.3 状態空間モデル・動的線形モデル F.4 その他", " F 今後の学習のために 今学期授業でカバー出来なかった内容や, 授業を踏まえた発展的内容に関する参考書や (ダウンロード可能な) サーベイ論文や概説論文を幾つか紹介します. 個別の論文については, これらの文献内の参考文献リストや, Google検索などで, サーチしてください. 多数見つかるはずです. なお, 学術誌に掲載された論文については, 都立大学の電子ジャーナル検索サービスを利用して入手を試みてください. F.1 AI/機械学習と時系列解析 (サーベイ) John W. Goodell, Satish Kumar, Weng Marc Lim, Debidutta Pattnaik (2021). Artificial intelligence and machine learning in finance: Identifying foundations, themes, and research clusters from bibliometric analysis, Journal of Behavioral and Experimental Finance 32, 100577. https://linkinghub.elsevier.com/retrieve/pii/S2214635021001210 (時系列予測 + 深層学習) Bryan Lim and Stefan Zohren (2020). Time Series Forecasting With Deep Learning: A Survey. *Philosophical Transactions A. https://arxiv.org/pdf/2004.13408.pdf (同) John Cristian Borges Gamboa (2017). Deep Learning for Time-Series Analysis, arXiv. https://arxiv.org/abs/1701.01887 (時系列予測+自然言語処理) Xing, Frank Z., et al. (2018). Natural Language Based Financial Forecasting: A Survey. Artificial Intelligence Review, vol. 50, no. 1, June 2018, pp. 49–73. https://dspace.mit.edu/bitstream/handle/1721.1/116314/10462_2017_9588_ReferencePDF.pdf?sequence=2&amp;isAllowed=y (GARCH + 深層学習 (LSTM)) Wing Ki Liu and Mike K.P.So (2020). A GARCH Model with Artificial Neural Networks, Information, 11, 489. https://www.mdpi.com/863510 (GAN (シミュレーター)) Lezmi, Edmond, Roche, Jules, Roncalli, Thierry, and Xu, Jiali (2020). Improving the Robustness of Trading Strategy Backtesting with Boltzmann Machines and Generative Adversarial Networks, http://arxiv.org/abs/2007.04838. (同) Magnus Wiese, Robert Knobloch, Ralf Korn, and Peter Kretschmer (2020). Quant GANs: Deep Generation of Financial Time Series, Quantitative Finance, 20(9), 1419-1440. http://arxiv.org/abs/1907.06673 (Variational Autoencoder (シミュレーター)) Hans Buehler,, Blanka Horvath, Terry Lyons, Imanol Perez Arribas, and Ben Wood (2020). A Data-driven Market Simulator for Small Data Environments. http://arxiv.org/abs/2006.14498. (高頻度データ/マイクロストラクチャ + 深層学習) Justin Sirignano and Rama Cont (2019), Universal features of price formation in financial markets: perspectives from deep learning, Quantitative Finance, 2019 Vol. 19, No. 9, 1449–1459, https://doi.org/10.1080/14697688.2019.1622295 F.2 カテゴリーデータや整数値データ等に対する時系列解析 (動的一般化線形モデル) Mike West, P. Jeff Harrison, and Helio S. Migon (1985), Dynamic Generalized Linear Models and Bayesian Forecasting, J. American Statistical Association, 80 (389). https://www2.stat.duke.edu/~mw/MWextrapubs/West1985a.pdf (整数値自己回帰モデル) 中嶋 雅彦, 酒折文武, 川崎能典 (2017). 整数値自己回帰モデルの最近の発展, 統計数理, 第 65 巻 第 2 号 323–339. https://www.ism.ac.jp/editsec/toukei/pdf/65-2-323.pdf 参考書 (一般化線形モデルの時系列モデリングへの拡張) Fahrmeir, L. and Tutz, G. (2001). Multivariate Statistical Modelling Based on Generalized Linear Models, 2nd ed., Springer-Verlag, New York. F.3 状態空間モデル・動的線形モデル 参考書 Giovanni Petris, Sonia Petrone, and Patrizia Campagnoli (2009). Dynamic Linear Models with R, Springer. (R利用ガイド) Giovanni Petris, Petrone (2011). State Space Models in R, J. Statistical Software 41(104). https://www.researchgate.net/publication/227450969_State_Space_Models_in_R (ウェブサイト) Giovanni Petris, State Space Models in R - useR! 2011 Tutorial. https://www.r-project.org/conferences/useR-2011/tutorials/Petris.html 参考書 萩原淳一郎, 瓜生真也, 牧山幸史(2018). 基礎からわかる時系列分析. 技術評論社. F.4 その他 参考書 (時系列解析全般. “バイブル”) James D. Hamilton (1994). Time Series Analysis, Princeton University Press. 参考書 (Wavelet) Ramazan Gençay, Faruk Selçuk and Brandon Whitcher (2001). An Introduction to Wavelets and Other Filtering Methods in Finance and Economics, Academic Press. 参考書 (高頻度データ分析) 林, 佐藤彰洋(2016). 金融市場の高頻度データ分析. 朝倉書店. 参考書 (パネル回帰) Jeffrey M.Wooldridge (2016). Econometric Analysis of Cross Section and Panel Data, 2nd ed., MIT Press. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
