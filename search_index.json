[["index.html", "金融時系列解析 1 はじめに 1.1 時系列モデリング 1.2 金融時系列データの特徴 1.3 シミュレーションによるサンプルパス生成 1.4 Rにおける時系列オブジェクト・クラスおよび関数の例 1.5 時系列データの分解", " 金融時系列解析 林 高樹 2025-11-29 (内容は随時更新します) 1 はじめに 1.1 時系列モデリング ターゲットの時系列データの特徴を表現できるような確率・統計モデルの構築 金融証券市場で観察される”stylized facts”等の中から, 重要な特徴にフォーカスする 実際の時系列データと構築モデルの持つ特徴が類似するように 時系列プロット, 散布図, ヒストグラム, 要約統計量等に関して 理論計算やシミュレーション(パスの生成) 金融時系列データに現れる特徴は, データ期間 (例, コロナ禍以前・以後) の他, データの観測頻度 (例, 月次, 週次, 日次, 5分次) にも依存 時系列データにおいて, 時間を通じて安定的に観察される”規則性”や構造 (“時系列構造”) をモデルによって表現する. その規則性が将来予測の源泉となる 規則性には, トレンドや周期性などの時系列データから目視できる特徴の他, “定常性”と呼ばれる時系列データの背後にある確率過程モデルの従う確率分布やモーメントに関する特徴などがある 構築される時系列モデルに望まれる性質 (要件) 記述性 (ターゲットの時系列データとの特徴の類似性の表現) 解析容易性, 解釈可能性 操作性・取扱容易性 推定容易性, 計算効率性 モデル安定性・頑強性 予測精度の高さなど 候補となるモデルは無数 汎用的で, 良い性質を持つモデルクラスに関する研究 時系列解析分野で中核を成すクラス → 線形+定常時系列過程 モデル選択・推定, モデルの利用 ターゲット時系列の特徴を踏まえ. 適切なモデルクラスを選択する データに対してモデルを適合し, パラメータを推定する 推定モデルの妥当性をチェック (モデル診断) 予測や制御等に利用 本授業で扱う対象・アプローチ 目的変数 (観測変数) 自体が時系列構造を持ち, 時系列モデルで記述されるケースに主要な関心 出発点(基本的設定): 1変量の線形・定常時系列過程 → 金融時系列データは, 線形・定常時系列過程から乖離する特徴も有する → 非線形 and/or 非定常な時系列過程へ 観測変数が多次元で時系列構造を持つケース (多変量時系列) 観測変数に影響を与える外部変数 (“共変量”) のあるケース 金融時系列解析におけるチャレンジ 時系列データは, 確率過程の観点からは, 一本の”サンプルパス”の実現と見なせる マクロ・ミクロの状態が 時間と共に変化する金融・経済時系列データは, 再現性の乏しいデータであると考えられる さらに, 金融市場は過去に実現したデータに基づいて市場参加者が行動を変化させる ある種の規則性・ 法則性を過去のデータから見出し, それをモデルにより表現することで, 将来を予測し, 金融市場において”最適な”行動を取りたい 1.2 金融時系列データの特徴 金融時系列データの特徴: みずほ (8411) 株価データの例 quantmod()による株価データの取得 library(&#39;quantmod&#39;) YJ8411.T &lt;- getSymbols(&#39;8411.T&#39;,from = &#39;2020-09-01&#39;, to = &#39;2024-08-30&#39;, src = &quot;yahoo&quot;, auto.assign = FALSE) # 日次株価の時系列プロット chartSeries(YJ8411.T) Figure 1.1: … # 日次4本値 chartSeries(OHLC(YJ8411.T)) Figure 1.2: … 日次収益率の時系列プロット # 日次収益率の時系列プロット ret_YJ8411 &lt;- ClCl(YJ8411.T) chartSeries(ret_YJ8411) 日次収益率のヒストグラム # 日次収益率のヒストグラム hist(ret_YJ8411) 日次収益率の要約統計量 library(psych) describe(ret_YJ8411) #&gt; vars n mean sd median trimmed mad min max range skew kurtosis se #&gt; X1 1 979 0 0.02 0 0 0.01 -0.2 0.09 0.28 -1.87 22.68 0 # 要約統計量を計算 # デフォルト出力 # mean # standard deviation # trimmed mean (with trim defaulting to .1) # median (standard or interpolated # mad: median absolute deviation (from the median). # minimum # maximum # skew # kurtosis # standard error # 注) kurtosisは-3した値 日次収益率の自己相関 # 日次収益率の自己相関 acf(ret_YJ8411, na.action = na.pass) 日次収益率絶対値の自己相関 # 日次収益率絶対値の自己相関 acf(abs(ret_YJ8411), na.action = na.pass) 1.3 シミュレーションによるサンプルパス生成 時系列モデリングでは, 観測時系列データの特徴と比較し, 適切なモデルを見い出すため, シミュレーションを積極的に利用する 正規AR(1)モデルの例: \\(X(t)=\\phi X(t-1) + W(t)\\), \\(W(t) \\sim_{i,i.d.} N(0,\\sigma^2)\\) x_ts &lt;- NULL; tlen &lt;- 50 phi &lt;- -0.8; s &lt;- 2 for (seed_tmp in 1:5){ set.seed(seed_tmp) x &lt;- w &lt;- rnorm(tlen) * s for (t in 2:tlen) x[t] &lt;- phi * x[t - 1] + w[t] # x_ts &lt;- ts.intersect(x_ts, ts(cumsum(x))) } ts.plot(x_ts, type = &quot;l&quot;, col = 1:5, lty = 1:5, ylab = &quot;&quot;, main = &quot;Simulated sample paths&quot;) 1.4 Rにおける時系列オブジェクト・クラスおよび関数の例 1.4.1 日付・時間データに対するクラス 1.4.1.1 Dateクラス 日付を表現する R内部的には, “Date”というclass属性を持つdouble型の値を持つ # as.Date(): 日付を表す文字列をDate型に変更する tomorrow &lt;- as.Date(&quot;2023-10-04&quot;) tomorrow #&gt; [1] &quot;2023-10-04&quot; attributes(tomorrow) # 出力オブジェクトの属性(attribute) #&gt; $class #&gt; [1] &quot;Date&quot; # typeof(tomorrow) # 出力オブジェクトの型(type) # typeof(&quot;2023-10-23&quot;) # 入力オブジェクトの型(type) today &lt;- Sys.Date() today #&gt; [1] &quot;2025-11-29&quot; 1.4.1.2 POSIXctクラス 日時 (日-時間) を表現する Rの内部的には, “POSIXct”というclass属性を持つdouble型の値を持つ POSIX = Portable Operating System Interfaceの略 POSIXct, POSXltの2種類: ct = calender time, lt = local time now_ct &lt;- as.POSIXct(&quot;2023-10-05 19:00&quot;, tz = &quot;UTC&quot;) now_ct #&gt; [1] &quot;2023-10-05 19:00:00 UTC&quot; attributes(now_ct) #&gt; $class #&gt; [1] &quot;POSIXct&quot; &quot;POSIXt&quot; #&gt; #&gt; $tzone #&gt; [1] &quot;UTC&quot; tomorrow_ct &lt;- as.POSIXct(&quot;2023-10-06 20:00&quot;, tz = &quot;UTC&quot;) tomorrow_ct - now_ct # 時間差(1日当たり) #&gt; Time difference of 1.041667 days attributes(tomorrow_ct - now_ct) #&gt; $class #&gt; [1] &quot;difftime&quot; #&gt; #&gt; $units #&gt; [1] &quot;days&quot; 1.4.1.3 difftimeクラス 時間差を表現する Rの内部的には, “POSIXct”というclass属性を持つdouble型の値を持つ onewk_1 &lt;- as.difftime(1, units = &quot;weeks&quot;) onewk_1 #&gt; Time difference of 1 weeks typeof(onewk_1) #&gt; [1] &quot;double&quot; attributes(onewk_1) #&gt; $class #&gt; [1] &quot;difftime&quot; #&gt; #&gt; $units #&gt; [1] &quot;weeks&quot; onewk_2 &lt;- as.difftime(7, units = &quot;days&quot;) onewk_2 #&gt; Time difference of 7 days 1.4.1.4 よりモダンかつ柔軟な日付や時間の操作 lubridateパッケージ hmsパッケージ (日内時間の操作・蓄積に特化) 1.4.2 時系列データに対するクラス(1): tsクラス tsクラス: Rの時系列オブジェクトの基本クラス # AirPassengers, # Pan Am, # international passenger bokking (in 1000s) per month # 1949--1960 (Brown, 1963) data(AirPassengers) ap &lt;- AirPassengers ap #&gt; Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #&gt; 1949 112 118 132 129 121 135 148 148 136 119 104 118 #&gt; 1950 115 126 141 135 125 149 170 170 158 133 114 140 #&gt; 1951 145 150 178 163 172 178 199 199 184 162 146 166 #&gt; 1952 171 180 193 181 183 218 230 242 209 191 172 194 #&gt; 1953 196 196 236 235 229 243 264 272 237 211 180 201 #&gt; 1954 204 188 235 227 234 264 302 293 259 229 203 229 #&gt; 1955 242 233 267 269 270 315 364 347 312 274 237 278 #&gt; 1956 284 277 317 313 318 374 413 405 355 306 271 306 #&gt; 1957 315 301 356 348 355 422 465 467 404 347 305 336 #&gt; 1958 340 318 362 348 363 435 491 505 404 359 310 337 #&gt; 1959 360 342 406 396 420 472 548 559 463 407 362 405 #&gt; 1960 417 391 419 461 472 535 622 606 508 461 390 432 #is.ts(ap); is.vector(ap) #attributes(ap) class(ap) # tsクラス #&gt; [1] &quot;ts&quot; start(ap); end(ap); frequency(ap) #&gt; [1] 1949 1 #&gt; [1] 1960 12 #&gt; [1] 12 plot(ap, ylab = &quot;Passengers (1000&#39;s)&quot;) layout(1:2) plot(aggregate(ap)) # annual levelに累計, seasonal effectsの除去、trend cycle(ap) # データ内各アイテムのシーズン抽出 #&gt; Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #&gt; 1949 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1950 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1951 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1952 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1953 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1954 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1955 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1956 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1957 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1958 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1959 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1960 1 2 3 4 5 6 7 8 9 10 11 12 boxplot(ap ~ cycle(ap)) # seasonal effects 1.4.3 時系列データに対するクラス(2): zooクラスとxtsクラス 有用な時系列オブジェクトのクラス: zoo, xts zoo, xts共に, 多変量時系列を扱うことも可能 xtsは, zooに類似. かつ, 高速なため, 大規模DATAの処理に適している zooやxtsのメリット. 有用な関数が多数用意されている: differencing, merging, periodic sampling, applying rolling functions xtsパッケージは, zooパッケージが出来ること全てできる - zooクラス・オブジェクトの生成 - ts &lt;- zoo(x, dt) - 時間(index)は, Dateオブジェクト, POSIXctオブジェクト, 整数, 浮動小数点でも, 順序付き数値なら何でもOK - xtsクラス・オブジェクトの生成 - ts &lt;- xts(x, dt) - 時間(index)は, Dateオブジェクト, POSIXctオブジェクト等、日付や時間のクラスのみに対応 # R マニュアル vignette(&quot;zoo&quot;) vignette(&quot;xts&quot;) zooクラス library(zoo) # 日経平均先物(ラージ), 2018年2月5日, 1日内約定データ prices &lt;- c(22790, 22800, 22790, 22790, 22790) seconds &lt;- c(32400.014, 32400.020, 32400.035, 32400.036) # タイムスタンプ (秒) nkft_sec &lt;- zoo(prices, seconds) print(nkft_sec) #&gt; 32400.014 32400.02 32400.035 32400.036 #&gt; 22790 22800 22790 22790 # 同, 2023年9月25日〜9月29日(5営業日) prices &lt;- c(32480, 32080, 32150, 31850, 32020) dates &lt;- as.Date(c(&quot;2023-09-25&quot;, &quot;2023-09-26&quot;, &quot;2023-09-27&quot;, &quot;2023-09-28&quot;, &quot;2023-09-29&quot;)) # 日付 nkft_daily &lt;- zoo(prices, dates) print(nkft_daily) #&gt; 2023-09-25 2023-09-26 2023-09-27 2023-09-28 2023-09-29 #&gt; 32480 32080 32150 31850 32020 coredata(nkft_daily) # 株価の取り出し #&gt; [1] 32480 32080 32150 31850 32020 index(nkft_daily) # 時間の取り出し #&gt; [1] &quot;2023-09-25&quot; &quot;2023-09-26&quot; &quot;2023-09-27&quot; &quot;2023-09-28&quot; &quot;2023-09-29&quot; coredata(nkft_sec) #&gt; [1] 22790 22800 22790 22790 index(nkft_sec) #&gt; [1] 32400.01 32400.02 32400.03 32400.04 nkft_daily[2:4] #&gt; 2023-09-26 2023-09-27 2023-09-28 #&gt; 32080 32150 31850 nkft_daily[as.Date(&quot;2023-09-26&quot;)] #&gt; 2023-09-26 #&gt; 32080 nkft_daily[&quot;2023-09-26&quot;] # &lt;-- NO #&gt; 2023-09-26 #&gt; 32080 window(nkft_daily, start = as.Date(&#39;2023-09-26&#39;), end = as.Date(&#39;2023-09-28&#39;)) #&gt; 2023-09-26 2023-09-27 2023-09-28 #&gt; 32080 32150 31850 library(xts) first(nkft_sec) # 最初のデータ #&gt; 32400.014 #&gt; 22790 last(nkft_sec) # 最後のデータ #&gt; 32400.036 #&gt; 22790 1.4.3.1 quantmodパッケージの利用による株価取得 &amp; チャート作成 library(&#39;quantmod&#39;) yj8411 &lt;- getSymbols(&#39;8411.T&#39;,from = &#39;2020-10-01&#39;, to = &#39;2023-09-29&#39;, src = &quot;yahoo&quot;, auto.assign = FALSE) # 注) R/RStudioや, guantmodのバージョンによっては, 動かないことがある # 注) 画面に&quot;Error in new.session() : Could not establish session after 5 attempts.&quot;が表示され, # 株価を取得できない場合には, quantmodのバージョンを最新のものにすること. chartSeries(ClCl(yj8411)) chartSeries(yj8411) chartSeries(OHLC(yj8411)) Mizuho_ret &lt;- diff(log(Ad(yj8411))) # Adjusted price plot(Mizuho_ret) chartSeries(Mizuho_ret) class(Mizuho_ret) #&gt; [1] &quot;xts&quot; &quot;zoo&quot; # 便利な関数の例 Mizuho_m &lt;- apply.monthly(Mizuho_ret, mean, na.rm = T) # xts Mizuho_w &lt;- apply.weekly(Mizuho_ret, mean, na.rm = T) # xts # zooオブジェクトの場合, 一旦xtsに変換して適用 # apply.monthly(as.xts(ts), df) Mizuho_ma5 &lt;- rollapply(Mizuho_ret, width = 5, mean, align = &quot;right&quot;) # zooパッケージ内 head(Mizuho_ma5) #&gt; 8411.T.Adjusted #&gt; 2020-10-02 NA #&gt; 2020-10-05 NA #&gt; 2020-10-06 NA #&gt; 2020-10-07 NA #&gt; 2020-10-08 NA #&gt; 2020-10-09 0.002418733 #Mizuho_ma21 &lt;- rollapply(Mizuho_ret, width = 21, mean, align = &quot;right&quot;) # zooパッケージ内 # timestamp is taken from the rightmost value chartSeries(Mizuho_ma5) #chartSeries(Mizuho_ma21) 1.5 時系列データの分解 - データセット: AirPassengers - Pan Am, # international passenger bokking (in 1000s) per month - 1949--1960 (Brown, 1963) data(AirPassengers) ap &lt;- AirPassengers ap #&gt; Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #&gt; 1949 112 118 132 129 121 135 148 148 136 119 104 118 #&gt; 1950 115 126 141 135 125 149 170 170 158 133 114 140 #&gt; 1951 145 150 178 163 172 178 199 199 184 162 146 166 #&gt; 1952 171 180 193 181 183 218 230 242 209 191 172 194 #&gt; 1953 196 196 236 235 229 243 264 272 237 211 180 201 #&gt; 1954 204 188 235 227 234 264 302 293 259 229 203 229 #&gt; 1955 242 233 267 269 270 315 364 347 312 274 237 278 #&gt; 1956 284 277 317 313 318 374 413 405 355 306 271 306 #&gt; 1957 315 301 356 348 355 422 465 467 404 347 305 336 #&gt; 1958 340 318 362 348 363 435 491 505 404 359 310 337 #&gt; 1959 360 342 406 396 420 472 548 559 463 407 362 405 #&gt; 1960 417 391 419 461 472 535 622 606 508 461 390 432 # is.ts(ap); is.vector(ap) # attributes(ap) class(ap) # tsクラス #&gt; [1] &quot;ts&quot; start(ap); end(ap); frequency(ap) #&gt; [1] 1949 1 #&gt; [1] 1960 12 #&gt; [1] 12 plot(ap, ylab = &quot;Passengers (1000&#39;s)&quot;) layout(1:2) plot(aggregate(ap)) # annual levelに累計, seasonal effectsの除去、trend cycle(ap) # データ内各アイテムのシーズン抽出 #&gt; Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #&gt; 1949 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1950 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1951 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1952 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1953 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1954 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1955 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1956 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1957 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1958 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1959 1 2 3 4 5 6 7 8 9 10 11 12 #&gt; 1960 1 2 3 4 5 6 7 8 9 10 11 12 boxplot(ap ~ cycle(ap)) # seasonal effects 1.5.1 トレンド抽出, 平滑化 (smoothing) 対称移動平均 (centered moving average) # filter()関数の使用 f12 &lt;- c(1 / 24, rep(1 / 12, 11), 1 / 24) f12 #&gt; [1] 0.04166667 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 #&gt; [7] 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 #&gt; [13] 0.04166667 ap_m &lt;- stats::filter(as.vector(ap), f12, sides = 2) # vectorとして入力 --&gt; 年情報が欠落 plot(cbind(as.vector(ap), ap_m)) # --&gt; 年情報が欠落 # ap_m2 &lt;- filter(ap, f12, sides = 2) # tsとして入力 # plot(cbind(ap, ap_m2)) # または ap_m &lt;- ts(ap_m, start = c(1949, 1), frequency = 12) # &lt;-- 年情報を戻す # plot(cbind(ap, ap_m)) # grid() # lines(1:length(ap_m), ap_m, col=&quot;blue&quot;) # トレンド除去済データ ap_s &lt;- ap - ap_m # 上のts()を使った式によるap_mの生成が必要 plot(ap_s) 1.5.2 分解モデル 時系列データ (確率過程のサンプルパス) を時系列プロットすることで, トレンドや周期性などの明確な規則性・パターンを観察できることがある. 原系列をこのような特徴を持つ成分に分解することで, 現象に対する解釈や理解を得たり, さらには, 成分ごとに 予測することで, 全体としてより精度の高い 原系列の予測を行える可能性がある. “古典的”方法 - decompose, &quot;古典的&quot;分解モデル (Rのデフォルト) - The function first determines the trend component using a moving average (if filter is NULL, a symmetric window with equal weights is used), and removes it from the time series. Then, the seasonal figure is computed by averaging, for each time unit, over all periods. The seasonal figure is then centered. Finally, the error component is determined by removing trend and seasonal figure (recycled as needed) from the original time series. 加法モデル (デフォルト) decompose(ap) #&gt; $x #&gt; Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #&gt; 1949 112 118 132 129 121 135 148 148 136 119 104 118 #&gt; 1950 115 126 141 135 125 149 170 170 158 133 114 140 #&gt; 1951 145 150 178 163 172 178 199 199 184 162 146 166 #&gt; 1952 171 180 193 181 183 218 230 242 209 191 172 194 #&gt; 1953 196 196 236 235 229 243 264 272 237 211 180 201 #&gt; 1954 204 188 235 227 234 264 302 293 259 229 203 229 #&gt; 1955 242 233 267 269 270 315 364 347 312 274 237 278 #&gt; 1956 284 277 317 313 318 374 413 405 355 306 271 306 #&gt; 1957 315 301 356 348 355 422 465 467 404 347 305 336 #&gt; 1958 340 318 362 348 363 435 491 505 404 359 310 337 #&gt; 1959 360 342 406 396 420 472 548 559 463 407 362 405 #&gt; 1960 417 391 419 461 472 535 622 606 508 461 390 432 #&gt; #&gt; $seasonal #&gt; Jan Feb Mar Apr May Jun #&gt; 1949 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1950 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1951 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1952 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1953 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1954 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1955 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1956 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1957 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1958 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1959 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; 1960 -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; Jul Aug Sep Oct Nov Dec #&gt; 1949 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1950 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1951 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1952 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1953 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1954 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1955 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1956 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1957 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1958 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1959 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; 1960 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; #&gt; $trend #&gt; Jan Feb Mar Apr May Jun Jul Aug #&gt; 1949 NA NA NA NA NA NA 126.7917 127.2500 #&gt; 1950 131.2500 133.0833 134.9167 136.4167 137.4167 138.7500 140.9167 143.1667 #&gt; 1951 157.1250 159.5417 161.8333 164.1250 166.6667 169.0833 171.2500 173.5833 #&gt; 1952 183.1250 186.2083 189.0417 191.2917 193.5833 195.8333 198.0417 199.7500 #&gt; 1953 215.8333 218.5000 220.9167 222.9167 224.0833 224.7083 225.3333 225.3333 #&gt; 1954 228.0000 230.4583 232.2500 233.9167 235.6250 237.7500 240.5000 243.9583 #&gt; 1955 261.8333 266.6667 271.1250 275.2083 278.5000 281.9583 285.7500 289.3333 #&gt; 1956 309.9583 314.4167 318.6250 321.7500 324.5000 327.0833 329.5417 331.8333 #&gt; 1957 348.2500 353.0000 357.6250 361.3750 364.5000 367.1667 369.4583 371.2083 #&gt; 1958 375.2500 377.9167 379.5000 380.0000 380.7083 380.9583 381.8333 383.6667 #&gt; 1959 402.5417 407.1667 411.8750 416.3333 420.5000 425.5000 430.7083 435.1250 #&gt; 1960 456.3333 461.3750 465.2083 469.3333 472.7500 475.0417 NA NA #&gt; Sep Oct Nov Dec #&gt; 1949 127.9583 128.5833 129.0000 129.7500 #&gt; 1950 145.7083 148.4167 151.5417 154.7083 #&gt; 1951 175.4583 176.8333 178.0417 180.1667 #&gt; 1952 202.2083 206.2500 210.4167 213.3750 #&gt; 1953 224.9583 224.5833 224.4583 225.5417 #&gt; 1954 247.1667 250.2500 253.5000 257.1250 #&gt; 1955 293.2500 297.1667 301.0000 305.4583 #&gt; 1956 334.4583 337.5417 340.5417 344.0833 #&gt; 1957 372.1667 372.4167 372.7500 373.6250 #&gt; 1958 386.5000 390.3333 394.7083 398.6250 #&gt; 1959 437.7083 440.9583 445.8333 450.6250 #&gt; 1960 NA NA NA NA #&gt; #&gt; $random #&gt; Jan Feb Mar Apr May Jun #&gt; 1949 NA NA NA NA NA NA #&gt; 1950 8.4987374 29.1047980 8.3244949 6.6199495 -7.9103535 -25.1527778 #&gt; 1951 12.6237374 26.6464646 18.4078283 6.9116162 9.8396465 -26.4861111 #&gt; 1952 12.6237374 29.9797980 6.1994949 -2.2550505 -6.0770202 -13.2361111 #&gt; 1953 4.9154040 13.6881313 17.3244949 20.1199495 9.4229798 -17.1111111 #&gt; 1954 0.7487374 -6.2702020 4.9911616 1.1199495 2.8813131 -9.1527778 #&gt; 1955 4.9154040 2.5214646 -1.8838384 1.8282828 -3.9936869 -2.3611111 #&gt; 1956 -1.2095960 -1.2285354 0.6161616 -0.7133838 -1.9936869 11.5138889 #&gt; 1957 -8.5012626 -15.8118687 0.6161616 -5.3383838 -4.9936869 19.4305556 #&gt; 1958 -10.5012626 -23.7285354 -15.2588384 -23.9633838 -13.2020202 18.6388889 #&gt; 1959 -17.7929293 -28.9785354 -3.6338384 -12.2967172 4.0063131 11.0972222 #&gt; 1960 -14.5845960 -34.1868687 -43.9671717 -0.2967172 3.7563131 24.5555556 #&gt; Jul Aug Sep Oct Nov Dec #&gt; 1949 -42.6224747 -42.0732323 -8.4785354 11.0593434 28.5934343 16.8699495 #&gt; 1950 -34.7474747 -35.9898990 -4.2285354 5.2260101 16.0517677 13.9116162 #&gt; 1951 -36.0808081 -37.4065657 -7.9785354 5.8093434 21.5517677 14.4532828 #&gt; 1952 -31.8724747 -20.5732323 -9.7285354 5.3926768 15.1767677 9.2449495 #&gt; 1953 -25.1641414 -16.1565657 -4.4785354 7.0593434 9.1351010 4.0782828 #&gt; 1954 -2.3308081 -13.7815657 -4.6868687 -0.6073232 3.0934343 0.4949495 #&gt; 1955 14.4191919 -5.1565657 2.2297980 -2.5239899 -10.4065657 1.1616162 #&gt; 1956 19.6275253 10.3434343 4.0214646 -10.8989899 -15.9482323 -9.4633838 #&gt; 1957 31.7108586 32.9684343 15.3131313 -4.7739899 -14.1565657 -9.0050505 #&gt; 1958 45.3358586 58.5101010 0.9797980 -10.6906566 -31.1148990 -33.0050505 #&gt; 1959 53.4608586 61.0517677 8.7714646 -13.3156566 -30.2398990 -17.0050505 #&gt; 1960 NA NA NA NA NA NA #&gt; #&gt; $figure #&gt; [1] -24.748737 -36.188131 -2.241162 -8.036616 -4.506313 35.402778 #&gt; [7] 63.830808 62.823232 16.520202 -20.642677 -53.593434 -28.619949 #&gt; #&gt; $type #&gt; [1] &quot;additive&quot; #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;decomposed.ts&quot; ap_decom &lt;- decompose(ap) # additive (デフォルト) plot(ap_decom) 原系列が正のトレンドを持ち, 水準が時間と共に切り上がるにつれて分散も増大. → 積分解がベター 乗法モデル オプション type = “multiplicative” (or “mult”) を指定 ap_decom_m &lt;- decompose(ap, type = &quot;mult&quot;) plot(ap_decom_m) trend &lt;- ap_decom_m$trend seasonal &lt;- ap_decom_m$seasonal ts.plot(cbind(trend, trend * seasonal), lty = 1:2) # トレンド成分 vs トレンド×季節性成分 または, 時系列を対数変換 lnap &lt;- log(ap) lnap_decom &lt;- decompose(lnap) plot(lnap_decom) trend &lt;- lnap_decom$trend seasonal &lt;- lnap_decom$seasonal ts.plot(cbind(trend, trend + seasonal), lty = 1:2) → 残差項の分散は, 加法モデルと比べて時間的に安定 参考文献: CM (2009), Ch.1 (自主課題) decompose()と同じように3成分に分解する自作関数を作成せよ 1.5.2.1 代替的方法 観察された1本の時系列データ\\({Y_t}\\)を, \\[ Y_t = m_t + s_t + \\epsilon_t \\] のように, トレンド\\(m_t\\), 季節性\\(s_t\\), 誤差項\\(\\epsilon_t\\) に分解する方法は無数に存在する. ここでは, R関数として利用可能なものを幾つか紹介する. - stl(), Seasonal Decomposition of Time Series by Loess - loess(locally weighted regression)によるsmoothingを行い, 3成分に分解 # plot(stl(ap, s.window = 13)) # plot(stl(ap, s.window = 5)) plot(stl(ap, s.window = &quot;per&quot;)) - timsac: 統数研開発パッケージ - H.Akaike, T.Ozaki, M.Ishiguro, Y.Ogata, G.Kitagawa, Y-H.Tamura, E.Arahata, K.Katsura and Y.Tamura (1984) Computer Science Monographs, Timsac-84 Part 1. The Institute of Statistical Mathematics. library(timsac) # decomp() # Decompose a nonstationary time series into several possible components by square-root filter. # トレンド成分、AR成分、季節変動成分、曜日効果、白色雑音 # データセット: Blsallfood data(Blsallfood) # アメリカの食品産業に従事する労働者の人数を毎月調べた時系列 (合衆国 Bureau of Labor Statistics (BLS) 公表) # z &lt;- decomp(Blsallfood, trade = TRUE, year = 1973) # year: the first year of the data z &lt;- decomp(Blsallfood, year = 1973) z$aic; z$lkhd #&gt; [1] 1505.477 #&gt; [1] -743.7385 z$sigma2; z$tau1; z$tau2; z$tau3 #&gt; [1] 209.0874 #&gt; [1] 0.0004305741 #&gt; [1] 1.0001 #&gt; NULL z &lt;- decomp(Blsallfood, trade = TRUE, year = 1973) # decomp(as.vector(ap), year = 1949) # OK? z &lt;- decomp(ap, year = 1949) - baysea() - Decompose a nonstationary time series into several possible components z &lt;- baysea(ap, forecast = 12) 代替的方法: Prophet パッケージprophet内, 関数prophet() https://facebook.github.io/prophet/docs/quick_start.html#r-api https://cran.r-project.org/web/packages/prophet/prophet.pdf “非線形のトレンドに年次・週次・日次の季節性, さらに 休日効果を加えた加法モデルに基づいて時系列データを予測する手続を実装. 強い季節性があり, 数シーズンの過去データを持つ時系列データに対して良く機能. 欠損値やトレンドのシフトに対して頑強. 通常, 外れ値をうまく処理.” prophet()の主な引数 - growth: &quot;linear&quot;(デフォルト), &quot;logisitc&quot;, &quot;flat&quot; - changepoints (変化点): 日付ベクトルをユーザー指定 or 潜在的な変化点の自動選択(デフォルト) - n.changepoints (変化点の数): 25 (デフォルト) - yearly.seasonality (年次季節性への適合): &quot;auto&quot;(デフォルト), T, F, 生成するFourier項の数 - weekly.seasonality (週次季節性への適合): 同上 - daily.seasonality (週次季節性への適合): 同上 - holidays (休日の指定): なし(デフォルト - seasonality.mode (季節性の入り方): &quot;additive&quot;(加法的)(デフォルト), &quot;multiplictive&quot;(乗法的) # install.packages(&quot;prophet&quot;) library(prophet) library(zoo) # index, yearmon # 以下, 生データのまま使用 (対数変換せず) # 年月の取り出し tt &lt;- as.Date(yearmon(index(ap))) prophetモデルの適合 # prophetモデルの生成 ap_df &lt;- data.frame(ds = tt, y = ap) ap_ppht &lt;- prophet(ap_df) # 予測年月の生成 dates_ft &lt;- make_future_dataframe(ap_ppht, periods = 12, freq = &quot;month&quot;) tail(dates_ft) #&gt; ds #&gt; 151 1961-07-01 #&gt; 152 1961-08-01 #&gt; 153 1961-09-01 #&gt; 154 1961-10-01 #&gt; 155 1961-11-01 #&gt; 156 1961-12-01 適合モデルによる予測 # 予測値の生成 ap_forecast &lt;- predict(ap_ppht, dates_ft) tail(ap_forecast[c(&#39;ds&#39;, &#39;yhat&#39;, &#39;yhat_lower&#39;, &#39;yhat_upper&#39;)]) #&gt; ds yhat yhat_lower yhat_upper #&gt; 151 1961-07-01 576.3980 548.8417 603.8002 #&gt; 152 1961-08-01 576.8090 550.0218 606.4126 #&gt; 153 1961-09-01 528.3037 500.7222 557.7332 #&gt; 154 1961-10-01 493.0463 464.1433 520.1720 #&gt; 155 1961-11-01 459.2066 430.9610 489.4143 #&gt; 156 1961-12-01 488.5528 455.9171 517.2366 str(ap_forecast) #&gt; &#39;data.frame&#39;: 156 obs. of 16 variables: #&gt; $ ds : POSIXct, format: &quot;1949-01-01&quot; &quot;1949-02-01&quot; ... #&gt; $ trend : num 106 108 110 113 115 ... #&gt; $ additive_terms : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ additive_terms_lower : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ additive_terms_upper : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ yearly : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ yearly_lower : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ yearly_upper : num -21.951 -30.725 -0.498 -5.184 -3.774 ... #&gt; $ multiplicative_terms : num 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ multiplicative_terms_lower: num 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ multiplicative_terms_upper: num 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ yhat_lower : num 53.8 49.4 80.8 77.1 83 ... #&gt; $ yhat_upper : num 113 108 138 136 138 ... #&gt; $ trend_lower : num 106 108 110 113 115 ... #&gt; $ trend_upper : num 106 108 110 113 115 ... #&gt; $ yhat : num 84.3 77.7 109.9 107.4 110.9 ... plot(ap_ppht, ap_forecast) # prophetによる予測の各成分のプロット prophet_plot_components(ap_ppht, ap_forecast) 1.5.2.2 代替的方法: Holt-Winters法 原系列が, level (講義資料では”水準”), trend (“傾き”), seasonality (“季節性”) の成分 (のいずれか) で構成されているとみなし, 各構成成分に指数平滑化法を適用して予測値を計算し, それらを積み上げて原系列の予測値を算出するアプローチ. 時系列の分解は手段であり, 原系列の将来予測の方に興味. 関数HoltWinters() 与えられた時系列に対してHolt-Wintersフィルタリングを実行 未知パラメータは平方予測誤差で決定 標準ライブラリstatsに含まれる Usage: HoltWinters(x, alpha = NULL, beta = NULL, gamma = NULL, seasonal = c(&quot;additive&quot;, &quot;multiplicative&quot;), start.periods = 2, l.start = NULL, b.start = NULL, s.start = NULL, optim.start = c(alpha = 0.3, beta = 0.1, gamma = 0.1), optim.control = list()) Holt-Wintersフィルタリングの実行 (季節性に関する乗法バージョン) ap_hw &lt;- HoltWinters(ap, seasonal = &quot;mult&quot;) # 原系列 (観測値) vs (各成分を合計した) フィルタ値 plot(ap_hw) 各成分 (状態変数) の推定値 a: level (水準), b: trend (傾き), s1–sp: seasonality (季節性) ap_hw$coef #&gt; a b s1 s2 s3 s4 #&gt; 469.3232206 3.0215391 0.9464611 0.8829239 0.9717369 1.0304825 #&gt; s5 s6 s7 s8 s9 s10 #&gt; 1.0476884 1.1805272 1.3590778 1.3331706 1.1083381 0.9868813 #&gt; s11 s12 #&gt; 0.8361333 0.9209877 平滑化パラメータの各推定値 (デフォルト: 1期先予測の平方誤差を最小化) 1に近い → 適応性が高い・直近の情報にウェイト 0に近い → 持続性が高い・過去の情報にもウェイト (より滑らかなパス) ap_hw$alpha; ap_hw$beta; ap_hw$gamma #&gt; alpha #&gt; 0.2755925 #&gt; beta #&gt; 0.03269295 #&gt; gamma #&gt; 0.8707292 # ap_hw$seasonal → 季節性成分 (\\(\\hat{\\gamma}=0.87\\)) は適応性が高く, 傾き成分 (\\(\\hat{\\beta}=0.03\\)) は持続性が高い 予測誤差 (1期先予測に対する) # 誤差平方和 ap_hw$SSE #&gt; [1] 16570.78 # RMSE sqrt(ap_hw$SSE / length(ap)) #&gt; [1] 10.72729 # 原系列の標準偏差 sd(ap) #&gt; [1] 119.9663 成分ごとの各時点\\(t\\)におけるフィルタ値と残差 # 成分ごとの各時点tにおけるフィルタ値 (filtered series) plot(ap_hw$fitted) # 残差 residuals(ap_hw) #&gt; Jan Feb Mar Apr May #&gt; 1950 3.918191291 3.668547859 3.560987430 2.676619655 1.520319537 #&gt; 1951 10.169631710 0.294856559 11.459174000 1.250271622 22.242492007 #&gt; 1952 0.639058465 2.561809528 -13.247937478 -4.960743337 -1.798362274 #&gt; 1953 -2.309951793 -10.984490575 11.807034404 20.934576164 6.324760310 #&gt; 1954 -7.884606924 -25.278507451 -6.844292266 -4.126648634 11.152422735 #&gt; 1955 9.492307599 6.844512503 -17.984109810 -2.954044415 -4.414349879 #&gt; 1956 2.366074092 7.032754109 -3.174999872 -8.276899149 -4.045741326 #&gt; 1957 -0.103179026 -3.405357956 6.941798182 -1.292551022 -0.073176743 #&gt; 1958 -12.616294292 -16.810889595 -24.941371144 -24.190854481 -9.090123850 #&gt; 1959 9.356931169 7.005413487 15.314121160 9.501136587 12.869260335 #&gt; 1960 3.083235437 -1.451160572 -41.170501367 25.578209728 6.904887268 #&gt; Jun Jul Aug Sep Oct #&gt; 1950 1.332711685 7.556756288 4.470410387 4.112287706 -3.318641449 #&gt; 1951 -7.647723596 -7.262153619 -4.180886326 -2.419252204 3.852200863 #&gt; 1952 22.315604495 2.501602281 12.995228211 -6.630984243 4.713402630 #&gt; 1953 -13.737994926 -4.358000825 -3.595138563 -3.950054519 -5.418708751 #&gt; 1954 19.596410444 31.074569878 4.536718996 5.674435479 0.542766289 #&gt; 1955 13.889124087 26.518519783 11.014466838 14.163333928 6.699554535 #&gt; 1956 6.048821526 -4.203225397 10.393752287 2.693344663 -2.449808881 #&gt; 1957 7.639077734 2.908853356 18.020294032 6.364989620 1.549021882 #&gt; 1958 -0.498537076 12.581616475 28.702263571 -13.219138602 4.563093559 #&gt; 1959 -19.604975309 4.219977680 9.064706000 13.361230112 7.086972733 #&gt; 1960 0.647289130 5.264644362 -21.551048083 -2.133147349 14.837197056 #&gt; Nov Dec #&gt; 1950 -5.090610790 6.011280050 #&gt; 1951 7.631271802 -3.141340932 #&gt; 1952 5.962357239 1.157482330 #&gt; 1953 -11.302349202 -11.165209087 #&gt; 1954 4.233276856 2.674631856 #&gt; 1955 0.007456865 11.099310837 #&gt; 1956 4.303662198 -3.394161373 #&gt; 1957 0.756961385 -9.615242815 #&gt; 1958 -1.876474530 -8.975126182 #&gt; 1959 13.602784883 18.347906089 #&gt; 1960 -5.452817647 -2.572462781 先述の諸手法との比較のため, 原系列を”トレンド”と季節性, “ノイズ”に分解 (水準と傾き → “トレンド”に統合) ap_hw_decomp &lt;- ts.union(y = ap_hw$x, trend = ap_hw$fitted[, &quot;level&quot;] + ap_hw$fitted[, &quot;trend&quot;], season = ap_hw$fitted[, &quot;season&quot;], resid. = residuals(ap_hw)) plot(ap_hw_decomp, main = &quot;Holt-Winters&quot;) 外挿予測 (3年先まで) # 予測 ap_hw_pred &lt;- predict(ap_hw, n.ahead = 3*12) ts.plot(ap, ap_hw_pred, lty = 1:2) Non-Seasonal Holt-Wintersの実行例 データセット: uspop - 米国の国勢調査人口 (百万人), 1790--1970年 x &lt;- uspop + rnorm(uspop, sd = 5) m &lt;- HoltWinters(x, gamma = FALSE) plot(m) "],["定常性と自己相関関数.html", "2 定常性と自己相関関数 2.1 確率過程の2次特性: 平均関数と自己共分散関数 2.2 定常性 (stationarity) 2.3 標本平均と標本自己共分散関数 2.4 R操作: 標本ACF 2.5 母ACF vs 標本ACF", " 2 定常性と自己相関関数 2.1 確率過程の2次特性: 平均関数と自己共分散関数 \\(E[X_t]&lt;\\infty\\)である確率過程 \\(\\{X_t,t=0,\\pm1,\\pm2,\\ldots\\}\\) に対して以下の二つの関数を定義することができる. 平均関数 (mean function): \\[ \\mu_X(t) = E[X_t] \\qquad (\\#eq:mean.func)\\] 自己共分散関数 (autocovariance function): \\[ \\gamma_X(t,s) = Cov[X_t,X_s] = E[(X_t - \\mu_X(t))(X_s - \\mu_X(s))] \\] さらに, 自己相関関数 (autocorrelation function) も定義できる: \\[ \\rho_X(t,s) = \\frac{\\gamma_X(t,s)}{\\sqrt{\\gamma_X(t,t)}\\sqrt{\\gamma_X(s,s)}} \\] 時系列解析では, 主にこれら1次, 2次モーメントに依存する時系列的性質に注意を向ける. 2.2 定常性 (stationarity) 確率過程に関する規則性の概念の一つ 大雑把に言えば, \\(\\{X_t,t=0,\\pm1,\\pm2,\\ldots\\}\\) とそれが時間的に任意の整数\\(h\\)だけシフトした \\(\\{X_{t+h},t=0,\\pm1,\\pm2,\\ldots\\}\\) とが統計的に類似の性質を持つこと 理論面ばかりでなく, 時系列データの解析の実践面においても想定されることの多い重要な性質 大きく, 強定常性 (strict stationarity), 弱定常性 (weak stationarity)の2種類 2.2.1 強定常性 確率過程 \\(\\{X_t,t=0,\\pm1,\\pm2,\\ldots\\}\\) が強定常であるとは (定義): 任意の長さ\\(k=1,2,\\ldots\\), 任意の時点組合せ\\(t_1,t_2,\\ldots,t_k\\), 任意のラグ\\(h=0,\\pm1,\\pm2,\\ldots\\)に対して, 二つの確率変数ベクトル \\((X_{t_1},X_{t_2},\\ldots,X_{t_k})\\) と \\((X_{t_1+h},X_{t_2+h},\\ldots,X_{t_k+h})\\) が, 同じ確率分布を持つ. すなわち, 強定常であれば, \\(X_t\\)は同一分布を持つ. また, iid確率過程は, 強定常である. 2.2.2 弱定常性 確率過程 \\(\\{X_t,t=0,\\pm1,\\pm2,\\ldots\\}\\) が弱定常であるとは (定義): \\(\\mu_X(t)\\)が時間\\(t\\)に独立である: \\(\\mu_X(t) =\\mu_X(0) =: \\mu\\) \\(\\gamma_X(t+h,t)\\)が, 各\\(h\\)に対して時間\\(t\\)に独立である: : \\(\\gamma_X(t+h,t) = \\gamma_X(h,0) =: \\gamma_X(h)\\) さらに, 自己相関関数: \\[ \\rho_X(h) = \\frac{\\gamma_X(h)}{\\gamma_X(0)}\\] 習慣により, 時系列解析では単に“定常”と言えば弱定常を指す. 2.2.3 ホワイトノイズ 最も単純な定常過程にホワイトノイズ (白色ノイズ) がある. ホワイトノイズは, 時系列解析で使われる各種モデルの構築に中心的役割を果たす. ホワイトノイズ (“弱ホワイトノイズ”): 平均が一定(通常, ゼロ), 分散が有限で一定, 自己相関がゼロの確率過程 表記: \\(\\{X_t\\} \\sim WN(0,\\sigma^2)\\) 数式表現: \\(E[X_t]=0\\), \\(E[X_t^2]=\\sigma^2 &lt; \\infty \\quad (\\forall t)\\) \\[ E[X_t X_s] = \\begin{cases} \\sigma^2 &amp; (t = s)\\\\ 0 &amp; (t \\ne s) \\end{cases} \\quad (\\forall t,s) \\] IIDノイズ 有限分散を持つiid確率過程 (通常, 平均ゼロ) 独立性 → 無相関性により, ホワイトノイズと同じ形の自己共分散関数を持つ 表記: \\(\\{X_t\\} \\sim IID(0,\\sigma^2)\\) “強ホワイトノイズ”と呼ばれることもある 2.3 標本平均と標本自己共分散関数 観測された時系列データ\\(x_1,x_2,\\ldots,x_n\\)に対して 標本平均: \\[ \\bar{x} = \\frac{1}{n} \\sum_{t=1}^n x_t \\qquad (\\#eq:smean)\\] 確率過程 \\(\\{X_t,t=0,\\pm1,\\pm2,\\ldots\\}\\) の実現値を時間軸方向に平均した値 標本自己共分散関数: \\[ \\hat{\\gamma}(h) = \\frac{1}{n} \\sum_{i=1}^{n-|h|} (x_{t+|h|}-\\bar{x})(x_{t}-\\bar{x}),\\quad|h|&lt;n \\] 標本自己相関関数: \\[ \\hat{\\rho}(h) = \\frac{\\hat{\\gamma}(h)}{\\hat{\\gamma}(0)}, \\quad |h|&lt;n \\] 定常性の仮定が成立していなとくとも, 任意の時系列データに対して, (時間軸に沿って) 標本平均関数および標本自己共分散関数・標本自己相関関数を計算することができる. 標本自己共分散関数・標本自己相関関数の形状は, トレンドや周期性の存在を示す手掛かりとなる. 2.3.1 アンサンブル平均 vs 標本平均 平均関数の定義式における期待値 (式@ref(eq:mean.func)) は, 時点\\(t\\)において, 確率変数 \\(X_t\\) の全ての実現可能な値に対して平均を計算したもの (“アンサンブル平均”) である. 一方, 標本平均 (式(??)) は, 時系列データ (確率過程の実現値) を時間軸方向に平均した値 (時系列平均) である. よって, アンサンブル平均と時系列平均は, 概念的には別物である. データの背後にある確率過程\\(\\{X_t\\}\\)が定常であれば, 平均関数は定数値 \\(\\mu\\) を取るので, 標本平均を用いて推定する意味が出てくる. 標本平均 \\(\\bar{x}\\) の計算において, 十分に長いデータ期間を取る (標本サイズ \\(n \\rightarrow \\infty\\) ) ことで, \\(\\bar{x}\\) が真の値 \\(\\mu\\)に次第に近付いていく確率過程の性質を, (平均)エルゴード性 (ergodicity in (the) mean) と呼ぶ. 定常な確率過程を前提とした時系列解析は, 通常は, エルゴード性を有するモデルを前提に行われる. 2.4 R操作: 標本ACF 関数acf()を使うことで, 与えられた時系列データの標本自己相関関数 (標本ACF) を 計算し, コレログラムを作図することができる. 参考文献: CM, Ch.2 &amp; 4, Tsay, Ch.2 2.4.1 白色ノイズ 正規乱数を使って生成 → 正規白色ノイズ (Gaussian white noise)と呼ばれる. # 乱数のシード設定 set.seed(1) w &lt;- rnorm(100) # 時系列プロット plot(w, type = &quot;l&quot;) # ヒストグラム z &lt;- seq(-3, 3, length = 1000) hist(rnorm(100), prob = T, xlim = c(-3, 3)); points(z, dnorm(z), type = &quot;l&quot;) # 自己相関関数(ACF) acf(w) # 2乗系列のACF acf(w ^ 2) # 絶対値系列のACF acf(abs(w)) 2.4.2 ランダムウォーク 正規乱数を使って生成 → 正規ランダムウォーク (Gaussian random walk)と呼ばれる. x &lt;- cumsum(w) # 時系列プロット plot(x, type = &quot;l&quot;) # ACF acf(x) # 2乗系列のACF acf(x ^ 2) # 絶対値系列のACF acf(abs(x)) 2.4.3 非定常成分を含む時系列 2.4.3.1 AirPassengersデータ (出所: CM, Ch.2) 1章でも登場したAirPassengersデータを利用して, ACFを作成する. 特に, 同データに見られる非定常性成分であるトレンドや季節性がACFの形状にどのように影響するかを確認する. data(AirPassengers) ap &lt;- AirPassengers acf(ap) ACFはゆっくり減衰しつつ, 横軸が1.0 (月次データのラグ=12に対応) で, 山が作られることが観察される. 2.4.3.2 時系列の分解 関数decompose()を利用して積分解する. - トレンド成分 # 乗法モデルを仮定 ap_decom &lt;- decompose(ap, &quot;multiplicative&quot;) # トレンド成分 plot(ts(ap_decom$trend[7:138])) acf(ts(ap_decom$trend[7:138])) 正の (直線的な) トレンド → ACFの減衰が遅いことが確認される. 季節性成分 # 季節性成分 plot(ts(ap_decom$seasonal[7:138])) acf(ts(ap_decom$seasonal[7:138])) 1年周期 → 6ヶ月に負の最小値, 12ヶ月に正の最大値が確認される. ランダムノイズ成分 # ランダムノイズ成分 plot(ts(ap_decom$random[7:138])) acf(ts(ap_decom$random[7:138])) 周期性が未だ残っているが, 自己相関はかなり除去されたことが確認される. #library(zoo) # na.trim()使用 #acf(ap_decom$random, na.action = na.trim) # ← NA除去 # 標準偏差 sd(ap[7:138]) # sd of the original series #&gt; [1] 109.4187 sd(ap[7:138] - ap_decom$trend[7:138]) # after substracting the trend estimate #&gt; [1] 41.11491 sd(ap_decom$random[7:138]) # the error component #&gt; [1] 0.0333884 # → std dev gets smaller #または #library(zoo) #ap_d_zoo = zoo(ap_decom$random) 関数stl()の利用 # stl(): Seasonal Decomposition of Time Series by Loess ap_stl&lt;- stl(ap, &quot;period&quot;) # トレンド成分 plot(ap_stl$time.series[, &quot;trend&quot;]) # 季節性成分 plot(ap_stl$time.series[, &quot;seasonal&quot;]) # ランダムノイズ成分 plot(ap_stl$time.series[, &quot;remainder&quot;]) acf(ap_stl$time.series[, &quot;remainder&quot;]) 2.4.3.3 階差 (differencing) 次に, 時系列データに対して, 階差 (差分) 操作を行うことによりACFの形状がどう変化するかを観察する. 上の観察から, 原系列を一旦対数変換してから 階差を取る. # ap &lt;- AirPassengers # is.ts(ap); is.vector(ts) # ACF # acf(ap) # 対数値の階差系列のACF plot(diff(log(ap), lag = 1)) # 前月との階差 acf(diff(log(ap), lag = 1)) ラグ1の階差を取ることにより, トレンドは消えたが, 横軸1.0 (ラグ12ヶ月に対応) にピークがあり, この階差系列には1年の周期性が残っていることが分かる. plot(diff(log(ap), lag = 12)) # 1年前との階差 acf(diff(log(ap), lag = 12)) 一方, ラグ12の階差を取ると, 1年の周期性は概ね消えるが, 自己相関の減衰が遅く, トレンドが残った系列 であることが分かる. かばん検定 ラグ12の階差を取った系列に対して, Box-Pierce検定, Ljung-Box検定 を実行してみる. # かばん検定 (portmanteau test) Box.test(diff(log(ap), lag = 12)) # Box-Pierce検定 (デフォルト) #&gt; #&gt; Box-Pierce test #&gt; #&gt; data: diff(log(ap), lag = 12) #&gt; X-squared = 67.234, df = 1, p-value = 2.22e-16 Box.test(diff(log(ap), lag = 12), type = &quot;Ljung&quot;) # Ljung-Box検定 #&gt; #&gt; Box-Ljung test #&gt; #&gt; data: diff(log(ap), lag = 12) #&gt; X-squared = 68.774, df = 1, p-value &lt; 2.2e-16 2.4.3.4 株価データの例 (出所: Tsay, Ch.2) 教科書のIBM月次株価データを利用して ACFを計算する. ifl &lt;- file.path(idir, &quot;m-ibmsp-2611.txt&quot;) da &lt;- read.table(&quot;m-ibmsp-2611.txt&quot;, header = T) #da &lt;- read.table(&quot;m-ibmsp6709.txt&quot;, header = T) head(da) #&gt; data ibm sp #&gt; 1 19260130 -0.010381 0.022472 #&gt; 2 19260227 -0.024476 -0.043956 #&gt; 3 19260331 -0.115591 -0.059113 #&gt; 4 19260430 0.089783 0.022688 #&gt; 5 19260528 0.036932 0.007679 #&gt; 6 19260630 0.068493 0.043184 ibm &lt;- da$ibm sp5 &lt;- da$sp plot(sp5, ibm) plot(ibm, type = &quot;l&quot;) plot(cumsum(log(ibm + 1)), type = &quot;l&quot;) # 原系列に対する自己相関性の検証 acf(ibm) acf(ibm)$acf #&gt; , , 1 #&gt; #&gt; [,1] #&gt; [1,] 1.000000000 #&gt; [2,] 0.037561974 #&gt; [3,] -0.008664145 #&gt; [4,] -0.016156989 #&gt; [5,] -0.030554233 #&gt; [6,] 0.015370816 #&gt; [7,] -0.041809301 #&gt; [8,] 0.003236462 #&gt; [9,] 0.063082544 #&gt; [10,] 0.048232274 #&gt; [11,] 0.037150816 #&gt; [12,] 0.011816712 #&gt; [13,] 0.010848647 #&gt; [14,] -0.067274698 #&gt; [15,] -0.011545286 #&gt; [16,] -0.038790792 #&gt; [17,] 0.031043139 #&gt; [18,] 0.029670820 #&gt; [19,] 0.065795548 #&gt; [20,] 0.019771486 #&gt; [21,] -0.013009184 #&gt; [22,] -0.012984508 #&gt; [23,] 0.002353094 #&gt; [24,] -0.072724702 #&gt; [25,] 0.053508492 #&gt; [26,] -0.010189813 #&gt; [27,] 0.036015597 #&gt; [28,] 0.019976030 #&gt; [29,] 0.032989584 #&gt; [30,] 0.004650878 #&gt; [31,] -0.016390330 Box.test(ibm, lag = 30) # Box-Pierce (デフォルト) #&gt; #&gt; Box-Pierce test #&gt; #&gt; data: ibm #&gt; X-squared = 38.094, df = 30, p-value = 0.1473 Box.test(ibm, lag = 30, type = &#39;Ljung&#39;) # Ljung-Box #&gt; #&gt; Box-Ljung test #&gt; #&gt; data: ibm #&gt; X-squared = 38.75, df = 30, p-value = 0.1314 #lnibm &lt;- log(ibm + 1) # Transfer to log returns #Box.test(lnibm, lag = 30, type = &#39;Ljung&#39;) # 絶対値系列, 2乗系列に対する自己相関性の検証 acf(abs(ibm)) acf(ibm ^ 2) Box.test(abs(ibm), lag = 30, type = &#39;Ljung&#39;) # Ljung-Box #&gt; #&gt; Box-Ljung test #&gt; #&gt; data: abs(ibm) #&gt; X-squared = 256.75, df = 30, p-value &lt; 2.2e-16 Box.test(ibm^2, lag = 30, type = &#39;Ljung&#39;) # Ljung-Box #&gt; #&gt; Box-Ljung test #&gt; #&gt; data: ibm^2 #&gt; X-squared = 189.3, df = 30, p-value &lt; 2.2e-16 2.4.4 線形・定常時系列モデル 2.4.4.1 MA(1)・AR(1)モデル 2.4.4.1.1 シミュレーションによるパス生成 AR(1)モデル #par(mfrow = c(3,1)) tlen = 100 set.seed(1) phi &lt;- - 0.8 x &lt;- w &lt;- rnorm(100) for (t in 2:100) x[t] = phi * x[t-1] + w[t] plot(x, type = &quot;l&quot;) # 時系列プロット acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) MA(1)モデル theta &lt;- - 0.8 for (t in 2:100) x[t] &lt;- w[t] + theta * w[t-1] plot(x, type = &quot;l&quot;) # 時系列プロット acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 2.4.4.2 ARMA(1,1)モデル ARMA(1,1)モデル phi &lt;- 0.5; theta &lt;- 0.5 set.seed(1) x &lt;- arima.sim(n = tlen, model = list(order = c(1,0,1), ar = phi, ma = theta)) plot(x, type = &quot;l&quot;) # 時系列プロット acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 2.5 母ACF vs 標本ACF AR(2)モデルを例に, ACFの理論値 (母自己相関関数) とシミュレーションで生成した パスから計算される標本値 (標本自己相関関数) の形状を比較する. AR(2) モデルのシミュレーション 4つのパラメータセットに対して, 各400個の正規乱数を 使って, AR(2)モデルのサンプルパスを1本ずつ生成する. 次に, 各パスに対して関数acf()を適用し, コレログラムを2枚作図する. 左図が標本ACF (自己相関), 右図が標本PACF (偏自己相関) である. 本節では, 左図に注目する. sim_AR2 &lt;- function(phi_par, n_sim = 100, seed = 1, ...){ set.seed(seed) # par(mfrow = c(3, 1)) x &lt;- w &lt;- rnorm(n_sim) for (t in 3:n_sim) {x[t] &lt;- phi_par[1] * x[t-1] + phi_par[2] * x[t-2] + w[t]} par(mfrow = c(1, 1)) plot(x, type = &quot;l&quot;, ...) par(mfrow = c(1, 2)) acf(x, lag.max = 20); pacf(x, lag.max = 20) par(mfrow = c(1,1)) } # Tsay, p_57, Fig 2_9のパラメータ例 phi_par1 &lt;- c(1.2, -0.35) # (phi1, phi2) phi_par2 &lt;- c(0.6, -0.4) # (phi1, phi2) phi_par3 &lt;- c(0.2, 0.35) # (phi1, phi2) phi_par4 &lt;- c(-0.2, 0.35) # (phi1, phi2) nsize &lt;- 400 seed_tmp &lt;- 100 sim_AR2(phi_par1, n_sim = nsize, seed = seed_tmp, main = &quot;(1)&quot;) sim_AR2(phi_par2, n_sim = nsize, seed = seed_tmp, main = &quot;(2)&quot;) sim_AR2(phi_par3, n_sim = nsize, seed = seed_tmp, main = &quot;(3)&quot;) sim_AR2(phi_par4, n_sim = nsize, seed = seed_tmp, main = &quot;(4)&quot;) AR(2)のACF理論値の計算およびプロット AR(2)の特性方程式の解 sol_AR2eqn &lt;- function(phi_par){ D &lt;- phi_par[1]^2 + 4 * phi_par[2] if (D&gt;= 0){ z1 &lt;- (phi_par[1] + sqrt(D)) / (-2 * phi_par[2]) z2 &lt;- (phi_par[1] - sqrt(D)) / (-2 * phi_par[2]) } else{ z1 &lt;- complex(re = phi_par[1] / (-2 * phi_par[2]), im = sqrt(-D)/(-2 * phi_par[2])) z2 &lt;- complex(re = phi_par[1] / (-2 * phi_par[2]), im = -sqrt(-D)/(-2 * phi_par[2])) } return(c(z1,z2)) } sol_AR2eqn(phi_par1) ## [1] 2.000000 1.428571 sol_AR2eqn(phi_par2) ## [1] 0.75+1.391941i 0.75-1.391941i sol_AR2eqn(phi_par3) ## [1] -2.000000 1.428571 sol_AR2eqn(phi_par4) ## [1] -1.428571 2.000000 AR(2)のACF理論値: rhoに関する差分方程式(漸化式)より計算 plot_ACF_AR2 &lt;- function(phi_par, hlen = 20){ rho_0 &lt;- 1 rho_1 &lt;- phi_par[1]/(1-phi_par[2]) ACF_h &lt;- c(rho_0, rho_1) for (h in 1:hlen){ rho_2 = phi_par[1]*rho_1 + phi_par[2]*rho_0 ACF_h = c(ACF_h, rho_2) rho_0 = rho_1; rho_1 = rho_2 } barplot(ACF_h, main=phi_par) } 代替的アプローチ: 特性方程式の解を使って導出 plot_ACF_AR2_2 &lt;- function(phi_par, hlen = 20){ zvec &lt;- sol_AR2eqn(phi_par) # 特性方程式の解 rho_0 &lt;- 1 rho_1 &lt;- phi_par[1]/(1-phi_par[2]) # c1, c2に関する連立方程式 cvec &lt;- solve(matrix(c(1, 1 , 1 / zvec[1], 1 / zvec[2]), 2, byrow = T), c(rho_0, rho_1) ) hvec &lt;- 0:hlen if (! is_complex(zvec)){ # 実根の場合 if (zvec[1] != zvec[2]) ACF_h &lt;- cvec[1] * zvec[1] ^ (-hvec) + cvec[2] * zvec[2] ^ (-hvec) else ACF_h &lt;- zvec[1]^(-hvec) * (cvec[1] + cvec[2] * hvec) # 重根 } else{ # 複素共役 (complex conjugates) の場合 z_mod &lt;- Mod(zvec[1]) th &lt;- Arg(zvec[1]) ACF_h &lt;- z_mod ^ (-hvec) * cos(hvec * th) } barplot(ACF_h, main = phi_par) } plot_ACF_AR2(phi_par1) plot_ACF_AR2(phi_par2) plot_ACF_AR2(phi_par3) plot_ACF_AR2(phi_par4) 先に生成した理論ACFと, それぞれの形状が類似していることが 確認される. "],["armapqモデル.html", "3 ARMA\\((p,q)\\)モデル 3.1 ARMA\\((p,q)\\)モデルとは 3.2 ARMA\\((p,q)\\)モデルによる予測 3.3 ARMA\\((p,q)\\)モデルの推定 3.4 ARMA\\((p,q)\\)モデルの同定 (次数の特定) 3.5 R操作 3.6 データ分析例 (Tsay, Ch2より)", " 3 ARMA\\((p,q)\\)モデル 時系列解析の体系において中核をなす, 最も基本的な 特性をもつ線形・定常確率過程, その 線形・定常確率過程の中で, 実用上最も良く用いられる 時系列モデルのクラスにARMA\\((p,q)\\)モデルがある. ARMA\\((p,q)\\)モデルは, 有限個のパラメータで定常時系列の 動的構造を表現するパラメトリックなクラスである. AR\\((p)\\)項にMA\\((q)\\)項を加えることで, 比較的少数のパラメータを使って, 複雑な定常時系列の挙動, すなわち, 自己相関の構造を (近似的に) 表現することができる. 3.1 ARMA\\((p,q)\\)モデルとは 定常, かつ 次の差分方程式を満たす\\({X_t}\\): \\[ X_t - \\phi_1 X_{t-1} - \\cdots - \\phi_p X_{t-p}= Z_t + \\theta_1 X_{t-1} + \\cdots + \\theta_q Z_{t-q} \\tag{1}\\] コンパクトな代替表現: \\[ \\phi(B)X_t = \\theta(B) Z_t \\tag{2}\\] Backward shift operator \\(B\\) AR多項式 \\(\\phi(z)=1 - \\phi_1 z - \\cdots - \\phi_p z^p\\) MA多項式 \\(\\theta(z)=1 + \\theta_1 z + \\cdots + \\theta_q z^q\\) 因果性と反転可能性 差分方程式の解\\({X_t}\\) 形式的に解くと, \\[ X_t = \\frac{\\theta(B)}{\\phi(B)} Z_t \\tag{3}\\] 解が存在 (定常, 因果的) するための条件? 定常性: \\(\\phi(z) \\ne 0,\\ \\forall |z|=1\\) 因果性: \\(\\phi(z) \\ne 0,\\ \\forall |z|\\le 1\\) +反転可能性: \\(\\theta(z) \\ne 0,\\ \\forall |z|\\le 1\\) ※ \\(\\phi(z)=0, \\theta(z)=0\\)は共通根を持たない (識別可能性) ※ 因果性は実用上不可欠: \\(X_t = \\sum_{i=0}^{\\infty}\\psi_i Z_{t-i}\\) (with \\(\\sum_{i=0}^{\\infty}|\\psi_i|&lt;\\infty\\)) (MA\\((\\infty)\\)表現) ※ 反転可能性は推定のために付加する条件: \\(Z_t = \\sum_{i=0}^{\\infty}\\pi_i X_{t-i}\\) (with \\(\\sum_{i=0}^{\\infty}|\\pi_i|&lt;\\infty\\)) (AR\\((\\infty)\\)表現) ARMA\\((p,q)\\)モデルの意義 なぜ必要か? AR(p)過程 実際の時系列データの記述 → 大きな\\(p\\)が必要となる可能性 MA\\((q)\\)過程. 反転可能な場合, AR\\((\\infty)\\)表現が可能 \\[ Z_t = X_t + \\sum_{i=1}^{\\infty}\\pi_i X_{t-i} \\] ∴ AR\\((p)\\)過程にMA\\((q)\\)項を付与することで, 少ないパラメータで, 現象を表現できることが期待される 3.2 ARMA\\((p,q)\\)モデルによる予測 過去データ\\(X_t,X_{t-1},\\cdots,X_1\\)に基づき, \\(h\\)期先の値\\(X_{t+h}\\)を予測したい モデルを推定 → 推定モデルを使って予測 どのように予測するか? 定常過程の予測 (当然, ARMA\\((p,q)\\)過程を含む) 線形予測 (Best Linear Prediction) 線形回帰問題を解く(正規方程式の解) AR\\((p)\\)モデル → \\(\\phi\\)係数をそのまま予測に使用 一般的解法 (MA\\((q)\\), ARMA\\((p,q)\\)モデル等にも適用): アルゴリズムによる予測(Duribin-Levinsonアルゴリズム, Innovationアルゴリズム) 3.3 ARMA\\((p,q)\\)モデルの推定 モデルをどのように推定するか? 次数\\(p,q\\)の同定(identification) (モデル選択) モデルパラメータ\\(\\phi\\) , \\(\\theta\\)の推定 予備的な推定 (→ 最尤法の初期値に利用可能) AR\\((p)\\)モデルのみ: Yule-Walker法, Burg法 MA\\((q)\\), ARMA\\((p,q)\\)モデル: Innovationアルゴリズム, Hannan-Rissanenアルゴリズム等 最尤法 標準的には, \\(Z_t\\)が正規ホワイトノイズ (IID + 正規分布) → \\(X_t\\)は, Gaussian過程 \\(Z_t\\)が非正規のIIDノイズの場合でも, 大標本ならば使用OK モデル診断 適合モデルから得られた残差系列がホワイトノイズか? 時系列プロット, 標本ACFプロット 自己相関の検定, かばん検定 正規性検定 (qqプロット, Jarque-Bera検定など) 参考文献: Brockwell and Davis, Introduction to Time Series and Forecasting. 3.4 ARMA\\((p,q)\\)モデルの同定 (次数の特定) 標本自己相関(ACF), 標本偏自己相関(PACF)の使用 定常過程は, ACVF/ACFによって特徴付けられる →時系列データから標本SACFをプロット AR\\((p)\\) → PACFが\\((p+1)\\)次以降のラグが値\\(0\\) MA\\((q)\\) → ACFが\\((q+1)\\)次以降のラグが値\\(0\\) ARMA\\((p,q)\\) →Extended ACF(EACF)の表内で, “○”(値が有意でない)の領域中で最も左上の要素の位置(行\\(p\\),列\\(q\\))を見つける AIC, BICなどのモデル選択基準の使用 モデル推定と同時に行う モデル選択基準 = - 2・対数尤度 + 罰則項(パラメータ数の増加関数) 3.5 R操作 ARMA\\((p,q)\\)モデルの同定 (ACF/PACF/EACFの利用) AR(3)モデル #par(mfrow = c(3,1)) Tlen = 100 phi=c(0.5,-0.8, 0.5); theta = NULL set.seed(10) x = arima.sim(n = Tlen, model = list(order = c(3,0,0), ar = phi, ma = theta)) #plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) MA(2)モデル phi = NULL; theta=c(0.3,0.4) set.seed(10) x = arima.sim(n = Tlen, model = list(order = c(0,0,2), ar = phi, ma = theta)) #plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) par(mfrow = c(1, 1)) ARMA(2,1)モデル phi = c(0.3,-0.8); theta = 0.9 set.seed(10) x = arima.sim(n = Tlen, model = list(order = c(2,0,1), ar = phi, ma = theta)) #plot(x, type=&quot;l&quot;) # 時系列プロット par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) par(mfrow = c(1, 1)) require(TSA) ## Loading required package: TSA ## ## Attaching package: &#39;TSA&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## acf, arima ## The following object is masked from &#39;package:utils&#39;: ## ## tar m1 = eacf(x, 6, 8) # Simplified table ## AR/MA ## 0 1 2 3 4 5 6 7 8 ## 0 x x x x x o x o o ## 1 x x x x x x x o o ## 2 x o o o o o o o o ## 3 x o o o o o o o o ## 4 x x x o o o o o o ## 5 x o x o o o o o o ## 6 x o o o o o o o o print(m1$eacf, digits = 2) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## [1,] 0.30 -0.613 -0.41 0.304 0.3518 -0.131 -0.269 0.048 0.197 ## [2,] 0.34 -0.767 -0.43 0.462 0.3388 -0.214 -0.250 0.088 0.182 ## [3,] 0.50 -0.021 -0.13 -0.135 -0.0102 0.053 0.033 -0.095 -0.205 ## [4,] 0.51 -0.097 -0.11 -0.140 -0.0241 0.116 0.031 -0.062 -0.183 ## [5,] 0.26 -0.364 0.40 -0.137 -0.0169 -0.032 0.012 -0.078 -0.104 ## [6,] 0.47 -0.028 0.23 -0.162 0.0055 -0.045 0.055 -0.055 -0.114 ## [7,] 0.49 0.052 0.17 -0.067 -0.1727 -0.019 0.038 -0.070 -0.059 → EACFは\\((p,q)=(2,1)\\)を示唆. ARMA\\((p,q)\\)モデルの推定・診断 仮に\\((p,q)=(2,2)\\)を選んだとすると, (x.fit = arima(x,order = c(2,0,2))) # ARMA(2,2)モデルの推定(制約なし) ## ## Call: ## arima(x = x, order = c(2, 0, 2)) ## ## Coefficients: ## ar1 ar2 ma1 ma2 intercept ## 0.3556 -0.7777 0.8059 -0.0712 -0.0247 ## s.e. 0.0887 0.0687 0.1279 0.1353 0.1187 ## ## sigma^2 estimated as 0.9372: log likelihood = -140.93, aic = 291.87 # --&gt; 有意でない係数=0を指定 (x.fit2 = arima(x,order = c(2,0,2), fixed = c(NA,NA,NA,0,NA))) # 制約付き推定 ## ## Call: ## arima(x = x, order = c(2, 0, 2), fixed = c(NA, NA, NA, 0, NA)) ## ## Coefficients: ## ar1 ar2 ma1 ma2 intercept ## 0.3270 -0.7772 0.8604 0 -0.0260 ## s.e. 0.0706 0.0691 0.0802 0 0.1249 ## ## sigma^2 estimated as 0.9407: log likelihood = -141.07, aic = 290.15 tsdiag(x.fit2, gof = 20) # モデル診断 Box.test(x.fit2$residuals, lag = 20, type = &#39;Ljung&#39;) # Ljung-Box検定 ## ## Box-Ljung test ## ## data: x.fit2$residuals ## X-squared = 13.785, df = 20, p-value = 0.8412 パッケージ{forecast}の利用 モデルの自動選択・推定 require(forecast) ## Loading required package: forecast ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo ## Registered S3 methods overwritten by &#39;forecast&#39;: ## method from ## fitted.Arima TSA ## plot.Arima TSA (x.fit3 = auto.arima(x)) # AIC/AICc(デフォルト)/BICによりモデルを自動選択&amp;推定 ## Series: x ## ARIMA(2,0,1) with zero mean ## ## Coefficients: ## ar1 ar2 ma1 ## 0.3273 -0.7773 0.8606 ## s.e. 0.0706 0.0691 0.0801 ## ## sigma^2 = 0.9702: log likelihood = -141.1 ## AIC=290.19 AICc=290.61 BIC=300.61 推定モデルを使った予測 (x.pred = forecast(x.fit3, h=20)) ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 101 4.8076600 3.5453579 6.0699620 2.8771355 6.7381844 ## 102 3.2942800 1.3342557 5.2543043 0.2966815 6.2918785 ## 103 -2.6587345 -4.6791846 -0.6382845 -5.7487463 0.4312772 ## 104 -3.4306758 -5.8473695 -1.0139821 -7.1266899 0.2653382 ## 105 0.9437980 -1.4734713 3.3610674 -2.7530964 4.6406925 ## 106 2.9754436 0.3543532 5.5965340 -1.0331682 6.9840554 ## 107 0.2401888 -2.4072595 2.8876371 -3.8087340 4.2891116 ## 108 -2.2341203 -4.9639829 0.4957423 -6.4090848 1.9408442 ## 109 -0.9178543 -3.6944931 1.8587845 -5.1643569 3.3286483 ## 110 1.4361307 -1.3626481 4.2349096 -2.8442321 5.7164936 ## 111 1.1834256 -1.6613440 4.0281953 -3.1672741 5.5341253 ## 112 -0.7289626 -3.5757196 2.1177945 -5.0827018 3.6247766 ## 113 -1.1584110 -4.0375796 1.7207575 -5.5617193 3.2448973 ## 114 0.1874876 -2.6922716 3.0672467 -4.2167240 4.5916991 ## 115 0.9617589 -1.9352597 3.8587775 -3.4688487 5.3923665 ## 116 0.1690270 -2.7318039 3.0698578 -4.2674110 4.6054649 ## 117 -0.6922301 -3.5997273 2.2152671 -5.1388633 3.7544032 ## 118 -0.3579265 -3.2709875 2.5551344 -4.8130688 4.0972157 ## 119 0.4209117 -2.4936672 3.3354906 -4.0365521 4.8783755 ## 120 0.4159582 -2.5036126 3.3355289 -4.0491400 4.8810563 plot(x.pred) # 3.6 データ分析例 (Tsay, Ch2より) 出所: Tsay, Ch.2 (一部改変) 標本ACF pp.46–47 Example 2.1 ifl &lt;- file.path(dir_introTS, &quot;m-dec12910.txt&quot;) da = read.table(ifl, header=T) #da = read.table(&quot;m-dec12910.txt&quot;, header = T) head(da) ## date dec1 dec2 dec9 dec10 ## 1 19670131 0.068568 0.080373 0.180843 0.211806 ## 2 19670228 0.008735 0.011044 0.048767 0.064911 ## 3 19670331 0.039698 0.035364 0.067494 0.068904 ## 4 19670428 0.044030 0.037541 0.040785 0.044602 ## 5 19670531 -0.050631 -0.036233 -0.002191 0.000295 ## 6 19670630 0.014998 0.018870 0.102075 0.118678 d10 = da$dec10 # select the Decile 10 returns dec10 = ts(d10, frequency = 12, start = c(1967, 1)) par(mfcol = c(2, 1)) plot(dec10, xlab = &#39;year&#39;, ylab = &#39;returns&#39;) # matplot(da[, -1], type = &quot;l&quot;) title(main = &#39;(a): Simple returns&#39;) acf(d10, lag = 24) # command to obtain sample ACF of the data # RK: 有意性確認 f1 = acf(d10, lag = 24) f1$acf ## , , 1 ## ## [,1] ## [1,] 1.000000000 ## [2,] 0.227386585 ## [3,] -0.019026447 ## [4,] -0.021258247 ## [5,] 0.011011345 ## [6,] 0.002676057 ## [7,] -0.027654887 ## [8,] -0.016910608 ## [9,] -0.049183690 ## [10,] -0.039617756 ## [11,] 0.013265549 ## [12,] 0.061013220 ## [13,] 0.130411045 ## [14,] -0.036881195 ## [15,] -0.082462743 ## [16,] -0.020950139 ## [17,] 0.016726386 ## [18,] -0.013961209 ## [19,] -0.059422809 ## [20,] -0.082246074 ## [21,] -0.063641596 ## [22,] -0.039858376 ## [23,] 0.017770989 ## [24,] -0.015413528 ## [25,] 0.052212082 # (tt = f1$acf[13] * sqrt(516)) # nrow(da) = 516 (tt = f1$acf[13] * sqrt(length(d10))) # 絶対値の大きいh = 13でのt値 ## [1] 2.962369 Ljung-Box Q statistics P.48, Example 2.2 ifl &lt;- file.path(dir_introTS, &quot;m-ibmsp6709.txt&quot;) da = read.table(ifl, header=T) #da = read.table(&quot;m-ibmsp6709.txt&quot;, header = T) ibm = da$ibm lnibm = log(ibm + 1) # Transfer to log returns Box.test(ibm, lag = 12, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: ibm ## X-squared = 7.5666, df = 12, p-value = 0.818 Box.test(lnibm, lag = 12, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: lnibm ## X-squared = 7.4042, df = 12, p-value = 0.8298 AR, MA, ARMA (2.4–2.6) p.58, Example 2.3 GNP, 1947.Q1–2010.Q1 par(mfrow = c(1, 1)) ifl &lt;- file.path(dir_introTS, &quot;q-gnp4710.txt&quot;) da = read.table(ifl, header=T) #da = read.table(&quot;q-gnp4710.txt&quot;, header = T) head(da); tail(da); nrow(da) ## Year Mon Dat VALUE ## 1 1947 1 1 238.1 ## 2 1947 4 1 241.5 ## 3 1947 7 1 245.6 ## 4 1947 10 1 255.6 ## 5 1948 1 1 261.7 ## 6 1948 4 1 268.7 ## Year Mon Dat VALUE ## 248 2008 10 1 14317.2 ## 249 2009 1 1 14172.2 ## 250 2009 4 1 14164.2 ## 251 2009 7 1 14281.9 ## 252 2009 10 1 14442.8 ## 253 2010 1 1 14637.6 ## [1] 253 G = da$VALUE plot(G, type = &quot;l&quot;) LG = log(G) gnp = diff(LG) dim(da) ## [1] 253 4 #tdx = c(1:253) / 4 + 1947 # create the time index tdx = c(1:length(G)) / 4 + 1947 # 1947スタート, 四半期データ par(mfcol = c(2, 1)) plot(tdx, G, xlab = &#39;year&#39;, ylab = &#39;GNP&#39;, type = &#39;l&#39;) #plot(tdx[2:253], gnp, type = &#39;l&#39;, xlab = &#39;year&#39;, ylab = &#39;growth&#39;) plot(tdx[-1], gnp, type = &#39;l&#39;, xlab = &#39;year&#39;, ylab = &#39;growth&#39;) # par(mfrow = c(1, 2)) acf(gnp, lag = 12) pacf(gnp, lag = 12) # compute PACF par(mfrow = c(1, 1)) arima(): 一変量arimaモデルの適合 (次数order, 分析者が指定) (m1 = arima(gnp, order = c(3, 0, 0))) # ARIMA(3, 0, 0) = AR(3) ## ## Call: ## arima(x = gnp, order = c(3, 0, 0)) ## ## Coefficients: ## ar1 ar2 ar3 intercept ## 0.4386 0.2063 -0.1559 0.0163 ## s.e. 0.0620 0.0666 0.0626 0.0012 ## ## sigma^2 estimated as 9.549e-05: log likelihood = 808.56, aic = -1607.12 tsdiag(m1, gof = 12) # model checking discussed later p1 = c(1, -m1$coef[1:3]) # set-up the polynomial (AR係数) (r1 = polyroot(p1)) # solve the polynomial equation (AR特性方程式の解) ## [1] 1.616116+8.642123e-01i -1.909216+3.670031e-17i 1.616116-8.642123e-01i Mod(r1) # compute absolute value ## [1] 1.832674 1.909216 1.832674 (k = 2 * pi / acos(1.616116 / 1.832674)) # compute length of the period ## [1] 12.79523 # &lt;-- (ACF)周期の計算, p.56内, k = の式 (参考) zooクラスにして実行した場合 library(zoo) ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric G.zoo = zoo(G, tdx) plot(G.zoo) m1.zoo = arima(diff(log(G.zoo)), order = c(3, 0, 0)) tsdiag(m1.zoo, gof = 12) # gnp.zoo = zoo(gnp, tdx[-1]) gnp.zoo = diff(log(G.zoo)) # zoo クラス plot(gnp.zoo) # Q statistic: based on lag autocorrelation coefficients Box.test(m1.zoo$residuals, lag = 1, type = &quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: m1.zoo$residuals ## X-squared = 0.0071647, df = 1, p-value = 0.9325 Box.test(m1.zoo$residuals, lag = 5, type = &quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: m1.zoo$residuals ## X-squared = 6.1525, df = 5, p-value = 0.2917 Box.test(m1.zoo$residuals, lag = 12, type = &quot;Ljung-Box&quot;) # → p = 0.05271 ## ## Box-Ljung test ## ## data: m1.zoo$residuals ## X-squared = 20.844, df = 12, p-value = 0.05271 p.63 mm1 = ar(gnp, method = &#39;mle&#39;) # yule-walker(デフォルト), burg, ols, yw # aic = T (デフォルト) --&gt; 次数選択実行 mm1$order # Find the identified order ## [1] 9 names(mm1) ## [1] &quot;order&quot; &quot;ar&quot; &quot;var.pred&quot; &quot;x.mean&quot; &quot;aic&quot; ## [6] &quot;n.used&quot; &quot;n.obs&quot; &quot;order.max&quot; &quot;partialacf&quot; &quot;resid&quot; ## [11] &quot;method&quot; &quot;series&quot; &quot;frequency&quot; &quot;call&quot; &quot;asy.var.coef&quot; print(mm1$aic, digits = 3) ## 0 1 2 3 4 5 6 7 8 9 10 ## 77.767 11.915 8.792 4.669 6.265 5.950 5.101 4.596 6.541 0.000 0.509 ## 11 12 ## 2.504 2.057 aic = mm1$aic # For plotting below. length(aic) ## [1] 13 plot(c(0:12), aic, type = &#39;h&#39;, xlab = &#39;order&#39;, ylab = &#39;aic&#39;) lines(0:12, aic, lty = 2) # RK: In ar.yw the variance matrix of the innovations is computed from the fitted coefficients and the autocovariance of x. (参考) zooクラス利用の場合 aic.zoo = zoo(aic, order.by = c(0:12)) plot(aic.zoo) table 2.1 (p.61)の例, Value-weighted Index # AR係数は小さいが有意. 定数項の有意性⇒期待値非ゼロ? #vw = read.table(&#39;m-ibm3dx.txt&#39;, header = T)[, 3] ifl &lt;- file.path(dir_introTS, &#39;m-ibm3dx2608.txt&#39;) vw = read.table(ifl, header=T)[, 3] ar(vw, method = &quot;mle&quot;) # demean = T ## ## Call: ## ar(x = vw, method = &quot;mle&quot;) ## ## Coefficients: ## 1 2 3 4 5 6 7 8 ## 0.1167 -0.0112 -0.1126 0.0217 0.0735 -0.0452 0.0254 0.0462 ## 9 ## 0.0660 ## ## Order selected 9 sigma^2 estimated as 0.002831 #ar(vw) # average annual simple gross returnの計算 (t1 = prod(vw + 1)) ## [1] 1592.953 # t1^(12 / 996)-1 # 年平均成長率 t1^(12 / length(vw))-1 # 年平均成長率 ## [1] 0.09290084 #tmp &lt;- ar(vw, method = &quot;mle&quot;) # tmp$ar / sqrt(diag(tmp$asy)) (m3 = arima(vw, order = c(3, 0, 0))) # include.mean = T (デフォルト) ## ## Call: ## arima(x = vw, order = c(3, 0, 0)) ## ## Coefficients: ## ar1 ar2 ar3 intercept ## 0.1158 -0.0187 -0.1042 0.0089 ## s.e. 0.0315 0.0317 0.0317 0.0017 ## ## sigma^2 estimated as 0.002875: log likelihood = 1500.86, aic = -2991.73 # --&gt; phi2有意でない (1-.1158 + .0187 + .1042)*mean(vw) # Compute the intercept phi(0). ## [1] 0.008967611 # m3$coef sqrt(m3$sigma2) # Compute standard error of residuals ## [1] 0.0536189 Box.test(m3$residuals, lag = 12, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: m3$residuals ## X-squared = 16.352, df = 12, p-value = 0.1756 # --&gt; X-squared = 16.352 (pv = 1-pchisq(16.35, 9)) # Compute p value using 12 degrees of freedom ## [1] 0.05992276 # ← カイ2乗分布の自由度12-3 = 9(AR多項式の次数p = 3) (m3 = arima(vw, order = c(3, 0, 0), fixed = c(NA, 0, NA, NA))) ## Warning in arima(vw, order = c(3, 0, 0), fixed = c(NA, 0, NA, NA)): some AR ## parameters were fixed: setting transform.pars = FALSE ## ## Call: ## arima(x = vw, order = c(3, 0, 0), fixed = c(NA, 0, NA, NA)) ## ## Coefficients: ## ar1 ar2 ar3 intercept ## 0.1136 0 -0.1063 0.0089 ## s.e. 0.0313 0 0.0315 0.0017 ## ## sigma^2 estimated as 0.002876: log likelihood = 1500.69, aic = -2993.38 # ← パラメータを推定する場合には&quot;NA&quot;指定: この例では, phi2 = 0 (1-.1136 + .1063)*.0089 # compute phi(0) ## [1] 0.00883503 sqrt(m3$sigma2) # compute residual standard error ## [1] 0.05362832 Box.test(m3$residuals, lag = 12, type = &#39;Ljung&#39;) ## ## Box-Ljung test ## ## data: m3$residuals ## X-squared = 16.828, df = 12, p-value = 0.1562 (pv = 1-pchisq(16.83, 10)) ## [1] 0.07821131 # ← カイ2乗分布の自由度12-2 = 10(AR多項式の次数p = 2) p.77 ifl &lt;- file.path(dir_introTS, &#39;m-ibm3dx2608.txt&#39;) da = read.table(ifl, header=T) head(da) ## date ibmrtn vwrtn ewrtn sprtn ## 1 19260130 -0.010381 0.000724 0.023174 0.022472 ## 2 19260227 -0.024476 -0.033374 -0.053510 -0.043956 ## 3 19260331 -0.115591 -0.064341 -0.096824 -0.059113 ## 4 19260430 0.089783 0.038358 0.032946 0.022688 ## 5 19260528 0.036932 0.012172 0.001035 0.007679 ## 6 19260630 0.068493 0.056888 0.050487 0.043184 ew = da$ewrtn (m1 = arima(ew, order = c(0, 0, 9))) # unrestricted model ## ## Call: ## arima(x = ew, order = c(0, 0, 9)) ## ## Coefficients: ## ma1 ma2 ma3 ma4 ma5 ma6 ma7 ma8 ## 0.2144 0.0374 -0.1203 -0.0425 0.0232 -0.0302 0.0482 -0.0276 ## s.e. 0.0316 0.0321 0.0328 0.0336 0.0319 0.0318 0.0364 0.0354 ## ma9 intercept ## 0.1350 0.0122 ## s.e. 0.0323 0.0028 ## ## sigma^2 estimated as 0.005043: log likelihood = 1220.86, aic = -2419.72 # --&gt; 有意でない係数 = 0を指定 (m1 = arima(ew, order = c(0, 0, 9), fixed = c(NA, 0, NA, 0, 0, 0, 0, 0, NA, NA))) ## ## Call: ## arima(x = ew, order = c(0, 0, 9), fixed = c(NA, 0, NA, 0, 0, 0, 0, 0, NA, NA)) ## ## Coefficients: ## ma1 ma2 ma3 ma4 ma5 ma6 ma7 ma8 ma9 intercept ## 0.1909 0 -0.1199 0 0 0 0 0 0.1227 0.0122 ## s.e. 0.0293 0 0.0338 0 0 0 0 0 0.0312 0.0027 ## ## sigma^2 estimated as 0.005097: log likelihood = 1215.61, aic = -2421.22 sqrt(0.005097) ## [1] 0.07139328 Box.test(m1$residuals, lag = 12, type = &#39;Ljung&#39;) # model checking ## ## Box-Ljung test ## ## data: m1$residuals ## X-squared = 17.604, df = 12, p-value = 0.1283 (pv = 1-pchisq(17.6, 9)) # compute p-value after adjusting the d.f. ## [1] 0.04010828 # ← カイ2乗分布の自由度12-3 = 9(AR多項式の次数p = 3) # Out-of-sample prediction (m1 = arima(ew[1:986], order = c(0, 0, 9), fixed = c(NA, 0, NA, 0, 0, 0, 0, 0, NA, NA))) ## ## Call: ## arima(x = ew[1:986], order = c(0, 0, 9), fixed = c(NA, 0, NA, 0, 0, 0, 0, 0, ## NA, NA)) ## ## Coefficients: ## ma1 ma2 ma3 ma4 ma5 ma6 ma7 ma8 ma9 intercept ## 0.1844 0 -0.1206 0 0 0 0 0 0.1218 0.0128 ## s.e. 0.0295 0 0.0338 0 0 0 0 0 0.0312 0.0027 ## ## sigma^2 estimated as 0.005066: log likelihood = 1206.44, aic = -2402.88 predict(m1, 10) # prediction ## $pred ## Time Series: ## Start = 987 ## End = 996 ## Frequency = 1 ## [1] 0.004282626 0.013558874 0.015024191 0.014453445 0.012046343 0.001805558 ## [7] 0.012211538 0.005514814 0.008513456 0.012791824 ## ## $se ## Time Series: ## Start = 987 ## End = 996 ## Frequency = 1 ## [1] 0.07117456 0.07237493 0.07237493 0.07288176 0.07288176 0.07288176 ## [7] 0.07288176 0.07288176 0.07288176 0.07339566 EACF table ifl &lt;- file.path(dir_introTS, &#39;m-3m4608.txt&#39;) da = read.table(ifl, header=T) head(da) ## date rtn ## 1 19460228 -0.077922 ## 2 19460330 0.018592 ## 3 19460430 -0.100000 ## 4 19460531 0.209877 ## 5 19460628 0.005128 ## 6 19460731 0.076531 mmm = log(da$rtn + 1) library(TSA) # Load the package ## ## Attaching package: &#39;TSA&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## acf, arima ## The following object is masked from &#39;package:utils&#39;: ## ## tar m1 = eacf(mmm, 6, 12) # Simplified table ## AR/MA ## 0 1 2 3 4 5 6 7 8 9 10 11 12 ## 0 o o x o o x o o o x o x o ## 1 x o x o o x o o o o o x o ## 2 x x x o o x o o o o o o o ## 3 x x x o o o o o o o o o o ## 4 x o x o o o o o o o o o o ## 5 x x x o x o o o o o o o o ## 6 x x x x x o o o o o o o o print(m1$eacf, digits = 2) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## [1,] -0.056 -0.0380 -0.082 -0.0046 0.01774 0.0821 0.0080 0.0127 -0.03014 ## [2,] -0.474 0.0096 -0.074 -0.0209 0.00196 0.0772 -0.0288 0.0026 -0.00683 ## [3,] -0.383 -0.3476 -0.074 0.0160 -0.00553 0.0772 0.0269 0.0120 0.00045 ## [4,] -0.177 0.1381 0.384 -0.0224 0.00232 0.0419 -0.0232 0.0154 -0.00440 ## [5,] 0.421 0.0287 0.454 -0.0079 0.00071 0.0025 -0.0140 0.0305 0.01159 ## [6,] -0.114 0.2135 0.449 0.0096 0.20242 -0.0063 -0.0038 0.0403 -0.01294 ## [7,] -0.208 -0.2504 0.243 0.3111 0.16745 -0.0388 -0.0034 0.0429 -0.01009 ## [,10] [,11] [,12] [,13] ## [1,] -0.0778 0.0488 0.0909 -0.011 ## [2,] -0.0694 0.0372 0.0938 -0.024 ## [3,] -0.0268 0.0221 0.0428 0.042 ## [4,] -0.0254 0.0185 0.0100 0.043 ## [5,] 0.0042 0.0191 -0.0043 0.013 ## [6,] -0.0123 0.0315 0.0117 0.028 ## [7,] -0.0260 0.0078 0.0106 0.037 # --&gt; ARMA(0, 0)モデル "],["arimasarimaモデル.html", "4 ARIMA/SARIMAモデル 4.1 ARIMA\\((p,d,q)\\)モデルとは 4.2 SARIMA\\((p,d,q)\\times (P,D,Q)_s\\)モデル (周期\\(s\\))とは 4.3 SARIMAモデルのパス生成: パッケージsarimaの利用 4.4 SARIMAモデルの推定・診断 4.5 データ分析例 4.6 外生変数があるケース", " 4 ARIMA/SARIMAモデル 4.1 ARIMA\\((p,d,q)\\)モデルとは \\(Y_t:=(1-B)^d X_t\\)が, causal ARMA\\((p,q)\\)となる確率過程\\(X_t\\) (\\(d\\)は非負整数), すなわち, \\[ \\phi(B)Y_t = \\theta(B) Z_t \\tag{2},\\qquad \\{Z_t\\} \\sim WN(0,\\sigma^2)\\] Backward shift operator \\(B\\) AR多項式 \\(\\phi(z)=1 - \\phi_1 z - \\cdots - \\phi_p z^p\\) MA多項式 \\(\\theta(z)=1 + \\theta_1 z + \\cdots + \\theta_q z^q\\) 4.2 SARIMA\\((p,d,q)\\times (P,D,Q)_s\\)モデル (周期\\(s\\))とは \\(Y_t:=(1-B)^d (1-B^s)^D X_t\\)が, 以下で定義されるcausal ARMAとなる確率過程\\(X_t\\) (\\(d,D\\)は非負整数) \\[ \\phi(B)\\Phi(B^s) Y_t = \\theta(B) \\Theta(B^s) Z_t \\tag{2}\\] Backward shift operator \\(B\\) AR多項式 \\(\\phi(z)=1 - \\phi_1 z - \\cdots - \\phi_p z^p\\) MA多項式 \\(\\theta(z)=1 + \\theta_1 z + \\cdots + \\theta_q z^q\\) SAR多項式 \\(\\Phi(z)=1 - \\Phi_1 z - \\cdots - \\Phi_p z^P\\) SMA多項式 \\(\\Theta(z)=1 + \\Theta_1 z + \\cdots + \\Theta_q z^Q\\) シミュレーションによるSARIMAモデルのパスの生成には, パッケージsarima収録の関数sim_sarima()が便利である. 標準パッケージstatsの関数arima.sim()はARIMAモデルのパスは生成できるが, SARIMAモデルのパスは生成できない. モデル推定については, statsの関数arima()は, SARIMAモデルの推定が可能である. 一方, forecastパッケージの関数auto.arima()を使っても, SARIMAモデルの推定が可能である. auto.arima()では, モデル推定の前提となる, SARIMAの形状を決定するモデル次数 (“ハイパー・パラメータ”) \\((p,d,q,P,D,Q)\\)も自動的に選択 (モデル同定) することができる. すなわち, auto.arima()を使えば, モデル同定を手動で行うことなく, 所与の時系列データに対して “最適な”モデルを一気に選択・推定ことができるので, 実務的に大変便利である. なお, 本章では扱わないが, 他のパッケージとしては, 例えばastsaは, シミュレーション用の関数 sarima.sim(), 推定用の関数 sarima(), 予測用の関数 sarima.for()を収録している. また, TSAは, 推定用の関数arima() (別名, arimax()), 予測用の関数 plot.Arima() を収録している. また, シミュレーションについては, $\\phi_1=0.9$を持つAR(1)モデルのパスを生成するar1.s(), $\\phi_1=0.4$を持つAR(1)モデルのパスを生成するar1.2.s()`, など, 具体的なモデルに関する関数を幾つか用意している. 4.3 SARIMAモデルのパス生成: パッケージsarimaの利用 以下, SARIMAの形状を決定するモデル次数 \\((p,d,q,P,D,Q)\\)の特別なケースを幾つか選んで, サンプルパスを1本生成し, 時系列プロットと 標本ACF/PACFのコレログラムを描いてみることで, 当該モデルの特性が表現されているかをみてみよう. “SAR(1)”モデル (s=12) library(sarima) ## Loading required package: stats4 ## ## Attaching package: &#39;sarima&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## spectrum #par(mfrow = c(3,1)) seed_val &lt;- 10 tlen &lt;- 144 set.seed(seed_val) #x &lt;- sim_sarima(n = tlen, model = list(ar = c(rep(0,11), 0.8))) # 12 seasons x &lt;- sim_sarima(n = tlen, model = list(sar = 0.8, nseasons = 12, sigma2 = 1)) # 12 seasons ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) “SMA(1)”モデル set.seed(seed_val) #x &lt;- sim_sarima(n = tlen, model = list(ma = c(rep(0,11), 0.8))) # 12 seasons x &lt;- sim_sarima(n = tlen,model = list(sma = 0.8, nseasons = 12, sigma2 = 1)) # 12 seasons ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) I(1) モデル (“Random Walk”) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(iorder = 1, sigma2 = 1)) # (1-B)X_t = e_t (random walk) ts.plot(x, type=&quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((0,0,0) \\times (0,1,0)_{12}\\) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(siorder = 1,nseasons = 12, sigma2 = 1)) # (1-B)^{12} X_t = e_t ts.plot(x, type=&quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((0,1,0) \\times (0,1,0)_{12}\\) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(iorder = 1, siorder = 1, nseasons = 12, sigma2 = 1)) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((0,1,0) \\times (0,1,0)_{12}\\)に, 初期値xを指定したシミュレーション x &lt;- sim_sarima(n = tlen, model = list(iorder = 1, siorder = 1, nseasons = 12, sigma2 = 1), x = list(init=AirPassengers[1:13])) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((0,0,0) \\times (1,0,1)_{12}\\) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(sar = 0.4, sma = 0.5, iorder = 0, siorder = 0, nseasons = 12)) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((0,0,1) \\times (1,0,1)_{12}\\) set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(ma = 0.7, sar = 0.4, sma = 0.5, iorder = 0, siorder = 0, nseasons = 12)) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) SARIMA\\((2,1,1) \\times (1,1,1)_{12}\\) \\[ (1 - 1.2 B + 0.8 B^2) (1 - 0.3 B^{12}) (1 - B) (1 - B^{12}) X_t = (1 - 0.4 B) (1 - 0.7 B^{12}) Z_t, \\ \\{Z_t\\}\\sim WN(0,1) \\] set.seed(seed_val) x &lt;- sim_sarima(n = tlen, model = list(ar = c(1.2, -0.8), ma = 0.4, sar = 0.3, sma = 0.7, iorder = 1, siorder = 1, nseasons = 12)) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) # par(mfrow = c(1,1)) → AICc基準 (デフォルト設定) の下で, 次のARIMA\\((2,1,1)(0,1,0)_{12}\\) モデルを最良モデルとして選択. 4.4 SARIMAモデルの推定・診断 標準パッケージstats収録の関数arima()を使って, SARIMAモデルを推定することができる (ちなみに, 同じパッケージ内の関数arima.sim()ではSARIMAモデルのパスを生成できない). 以下, 仮に\\((p,d,q)=(2,1,1), (P,D,Q)=(1,1,1), s=12\\)を正しく選んだとすると, (x.fit &lt;- arima(x, order = c(2,1,1), seasonal = list(order = c(1,1,1), period = 12))) ## ## Call: ## arima(x = x, order = c(2, 1, 1), seasonal = list(order = c(1, 1, 1), period = 12)) ## ## Coefficients: ## ar1 ar2 ma1 sar1 sma1 ## 1.2462 -0.8486 0.3504 0.2220 1.0000 ## s.e. 0.0589 0.0558 0.0842 0.0909 0.2598 ## ## sigma^2 estimated as 0.7217: log likelihood = -183.18, aic = 378.35 tsdiag(x.fit, gof = 20) # モデル診断 Box.test(x.fit$residuals,lag = 20,type = &#39;Ljung&#39;) # Ljung-Box検定 ## ## Box-Ljung test ## ## data: x.fit$residuals ## X-squared = 12.586, df = 20, p-value = 0.8944 なお, arima()の仕様によれば, ARIMAモデル指定 (\\(d\\ne0\\)) の場合には, 引数include.mean=TRUE (デフォルト) は無視される (定数項パラメータは推定されない). パッケージforecastの利用 パッケージforecastの関数auto.arima()を使えば, SARIMAモデルの自動選択・推定が可能である. すなわち, 引数seasonal=TRUE (デフォルト) によりSARIMAモデルを推定できる. これは, Hyndmanらが開発したアルゴリズムに基づいて計算される. auto.arima() - 一変量時系列データに対してARIMA/SARIMAモデルを適合し, 情報量基準(AIC, AICc, BICの一つ)の下で最良のARIMAモデルを返す - 所与の次数の制約条件の下で, 全ての可能なモデルの中からサーチを実行 - パラメータのデフォルト値: - max.p = 5 # pの最大値 - max.q = 5 # qの最大値 - max.P = 2 # Pの最大値 - max.Q = 2 # Qの最大値 - max.order = 5 # p+q+P+Qの最大値 - max.d = 2 # dの最大値 - max.D = 1 # Dの最大値 モデル自動選択&amp;推定 require(forecast) ## Loading required package: forecast ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo (x.fit3 &lt;- auto.arima(x)) # AIC/AICc(デフォルト)/BICによりモデルを自動選択&amp;推定 ## Series: x ## ARIMA(4,1,1) with drift ## ## Coefficients: ## ar1 ar2 ar3 ar4 ma1 drift ## 2.2193 -2.3467 1.3199 -0.4084 -0.7300 -3.0955 ## s.e. 0.0898 0.1786 0.1721 0.0780 0.0598 0.4031 ## ## sigma^2 = 14.72: log likelihood = -393.94 ## AIC=801.88 AICc=802.71 BIC=822.62 → モデルは正しく推定はされてはいない. 定数項は大きな値 モデル診断 tsdiag(x.fit3, gof = 20) # モデル診断 Box.test(x.fit3$residuals, lag = 20, type = &#39;Ljung&#39;) # Ljung-Box検定 ## ## Box-Ljung test ## ## data: x.fit3$residuals ## X-squared = 145.11, df = 20, p-value &lt; 2.2e-16 → 季節性も残留 推定モデルを使った予測 x.pred &lt;- forecast(x.fit3, h = 20) plot(x.pred) # 4.5 データ分析例 データセット: bonds bonds {expsmooth} - 米国10年債利回り(年率) , 1994.1〜2004.5, 月次 - データ出所: Hyndman, R.J., Koehler, A.B., Ord, J.K., and Snyder, R.D., (2008). Forecasting with exponential smoothing: the state space approach, Springer. コード出所 (一部改変): # Hyndman and Khandakar (JSS, 2008) https://www.jstatsoft.org/article/view/v027i03 library(forecast) library(expsmooth) # required for the data 季節性成分なしARIMAモデルを適合 # Seasonal成分なし bnd_aafit &lt;- auto.arima(bonds, max.P = 0, max.Q = 0, D = 0, approximation = FALSE) bnd_aafit ## Series: bonds ## ARIMA(0,1,1) ## ## Coefficients: ## ma1 ## 0.322 ## s.e. 0.090 ## ## sigma^2 = 0.05675: log likelihood = 2.38 ## AIC=-0.77 AICc=-0.67 BIC=4.88 → AICc基準 (デフォルト設定) の下で, 次のARIMA\\((0,1,1)\\equiv\\)IMA\\((1,1)\\)モデルを最良モデルとして選択. \\[ X_t = Z_t + 0.322 Z_{t-1}, \\ \\{Z_t\\}\\sim WN(0,0.05675) \\] モデル残差のチェック tsdiag(bnd_aafit) 適合ARIMAモデルを使って予測 bnd_fcast &lt;- forecast(bnd_aafit) # 時系列プロット plot(bnd_fcast) 予測値 (点予測) は青線, および, 予測区間は青線を囲む色のついた領域 (デフォルトでは, 内側の濃い色の領域が信頼水準80%, 外側の薄い色が95%) で表示される. 予測の長さは, デフォルトでは, 周期があれば, その2倍, なければ (周期=1) 10 である. 適合結果および予測結果の要約 summary(bnd_fcast) ## ## Forecast method: ARIMA(0,1,1) ## ## Model Information: ## Series: bonds ## ARIMA(0,1,1) ## ## Coefficients: ## ma1 ## 0.322 ## s.e. 0.090 ## ## sigma^2 = 0.05675: log likelihood = 2.38 ## AIC=-0.77 AICc=-0.67 BIC=4.88 ## ## Error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set -0.006475772 0.2363103 0.1948763 -0.1916236 3.544951 0.2414321 ## ACF1 ## Training set -0.01876417 ## ## Forecasts: ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## Jun 2004 4.761471 4.456175 5.066767 4.294561 5.228381 ## Jul 2004 4.761471 4.255410 5.267532 3.987517 5.535425 ## Aug 2004 4.761471 4.114176 5.408766 3.771519 5.751423 ## Sep 2004 4.761471 3.998659 5.524283 3.594850 5.928092 ## Oct 2004 4.761471 3.898468 5.624474 3.441621 6.081321 ## Nov 2004 4.761471 3.808755 5.714187 3.304418 6.218524 ## Dec 2004 4.761471 3.726793 5.796149 3.179067 6.343875 ## Jan 2005 4.761471 3.650862 5.872080 3.062941 6.460001 ## Feb 2005 4.761471 3.579801 5.943141 2.954263 6.568679 ## Mar 2005 4.761471 3.512777 6.010165 2.851758 6.671184 ## Apr 2005 4.761471 3.449172 6.073770 2.754483 6.768459 ## May 2005 4.761471 3.388510 6.134432 2.661709 6.861233 ## Jun 2005 4.761471 3.330418 6.192524 2.572864 6.950078 ## Jul 2005 4.761471 3.274593 6.248349 2.487488 7.035454 ## Aug 2005 4.761471 3.220790 6.302152 2.405203 7.117739 ## Sep 2005 4.761471 3.168803 6.354139 2.325696 7.197246 ## Oct 2005 4.761471 3.118461 6.404481 2.248704 7.274238 ## Nov 2005 4.761471 3.069616 6.453326 2.174001 7.348941 ## Dec 2005 4.761471 3.022141 6.500801 2.101396 7.421546 ## Jan 2006 4.761471 2.975929 6.547013 2.030720 7.492222 ## Feb 2006 4.761471 2.930883 6.592059 1.961828 7.561114 ## Mar 2006 4.761471 2.886919 6.636023 1.894592 7.628350 ## Apr 2006 4.761471 2.843963 6.678979 1.828896 7.694046 ## May 2006 4.761471 2.801948 6.720994 1.764640 7.758302 データセット: AirPassengers # データセット: AirPassengers ap &lt;- AirPassengers (デフォルトの制約条件下) SARIMAモデルを選択・適合 ap_aafit &lt;- auto.arima(ap, approximation = FALSE) ap_aafit ## Series: ap ## ARIMA(2,1,1)(0,1,0)[12] ## ## Coefficients: ## ar1 ar2 ma1 ## 0.5960 0.2143 -0.9819 ## s.e. 0.0888 0.0880 0.0292 ## ## sigma^2 = 132.3: log likelihood = -504.92 ## AIC=1017.85 AICc=1018.17 BIC=1029.35 → AICc基準 (デフォルト設定) の下で, 次のARIMA\\((2,1,1)(0,1,0)_{12}\\) モデルを最良モデルとして選択. \\[ (1 - 0.5960 B - 0.2143 B^2) (1 - B) (1 - B^{12}) X_t = (1 - 0.9819 B) Z_t, \\ \\{Z_t\\}\\sim WN(0,132.3) \\] モデル残差のチェック tsdiag(ap_aafit) 適合SARIMAモデルを使って予測 ap_fcast &lt;- forecast(ap_aafit) # 時系列プロット plot(ap_fcast) 24ヶ月先 (デフォルト設定により, 周期\\(s=12 \\times 2\\)倍) まで 予測を行っている. 先の米国債利回りデータと比べても, 予測区間が非常に狭い. 適合結果および予測結果の要約 summary(ap_fcast) ## ## Forecast method: ARIMA(2,1,1)(0,1,0)[12] ## ## Model Information: ## Series: ap ## ARIMA(2,1,1)(0,1,0)[12] ## ## Coefficients: ## ar1 ar2 ma1 ## 0.5960 0.2143 -0.9819 ## s.e. 0.0888 0.0880 0.0292 ## ## sigma^2 = 132.3: log likelihood = -504.92 ## AIC=1017.85 AICc=1018.17 BIC=1029.35 ## ## Error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 1.342306 10.84619 7.867539 0.4206996 2.800458 0.245628 ## ACF1 ## Training set -0.001248451 ## ## Forecasts: ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## Jan 1961 445.6349 430.8903 460.3794 423.0850 468.1847 ## Feb 1961 420.3950 403.0907 437.6993 393.9303 446.8596 ## Mar 1961 449.1983 429.7726 468.6240 419.4892 478.9074 ## Apr 1961 491.8399 471.0269 512.6529 460.0092 523.6706 ## May 1961 503.3944 481.5559 525.2330 469.9953 536.7936 ## Jun 1961 566.8624 544.2637 589.4611 532.3007 601.4242 ## Jul 1961 654.2601 631.0820 677.4383 618.8122 689.7081 ## Aug 1961 638.5974 614.9704 662.2245 602.4629 674.7319 ## Sep 1961 540.8837 516.9028 564.8646 504.2080 577.5593 ## Oct 1961 494.1266 469.8624 518.3908 457.0177 531.2355 ## Nov 1961 423.3327 398.8381 447.8272 385.8715 460.7939 ## Dec 1961 465.5075 440.8228 490.1922 427.7555 503.2595 ## Jan 1962 479.2908 448.9986 509.5830 432.9628 525.6187 ## Feb 1962 454.1768 421.7183 486.6352 404.5359 503.8177 ## Mar 1962 483.0869 448.7343 517.4395 430.5491 535.6247 ## Apr 1962 525.8192 490.1122 561.5262 471.2101 580.4283 ## May 1962 537.4506 500.6862 574.2150 481.2243 593.6769 ## Jun 1962 600.9838 563.3924 638.5753 543.4927 658.4750 ## Jul 1962 688.4369 650.1833 726.6905 629.9331 746.9408 ## Aug 1962 672.8212 634.0292 711.6133 613.4939 732.1485 ## Sep 1962 575.1474 535.9102 614.3845 515.1393 635.1555 ## Oct 1962 528.4241 488.8131 568.0350 467.8443 589.0038 ## Nov 1962 457.6589 417.7292 497.5885 396.5918 518.7259 ## Dec 1962 499.8581 459.6529 540.0633 438.3695 561.3466 4.6 外生変数があるケース 外生変数 (共変量) 付きのSARIMAモデルを扱うには, 次の引数を指定する: シミュレーション: パッケージsarimaの関数sim_sarima(): xinterceptオプション 推定: パッケージstatsの関数arima(), forecastの関数auto.arima(): xregオプション 関数sim_sarima()は, 次のようなSARIMA誤差項を持つ回帰モデルに対してパスを生成する: \\[ Y_t = \\alpha + \\beta X_t + \\epsilon_t,\\quad \\{\\epsilon_t\\} \\sim ~ SARIMA\\] なお, 一般には, SARIMA誤差項を持つ回帰モデルは複数の外生変数 (\\(X_t\\)の列数\\(d&gt;1\\), \\(\\beta\\)は\\(d&gt;1\\)次元ベクトル) を持つが, sim_sarima()では\\(d=1\\)のケースのみを扱うことができる. sim_sarima()の現在の仕様では, 引数xintercept は一変量のみ (ベクトル) の外生変数を受け付ける. もし, “定数項”のみモデル (外生変数なし) にしたい場合には, xintercept=1と与えればよい. それ以外の場合 (引数xintercept に何も与えない, or 1 以外のベクトルを与えると) 定数項なしモデル (\\(\\alpha = 0\\)) となる. 以下では, 外生変数の特別な場合として, 線形トレンドを持つケースを考える. 具体的には, \\(X_t\\equiv t\\), \\(\\beta=0.05\\), かつ, \\(\\epsilon_t\\)が以下のSARMAモデル (SARIMA\\((1,0,1) \\times (1,0,1)_{12}\\)) であるとする: \\[ (1 - 0.5 B) (1 - 0.8 B^{12}) \\epsilon_t = (1 - 0.4 B) (1 - 0.4 B^{12}) Z_t, \\ {Z_t}\\sim WN(0,1) \\] set.seed(seed_val) ltrend = 1:tlen x &lt;- sim_sarima(n = tlen, model = list(sma = 0.4, ma = 0.4, sar = 0.8, ar = 0.5, nseasons = 12, sigma2 = 1), xintercept = ltrend * 0.05) # exvars) ts.plot(x, type = &quot;l&quot;) # 時系列プロット par(mfrow = c(1,2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) par(mfrow = c(1,1)) 次に, SARIMA誤差項を持つ回帰モデルを使って, 生成された時系列データに対するモデル適合についてみてみよう. statsの関数arima()を使用する場合には, 引数xregに共変量 (ベクトルまたは行列) を与えることで, モデル適合を行う. statsの関数arima()や, forecastの関数auto.arima()を使用してモデル適合をする場合には, 引数xregに共変量 (ベクトルまたは行列) を与えることでSARIMAモデルを推定することができる. さらに, auto.arima()は, モデル推定のみならず, モデルの次数決定 (モデル同定) も自動的に行うので, 一気通貫で最適な適合モデルを得ることができる. 今回のケースは, 共変量が一つでかつ時間を表す特別なケース (線形トレンド) である. statsの関数arima()による適合 (モデル次数, 線形トレンドを正しく指定した場合): (x.fit &lt;- arima(x,order = c(1,0,1), seasonal = list(order = c(1,0,1), period = 12), xreg = ltrend)) ## ## Call: ## arima(x = x, order = c(1, 0, 1), seasonal = list(order = c(1, 0, 1), period = 12), ## xreg = ltrend) ## ## Coefficients: ## ar1 ma1 sar1 sma1 intercept ltrend ## 0.7606 0.1744 0.7531 0.6228 -5.2907 0.3521 ## s.e. 0.0656 0.1134 0.0576 0.0957 3.0592 0.0310 ## ## sigma^2 estimated as 0.9208: log likelihood = -211.59, aic = 437.19 # tsdiag(x.fit, gof = 20) # モデル診断 # Box.test(x.fit$residuals, lag = 20, type = &#39;Ljung&#39;) # Ljung-Box検定 ここで, 1次のMA項の係数\\(\\theta_1\\) (ma1) と定数項 (intercept) が有意でないので, これらを\\(0\\)とおいた制約付きで推定を行うと, (x.fit &lt;- arima(x,order = c(1,0,1), seasonal = list(order = c(1,0,1), period = 12), fixed = c(NA, 0, NA, NA, 0, NA), # interceptの係数=0 xreg = ltrend)) ## ## Call: ## arima(x = x, order = c(1, 0, 1), seasonal = list(order = c(1, 0, 1), period = 12), ## xreg = ltrend, fixed = c(NA, 0, NA, NA, 0, NA)) ## ## Coefficients: ## ar1 ma1 sar1 sma1 intercept ltrend ## 0.8375 0 0.7572 0.6341 0 0.3123 ## s.e. 0.0434 0 0.0559 0.0923 0 0.0266 ## ## sigma^2 estimated as 0.9426: log likelihood = -213.75, aic = 437.5 tsdiag(x.fit, gof = 20) # モデル診断 Box.test(x.fit$residuals, lag = 20, type = &#39;Ljung&#39;) # Ljung-Box検定 ## ## Box-Ljung test ## ## data: x.fit$residuals ## X-squared = 15.568, df = 20, p-value = 0.743 推定モデルとして, 線形トレンドの傾き\\(\\hat{\\beta}=0.3123\\), \\(\\{\\epsilon_t\\} \\sim\\) SARIMA\\((1,0,0) \\times (1,0,1)_{12}\\), ただし, \\(\\hat{\\phi}_1=0.8375, \\hat{\\Phi}_1=0.7572, \\hat{\\Theta}_1=0.6341, \\hat{\\sigma}^2=0.9426\\) が得られた. forecastの関数auto.arima()による適合 (線形トレンドを正しく指定した場合): require(forecast) (x.fit3 &lt;- auto.arima(x, xreg = ltrend)) # AIC/AICc(デフォルト)/BICによりモデルを自動選択&amp;推定 ## Series: x ## Regression with ARIMA(1,0,0) errors ## ## Coefficients: ## ar1 intercept xreg ## 0.8291 -8.3410 0.3737 ## s.e. 0.0485 1.9888 0.0233 ## ## sigma^2 = 4.862: log likelihood = -317.26 ## AIC=642.53 AICc=642.81 BIC=654.41 推定モデルとして, 線形トレンドの切片と傾き\\(\\hat{\\alpha}=-8.3410, \\hat{\\beta}=0.3123\\), \\(\\{\\epsilon_t\\} \\sim\\) AR(1), ただし, \\(\\hat{\\phi}_1=0.8291, \\hat{\\sigma}^2=4.862\\) が得られた. 以上, 二つの関数を使用して得られた適合モデルは, いずれも, 今回の生成パスに対しては真のモデルとはモデル形状 (次数やパラメータ値) が異なるものとなった. なお, パッケージTSAに収録されている推定用の関数arima() (別名, arimax())は データフレームを引数xregに与えることで複数の外生変数を持つARIMAモデルを推定することができるようになっている. この関数が対象とする“ARIMAX”モデルは, 上で紹介した“SARIMA誤差項を持つ回帰モデル” とは異なることに注意したい. 具体的には, これは伝達モデル (transfer function) と呼ばれる, 各外生変数 (共変量) が 動的に (ARMAフィルターを介して) ターゲットの時系列 (反応変数) に作用するタイプであり, Box-JenkinsにおいてARIMAモデルに外生入力を組み込んだ拡張クラスとして取り上げられている. "],["確率的トレンドと単位根検定.html", "5 確率的トレンドと単位根検定 5.1 確率的トレンド vs 確定的トレンド 5.2 単位根過程と見せかけの回帰 5.3 Augmented Dicky-Fuller (ADF) 検定 5.4 ADF検定以外の検定法", " 5 確率的トレンドと単位根検定 次のような定数項付きのランダムウォークを考える: \\[ X_t = \\beta + X_{t-1} +Z_t, \\quad \\{Z_t\\} \\sim WN(0,\\sigma^2). \\] いま, 定数項\\(\\beta \\ne 0\\)であれば, バイアス有りランダムウォークとも呼ばれる. 時点\\(t=0\\)において初期値\\(X_0=\\alpha\\)からスタートしたとすると, 再帰的代入によって, \\[ X_t = \\alpha + \\beta \\cdot t + \\eta_t \\] のように書ける. ただし, \\(\\eta_t = \\sum_{s=1}^{t} Z_s\\)と定義した (\\(\\sum_{s=1}^{0}=0\\)と表記). すなわち, 定数項\\(\\beta\\)は時点が1ステップ進むことに\\(X_t\\)の期待値が変化する量 (直線の傾き) を, 初期値\\(\\alpha\\)は\\(t=0\\)における\\(X_t\\)の期待値の値 (定数項) を表し, 全体として, \\(\\alpha + \\beta \\cdot t\\)は\\(X_t\\)の確定的な線形トレンドを構成している. 一方, 右辺第3項 \\(\\eta_t\\)は, (定数項なし, 初期値0スタートの) ランダムウォークであり, \\(I(1)\\), あるいは\\(ARIMA(0,1,0)\\)と表記される確定過程のクラスの代表例である. 第3項\\(\\eta_t\\)は, それ自体が確率的トレンドを形成する. 以上のように, 定数項付き (\\(\\beta \\ne 0\\)) のランダムウォークは, 線形トレンド部分と確率的トレンド部分を同時に持っている. 一方, 定数項なし (\\(\\beta = 0\\)) のランダムウォークは, 線形トレンド (傾き) を持たず確率的トレンドのみを持つが, 初期値(\\(X_0=\\alpha\\))の値だけ\\(y\\)軸方向にシフト (定数項) する. 次に, この定数項付きのランダムウォークを一般化して「確率的トレンド」モデルとして定義し, 一方, 第3項\\(\\eta_t\\)が (ランダムウォークせず) 確率的トレンドを持たないような「確定的トレンド」モデルとの比較を行う. 5.1 確率的トレンド vs 確定的トレンド -「確定的 (線形) トレンド (deterministic (linear) trend)」モデル \\[ X_{t}={\\color{olive}\\alpha}+\\beta\\cdot t+\\eta_{t}, \\quad \\{\\eta_{t}\\}\\sim\\mathrm{ARMA}(p,q) \\] -「確率的トレンド (stochastic trend)」モデル \\[ X_{t}={\\color{olive}\\alpha}+\\beta\\cdot t+\\eta_{t}, \\quad \\{\\eta_{t}\\}\\sim\\mathrm{ARIMA}(p,1,q) \\] より正確には, この「確率的トレンド」モデルは, 「確定的トレンド」を表す項\\(\\alpha+\\beta\\cdot t\\)と 文字通り「確率的トレンド」をもたらす項\\(\\eta_t\\)の 二つの成分が重なり合って生成されている. 例えば, \\(\\alpha=0,\\beta=0.05,\\phi(z)=1-\\phi_{1}z\\) において, 順に, \\(\\phi_{1}=1,0.98, 0.95\\)の場合について, 同一の乱数を用いて一本のサンプルパスを生成した場合を図示する. シミュレーションでは, 便宜上 \\(X_0=0\\) (あるいは, \\(\\eta_0=0\\)) を初期値として与え, その後の値を再帰的に生成した. この場合, 初期時点付近の観測値は, 確定的トレンドのケースにおいては, 定常分布からの逸脱を含む過渡状態となるが, 十分大きな \\(t\\) に対しては, トレンドを除いたプロセス \\(\\{X_t - \\alpha - \\beta \\cdot t\\}\\) は定常 ARMA 過程の分布に漸近的に近づく. 一方, 確率的トレンドのケースは初期値の設定有無によらず常に非定常である. これらの「確定的な(線形トレンド)」モデルと「確率的トレンド」モデルは, モデルの形状は類似しているが, 時系列的な性質は大きく異なる. 特に, 確率的トレンドを持つ場合は, 時間と共に観測時系列の 分散は増大していく一方, それを持たない場合には, 時間を通じて 定常 (分散は一定) であるという違いがある. ある時系列データが, (より正確にはその背後にある確率過程が) 確率的トレンドを持つか否かを定量的に評価する方法が 単位根検定 (unit root test) である. 「確率的トレンド」モデルは, 確定的トレンド部分と確率的トレンド部分を同時に 持っていたが, 私達が手にする実際の時系列データが見かけ上トレンドを 持っている時, それを確定的トレンドの部分と 確率的トレンドの部分に仕分けするのは容易ではない. 単位根検定を実施する際に, 厄介なことに, 確定的線形トレンドを構成するパラメータ 切片項 (定数) \\(\\alpha\\), 傾き \\(\\beta\\)の有無によって, 単位根検定を行う際の理論的な評価の計算方法が変わる ため, 検定結果がパラメータに関する仮定に依存する という課題が存在している. (正確には, 単位根帰無仮説の下で, 検定統計量が 従う漸近的な確率分布が異なることによって, それより計算される帰無仮説の棄却点が異なる) 例えば, より具体的には, 主要な単位根検定法であるADF検定 (その特別な場合のDF検定)においては, 確定的線形トレンドについて, トレンドが存在しない (\\(\\alpha=\\beta=0\\)), 定数項のみ存在する (\\(\\beta=0\\), \\(\\alpha\\)に制約なし), 定数項および傾きが存在する (\\(\\alpha,\\beta\\)に制約なし), の3ケースについて, 同一の検定統計量が異なる棄却域を持つため, 検定を実施するにあたり確定的トレンドがどのケースに 当てはまるのかを予め指定する必要がある. ところが, \\(\\alpha\\), \\(\\beta\\)が あるか否かは事前に分からない, あるいは, 上の例を見てもデータからは判断が難しいことも多い (グレイの点線がないものとしてプロットを目視してみよう). さらに, 単位根検定は十分な標本サイズの下で行うことが前提となっている. (正確には, 棄却点の評価を行うのに必要な帰無仮説の下での 検定統計量の従う確率分布は, 標本サイズを十分大きくとった場合, すなわち, 漸近分布として得られる) 実践において, ある時系列が単位根過程かどうか判断するには, 単位根検定を行うのと並行して, その時系列が それ自体に対して取引が行われているような 資産価格系列かどうか, すなわち, ランダムウォークするか (トレンドが予測できないような挙動を持つかどうか), あるいは, ある一定水準 (長期的な均衡値) の周りで 平均回帰的 (mean reversion) な性質を持つ系列かどうか など, 対象に関する前提知識や経験を活かすことが 重要である. 5.2 単位根過程と見せかけの回帰 5.2.1 単位根過程 ランダムウォークモデル (I(1))のパス生成 # require(sarima) Tlen &lt;- 100 Seedv &lt;- 1 # set.seed(Seedv) # x &lt;- sim_sarima(n = Tlen, model = list(iorder = 1, sigma2 = 1)) # (1-B)X_t = e_t (random walk) # y &lt;- sim_sarima(n = Tlen, model = list(iorder = 1, sigma2 = 1)) x &lt;- arima.sim(n = Tlen, list(order = c(0, 1, 0))) y &lt;- arima.sim(n = Tlen, list(order = c(0, 1, 0))) # # par(mfrow=c(1,2)) # acf(x) # 自己相関(ACF) # pacf(x) # 偏自己相関(PACF) # matplot(cbind(x, y), type = &quot;l&quot;) ts.plot(cbind(x, y), lty = 1:2) 5.2.2 見せかけの回帰 reslm &lt;- lm(y ~ x) summary(reslm) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.049 -2.862 1.383 3.172 5.519 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.42205 0.68668 0.615 0.54 ## x -0.51303 0.09909 -5.178 1.18e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.752 on 99 degrees of freedom ## Multiple R-squared: 0.2131, Adjusted R-squared: 0.2051 ## F-statistic: 26.81 on 1 and 99 DF, p-value: 1.182e-06 plot(x, y) plot(as.numeric(x), as.numeric(y)) abline(reslm) 5.2.3 見せかけの回帰の判定 library(lmtest) ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric dwtest(reslm) ## ## Durbin-Watson test ## ## data: reslm ## DW = 0.080227, p-value &lt; 2.2e-16 ## alternative hypothesis: true autocorrelation is greater than 0 Durbin-Watson検定 (簡便法) 回帰残差の系列相関の有無を検定 \\(DW \\approx 2(1-\\rho)\\) \\(0&lt;DW&lt;4\\). 無相関 \\(\\Leftrightarrow DW=2\\) 見せかけの回帰の場合. DWが小さい傾向 (正の系列相関) 代替法: Engle-Granger検定 「見せかけの回帰」への対処法については後日扱う. 5.2.4 Rで実行可能な主な単位根検定法 Rでは単位根検定を実行するための多くの関数が用意されている. 引数の指定方法や出力表示などの仕様が異なるので, 色々実行して自分が使いやすいと感じるものを選ぶと良いだろう. ADF検定: tseries内, adf.test(); fUnitRoots内, unitrootTest(), adfTest() Phillips-Perron(PP)検定: urca内, ur.pp(); tseries内, pp.test() PP検定は, 沖本, pp.118–120参照 KPSS検定: urca内, ur.kpss(); tseries内, kpss.test() KPSS検定は, 福地・伊藤, pp.139–140参照 その他の検定法: fUnitRoots内, urersTest() (Elliott-Rothenberg-Stock検定), urspTest() (Schmidt-Phillips検定), urzaTest() (Zivot-Andrews), 等 5.3 Augmented Dicky-Fuller (ADF) 検定 単位根検定としてもっとも良く用いられるのが Augmented Dicky-Fuller (ADF) 検定である. ADF検定は, 時系列\\(\\{X_t\\}\\)が, 確定的トレンド (線形トレンド) にAR(\\(p\\))に従う誤差を伴って観測されたと想定する: \\[ X_{t}=\\alpha+\\beta\\cdot t+\\eta_{t},\\quad\\eta_{t}=\\phi_{1}\\eta_{t-1}+\\cdots+\\phi_{p}\\eta_{t-p}+Z_{t}\\quad Z_{t}\\sim IID(0,\\sigma^{2})\\qquad(\\eta_{0}=0) \\] これを次式のように変形する: \\[ \\Delta X_{t}=a+bt+\\kappa X_{t-1}+\\sum_{j=1}^{p-1}\\delta_{j}\\Delta X_{t-j}+Z_{t} \\] 但し, \\(\\kappa=-(1-\\sum_{j=1}^{p}\\phi_{j}), \\,a=-\\kappa\\alpha+\\beta\\sum_{j=1}^{p}j\\phi_{j},\\, b=-\\kappa\\beta.\\) ADF検定は, この\\(\\{\\Delta X_t\\}\\)に対する回帰式 (“ADF回帰モデル”) の\\(X_{t-1}\\)の係数の大きさに基づいて単位根検定を行う. \\(H_{0}:\\kappa=0\\) (単位根あり) vs. \\(H_{1}:\\kappa&lt;0\\) (単位根なし) ADF (Augmented DF) 検定統計量: \\(X_{t-1}\\)の回帰係数\\(\\kappa\\)の最小二乗推定量 \\(\\hat{\\kappa}\\)に対して, \\[ ADF=\\frac{\\hat{\\kappa}}{s.e.(\\hat{\\kappa})} \\] ADF統計量は \\(\\hat{\\kappa}\\)の“\\(t\\)値”にほかならず, この値が, 0から下方に (負の方向に) 乖離するほど, 単位根帰無仮説が棄却されやすい, すなわち, (単位根を持たない) トレンド定常モデルである可能性が高いと言える. ADF検定は, (その特別な場合であるDickey-Fuller検定と同様に) 確定的トレンドの有無により, 3つのモデル, 具体的には, (i) 定数項も1次トレンドも存在しない場合 (\\(a=0,b=0\\)), (ii) 定数項のみ存在する場合 (\\(b=0, a\\)制約なし), (iii) 定数項も1次トレンドも存在する場合 (\\(a,b\\) 制約なし) の3つのケースがあり, 各々のケースにより検定統計量が帰無仮説の下で従う (漸近的) 検定分布が異なるため, 検定結果が異なる可能性のあることに注意が必要である. ADF統計量は, “\\(t\\)値”の形をしているものの, いずれのケースにおいても, 帰無仮説の下で, \\(t\\)分布には (漸近的にも) 従わない. なお, オリジナルのDicky and Fuller (81) にもある通り, ADF検定には, このADF統計量に基づく検定 (“\\(\\tau\\)検定”) のほか, “\\(\\rho\\)統計量” (または, “正則化されたバイアス (normalized bias) 統計量”) \\[ Z=T \\hat{\\kappa} \\] に基づく“\\(\\rho\\)検定” (\\(T\\)はサンプルサイズ), さらに, 単位根とトレンドの有無を同時に検定する, “\\(F\\)値” (“\\(\\phi\\)統計量”) に基づく“\\(F\\)検定”がある (同様に, 帰無仮説の下で, \\(F\\)分布には (漸近的にも) 従わない). ADF検定の実行前に, この \\(\\{\\Delta X_t\\}\\) 式におけるラグ次数 (\\(p-1\\)) の大きさを決める必要がある. 手動によるアプローチ, 例えば, 十分大きな \\(p\\) から値を順次小さくしていき, 係数の \\(t\\) 値を調べるアプローチや, AICやBICなどの情報量基準を使って決定するアプローチなどがある. 例えば, パッケージurcaの関数ur.df()を使えば, AIC/BICによって \\(p\\) の大きさを自動選択することができる. ADF検定は, 標本サイズが十分大きいことを想定しているため, 小標本の時は結果の信頼性が保証されず注意が必要である. 以下では, Rを使って, ADF検定を幾つかのデータセットに対して実行する. パッケージfUnitRoots まず, ADF検定を行う二つのR関数unitrootTest(), adfTest()の実行例を示す. adfTest(): Banerjee&#39;s et al.(93)による検定統計量の計算 unitrootTest(): McKinnons(96) のアプローチによる検定統計量の計算 用法: adfTest(x, lags = 1, type = c(&quot;nc&quot;, &quot;c&quot;, &quot;ct&quot;), title = NULL, description = NULL) unitrootTest(x, lags = 1, type = c(&quot;nc&quot;, &quot;c&quot;, &quot;ct&quot;), title = NULL, description = NULL) 引数: - type: &quot;nc&quot;(定数項・時間トレンド項共なし), &quot;c&quot;(定数項のみ有), &quot;ct&quot;(定数項・時間トレンド項共有) - lags: 誤差項の持つ最大ラグ数 上記シミュレーションデータに対して, ADF検定を実行する. library(fUnitRoots) adfTest(x, type = &quot;nc&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: 0.282 ## P VALUE: ## 0.703 ## ## Description: ## Sat Nov 29 13:16:34 2025 by user: unitrootTest(x, type = &quot;nc&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## DF: 0.282 ## P VALUE: ## t: 0.7657 ## n: 0.7506 ## ## Description: ## Sat Nov 29 13:16:34 2025 by user: 関数unitrootTest()には, 2つの統計量 “t”と“n” の\\(p\\)値が出力されている. “t”が\\(\\tau\\)検定, “n”が\\(\\rho\\)検定の結果にほかならない. adfTest()の結果と, unitrootTest()の結果を比較すると, ADF検定統計量は同じ (0.282) 値を取っているものの, \\(p\\)値の大きさ (後者については “t” を参照) 異なったものとなっている (それぞれ, 0.703, 0.7657). これは, 帰無分布の近似計算の方法, すなわち\\(p\\)値算出のアルゴリズムの違いを反映したものである. (参考) - `unitrootTest()`: MacKinnon (1994, 1996), シミュレーション結果を多項式回帰（response surface）で近似し，連続的に p 値を計算する方法 - `adfTest()`: Banerjee et al. (1993), サンプルサイズとモデル仕様ごとにシミュレーションで表を作り，その間を補間する方法 MacKinnonの response surface に基づく近似は，EViews, Stataなどでも採用されている. より正確で標準的. `fUnitRoots` の作者自身も，`unitrootTest()` を “the same (ADF) test based on McKinnon&#39;s statistics” と位置付けている (ADF の“改良版”に近い扱い). このデータセットに関しては, いずれの\\(p\\)値をみても, 時系列\\(x\\)に対して, 単位根帰無仮説は棄却されない. adfTest(y, type = &quot;nc&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -0.7206 ## P VALUE: ## 0.3835 ## ## Description: ## Sat Nov 29 13:16:34 2025 by user: unitrootTest(y, type = &quot;nc&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## DF: -0.7206 ## P VALUE: ## t: 0.4021 ## n: 0.522 ## ## Description: ## Sat Nov 29 13:16:34 2025 by user: → いずれも, 帰無仮説 (\\(\\phi_1=1\\)) を棄却せず (単位根有り). adfTest(x, type = &quot;c&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -1.4551 ## P VALUE: ## 0.5166 ## ## Description: ## Sat Nov 29 13:16:34 2025 by user: # unitrootTest(x, type = &quot;c&quot;, lags = 1) adfTest(y, type = &quot;c&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -1.0635 ## P VALUE: ## 0.6617 ## ## Description: ## Sat Nov 29 13:16:34 2025 by user: # unitrootTest(y, type = &quot;c&quot;, lags = 1) adfTest(x, type = &quot;c&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -1.4551 ## P VALUE: ## 0.5166 ## ## Description: ## Sat Nov 29 13:16:34 2025 by user: # unitrootTest(x, type = &quot;ct&quot;, lags = 1) adfTest(y, type = &quot;c&quot;, lags = 1) ## ## Title: ## Augmented Dickey-Fuller Test ## ## Test Results: ## PARAMETER: ## Lag Order: 1 ## STATISTIC: ## Dickey-Fuller: -1.0635 ## P VALUE: ## 0.6617 ## ## Description: ## Sat Nov 29 13:16:34 2025 by user: # unitrootTest(y, type = &quot;ct&quot;, lags = 1) パッケージtseries 次に, パッケージtseries内の関数adf.test()の実行例を示す. 用法: adf.test(x, alternative = c(&quot;stationary&quot;, &quot;explosive&quot;), k = trunc((length(x)-1)^(1/3))) 引数: - ラグ次数k: number of lags in the regression - デフォルト値: trunc((length(x)-1)^(1/3)): the suggested upper bound on the rate (to grow with the sample size for the general ARMA(p,q) setup) - 対立仮説alternative: &quot;stationary&quot;(デフォルト) or &quot;explosive&quot; 検定を行うデータセットは, パッケージquantmodにより取得する株価データ (みずほFG, 証券コード8411) である. - 注) R/RStudioやquantmodのバージョンが更新されていないと, 動かないことがある. library(&#39;quantmod&#39;) ## Loading required package: xts ## Loading required package: TTR ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo yj8411 &lt;- getSymbols(&#39;8411.T&#39;,from = &#39;2020-10-01&#39;, to = &#39;2024-10-31&#39;, src = &quot;yahoo&quot;, auto.assign = FALSE) p8411 &lt;- Ad(yj8411) # 調整後株価 # lnp8411 &lt;- log(Ad(yj8411)) # 対数株価 plot(p8411) par(mfrow = c(1,2)) acf(p8411) pacf(p8411) # acf(diff(p8411), na.action = na.omit) # pacf(diff(p8411),na.action = na.omit) 得られた日次株価データに対してADF検定を実行する. (帰無仮説\\(H_0\\): \\({X_t}\\)は単位根を持つ) # ADF検定 (Augmentd Dicky-Fuller test) # (H0: x has unit root) library(tseries) adf.test(p8411) adf.test(p8411, k = 1) # ← adfTest(p8411, type =&quot;ct&quot;, lags = 1)と同一の結果 adf.test(p8411, k = 1, alternative = &quot;explosive&quot;) # &lt;-- H0 と H1を入替 (→ 同一のDF値. 上行のp値 = 1-下行のp値) ## ## Augmented Dickey-Fuller Test ## ## data: p8411 ## Dickey-Fuller = -1.8768, Lag order = 9, p-value = 0.6305 ## alternative hypothesis: stationary ## ## ## Augmented Dickey-Fuller Test ## ## data: p8411 ## Dickey-Fuller = -2.7501, Lag order = 1, p-value = 0.2608 ## alternative hypothesis: stationary ## ## ## Augmented Dickey-Fuller Test ## ## data: p8411 ## Dickey-Fuller = -2.7501, Lag order = 1, p-value = 0.7392 ## alternative hypothesis: explosive パッケージurca 次に, パッケージurca内の関数ur.df()の実行例を示す. 本格的な時系列分析の実務や研究においては, ur.df() は, 以下に示すように, 高機能で, より推奨されるツールとして扱われることも多い. 用法: ur.df(y, type = c(&quot;none&quot;, &quot;drift&quot;, &quot;trend&quot;), lags = 1, selectlags = c(&quot;Fixed&quot;, &quot;AIC&quot;, &quot;BIC&quot;)) データセットは, パッケージexpsmoothに収納されているbondsを使用する. データセット: bonds {expsmooth} - 米国10年債利回り(年率) , 1994.1〜2004.5, 月次 - データ出所 (オリジナル): Hyndman, R.J., Koehler, A.B., Ord, J.K., and Snyder, R.D., (2008), Forecasting with exponential smoothing: the state space approach, Springer. # library(&quot;forecast&quot;) library(&quot;expsmooth&quot;) # required for the data ## Loading required package: forecast plot(bonds) par(mfrow = c(1,2)) acf(bonds) pacf(bonds) まず, ラグ次数 (引数lags) を1に固定した場合 (デフォルト) を実行する. トレンドの指定 (引数type) は, なし (“none”), 定数項のみ (“drift”), 定数項+傾き (“trend”) の3通りの結果を比較してみる. library(urca) ## ## Attaching package: &#39;urca&#39; ## The following objects are masked from &#39;package:fUnitRoots&#39;: ## ## punitroot, qunitroot, unitrootTable # ラグ次数固定 # selectlags = &quot;fixed&quot; (デフォルト) # lags = 1 (デフォルト) トレンドなし (type=\"none\") ur.df(bonds) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression none ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 - 1 + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.49498 -0.18042 -0.02486 0.18454 0.68176 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## z.lag.1 -0.002436 0.003747 -0.650 0.51690 ## z.diff.lag 0.265314 0.088063 3.013 0.00315 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2408 on 121 degrees of freedom ## Multiple R-squared: 0.07345, Adjusted R-squared: 0.05813 ## F-statistic: 4.796 on 2 and 121 DF, p-value: 0.0099 ## ## ## Value of test-statistic is: -0.65 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau1 -2.58 -1.95 -1.62 定数項のみモデル (type=\"drift\") ur.df(bonds, type = &quot;drift&quot;) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression drift ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1 + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.50712 -0.18094 -0.04008 0.17625 0.61088 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.17260 0.11527 1.497 0.13692 ## z.lag.1 -0.03166 0.01987 -1.593 0.11371 ## z.diff.lag 0.28483 0.08858 3.216 0.00167 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2395 on 120 degrees of freedom ## Multiple R-squared: 0.08863, Adjusted R-squared: 0.07344 ## F-statistic: 5.835 on 2 and 120 DF, p-value: 0.003816 ## ## ## Value of test-statistic is: -1.5934 1.3345 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau2 -3.46 -2.88 -2.57 ## phi1 6.52 4.63 3.81 定数項+傾きモデル (type=\"trend\") ur.df(bonds, type = &quot;trend&quot;) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression trend ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.56296 -0.15468 -0.01879 0.16003 0.60493 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.059755 0.289261 3.664 0.000373 *** ## z.lag.1 -0.143763 0.038789 -3.706 0.000321 *** ## tt -0.003952 0.001190 -3.320 0.001196 ** ## z.diff.lag 0.314505 0.085564 3.676 0.000357 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2301 on 119 degrees of freedom ## Multiple R-squared: 0.1659, Adjusted R-squared: 0.1449 ## F-statistic: 7.889 on 3 and 119 DF, p-value: 7.626e-05 ## ## ## Value of test-statistic is: -3.7062 4.6378 6.8862 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau3 -3.99 -3.43 -3.13 ## phi2 6.22 4.75 4.07 ## phi3 8.43 6.49 5.47 **Rコーディング上のヒント**: `ur.df()`は単体では検定結果を表示しないことから, ここでは, `tidyverse`流コーディングにより, パイプ演算子(`%&gt;%`)を`summary()`と 組合せて, `ur.df()`の結果を`summary()`に流し込んで, 一気に出力するようにした. ur.df()を実行すると, ADF回帰式の各係数の推定結果も表示される. 今回データセットbondsに対して, 実行された回帰式 (Rのformula表記) は, トレンドなしモデル (type=\"none\"): z.diff ~ z.lag.1 - 1 + z.diff.lag 定数項のみモデル (type=\"drift\"): z.diff ~ z.lag.1 + 1 + z.diff.lag 定数項+傾きモデル (type=\"trend\"): z.diff ~ z.lag.1 + 1 + tt + z.diff.lag である. すなわち, 先述の回帰式の記号によれば, “z.diff”: \\(\\Delta X_{t}\\) “z.lag.1”: \\(X_{t-1}\\) “z.diff.lag”: \\(\\Delta X_{t-j}, \\,j=1,...,p-1\\) (まとめて表記) に対応する. また, 3番目のformula内の“tt”は, 時間に対応する変数であり, この回帰係数が線形トレンドの傾きを表す. また, formula内の“-1”は定数項なし (“+1”はあり) を表す. 次に ラグ次数 (引数lags) を0に固定した場合 (DF検定に対応) を実行する. これはモデル式において, z.diff.lag項がないケースである. トレンドなし (type=\"none\") # ラグ次数固定 # lags = 0 (DF検定の場合) ← z.diff.lag項なし ur.df(bonds, lags = 0) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression none ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 - 1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.52732 -0.19639 -0.03244 0.21610 0.61778 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## z.lag.1 -0.002344 0.003852 -0.609 0.544 ## ## Residual standard error: 0.2486 on 123 degrees of freedom ## Multiple R-squared: 0.003001, Adjusted R-squared: -0.005104 ## F-statistic: 0.3703 on 1 and 123 DF, p-value: 0.544 ## ## ## Value of test-statistic is: -0.6085 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau1 -2.58 -1.95 -1.62 定数項のみモデル (type=\"drift\") ur.df(bonds, type = &quot;drift&quot;, lags = 0) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression drift ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.53720 -0.19521 -0.04203 0.21914 0.56585 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.11873 0.11831 1.004 0.318 ## z.lag.1 -0.02246 0.02042 -1.100 0.273 ## ## Residual standard error: 0.2486 on 122 degrees of freedom ## Multiple R-squared: 0.009827, Adjusted R-squared: 0.001711 ## F-statistic: 1.211 on 1 and 122 DF, p-value: 0.2733 ## ## ## Value of test-statistic is: -1.1004 0.6887 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau2 -3.46 -2.88 -2.57 ## phi1 6.52 4.63 3.81 定数項+傾きモデル (type=\"trend\") ur.df(bonds, type = &quot;trend&quot;, lags = 0) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression trend ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1 + tt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.58842 -0.17011 -0.01825 0.16278 0.51496 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.910594 0.288463 3.157 0.00201 ** ## z.lag.1 -0.122593 0.038880 -3.153 0.00204 ** ## tt -0.003553 0.001188 -2.991 0.00337 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2408 on 121 degrees of freedom ## Multiple R-squared: 0.07801, Adjusted R-squared: 0.06278 ## F-statistic: 5.119 on 2 and 121 DF, p-value: 0.007342 ## ## ## Value of test-statistic is: -3.1531 3.472 5.1193 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau3 -3.99 -3.43 -3.13 ## phi2 6.22 4.75 4.07 ## phi3 8.43 6.49 5.47 以上, 引数typeについて3通りの結果を示したが, 先に取り上げた, fUnitRootsのadfTest()やunitrootTest(), tseriesのadf.test()よりも出力が多く, 使いこなすには補足説明が必要であろう. ur.df()においては, Dicky and Fuller (79,81) にならい, 次のような統計量を用いた検定結果を (同時に) 表示する： #次のような統計量に関して, 複数の検定結果を表示する： “none”タイプ: tau1 “drift”タイプ: tau2, phi1 “trend”タイプ: tau3, phi2, phi3 ここで, トレンドなしモデル (“none”タイプ) では, \\(\\tau_1\\) (tau1) は仮説\\(\\kappa=0\\) (単位根あり) を検定する“\\(t\\)統計量”である. 次に, 定数項のみモデル (“drift”タイプ) では, \\(\\tau_2\\) (tau2) は仮説\\(\\kappa=0\\) (単位根あり) を検定する“\\(t\\)統計量”, \\(\\phi_1\\) (phi1) は 同時仮説\\(a=\\kappa=0\\) (単位根あり, かつ定数項はない) を検定するための“\\(F\\)統計量”である. 一方, 定数項+傾きモデル (“trend”タイプ) では, \\(\\tau_3\\) (tau3) は, 仮説\\(\\kappa=0\\) (単位根あり) を検定する“\\(t\\)統計量”, \\(\\phi_2\\) (phi2) は同時仮説\\(a=b=\\kappa=0\\) (単位根あり, かつ定数項も傾きもない) を検定するための“\\(F\\)統計量”, \\(\\phi_3\\) (phi3) は, 同時仮説\\(b=\\kappa=0\\) (単位根あり, 定数項のみあり) を検定するための“\\(F\\)統計量”である. 以上整理すると, 次のような“(A)DF戦略”で単位根検定をすることが考えられる. いちばん一般的な trend モデルから始める： \\[ \\Delta X_t = a + b t + \\kappa X_{t-1} + \\cdots \\] まず \\(\\tau_3\\)で「単位根の有無」を調べる. 単位根を棄却できない場合（\\(\\kappa=0\\) を棄却できない場合）は, \\(\\phi_3,\\phi_2\\)を使って「トレンドやドリフトを落としてよいか」を検討する. \\(\\phi_3\\) を棄却できなければ「トレンドは不要」→ type=\"drift\"へ さらに \\(\\phi_2\\) も棄却できなければ「切片も不要」→ type=\"none\"へ. 最終的に妥当だと判断した仕様の \\(\\tau\\) 統計量（\\(\\tau_1,\\tau_2,\\tau_3\\)) で単位根の有無を判断する 引数type = \"trend\"を与えた時のur.df() の出力はちょうどこの戦略のフローを反映しており： 1つ目の統計量 (\\(\\tau_3\\)) が「単位根の有無」 2つ目・3つ目 (\\(\\phi_2,\\phi_3\\)) が「ドリフト・トレンドの必要性」 を同時に表示している. ラグ次数の自動選択 つぎに, ラグ次数 (引数lags) を自動選択した場合を実行する. 引数selectlags=\"AIC\"に設定すればAIC基準で, selectlags=\"BIC\"とすればBIC基準で次数選択が行われる. デフォルトは, 上で示したように固定 (selectlags=\"fixed\") である. トレンドなし (type=\"none\") # ラグ次数をAIC基準により自動選択 # selectlags = &quot;AIC&quot; # サーチするラグ次数の最大値lags=10 ur.df(bonds, selectlags = &quot;AIC&quot;, lags = 10) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression none ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 - 1 + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.46513 -0.13370 -0.02074 0.14663 0.60725 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## z.lag.1 -0.006504 0.003876 -1.678 0.0962 . ## z.diff.lag1 0.239620 0.093240 2.570 0.0115 * ## z.diff.lag2 -0.138994 0.098096 -1.417 0.1594 ## z.diff.lag3 0.135671 0.098201 1.382 0.1700 ## z.diff.lag4 0.003777 0.098249 0.038 0.9694 ## z.diff.lag5 -0.227444 0.095012 -2.394 0.0184 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2305 on 108 degrees of freedom ## Multiple R-squared: 0.1504, Adjusted R-squared: 0.1032 ## F-statistic: 3.185 on 6 and 108 DF, p-value: 0.006444 ## ## ## Value of test-statistic is: -1.6781 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau1 -2.58 -1.95 -1.62 出力結果によれば, 確定的トレンドなし (\\(a=0,b=0\\)) のケースにおいては,1回差分 \\(\\{\\Delta X_t\\}\\) に対する 上記ADF検定の回帰式における \\(\\{\\Delta X_t\\}\\) のラグ次数 (\\(p-1\\)) として, 5が, AIC基準の下で自動選択された. 二つのADF検定統計量tau2, phi1いずれも 有意でない (10%水準に達していない), すなわち, 単位根仮説は棄却されない. 定数項のみモデル (type=\"drift\") ur.df(bonds, type = &quot;drift&quot;, selectlags = &quot;AIC&quot;, lags = 10) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression drift ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1 + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.47654 -0.15143 -0.01987 0.14226 0.55707 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.23568 0.12153 1.939 0.05510 . ## z.lag.1 -0.04696 0.02121 -2.214 0.02894 * ## z.diff.lag1 0.24669 0.09214 2.677 0.00859 ** ## z.diff.lag2 -0.11712 0.09752 -1.201 0.23241 ## z.diff.lag3 0.15712 0.09760 1.610 0.11038 ## z.diff.lag4 0.02585 0.09768 0.265 0.79182 ## z.diff.lag5 -0.19839 0.09501 -2.088 0.03917 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2276 on 107 degrees of freedom ## Multiple R-squared: 0.1665, Adjusted R-squared: 0.1198 ## F-statistic: 3.563 on 6 and 107 DF, p-value: 0.002947 ## ## ## Value of test-statistic is: -2.2141 3.3245 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau2 -3.46 -2.88 -2.57 ## phi1 6.52 4.63 3.81 このケースでは, 定数項 (\\(a\\)) が回帰式に含まれており, 出力結果には”(Interecept)“として推定値や 標準誤差等が表示されている (ただし, \\(b=0\\)). ADF検定統計量tau1は 10%有意ではあるが, 5%有意ではない. すなわち, 有意水準を10%に設定した場合には, 単位根仮説は棄却される. 定数項+傾きモデル (type=\"trend\") ur.df(bonds, type = &quot;trend&quot;, selectlags = &quot;AIC&quot;, lags = 10) %&gt;% summary() ## ## ############################################### ## # Augmented Dickey-Fuller Test Unit Root Test # ## ############################################### ## ## Test regression trend ## ## ## Call: ## lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.52136 -0.16195 -0.03909 0.14174 0.61941 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.081602 0.323598 3.342 0.001142 ** ## z.lag.1 -0.154046 0.042816 -3.598 0.000486 *** ## tt -0.003555 0.001339 -2.655 0.009129 ** ## z.diff.lag1 0.300752 0.091537 3.286 0.001373 ** ## z.diff.lag2 -0.099373 0.095099 -1.045 0.298386 ## z.diff.lag3 0.244475 0.094637 2.583 0.011123 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2239 on 108 degrees of freedom ## Multiple R-squared: 0.1853, Adjusted R-squared: 0.1476 ## F-statistic: 4.914 on 5 and 108 DF, p-value: 0.0004322 ## ## ## Value of test-statistic is: -3.5979 5.095 7.0366 ## ## Critical values for test statistics: ## 1pct 5pct 10pct ## tau3 -3.99 -3.43 -3.13 ## phi2 6.22 4.75 4.07 ## phi3 8.43 6.49 5.47 線形トレンドあり (type = \"trend\") のケースは, それ以外の2ケースと異なり, tau3検定統計量では5%, phi2では10%, phi3では5%の有意水準で, 帰無仮説 (単位根なし) が棄却された. すなわち, 最後の結果は, このデータ期間においては, 確定的な線形トレンド (傾きが一定) に定常ノイズが加わっているモデルで 表現できる可能性 (長期間に渡っての債券利回り=長期金利の低下傾向) を示唆している. 企業成長に従って際限なく増加する可能性のある株価とは異なり, そもそも, 金利は上がっては下がり, 下がっては上がるという 平均回帰的 (mean reversion) な特性を持っている. さらに, 金利市場はマクロ経済環境だけでなく, 金融当局の政策の影響を受け, しかも, 金融政策は一貫性を保つようある程度長期に渡って 維持されることが期待されるものである (頻繁には変更されないものである) から, このような「線形トレンド+定常ノイズ」のモデルによるデータの記述は説得力を持つようにも見えるし, 予測への利用可能性も期待できそうである. しかしながら, もとより, 金融市場データにおいては, 確定的トレンドが長い期間, とりわけ将来にわたって続くことは考えにくいことから, このような推定結果に関する評価や, 将来予測への使用には注意が必要なのは当然である. 以上の例で示した通り, 分析対象の時系列データによっては, 確定トレンドの仮定に依存して, 単位根の有無に関する結論が逆転する可能性がある. 金融市場等, そのデータを生成しているメカニズムや, 外部環境に関する専門知識や経験をフルに活用したモデリングや 分析が求められる. 自主課題: 引数typeの3つのケースについて, トレンドなし → 定数項有 → 定数項+傾き有, の順に結果を出力したが, アプローチを変え, 今度は, 先の“(A)DF戦略”に沿ってbondsデータの単位根検定を行うとどうなるか考えてみよう. 5.4 ADF検定以外の検定法 Phillips-Perron (PP) 検定, KPSS検定について, 先に使用したみずほFGの日次株価データ (8411) に対して実行する. 上で得られたADF検定の結果と比較してみよう. PP検定やKPSS検定においては, 確定的トレンドは, (i) 定数項のみ, (ii) 線形トレンド (定数項+傾き), の2つのケースがあり (注: ADF検定では3つのケースがあった), 実行に際してどちらかを指定して行う. Phillips-Perron (PP) 検定 PP検定では, 確定的トレンドに加わる誤差項として一般の線形過程を用いる. すなわち, ADF検定のような誤差項のモデル化 (AR(\\(p\\))モデルによるラグ構造の特定) をする必要がない. しかし, 標本数が十分大きくない状況では, PP検定も結果の信頼性の点で問題があることから, モデルに関する事前の情報を 使える場合には, ADF検定の方が望ましいと言える. 5.4.0.1 パッケージtseries内, 関数pp.test() 用法: pp.test(x, alternative = c(&quot;stationary&quot;, &quot;explosive&quot;), type = c(&quot;Z(alpha)&quot;, &quot;Z(t_alpha)&quot;), lshort = TRUE) 主要な引数: - 対立仮説alternative: &quot;stationary&quot;, &quot;explosive&quot; - 検定の種類type: &quot;Z(alpha)&quot;, &quot;Z(t_alpha)&quot; - ラグ次数の打ち切りlshort: T (→ 4(T/100)^(1/4)), F (→ 12(T/100)^(1/4)) ※ 確定的トレンドの仮定は, 線形トレンド (定数項+傾き) #library(tseries) pp.test(p8411, type = &quot;Z(alpha)&quot;, lshort = T) # デフォルト ## ## Phillips-Perron Unit Root Test ## ## data: p8411 ## Dickey-Fuller Z(alpha) = -10.768, Truncation lag parameter = 7, p-value ## = 0.5091 ## alternative hypothesis: stationary pp.test(p8411, type = &quot;Z(alpha)&quot;, lshort = F) ## ## Phillips-Perron Unit Root Test ## ## data: p8411 ## Dickey-Fuller Z(alpha) = -8.9384, Truncation lag parameter = 21, ## p-value = 0.6111 ## alternative hypothesis: stationary pp.test(p8411, type = &quot;Z(t_alpha)&quot;) ## ## Phillips-Perron Unit Root Test ## ## data: p8411 ## Dickey-Fuller Z(t_alpha) = -2.3096, Truncation lag parameter = 7, ## p-value = 0.4472 ## alternative hypothesis: stationary #pp.test(p8411, alternative = &quot;explosive&quot;) パッケージurca内, 関数ur.pp() 用法: ur.pp(x, type = c(&quot;Z-alpha&quot;, &quot;Z-tau&quot;), model = c(&quot;constant&quot;, &quot;trend&quot;), lags = c(&quot;short&quot;, &quot;long&quot;), use.lag = NULL) 主要な引数: - 確定的トレンドの種類model: &quot;constant&quot; (定数項), &quot;trend&quot; (線形トレンド) - 検定の種類type: &quot;Z-alpha&quot;, &quot;Z-tau&quot; - 誤差修正項のラグ長lag: &quot;short&quot;, &quot;long&quot; library(urca) #lags: ラグの長さの指定. 4(T/100)^(1/4) or 12(T/100)^(1/4) #model: トレンドを持つ(&quot;trend&quot;), 定数項を持つ(&quot;constant&quot;) \\(Z_{\\alpha}\\)検定 &amp; 線形トレンドあり ur.pp(p8411, type = &quot;Z-alpha&quot;, model = &quot;trend&quot;, lags = &quot;short&quot;) %&gt;% summary() ## ## ################################## ## # Phillips-Perron Unit Root Test # ## ################################## ## ## Test regression with intercept and trend ## ## ## Call: ## lm(formula = y ~ y.l1 + trend) ## ## Residuals: ## Min 1Q Median 3Q Max ## -571.21 -13.94 -1.14 14.96 203.75 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 24.908408 9.184757 2.712 0.00680 ** ## y.l1 0.987289 0.005062 195.048 &lt; 2e-16 *** ## trend 0.029106 0.011051 2.634 0.00857 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 38.44 on 997 degrees of freedom ## Multiple R-squared: 0.9963, Adjusted R-squared: 0.9963 ## F-statistic: 1.343e+05 on 2 and 997 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic, type: Z-alpha is: -10.7685 ## ## aux. Z statistics ## Z-tau-mu 3.3589 ## Z-tau-beta 2.4723 ur.pp(p8411, type = &quot;Z-alpha&quot;, model = &quot;trend&quot;, lags = &quot;long&quot;) %&gt;% summary() ## ## ################################## ## # Phillips-Perron Unit Root Test # ## ################################## ## ## Test regression with intercept and trend ## ## ## Call: ## lm(formula = y ~ y.l1 + trend) ## ## Residuals: ## Min 1Q Median 3Q Max ## -571.21 -13.94 -1.14 14.96 203.75 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 24.908408 9.184757 2.712 0.00680 ** ## y.l1 0.987289 0.005062 195.048 &lt; 2e-16 *** ## trend 0.029106 0.011051 2.634 0.00857 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 38.44 on 997 degrees of freedom ## Multiple R-squared: 0.9963, Adjusted R-squared: 0.9963 ## F-statistic: 1.343e+05 on 2 and 997 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic, type: Z-alpha is: -8.9395 ## ## aux. Z statistics ## Z-tau-mu 4.1119 ## Z-tau-beta 2.3111 \\(Z_{\\tau}\\)検定 &amp; 線形トレンドあり ur.pp(p8411, type = &quot;Z-tau&quot;, model = &quot;trend&quot;, lags = &quot;long&quot;) %&gt;% summary() ## ## ################################## ## # Phillips-Perron Unit Root Test # ## ################################## ## ## Test regression with intercept and trend ## ## ## Call: ## lm(formula = y ~ y.l1 + trend) ## ## Residuals: ## Min 1Q Median 3Q Max ## -571.21 -13.94 -1.14 14.96 203.75 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 24.908408 9.184757 2.712 0.00680 ** ## y.l1 0.987289 0.005062 195.048 &lt; 2e-16 *** ## trend 0.029106 0.011051 2.634 0.00857 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 38.44 on 997 degrees of freedom ## Multiple R-squared: 0.9963, Adjusted R-squared: 0.9963 ## F-statistic: 1.343e+05 on 2 and 997 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic, type: Z-tau is: -2.1024 ## ## aux. Z statistics ## Z-tau-mu 4.1119 ## Z-tau-beta 2.3111 ## ## Critical values for Z statistics: ## 1pct 5pct 10pct ## critical values -3.9722 -3.416657 -3.130326 \\(Z_{\\tau}\\)検定 &amp; 定数項あり ur.pp(p8411, type = &quot;Z-tau&quot;, model = &quot;constant&quot;) %&gt;% summary() ## ## ################################## ## # Phillips-Perron Unit Root Test # ## ################################## ## ## Test regression with intercept ## ## ## Call: ## lm(formula = y ~ y.l1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -571.86 -14.33 -1.27 15.17 208.49 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.740812 3.688285 0.743 0.458 ## y.l1 0.999615 0.001934 516.776 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 38.55 on 998 degrees of freedom ## Multiple R-squared: 0.9963, Adjusted R-squared: 0.9963 ## F-statistic: 2.671e+05 on 1 and 998 DF, p-value: &lt; 2.2e-16 ## ## ## Value of test-statistic, type: Z-tau is: -0.0185 ## ## aux. Z statistics ## Z-tau-mu 0.6342 ## ## Critical values for Z statistics: ## 1pct 5pct 10pct ## critical values -3.439528 -2.864846 -2.568542 Kwiatkowski-Phillips-Schmidt-Shin (KPSS) 検定 KPSS検定は, ADF検定やPP検定とは, 帰無仮説・対立仮説が入れ替わる: \\(H_{0}\\): 確定的トレンド付き定常過程 vs \\(H_{1}\\): 単位根過程 すなわち, \\(H_0\\) を棄却しない場合は, 確定的トレンド付き定常過程 (トレンド定常性) を結論として得ることに注意が必要である. 観測過程が \\(\\{X_{t}\\}=\\)確定的トレンド + ランダムウォーク + 定常過程, すなわち, \\[ X_{t} = \\alpha+\\beta \\cdot t + \\sum_{s=1}^{t}Z_{s} + \\epsilon_{t}, \\, \\{Z_t\\}\\sim IID(0,\\sigma_Z^2) \\] として生成されていると仮定, ランダムウォーク項の有無の検定を\\(Z_t\\)の分散が0か否かを調べることで行う. \\(H_{0}:\\,\\sigma_{Z}^{2}=0\\) (トレンド定常過程) vs \\(H_{1}:\\,\\sigma_{Z}^{2}\\ne0\\) (単位根過程) 具体的には, 確定的トレンド (\\(\\alpha+\\beta t\\)) を説明変数とする最小二乗回帰によって得られる残差部分和の大きさを使って検定を行う. パッケージurca内, 関数ur.kpss() 用法: ur.kpss(y, type = c(&quot;mu&quot;, &quot;tau&quot;), lags = c(&quot;short&quot;, &quot;long&quot;, &quot;nil&quot;), use.lag = NULL) 主要な引数: - 確定的トレンドの種類type: &quot;mu&quot; (定数項), &quot;tau&quot; (線形トレンド) - 誤差修正項のラグ長lags: &quot;short&quot;=4(T/100)^(1/4), &quot;long&quot;=12(T/100)^(1/4) 定数項あり ur.kpss(p8411, type = &quot;mu&quot;, lags = &quot;long&quot;) %&gt;% summary() ## ## ####################### ## # KPSS Unit Root Test # ## ####################### ## ## Test is of type: mu with 21 lags. ## ## Value of test-statistic is: 4.156 ## ## Critical value for a significance level of: ## 10pct 5pct 2.5pct 1pct ## critical values 0.347 0.463 0.574 0.739 線形トレンドあり ur.kpss(p8411, type = &quot;tau&quot;, lags = &quot;long&quot;) %&gt;% summary() ## ## ####################### ## # KPSS Unit Root Test # ## ####################### ## ## Test is of type: tau with 21 lags. ## ## Value of test-statistic is: 0.9797 ## ## Critical value for a significance level of: ## 10pct 5pct 2.5pct 1pct ## critical values 0.119 0.146 0.176 0.216 ちなみに, forecastパッケージの関数ndiff()は, 時系列データが定常になるのに必要な差分操作の回数を求める関数で, 内部で単位根検定を繰り返し実行する. 用法: ndiffs(x, alpha = 0.05, test = c(&quot;kpss&quot;, &quot;adf&quot;, &quot;pp&quot;), type = c(&quot;level&quot;, &quot;trend&quot;), max.d = 2, ...) - 単位根検定の種類test: KPSS (デフォルト)/ADF/PP - 確定的トレンドの種類type: &quot;level&quot;(定数項のみ)/&quot;trend&quot;(定数項+線形トレンド) "],["長期記憶過程.html", "6 長期記憶過程 6.1 長期記憶過程のシミュレーション 6.2 Hurst指数の推定 6.3 ARFIMAモデルの推定 6.4 ARFIMAモデル: データ分析例 (1) 6.5 ARFIMAモデル: データ分析例 (2)", " 6 長期記憶過程 本章は, 長期記憶性 (long memory) (別名, 長期従属性 (long-range dependence)) を扱う. 長期記憶性は, 為替レート, 為替フォワード・プレミアム, 金利スプレッド, 株式の出来高, オーダー・フロー, ボラティリティなど, 様々な金融時系列において報告されている. 前章までで学んだARIMA(\\(p,d,q\\))モデルにおいて, 定常になるまでの差分の回数を表す\\(d\\)を, 非負の整数\\(d\\)から小数へと拡張したモデル, 自己回帰非整数平均 (Auto-Regressive Fractionally Integrated Moving Average) モデル, 略して, ARFIMA(\\(p,d,q\\)) モデルは, 離散時間の時系列解析における長期記憶過程の一つとして 重要なモデルクラスである. \\(d\\)を小数に取ることで, 長期記憶性を記述することができるようになっている. \\[ \\phi(B)(1-B)^d X_t = \\theta(B) Z_t \\tag{2}, \\quad -0.5&lt;d&lt;0.5\\] ただし, 前章までと同様に, Backward shift operator \\(B\\) AR多項式 \\(\\phi(z)=1 - \\phi_1 z - \\cdots - \\phi_p z^p\\) MA多項式 \\(\\theta(z)=1 + \\theta_1 z + \\cdots + \\theta_q z^q\\) このARFIMA(\\(p,d,q\\))過程は, “差分”パラメータの次数が \\(-1/2 &lt; d &lt; 1/2\\) の範囲の時, 定常 (かつ反転可能) となる. 特別な場合として, ARFIMA(\\(0,d,0\\))モデルがある (非整数和分白色ノイズ, fractionally integrated white noise). \\[ (1-B)^d X_t = Z_t \\tag{2}, \\quad -0.5&lt;d&lt;0.5\\] 一般のARFIMA(\\(p,d,q\\))モデルは, このARFIMA(\\(0,d,0\\))を駆動ノイズ (イノベーション過程) として持つようなARMA(\\(p,q\\))モデルであると解釈することができる. すなわち, \\(W \\sim ARFIMA(0,d,0)\\)とすると, \\((1-B)^d W_t = Z_t\\)であるから, \\[ \\phi(B) X_t = \\theta(B) W_t= \\theta(B) \\frac{Z_t}{(1-B)^d}, \\quad -0.5&lt;d&lt;0.5\\] また, 定常なARMA(\\(p,q\\))モデルに対して, それを1回和分した非定常な過程であるARIMA(\\(p,1,q\\))モデルがあるように, 定常なARFIMA(\\(p,d,q\\))モデル (\\(-1/2&lt;d&lt;1/2\\)) に対して, 非定常なARFIMA(\\(p,1+d,q\\))モデルも存在する. ARFIMAモデルにおける\\(d\\)の大きさの影響を知るには, このARFIMA(\\(p,1+d,q\\))のサンプルパスの持つ確率的トレンドの挙動をみると分かりやすい. すなわち, \\(d\\)大きさにより, 時系列は次のような性質を持つ: \\(0 &lt; d &lt; 1/2\\): ARFIMA(\\(p,d,q\\)): 正の長期従属性, または持続性 (persistency) ARFIMA(\\(p,1+d,q\\)): 持続的なトレンドのサンプルパス \\(-1/2 &lt; d &lt; 0\\): ARFIMA(\\(p,d,q\\)): 負の長期従属性, 反持続性 (anti-persistency) ARFIMA(\\(p,1+d,q\\)): トレンドが持続せず, 素早く平均回帰するようなサンプルパス \\(d = 0\\): ARFIMA(\\(p,d,q\\)) \\(\\equiv\\) ARMA(\\(p,q\\)) (短期記憶のみ) ARFIMA(\\(p,1+d,q\\)) \\(\\equiv\\) ARIMA(\\(p,1,q\\)) 本章ではまた, 長期記憶性を持つ, 連続時間の確率過程のクラス として重要な非整数ブラウン運動 fBM (fractional Brownian motion) についても簡単に触れる. ハースト指数\\(H\\)は, 時系列データの長期記憶性を示す 指標の一つであり, 理論的には, fBMの増分過程 (非整数ガウスノイズ, fGN) に対する長期記憶性を表現する パラメータとして導入される. 上の\\(d\\)の場合分けに対応し, \\(H\\)の大きさにより, \\(1/2 &lt; H &lt; 1\\): fGNに正の長期従属性, または持続性 fBMはトレンドの続くサンプルパス \\(0 &lt; H &lt; 1/2\\): fGNに負の長期従属性, または反持続性 fBMはトレンドが続かない, 素早く反転するサンプルパス \\(H = 1/2\\): fGNは無相関 (独立) fBMは通常のブラウン運動. 過去のサンプルパスと未来のサンプルパスは独立. この\\(H\\)と\\(d\\)の間には, \\(H = d + 1/2\\)なる関係が成立する. 本章では, Rを使用した, 所与の時系列データに対する\\(H\\)の推定方法についても紹介する. 6.1 長期記憶過程のシミュレーション まず, Rパッケージを用い, 長期記憶性を持つ確率過程のサンプルパスを生成し, 視覚的に特徴を捉えてみよう. パッケージfracdiffの利用 ARFIMA(\\(p,d,q\\))過程のシミュレーション パッケージfracdiffに含まれる関数fracdiff.sim()を 使うことで, ARFIMA(\\(p,d,q\\))過程のサンプルパスを生成することができる. ここで, fracdiffにおけるAR/MA多項式は, \\(\\phi(z) = 1 - \\phi_1 z - \\cdots - \\phi_p z^p\\), \\(\\theta(z) = 1 - \\theta_1 z - \\cdots - \\theta_q z^q\\) である. すなわち, MA多項式の各項の符号が講義内の表記と 反対になっていることに注意しよう. まず, ARFIMA(\\(p,d,q\\))過程の長期記憶性を理解するために, AR項やMA項に起因する短期記憶性の影響を排除した, サブクラスであるARFIMA(\\(0,d,0\\))過程の挙動と, これを和分したARFIMA(\\(0,1+d,0\\))過程の挙動をシミュレートする. 持続性の場合 (\\(d=0.4\\)) tlen &lt;- 300 seedv &lt;- 100; set.seed(seedv) library(fracdiff) fds_sim &lt;- fracdiff.sim(tlen, d = 0.4) # -0.5&lt;=d&lt;=0.5 x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(0,d,0)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(0,1+d,0)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 反持続性の場合 (\\(d=-0.4\\)) set.seed(seedv) fds_sim &lt;- fracdiff.sim(tlen, d = -0.4) x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(0,d,0)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(0,1+d,0)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 無相関の場合 (\\(d=0\\)) set.seed(seedv) fds_sim &lt;- fracdiff.sim(tlen, d = 0) x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(0,d,0)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(0,1+d,0)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 次に, AR項やMA項の入っている一般のARFIMA(\\(p,d,q\\))の場合についてシミュレートする. ここでは, \\(p=2,q=1\\)に設定する. また, ここでも, ARFIMA(\\(p,1+d,q\\))のパスも合わせて表示する. 持続性の場合 (\\(d=0.4\\)) tlen &lt;- 300 seedv &lt;- 100; set.seed(seedv) library(fracdiff) fds_sim &lt;- fracdiff.sim(tlen, ar = c(0.7, -0.2), ma = 0.1, d = 0.4) # -0.5&lt;=d&lt;=0.5 x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(p,d,q)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(p,1+d,q)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) 反持続性の場合 (\\(d=-0.4\\)) set.seed(seedv) fds_sim &lt;- fracdiff.sim(tlen, ar = c(0.7, -0.2), ma = 0.1, d = -0.4) x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(p,d,q)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(p,1+d,q)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) ARMA/ARIMAの場合 (\\(d=0\\)) set.seed(seedv) fds_sim &lt;- fracdiff.sim(tlen, ar = c(0.7, -0.2), ma = 0.1, d = 0.1) x &lt;- fds_sim$series # 長期記憶系列 par(mfrow = c(2, 1)) plot(x, type = &quot;l&quot;, main = &quot;ARFIMA(p,d,q)&quot;) plot(cumsum(x), type = &quot;l&quot;, main = &quot;ARFIMA(p,1+d,q)&quot;) par(mfrow = c(1, 2)) acf(x) # 自己相関(ACF) pacf(x) # 偏自己相関(PACF) パッケージlongmemoの利用 ARFIMA, 非整数ガウス (fractional Gaussian) 過程の自己共分散関数 - ckARMA0(n, H): ARFIMA(0,d,0) 過程の自己共分散関数の理論計算 (大きなkでは近似) (d = H - 1/2). # install.packages(&quot;longmemo&quot;) library(longmemo) seedv &lt;- 1 tlen &lt;- 100 hval &lt;- 0.9 plot(ckARMA0(tlen, H = hval), type = &quot;h&quot;) # H &gt; 0.5の時のみ plot(x = 0:(tlen - 1), ckARMA0(tlen, H = hval), type = &quot;h&quot;, log = &quot;xy&quot;, main = paste0(&quot;Log-Log ACF for ARFIMA(0,d,0)\\nH = &quot;, hval)) - ckFGN0(n, H): 非整数ガウス過程の自己共分散関数の理論計算 # ckFGN0(n, H) # Compute the Autocovariances of a fractional Gaussian process plot(ckFGN0(tlen, H = hval), type = &quot;h&quot;) # (H &gt; 0.5の時のみ) plot(x = 0:(tlen-1), ckFGN0(tlen, H = hval), type = &quot;h&quot;, log = &quot;xy&quot;, main = paste0(&quot;Log-Log ACF for fGN\\nH = &quot;, hval)) ARFIMA, 非整数ガウス (fractional Gaussian) 過程のシミュレーション シミュレーションを行う関数として, ARFIMA(\\(0,d,0\\))にはsimARMA0()が, 非整数ガウス過程にはsimFGN0が用意されている. seedv &lt;- 1 set.seed(seedv) x1 &lt;- simFGN0(tlen, H = hval) # 非整数ガウス過程 x2 &lt;- simARMA0(tlen, H = hval) # ARFIMA(0,d,0) ts.plot(ts.union(x1, x2), col = 1:2, lty = 1:2, main = paste0(&quot;fGN vs ARFIMA(0,d,0): H = &quot;, hval)) # ts.plot(cbind(x1, x2), col = 1:2, lty = 1:2) 一般のARFIMA(\\(p,d,q\\)) (\\(-1/2&lt;d&lt;1/2\\)) のシミュレーションは, 以下のように, 関数simARMA0()を使ってイノベーション過程を生成し, それをarima.sim()に与えることで実現することもできる (AR/MAパラメータは数値ベクトルで指定する). # ARFIMA(2, 0.3, 1)の実行例 # AR係数: phi_1 = 0.9, phi_2 = -0.5 # MA係数: theta_1 = -0.2 phi &lt;- c(0.9, -0.5) theta &lt;- -0.2 d &lt;- 0.3 x3 &lt;- arima.sim(tlen, model = list(ar = phi, ma = theta), innov= simARMA0(tlen, H = d + 1/2), n.start = length(phi) + length(theta)) plot(x3, main = &quot;ARFIMA(p,d,q)&quot;) 非整数ブラウン運動 (fBM) は, 非整数ガウス過程 (fGN) を増分過程とする確率過程であることから, fGNのサンプルパスを 累積することで, fBMのサンプルパスを得ることができる. fBM_path &lt;- function(tlen = 100, H = 0.5, sd_val = 1) { set.seed(sd_val) cumsum(simFGN0(tlen, H)) } # plot(fBM_path(tlen, hval, seedv), type = &quot;l&quot;, main = &quot;fBM&quot;) Hurst指数を3通り (\\(0.1, 0.5, 0.8\\)) に変えてサンプルパスを生成し, 比較する. # 異なるHの値でのサンプルパスの比較 hvals &lt;- c(0.5, 0.1, 0.8) fBM1 &lt;- fBM_path(tlen, hvals[1], seedv) fBM2 &lt;- fBM_path(tlen, hvals[2], seedv) fBM3 &lt;- fBM_path(tlen, hvals[3], seedv) ts.plot(cbind(fBM1, fBM2, fBM3), col = c(&quot;#111111&quot;, &quot;darkgrey&quot;, &quot;lightgrey&quot;), lty = 1, lwd = c(1, 3, 3), main = paste0(&quot;fBM\\nH = &quot;, paste(hvals, collapse = &quot;,&quot;))) 次に, Hurst指数の推定や, ARFIMAモデルの推定を シミュレーションデータを用いて行う. 6.2 Hurst指数の推定 パッケージpracmaの利用 - hurstexp(): R/S分析によるHurst指数推定 (複数の方法を同時実行) - 出力: - Hs - simplified R over S approach - Hrs - corrected R over S Hurst exponent - He - empirical Hurst exponent - Hal - corrected empirical Hurst exponent - Ht - theoretical Hurst exponent 持続性, 系列無相関 (独立), 反持続性の3つの場合について, \\(H = 0.72, 0.50, 0.43\\) と設定された場合の サンプルパスを使う. x72はpracmaに収録されている予め生成された サンプルパスである. xlmの生成手順は, pracmaの マニュアルに従う. library(pracma) data(brown72) x72 &lt;- brown72 # H = 0.72 xgn &lt;- rnorm(1024) # H = 0.50 xlm &lt;- numeric(1024); xlm[1] &lt;- 0.1 # H = 0.43 for (i in 2:1024) { xlm[i] &lt;- 4 * xlm[i - 1] * (1 - xlm[i - 1]) } 持続性の場合 (\\(H = 0.72\\)) ここで, x72は平均が正の値を持っているため, 累積してfBMのパスを生成する際に 平均値を差し引いて (線形トレンドを除いてから) から可視化する. par(mfrow = c(2,1)) plot(x72, type = &quot;l&quot;, main = &quot;fGN&quot;) plot(cumsum(x72 - mean(x72)), type = &quot;l&quot;, main = &quot;fBM&quot;) ブラウン運動の場合 (\\(H = 0.50\\)) par(mfrow = c(2,1)) plot(xgn, type = &quot;l&quot;, main = &quot;fGN&quot;) plot(cumsum(xgn), type = &quot;l&quot;, main = &quot;fBM&quot;) 反持続性の場合 (\\(H = 0.43\\)) xlmはやはり平均値が正のため, fBMのパスを生成する際に 平均値を差し引いてから可視化する. par(mfrow = c(2,1)) plot(xlm, type = &quot;l&quot;, main = &quot;fGN&quot;) plot(cumsum(xlm - mean(xlm)), type = &quot;l&quot;,main = &quot;fBM&quot;) 各々のパスから推定されるハースト指数は以下の通りである. hurstexp(brown72) # d: smallest box size (default = 50) #&gt; Simple R/S Hurst estimation: 0.6628842 #&gt; Corrected R over S Hurst exponent: 0.7378703 #&gt; Empirical Hurst exponent: 0.6920439 #&gt; Corrected empirical Hurst exponent: 0.6577233 #&gt; Theoretical Hurst exponent: 0.5404756 hurstexp(xgn) #&gt; Simple R/S Hurst estimation: 0.4784489 #&gt; Corrected R over S Hurst exponent: 0.4898617 #&gt; Empirical Hurst exponent: 0.5041802 #&gt; Corrected empirical Hurst exponent: 0.4636032 #&gt; Theoretical Hurst exponent: 0.5404756 hurstexp(xlm) #&gt; Simple R/S Hurst estimation: 0.4762169 #&gt; Corrected R over S Hurst exponent: 0.4722421 #&gt; Empirical Hurst exponent: 0.4872281 #&gt; Corrected empirical Hurst exponent: 0.4460807 #&gt; Theoretical Hurst exponent: 0.5404756 パッケージfractalの利用 library(fractal) x &lt;- x72 hurstSpec(x) RoverS(x) hurstBlock(x, method=&quot;aggAbs&quot;) hurstBlock(x, method=&quot;aggVar&quot;) hurstBlock(x, method=&quot;diffvar&quot;) hurstBlock(x, method=&quot;higuchi&quot;) 6.3 ARFIMAモデルの推定 パッケージforecastの関数arfima()は, ARFIMAモデルの自動選択&amp;パラメータ推定を実行することができる. これについては本章の最後に紹介することとし, その前に, 手動でパラメータの推定を行う方法について幾つか紹介する. パッケージfracdiffの利用 真の確率過程がARFIMA(\\(2,d,0\\)) (\\(d=-0.49\\)) にも拘らず, 誤ってARモデルを選択し, ar()により推定した場合. # library(fracdiff) set.seed(seedv) fds_sim &lt;- fracdiff.sim(tlen, ar = c(0.7, -0.2), d = -0.49) x &lt;- fds_sim$series # 長期記憶系列 # (ar_fit &lt;- ar(x, method = &quot;mle&quot;)) # 最尤法 #&gt; #&gt; Call: #&gt; ar(x = x, method = &quot;mle&quot;) #&gt; #&gt; Coefficients: #&gt; 1 2 3 4 5 6 #&gt; 0.2060 -0.2321 -0.2082 -0.1717 -0.1534 -0.1875 #&gt; #&gt; Order selected 6 sigma^2 estimated as 0.7814 → 大きい\\(p\\)を選択 パッケージfracdiff内の関数fracdiff()により, AR係数, MA係数, 階差次数\\(d\\)を最尤推定する (以下, \\(p=2\\)を正しくしていたと仮定). # nar, nma # AR, MAパラメーター数 (fds_fit &lt;- fracdiff(x, nar = 2)) #&gt; #&gt; Call: #&gt; fracdiff(x = x, nar = 2) #&gt; #&gt; Coefficients: #&gt; d ar1 ar2 #&gt; 4.583013e-05 3.478729e-01 -2.143891e-01 #&gt; sigma[eps] = 0.9577181 #&gt; a list with components: #&gt; [1] &quot;log.likelihood&quot; &quot;n&quot; &quot;msg&quot; &quot;d&quot; #&gt; [5] &quot;ar&quot; &quot;ma&quot; &quot;covariance.dpq&quot; &quot;fnormMin&quot; #&gt; [9] &quot;sigma&quot; &quot;stderror.dpq&quot; &quot;correlation.dpq&quot; &quot;h&quot; #&gt; [13] &quot;d.tol&quot; &quot;M&quot; &quot;hessian.dpq&quot; &quot;length.w&quot; #&gt; [17] &quot;residuals&quot; &quot;fitted&quot; &quot;call&quot; → 通常は\\(p,q\\)は未知 → 引数nar, nmaは複数の候補を試すべき パッケージnsarfimaの利用 パッケージnsarfima内の関数mle.arfima()により, AR係数, MA係数, 階差次数\\(d\\)を最尤推定する. library(nsarfima) # p, q # AR, MAパラメーター数 (arfima_fit &lt;- mle.arfima(x, p = 2)) #&gt; $pars #&gt; mu sig2 d ar.1 ar.2 #&gt; -1.267263e-02 9.022758e-01 5.522776e-08 3.414323e-01 -2.625068e-01 #&gt; #&gt; $std.errs #&gt; mu sig2 d ar.1 ar.2 #&gt; 0.1016556 0.1395288 0.1733823 0.2163811 0.1612114 #&gt; #&gt; $cov.mat #&gt; sig2 d ar.1 ar.2 #&gt; sig2 0.019468294 0.00740705 -0.01170439 -0.004266261 #&gt; d 0.007407050 0.03006142 -0.03229578 -0.021628130 #&gt; ar.1 -0.011704389 -0.03229578 0.04682076 0.024479505 #&gt; ar.2 -0.004266261 -0.02162813 0.02447951 0.025989126 #&gt; #&gt; $fit.obj #&gt; $fit.obj$par #&gt; d ar.1 ar.2 #&gt; 5.522776e-08 3.414323e-01 -2.625068e-01 #&gt; #&gt; $fit.obj$value #&gt; [1] 89.3253 #&gt; #&gt; $fit.obj$counts #&gt; function gradient #&gt; 208 NA #&gt; #&gt; $fit.obj$convergence #&gt; [1] 0 #&gt; #&gt; $fit.obj$message #&gt; NULL #&gt; #&gt; #&gt; $p.val #&gt; [1] 0.8912225 #&gt; #&gt; $residuals #&gt; [1] -0.6764961052 -0.2968632520 -1.2310910722 1.4561378726 -0.0388534504 #&gt; [6] -0.8423204011 0.4686722844 0.4643382756 0.4107973532 -0.4309650411 #&gt; [11] 1.4299789135 -0.0006787575 -0.7857763053 -2.3890626204 1.1014635252 #&gt; [16] -0.3966402031 0.1652482404 1.0616568645 0.7446050471 0.5154245086 #&gt; [21] 0.7564241338 0.4668174692 -0.2693729499 -2.3064083881 0.5227350640 #&gt; [26] -0.4642720829 -0.1309552624 -1.4100725427 -0.2774497899 0.4650877267 #&gt; [31] 1.4649891568 -0.0290343810 0.5782727746 -0.1757284573 -1.4912805335 #&gt; [36] -0.3789621380 -0.4655630075 0.0738483187 1.2914770769 0.8336925539 #&gt; [41] -0.0737873115 -0.2251819617 0.5774490180 0.3286308280 -0.8047251630 #&gt; [46] -0.6986673145 0.2958393665 0.6510135686 -0.1339248247 0.9675384987 #&gt; [51] 0.2259759735 -0.7281405491 0.2716268869 -1.3784731074 1.4943394505 #&gt; [56] 1.7164276897 -0.5272803532 -1.0201592423 0.3729804733 -0.5359889283 #&gt; [61] 2.3350415888 -0.4086512940 0.6924717331 -0.3606512486 -1.0759283895 #&gt; [66] -0.0506511539 -2.1101132511 1.5976097508 -0.1172982949 2.3325016401 #&gt; [71] 0.2254993256 -0.8129057325 0.3788283790 -1.4331970583 -1.3747001462 #&gt; [76] 0.2411732472 -0.5537230862 0.2049218798 0.2004499504 -0.4766722677 #&gt; [81] -0.4042575452 -0.0270582246 1.2728679869 -1.5304518129 0.9624356049 #&gt; [86] 0.2186716228 1.1235112273 -0.3688834767 0.4233844401 0.0726586865 #&gt; [91] -0.6954346528 1.1689570269 0.8808727109 0.5369119812 1.3879840390 #&gt; [96] 0.0879308998 -1.6719344153 -0.8630402713 -1.6381541198 -0.5431240556 ARFIMAモデルの\\(d\\)を (再帰的に) 推定する方法 (ARFIMA(\\(p,d,g\\))過程から生成された) 時系列データ\\(\\{x_t\\}\\)が与えられた時に, 以下の手順に従うことで \\(d\\)を (再帰的に) 推定することができる: \\(x_t\\) (所与) と\\(d\\)の推定値 (初期値) があるとする 推定された\\(d\\)が正しい値ならば, \\(Y_t=(1-B)^d X_t\\)はARMA(\\(p,q\\))過程になるはず \\(x_t\\)より, パス\\(y_t\\)を (近似的に) 生成する (自作関数get_fracdiff_ts()使用) ARMAモデルを生成パス\\(y_t\\)に適合する. 得られる残差系列が白色ノイズか? (納得いくまで) 候補を変えて試す. ※ 参考: Cowpertwait and Metcalfe(2009), Ch.8 長期記憶過程xより非整数階差系列yを生成する自作関数: get_fracdiff_ts &lt;- function(x, d, l = 30) { # l: 項の打ち切り数 n &lt;- length(x) # 1. fdc: (1-B)^d の2項展開係数ベクトルを生成 frac_diff_coeffs &lt;- numeric(l) frac_diff_coeffs[1] &lt;- d for (k in 2:l) { frac_diff_coeffs[k] &lt;- frac_diff_coeffs[k - 1] * (d + 1 - k) / k } # 2. y: 非整数階差分系列 (fractionally differenced series) を生成 frac_diff_series &lt;- numeric(n) for (i in (l + 1):n) { current_sum &lt;- x[i] # 原系列 x for (j in 1:l) { current_sum &lt;- current_sum + ((-1) ^ j) * frac_diff_coeffs[j] * x[i - j] } frac_diff_series[i] &lt;- current_sum } # 3. l+1 以降の系列を返す frac_diff_series &lt;- frac_diff_series[(l + 1):n] return(frac_diff_series) } ここでは, (例示のため) AR(p)モデルに限定. 以下, 上で生成したパス\\(x_t\\)を所与, 得られた\\(d\\)の推定値を初期値として使用. (注: \\(x_t\\)は上で, ARFIMA(\\(2,d,0\\)), \\(d=-0.49\\)により生成されていた) # 先に得られたx, fds_fitをそのまま使用 y &lt;- get_fracdiff_ts(x, fds_fit$d) # {x_t}より非整数階差系列{y_t}を生成 (z_ar &lt;- ar(y)) # ARモデルを適合 #&gt; #&gt; Call: #&gt; ar(x = y) #&gt; #&gt; Coefficients: #&gt; 1 2 3 4 #&gt; 0.2598 -0.0943 -0.1637 -0.2469 #&gt; #&gt; Order selected 4 sigma^2 estimated as 0.8692 ns &lt;- 1 + z_ar$order z &lt;- z_ar$res [ns:length(y)] # z_ar$resの最初のns個は欠損 par(mfcol = c(2, 2)) plot(as.ts(x), ylab = &quot;x&quot;) acf(x) ; acf(y) ; acf(z) Box.test(z, lag = 30, type = &quot;Ljung&quot;) #&gt; #&gt; Box-Ljung test #&gt; #&gt; data: z #&gt; X-squared = 29.658, df = 30, p-value = 0.4833 階差次数\\(d\\)の代替的推定法 パッケージfracdiffにより, Geweke and Porter-Hudak(83), Reisen(94)の代替的な\\(d\\)の推定を行うことができる. これらは, 時系列データのperidogram (スペクトル密度の推定値) をベースにした方法である. # library(fracdiff) # Geweke and Porter-Hudak(83)の方法 (d_GPH &lt;- fdGPH(x)) #&gt; $d #&gt; [1] -0.7167363 #&gt; #&gt; $sd.as #&gt; [1] 0.2935592 #&gt; #&gt; $sd.reg #&gt; [1] 0.2232167 # Reisen(94)の方法 (d_Sper &lt;- fdSperio(x)) #&gt; $d #&gt; [1] -0.6491031 #&gt; #&gt; $sd.as #&gt; [1] 0.1334138 #&gt; #&gt; $sd.reg #&gt; [1] 0.08329104 先のget_fracdiff_ts()を使い\\(\\{y_t\\}\\)を生成し, これが白色ノイズになるかを確認する. # GPH推定値の使用 y &lt;- get_fracdiff_ts(x, d_GPH$d) # {x_t}より非整数階差系列{y_t}を生成 # ARMAモデルの適合に, パッケージforecastのauto.arima()関数使用 library(forecast) (y_fit &lt;- auto.arima(y)) # ARモデルをフィット #&gt; Series: y #&gt; ARIMA(0,0,3) with zero mean #&gt; #&gt; Coefficients: #&gt; ma1 ma2 ma3 #&gt; 0.8403 0.5521 0.2549 #&gt; s.e. 0.1171 0.1411 0.1297 #&gt; #&gt; sigma^2 = 0.8098: log likelihood = -90.83 #&gt; AIC=189.66 AICc=190.27 BIC=198.65 # y_resid &lt;- y_fit$res # par(mfcol = c(1, 2)) # acf(y_resid); pacf(y_resid) # Box.test(y_resid, lag = 30, type = &quot;Ljung&quot;) tsdiag(y_fit) # または accuracy(y_fit) #&gt; ME RMSE MAE MPE MAPE MASE #&gt; Training set 0.1063931 0.8803915 0.7113902 4.33671 171.6947 0.9058205 #&gt; ACF1 #&gt; Training set -0.01454969 checkresiduals(y_fit) #&gt; #&gt; Ljung-Box test #&gt; #&gt; data: Residuals from ARIMA(0,0,3) with zero mean #&gt; Q* = 1.6466, df = 7, p-value = 0.9768 #&gt; #&gt; Model df: 3. Total lags used: 10 ※ よりフォーマルなモデル同定・推定の手順は, 配布資料参照. 6.4 ARFIMAモデル: データ分析例 (1) Tsay, 2.11, pp.119–120 データ&amp;コードの出所: https://sites.google.com/site/econometricsr/home/rcode コードは一部改 # library(fracdiff) ifl &lt;- file.path(dir_introTS, &quot;d-ibm3dx7008.txt&quot;) da &lt;- read.table(ifl, header = T) head(da) #&gt; Date rtn vwretd ewretd sprtrn #&gt; 1 19700102 0.000686 0.012137 0.033450 0.010211 #&gt; 2 19700105 0.009596 0.006375 0.018947 0.004946 #&gt; 3 19700106 0.000679 -0.007233 -0.005776 -0.006848 #&gt; 4 19700107 0.000678 -0.001272 0.003559 -0.002047 #&gt; 5 19700108 0.002034 0.000564 0.002890 0.000540 #&gt; 6 19700109 -0.001353 -0.002797 -0.002923 -0.003021 ew &lt;- abs(da$vwretd) # daily abs ret&#39;s of value-weighted CRSP, 1970--2008 plot(as.ts(ew)) 次数dの推定 # pure fractionally differenced modelに対して(p=0, q=0) # Geweke-Porter-Hudak(83) estimate # (m3 &lt;- fdGPH(da$vwretd)) # d=0.05282 (m3 &lt;- fdGPH(ew)) #&gt; $d #&gt; [1] 0.372226 #&gt; #&gt; $sd.as #&gt; [1] 0.0698385 #&gt; #&gt; $sd.reg #&gt; [1] 0.06868857 → \\(0&lt;d&lt;0.5\\) ∴ 定常, かつ反転可能 (invertible) # Reisen (94) estimate # (m3.2 &lt;- fdSperio(ew)) # 0.3784656 # 最尤法 (nar, nmaの指定必要) # m3.0 &lt;- fracdiff(ew, nar = 0, nma = 0) # デフォルト: nar = 0, nma = 0 # summary(m3.0) # ARFIMA(1,d,1)の最尤推定 m2 &lt;- fracdiff(ew, nar = 1, nma = 1) summary(m2) #&gt; #&gt; Call: #&gt; fracdiff(x = ew, nar = 1, nma = 1) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; d 0.490938 0.007997 61.39 &lt;2e-16 *** #&gt; ar 0.113389 0.005988 18.94 &lt;2e-16 *** #&gt; ma 0.575895 0.005946 96.85 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; sigma[eps] = 0.0065619 #&gt; [d.tol = 0.0001221, M = 100, h = 0.0003742] #&gt; Log likelihood: 3.551e+04 ==&gt; AIC = -71021.02 [4 deg.freedom] coef(m2) #&gt; d ar ma #&gt; 0.4909382 0.1133893 0.5758949 confint(m2) #&gt; 2.5 % 97.5 % #&gt; d 0.4752637 0.5066127 #&gt; ar 0.1016536 0.1251250 #&gt; ma 0.5642407 0.5875491 注: MA係数の符号が, arima()の符号とは反対 Table 6.1: パラメータ推定値 2.5 % 97.5 % d 0.4909382 0.4752637 0.5066127 ar 0.1133893 0.1016536 0.1251250 ma 0.5758949 0.5642407 0.5875491 → dの値, 非定常境界 (d=0.5) に近い set.seed(101) m2_sim &lt;- fracdiff.sim(n = 512, ar = coef(m2)[&quot;ar&quot;], ma = -coef(m2)[&quot;ma&quot;], d = coef(m2)[&quot;d&quot;]) plot(as.ts(m2_sim$series)) hurstexp(ew) # ハースト指数 #&gt; Simple R/S Hurst estimation: 0.7368679 #&gt; Corrected R over S Hurst exponent: 0.8540535 #&gt; Empirical Hurst exponent: 0.9058207 #&gt; Corrected empirical Hurst exponent: 0.8784372 #&gt; Theoretical Hurst exponent: 0.5264069 6.5 ARFIMAモデル: データ分析例 (2) 日次ボラティリティ系列には, 長期記憶性があることが多くの実証分析で報告されている (stylized factsの一つ). ここでは, 実現ボラティリティ (RV) の日次系列に対して ARFIMAモデルの推定を試みる. データセットして, パッケージhighfrequencyに含まれている SPYRMデータセットを用いる. これはSPY (S&amp;P500 ETF)の高頻度 データより計算された日次のリスク・流動性指標を格納している データセットである. SPYRM - realized measuresの日次系列 - データ期間: 1/2/2014--12/31/2019 このSPYRM内の要素RV5は5分次リターンより計算された実現ボラティリティ (RV) である. 今回はこれに対してARFIMAモデルを適合する. # RV (Realized Volatility): 実現ボラティリティ library(highfrequency) data(SPYRM) # SPY (SPDR S&amp;P500 ETF) head(SPYRM) # realized measuresの日次系列 #&gt; Key: &lt;DT&gt; #&gt; DT RV1 RV5 BPV1 BPV5 medRV1 #&gt; &lt;Date&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; #&gt; 1: 2014-01-02 2.680770e-05 2.570763e-05 2.535726e-05 2.374001e-05 2.454129e-05 #&gt; 2: 2014-01-03 1.584448e-05 1.777932e-05 1.549670e-05 1.670686e-05 1.538273e-05 #&gt; 3: 2014-01-06 2.722618e-05 2.562549e-05 2.179050e-05 1.888701e-05 2.239435e-05 #&gt; 4: 2014-01-07 1.083393e-05 9.949228e-06 1.004319e-05 9.745236e-06 1.058696e-05 #&gt; 5: 2014-01-08 3.111775e-05 2.678386e-05 2.578336e-05 2.347057e-05 2.644604e-05 #&gt; 6: 2014-01-09 2.316577e-05 1.870702e-05 1.977435e-05 1.113170e-05 2.039378e-05 #&gt; medRV5 RK1 RK5 RQ1 RQ5 medRQ1 #&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; #&gt; 1: 1.933930e-05 2.586084e-05 2.639544e-05 0.05341515 0.05426241 0.04728122 #&gt; 2: 1.626439e-05 1.600491e-05 1.634770e-05 0.03020677 0.03037783 0.02960068 #&gt; 3: 1.638726e-05 3.195125e-05 2.586378e-05 0.06205223 0.05000808 0.04193434 #&gt; 4: 9.317152e-06 9.422459e-06 9.962419e-06 0.02134510 0.01695114 0.02069017 #&gt; 5: 2.323985e-05 1.978144e-05 1.942075e-05 0.08892314 0.05380877 0.08233854 #&gt; 6: 1.011690e-05 1.908528e-05 2.138626e-05 0.04709965 0.04329358 0.04527193 #&gt; medRQ5 CLOSE #&gt; &lt;num&gt; &lt;num&gt; #&gt; 1: 0.04728122 182.95 #&gt; 2: 0.02960068 182.80 #&gt; 3: 0.04193434 182.40 #&gt; 4: 0.02069017 183.45 #&gt; 5: 0.08233854 183.53 #&gt; 6: 0.04527193 183.63 # 1/2/2014--12/31/2019 ここでは, RV系列RV5に日付情報DTを加え, 関数as.xts()を使って, xtsクラスの時系列オブジェクトrv5を生成する. xtsオブジェクトにすることのメリットの一つとして, 例えば, 標準的なR関数であるplot()を適用すると, Rは見映えの良い時系列プロットを 作成する. library(xts) # 5分次リターンより計算された実現ボラティリティ (RV) rv5 &lt;- as.xts(SPYRM[, list(DT, RV5)]) * 10000 plot(rv5) 上で解説したように, まず, \\(d\\)の値を日次RV系列rv5より推定してみる. library(fracdiff) # Geweke-Porter-Hudak(83) estimate (d_gph = fdGPH(rv5)) #&gt; $d #&gt; [1] 0.2546147 #&gt; #&gt; $sd.as #&gt; [1] 0.1212817 #&gt; #&gt; $sd.reg #&gt; [1] 0.1234719 # Reisen (94) estimate (d_sperio = fdSperio(rv5)) #&gt; $d #&gt; [1] 0.2959239 #&gt; #&gt; $sd.as #&gt; [1] 0.04815862 #&gt; #&gt; $sd.reg #&gt; [1] 0.06010544 # 最尤法 (nar, nmaの指定必要) (fit_arfima &lt;- fracdiff(rv5, nar = 0, nma = 0)) #&gt; #&gt; Call: #&gt; fracdiff(x = rv5, nar = 0, nma = 0) #&gt; #&gt; Coefficients: #&gt; d #&gt; 0.3452906 #&gt; sigma[eps] = 0.7376825 #&gt; a list with components: #&gt; [1] &quot;log.likelihood&quot; &quot;n&quot; &quot;msg&quot; &quot;d&quot; #&gt; [5] &quot;ar&quot; &quot;ma&quot; &quot;covariance.dpq&quot; &quot;fnormMin&quot; #&gt; [9] &quot;sigma&quot; &quot;stderror.dpq&quot; &quot;correlation.dpq&quot; &quot;h&quot; #&gt; [13] &quot;d.tol&quot; &quot;M&quot; &quot;hessian.dpq&quot; &quot;length.w&quot; #&gt; [17] &quot;residuals&quot; &quot;fitted&quot; &quot;call&quot; # ARFIMA(1,d,1)の最尤推定 fit_arfima2 = fracdiff(rv5, nar = 1, nma = 1) summary(fit_arfima2) #&gt; #&gt; Call: #&gt; fracdiff(x = rv5, nar = 1, nma = 1) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; d 0.15971 0.01091 14.637 &lt;2e-16 *** #&gt; ar 0.74835 0.08420 8.888 &lt;2e-16 *** #&gt; ma 0.56622 0.06213 9.113 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; sigma[eps] = 0.7369145 #&gt; [d.tol = 0.0001221, M = 100, h = 1.755e-05] #&gt; Log likelihood: -1665 ==&gt; AIC = 3337.888 [4 deg.freedom] 最適なARFIMAモデルの選択および推定 パッケージforecastの関数arfima()は, 上記fracdiffの関数fracdiff()とforecastの auto.arima()を組合せて, ARFIMAモデルの自動選択&amp;パラメータ推定を実行することができる. モデル選択基準は, auto.arima()の引数icの選択肢 (“aicc”, “aic”, “bic”) から選ぶことができる (デフォルトは”aicc”). 関数arfima()はxtsオブジェクトをモデル推定する対象データセットとして 想定しない. R操作としては, 関数coredata()を先にrv5適用し, 日付情報を除いたデータの中身 (RV系列) を取り出す必要がある RV (分散表示) # RV fit_rv &lt;- forecast::arfima(coredata(rv5)) summary(fit_rv) #&gt; #&gt; Call: #&gt; forecast::arfima(y = coredata(rv5)) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; d 0.266671 0.009558 27.900 &lt; 2e-16 *** #&gt; ma.ma1 -0.063041 0.027422 -2.299 0.02151 * #&gt; ma.ma2 -0.084791 0.026271 -3.228 0.00125 ** #&gt; ma.ma3 -0.076951 0.026091 -2.949 0.00318 ** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; sigma[eps] = 0.7364955 #&gt; [d.tol = 0.0001221, M = 100, h = 1.755e-05] #&gt; Log likelihood: -1664 ==&gt; AIC = 3338.552 [5 deg.freedom] accuracy(fit_rv) #&gt; ME RMSE MAE MPE MAPE MASE #&gt; Training set -0.0007177275 0.7356355 0.2306756 -69.83532 87.93373 0.9842525 #&gt; ACF1 #&gt; Training set 0.001397451 RV (標準偏差表示) # sqrt(RV5) plot(sqrt(rv5)) fit_sqrtrv &lt;- forecast::arfima(coredata(sqrt(rv5))) summary(fit_sqrtrv) #&gt; #&gt; Call: #&gt; forecast::arfima(y = coredata(sqrt(rv5))) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; d 0.3353183 0.0009209 364.114 &lt; 2e-16 *** #&gt; ar.ar1 -0.2347200 0.0508590 -4.615 3.93e-06 *** #&gt; ar.ar2 0.6560776 0.0584624 11.222 &lt; 2e-16 *** #&gt; ma.ma1 -0.4738122 0.0668987 -7.083 1.42e-12 *** #&gt; ma.ma2 0.4597059 0.0603449 7.618 2.58e-14 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; sigma[eps] = 0.2161109 #&gt; [d.tol = 0.0001221, M = 100, h = 1.787e-06] #&gt; Log likelihood: 168.6 ==&gt; AIC = -325.1244 [6 deg.freedom] accuracy(fit_sqrtrv) #&gt; ME RMSE MAE MPE MAPE MASE #&gt; Training set -0.0004485554 0.2160546 0.136351 -9.742148 25.83164 0.9239617 #&gt; ACF1 #&gt; Training set 0.001251137 対数RV系列 # log(RV5) plot(log(rv5)) fit_lnrv &lt;- forecast::arfima(coredata(log(rv5))) summary(fit_lnrv) #&gt; #&gt; Call: #&gt; forecast::arfima(y = coredata(log(rv5))) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; d 0.422179 0.008266 51.074 &lt; 2e-16 *** #&gt; ar.ar1 0.674953 0.122455 5.512 3.55e-08 *** #&gt; ma.ma1 0.535849 0.103727 5.166 2.39e-07 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; sigma[eps] = 0.5985781 #&gt; [d.tol = 0.0001221, M = 100, h = 1.429e-05] #&gt; Log likelihood: -1355 ==&gt; AIC = 2717.863 [4 deg.freedom] accuracy(fit_rv) #&gt; ME RMSE MAE MPE MAPE MASE #&gt; Training set -0.0007177275 0.7356355 0.2306756 -69.83532 87.93373 0.9842525 #&gt; ACF1 #&gt; Training set 0.001397451 注) fracdiff()のAR/MA多項式は, \\(\\phi(z) = 1 - \\phi_1 z - \\cdots - \\phi_p z^p\\), \\(\\theta(z) = 1 - \\theta_1 z - \\cdots - \\theta_q z^q\\) であることに注意しよう. ARFIMAモデルによる外挿予測 forecastの関数arfima()による適合結果を 関数forecast()に与えることで外挿予測を行うことができる. RV (分散表示) fcast_rv &lt;- forecast(fit_rv, h = 20) autoplot(fcast_rv) RV (標準偏差表示) fcast_sqrtrv &lt;- forecast(fit_sqrtrv, h = 20) autoplot(fcast_sqrtrv) 対数RV系列 fcast_lnrv &lt;- forecast(fit_lnrv, h = 20) autoplot(fcast_lnrv) "],["バブル-生成崩壊-検出.html", "A バブル (生成・崩壊) 検出 A.1 検定法に関する最近のレビュー論文 A.2 Supreme ADF検定/SADF (PWY, 2011), Generalized supreme ADF 検定/GSADF (PSY, 2015) A.3 実証分析", " A バブル (生成・崩壊) 検出 論文多数. 一部の紹介. A.1 検定法に関する最近のレビュー論文 Skrobotov, A.(2021). Testing for Explosive Bubbles: A Review, preprint. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3779111 A.2 Supreme ADF検定/SADF (PWY, 2011), Generalized supreme ADF 検定/GSADF (PSY, 2015) Phillips, P.C.B., Wu, Y., Yu, J. (2011). Explosive behavior in the 1990s Nasdaq: when did exuber- ance escalate asset values? Int. Econ. Rev. 52 (1), 201–226. Phillips, P. C. B., Shi, S., &amp; Yu, J. (2015a). Testing for multiple bubbles: Historical episodes of exuberance and collapse in the S&amp;P 500. International Economic Review, 56(4), 1034–1078. Phillips, P. C. B., Shi, S., &amp; Yu, J. (2015b). Testing for multiple bubbles: Limit Theory for Real- Time Detectors. International Economic Review, 56(4), 1079–1134. Phillips, P. C. B., &amp; Shi, S.(2020) Real time monitoring of asset markets: Bubbles and crisis. In Hrishikesh D. Vinod and C.R. Rao (Eds.), Handbook of Statistics Volume 41 - Econometrics Using R. Rパッケージ psymonitor: https://cran.r-project.org/web/packages/psymonitor/psymonitor.pdf MultiBubbles: https://cran.r-project.org/web/packages/MultipleBubbles/MultipleBubbles.pdf exuber: https://www.dallasfed.org/~/media/documents/institute/wpapers/2020/0383.pdf https://cran.rstudio.com/web/packages/exuber/vignettes/exuber.html A.2.1 数理ファイナンス (Jarrow, Protterら) Jarrow, R., Protter P., and Shimbo, K. (2007), Asset price bubbles in complete markets, in Advances in Mathematical Finance, Birkha ̈user Boston, Cambridge, MA, 97–121. Jarrow, R., Protter P., and Shimbo, K. (2010). Asset price bubbles in incomplete markets, Math. Finance, 20, 145–185. Jarrow, R., Kchia, Y., and Protter, P. (2011). How to Detect an Asset Bubble, SIAM Journal on Financial Mathematics, 2-1, 839-865. Protter P. (2013) A Mathematical Theory of Financial Bubbles. In: Paris-Princeton Lectures on Mathematical Finance 2013. Lecture Notes in Mathematics, vol 2081. Springer, Cham. https://doi.org/10.1007/978-3-319-00413-6_1 A.2.2 経済物理学 (Sornetteら) Johansen, A., Ledoit, O., Sornette, D. (2000). Crashes as critical points, International Journal of Theoretical and Applied Finance 3, 219–255. https://arxiv.org/pdf/cond-mat/9810071.pdf Sornette, D., Woodard, R., Yan, W., and Zhou, W.X. (2013). Clarifications to Questions and Criticisms on the Johansen-Ledoit-Sornette Financial Bubble Model, Physica A, 392-19, Pages 4417-4428. https://arxiv.org/pdf/1107.3171.pdf Sornette, D. (2017) Why Stock Markets Crash: Critical Events in Complex Financial Systems, Revised ed., Princeton Science Library. ISBN-10: 0691175950 A.3 実証分析 株式市場の例 Breitung, J. and Kruse, R. (2013) ‘When bubbles burst: econometric tests based on structural breaks’, Statistical Papers, 54(4), pp. 911–930. Available at: https://doi.org/10.1007/s00362-012-0497-3. Monschang, V. and Wilfling, B. (2021) ‘Sup-ADF-style bubble-detection methods under test’, Empirical Economics, 61(1), pp. 145–172. Available at: https://doi.org/10.1007/s00181-020-01859-7. Shi, S. and Song, Y. (2014) ‘Identifying Speculative Bubbles Using an Infinite Hidden Markov Model’, Journal of Financial Econometrics, p. nbu025. Available at: https://doi.org/10.1093/jjfinec/nbu025. 暗号資産市場の例 Cross, J.L., Hou, C. and Trinh, K. (2021) ‘Returns, volatility and the cryptocurrency bubble of 2017–18’, Economic Modelling, 104, p. 105643. Available at: https://doi.org/10.1016/j.econmod.2021.105643. Yao, C.-Z. and Li, H.-Y. (2021) ‘A study on the bursting point of Bitcoin based on the BSADF and LPPLS methods’, The North American Journal of Economics and Finance, 55, p. 101280. Available at: https://doi.org/10.1016/j.najef.2020.101280. "],["長期記憶過程-1.html", "B 長期記憶過程 B.1 理論・概説 B.2 株式市場 B.3 外国為替市場 B.4 コモディティ・暗号資産 B.5 VIX B.6 高頻度データ (ボラティリティ, 注文フロー等) B.7 長期記憶性の発生要因, 非長期記憶モデルによる近似", " B 長期記憶過程 ダウンロード可能なものを中心に紹介します (ワーキングペーパー含む). 文献多数あり, 重要なものをカバーしている訳ではありません. ここにないものについては, 電子ジャーナル等を通じて適宜入手してください B.1 理論・概説 Gennady Samorodnitsky (2006). Long Range Dependence. Foundations and Trends in Stochastic Systems, 1(3), 163–257. https://people.orie.cornell.edu/gennady/techreports/LRD-NOW.pdf https://pdfs.semanticscholar.org/f182/3f5bcc8524d73af14ba3e29e7bbdcc50545e.pdf Rama Cont (2005). Long range dependence in financial markets, In: Lévy-Véhel J., Lutton E. (eds) Fractals in Engineering. Springer, London. https://doi.org/10.1007/1-84628-048-6_11 https://www.researchgate.net/publication/226697823_Long_range_dependence_in_financial_market Thomas Mikosch and Ca ̆ta ̆lin Sta ̆rica ̆ (2004). Nonstationarities in Financial Time Series, the Long-range Dependence, and the IGARCH Effects. The Review of Economics and Statistics, 86(1), 378–390. https://gec.cr.usgs.gov/outgoing/threshold_articles/Mikosch_Starica2004.pdf Richard T. Baillie (1996). Long memory processes and fractional integration in econometrics, Journal of Econometrics, 73, 5-59. http://long-memory.com/Baillie1996.pdf B.2 株式市場 Andrew W. Lo (1991). Long term memory in stock market prices, Econometrica 59 1279–313. https://www.nber.org/system/files/working_papers/w2984/w2984.pdf Walter Willinger, Murad S. Taqqu, Vadim Teverovsky (1999). Stock market prices and long-range dependence, Finance &amp; Stochastics, 3, 1–13. http://www.long-memory.com/returns/WillingerTaqquTeverovsky1999.pdf B.3 外国為替市場 Yin-Wong Cheung (1993). Long Memory in Foreign-Exchange Rates, Journal of Business &amp; Economic Statistics, 11(1), 93-101, DOI: 10.1080/07350015.1993.10509935. https://people.ucsc.edu/~cheung/JBES/LongMemoryFX_JBES1993.pdf Richard T. Baillie and Tim Bollerslev(1994). The long memory of the forward premium, Journal of International Money and Finance, 13(5), 565-571. https://dukespace.lib.duke.edu/dspace/bitstream/handle/10161/1965/Bollerslev_the_long_memory.pdf?sequence=1 Dominique M. Guillaume, Michel M. Dacorogna, Rakhal R. Davé, Ulrich A. Müller, Richard B. Olsen &amp; Olivier V. Pictet (1997). From the bird’s eye to the microscope: A survey of new stylized facts of the intra-daily foreign exchange markets. Finance and Stochastics, 1, pages95–129. https://link.springer.com/article/10.1007%2Fs007800050018 B.4 コモディティ・暗号資産 Mohamed El Hedi Arouri, Shawkat Hammoudeh, Amine Lahiani, Duc Khuong Nguyen(2012). Long memory and structural breaks in modeling the return and volatility dynamics of precious metals, The Quarterly Review of Economics and Finance, 52-2, 207-218. https://hal.archives-ouvertes.fr/file/index/docid/798033/filename/Arouri_et_al_QREF_R3-1.pdf Guglielmo Maria Caporale, Luis Gil-Alana, Alex Plastun (2018), Persistence in the cryptocurrency market, Research in International Business and Finance, 46, pp. 141-148. https://www.sciencedirect.com/science/article/pii/S0275531917309200 B.5 VIX Guglielmo Maria Caporale, Luis Gil-Alana, Alex Plastun (2018). Is market fear persistent? A long-memory analysis. Finance Research Letters, 27, 140-147. https://doi.org/10.1016/j.frl.2018.02.007. https://www.sciencedirect.com/science/article/pii/S1544612317303793 B.6 高頻度データ (ボラティリティ, 注文フロー等) Lillo, F. and Farmer, J. D. (2004). The Long Memory of the Efficient Market, Studies in Nonlinear Dynamics &amp; Econometrics, 8(3). doi: https://doi.org/10.2202/1558-3708.1226 https://arxiv.org/pdf/cond-mat/0311053 Torben G Andersen and Tim Bollerslev (1997), Heterogeneous Information Arrivals and Return Volatility Dynamics: Uncovering the Long‐Run in High Frequency Returns. The Journal of Finance, 52, 975-1005. https://doi.org/10.1111/j.1540-6261.1997.tb02722.x https://www.nber.org/system/files/working_papers/w5752/w5752.pdf Torben G Andersen, Tim Bollerslev, Francis X Diebold &amp; Paul Labys (2001). The Distribution of Realized Exchange Rate Volatility, Journal of the American Statistical Association, 96, 42-55. https://www.nber.org/system/files/working_papers/w6961/w6961.pdf B.7 長期記憶性の発生要因, 非長期記憶モデルによる近似 Chevillon, G. and Mavroeidis, S. (2018) ‘Perpetual learning and apparent long memory’, Journal of Economic Dynamics and Control, 90, pp. 343–365. Available at: https://doi.org/10.1016/j.jedc.2018.03.012. Corsi, F. (2004) ‘A Simple Long Memory Model of Realized Volatility’, SSRN Electronic Journal [Preprint]. Available at: https://doi.org/10.2139/ssrn.626064. Corsi, F., Audrino, F. and Renò, R. (2012) ‘HAR Modeling for Realized Volatility Forecasting’, in L. Bauwens, C. Hafner, and S. Laurent (eds) Handbook of Volatility Models and Their Applications. 1st edn. Wiley, pp. 363–382. Available at: https://doi.org/10.1002/9781118272039.ch15. Granger, C.W.J. (1980) ‘LONG MEMORY RELATIONSHIPS AND THE AGGREGATION OF DYNAMIC MODELS’, Journal of Econometrics, 14(2), pp. 227–238. Available at: https://www.sciencedirect.com/science/article/pii/0304407680900925. Granger, C.W.J. and Hyung, N. (2004) ‘Occasional structural breaks and long memory with an application to the S&amp;P 500 absolute stock returns’, Journal of Empirical Finance, 11(3), pp. 399–421. Available at: https://doi.org/10.1016/j.jempfin.2003.03.001. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
